{"config":{"lang":["en"],"prebuild_index":false,"separator":"[\\s\\-]+"},"docs":[{"location":"","text":"Material for MkDocs \u00b6 Create beautiful project documentation \u00b6 Material is a theme for MkDocs , an excellent static site generator geared towards project documentation. It is built using Google's Material Design guidelines. Quick start \u00b6 Install the latest version of Material with pip : pip install mkdocs-material Append the following line to your project's mkdocs.yml : theme : name : 'material' What to expect \u00b6 Responsive design and fluid layout for all kinds of screens and devices, designed to serve your project documentation in a user-friendly way in 41 languages with optimal readability. Easily customizable primary and accent color, fonts, favicon and logo; straight forward localization through theme extension; integrated with Google Analytics, Disqus and GitHub. Well-designed search interface accessible through hotkeys ( F or S ), intelligent grouping of search results, search term highlighting and lazy loading. For detailed instructions see the getting started guide .","title":"Material <small>for MkDocs</small>"},{"location":"#material-for-mkdocs","text":"","title":"Material for MkDocs"},{"location":"#create-beautiful-project-documentation","text":"Material is a theme for MkDocs , an excellent static site generator geared towards project documentation. It is built using Google's Material Design guidelines.","title":"Create beautiful project documentation"},{"location":"#quick-start","text":"Install the latest version of Material with pip : pip install mkdocs-material Append the following line to your project's mkdocs.yml : theme : name : 'material'","title":"Quick start"},{"location":"#what-to-expect","text":"Responsive design and fluid layout for all kinds of screens and devices, designed to serve your project documentation in a user-friendly way in 41 languages with optimal readability. Easily customizable primary and accent color, fonts, favicon and logo; straight forward localization through theme extension; integrated with Google Analytics, Disqus and GitHub. Well-designed search interface accessible through hotkeys ( F or S ), intelligent grouping of search results, search term highlighting and lazy loading. For detailed instructions see the getting started guide .","title":"What to expect"},{"location":"authors-notes/","text":"Author's notes \u00b6 Hi, I'm Martin ( @squidfunk ) \u00b6 I'm a freelance polyglot software engineer and entrepreneur from Cologne, Germany with more than 13 years of experience in full-stack web development and system programming. I'm currently working full time on an exciting new venture, an analytical browser engine called Ginseng . Why another theme? \u00b6 Some time ago I wanted to release a project to the open, but it was in need of user documentation. I checked out the available tools and stuck with MkDocs, because it was so simple and easy to use. However, none of the available themes convinced me. I wanted to build something that was usable on all screen sizes from the ground up, something beautiful and practical at the same time. Google's Material Design appeared to be the perfect fit and this something became Material, a Material Design theme for MkDocs.","title":"Author's notes"},{"location":"authors-notes/#authors-notes","text":"","title":"Author's notes"},{"location":"authors-notes/#hi-im-martin-squidfunk","text":"I'm a freelance polyglot software engineer and entrepreneur from Cologne, Germany with more than 13 years of experience in full-stack web development and system programming. I'm currently working full time on an exciting new venture, an analytical browser engine called Ginseng .","title":"Hi, I'm Martin (@squidfunk)"},{"location":"authors-notes/#why-another-theme","text":"Some time ago I wanted to release a project to the open, but it was in need of user documentation. I checked out the available tools and stuck with MkDocs, because it was so simple and easy to use. However, none of the available themes convinced me. I wanted to build something that was usable on all screen sizes from the ground up, something beautiful and practical at the same time. Google's Material Design appeared to be the perfect fit and this something became Material, a Material Design theme for MkDocs.","title":"Why another theme?"},{"location":"compliance/","text":"Compliance with GDPR \u00b6 Material does not process any personal data \u00b6 Material is a theme for MkDocs, a static site generator. In itself, Material does not perform any tracking or processing of personal data. However, some of the third-party services that Material integrates with may actually be in breach with the General Data Protection Regulation (GDPR) and need to be evaluated carefully. Third-party services \u00b6 Google Fonts \u00b6 Material makes fonts easily configurable by relying on Google Fonts CDN. However, embedding fonts from Google is currently within a gray area as there's no official statement or ruling regarding GDPR compliance and the topic is still actively discussed . For this reason, if you need to ensure GDPR compliance, you should disable the usage of the Google Font CDN with: theme : font : false When Google Fonts are disabled, Material will default to Helvetica Neue and Monaco with their corresponding fall backs, relying on system fonts. You could however include your own, self-hosted webfont by overriding the fonts block. The icon fonts (Material and FontAwesome) are bundled with the theme, and thus self-hosted so there's no third-party involved. Google Analytics and Disqus \u00b6 Material comes with Google Analytics and Disqus integrations that need to be enabled explicitly . Disable both integrations in order to be in compliance with the GDPR.","title":"Compliance with GDPR"},{"location":"compliance/#compliance-with-gdpr","text":"","title":"Compliance with GDPR"},{"location":"compliance/#material-does-not-process-any-personal-data","text":"Material is a theme for MkDocs, a static site generator. In itself, Material does not perform any tracking or processing of personal data. However, some of the third-party services that Material integrates with may actually be in breach with the General Data Protection Regulation (GDPR) and need to be evaluated carefully.","title":"Material does not process any personal data"},{"location":"compliance/#third-party-services","text":"","title":"Third-party services"},{"location":"compliance/#google-fonts","text":"Material makes fonts easily configurable by relying on Google Fonts CDN. However, embedding fonts from Google is currently within a gray area as there's no official statement or ruling regarding GDPR compliance and the topic is still actively discussed . For this reason, if you need to ensure GDPR compliance, you should disable the usage of the Google Font CDN with: theme : font : false When Google Fonts are disabled, Material will default to Helvetica Neue and Monaco with their corresponding fall backs, relying on system fonts. You could however include your own, self-hosted webfont by overriding the fonts block. The icon fonts (Material and FontAwesome) are bundled with the theme, and thus self-hosted so there's no third-party involved.","title":"Google Fonts"},{"location":"compliance/#google-analytics-and-disqus","text":"Material comes with Google Analytics and Disqus integrations that need to be enabled explicitly . Disable both integrations in order to be in compliance with the GDPR.","title":"Google Analytics and Disqus"},{"location":"contributing/","text":"Contributing \u00b6 Interested in contributing to the Material theme? Want to report a bug? Before you do, please read the following guidelines. Submission context \u00b6 Got a question or problem? \u00b6 For quick questions there's no need to open an issue as you can reach us on gitter.im . Found a bug? \u00b6 If you found a bug in the source code, you can help us by submitting an issue to the issue tracker in our GitHub repository. Even better, you can submit a Pull Request with a fix. However, before doing so, please read the submission guidelines . Missing a feature? \u00b6 You can request a new feature by submitting an issue to our GitHub Repository. If you would like to implement a new feature, please submit an issue with a proposal for your work first, to be sure that it is of use for everyone, as the Material theme is highly opinionated. Please consider what kind of change it is: For a major feature , first open an issue and outline your proposal so that it can be discussed. This will also allow us to better coordinate our efforts, prevent duplication of work, and help you to craft the change so that it is successfully accepted into the project. Small features and bugs can be crafted and directly submitted as a Pull Request. However, there is no guarantee that your feature will make it into the master, as it's always a matter of opinion whether if benefits the overall functionality of the theme. Submission guidelines \u00b6 Submitting an issue \u00b6 Before you submit an issue, please search the issue tracker, maybe an issue for your problem already exists and the discussion might inform you of workarounds readily available. We want to fix all the issues as soon as possible, but before fixing a bug we need to reproduce and confirm it. In order to reproduce bugs we will systematically ask you to provide a minimal reproduction scenario using the custom issue template. Please stick to the issue template. Unfortunately we are not able to investigate / fix bugs without a minimal reproduction scenario, so if we don't hear back from you we may close the issue. Submitting a Pull Request (PR) \u00b6 Search GitHub for an open or closed PR that relates to your submission. You don't want to duplicate effort. If you do not find a related issue or PR, go ahead. Development : Fork the project, set up the development environment , make your changes in a separate git branch and add descriptive messages to your commits. Build : Before submitting a pull requests, build the theme . This is a mandatory requirement for your PR to get accepted, as the theme should at all times be installable through GitHub. Pull Request : After building the theme, commit the compiled output, push your branch to GitHub and send a PR to mkdocs-material:master . If we suggest changes, make the required updates, rebase your branch and push the changes to your GitHub repository, which will automatically update your PR. After your PR is merged, you can safely delete your branch and pull the changes from the main (upstream) repository.","title":"Contributing"},{"location":"contributing/#contributing","text":"Interested in contributing to the Material theme? Want to report a bug? Before you do, please read the following guidelines.","title":"Contributing"},{"location":"contributing/#submission-context","text":"","title":"Submission context"},{"location":"contributing/#got-a-question-or-problem","text":"For quick questions there's no need to open an issue as you can reach us on gitter.im .","title":"Got a question or problem?"},{"location":"contributing/#found-a-bug","text":"If you found a bug in the source code, you can help us by submitting an issue to the issue tracker in our GitHub repository. Even better, you can submit a Pull Request with a fix. However, before doing so, please read the submission guidelines .","title":"Found a bug?"},{"location":"contributing/#missing-a-feature","text":"You can request a new feature by submitting an issue to our GitHub Repository. If you would like to implement a new feature, please submit an issue with a proposal for your work first, to be sure that it is of use for everyone, as the Material theme is highly opinionated. Please consider what kind of change it is: For a major feature , first open an issue and outline your proposal so that it can be discussed. This will also allow us to better coordinate our efforts, prevent duplication of work, and help you to craft the change so that it is successfully accepted into the project. Small features and bugs can be crafted and directly submitted as a Pull Request. However, there is no guarantee that your feature will make it into the master, as it's always a matter of opinion whether if benefits the overall functionality of the theme.","title":"Missing a feature?"},{"location":"contributing/#submission-guidelines","text":"","title":"Submission guidelines"},{"location":"contributing/#submitting-an-issue","text":"Before you submit an issue, please search the issue tracker, maybe an issue for your problem already exists and the discussion might inform you of workarounds readily available. We want to fix all the issues as soon as possible, but before fixing a bug we need to reproduce and confirm it. In order to reproduce bugs we will systematically ask you to provide a minimal reproduction scenario using the custom issue template. Please stick to the issue template. Unfortunately we are not able to investigate / fix bugs without a minimal reproduction scenario, so if we don't hear back from you we may close the issue.","title":"Submitting an issue"},{"location":"contributing/#submitting-a-pull-request-pr","text":"Search GitHub for an open or closed PR that relates to your submission. You don't want to duplicate effort. If you do not find a related issue or PR, go ahead. Development : Fork the project, set up the development environment , make your changes in a separate git branch and add descriptive messages to your commits. Build : Before submitting a pull requests, build the theme . This is a mandatory requirement for your PR to get accepted, as the theme should at all times be installable through GitHub. Pull Request : After building the theme, commit the compiled output, push your branch to GitHub and send a PR to mkdocs-material:master . If we suggest changes, make the required updates, rebase your branch and push the changes to your GitHub repository, which will automatically update your PR. After your PR is merged, you can safely delete your branch and pull the changes from the main (upstream) repository.","title":"Submitting a Pull Request (PR)"},{"location":"customization/","text":"Customization \u00b6 A great starting point \u00b6 Project documentation is as diverse as the projects themselves and the Material theme is a good starting point for making it look great. However, as you write your documentation, you may reach a point where some small adjustments are necessary to preserve the desired style. Adding assets \u00b6 MkDocs provides several ways to interfere with themes. In order to make a few tweaks to an existing theme, you can just add your stylesheets and JavaScript files to the docs directory. Additional stylesheets \u00b6 If you want to tweak some colors or change the spacing of certain elements, you can do this in a separate stylesheet. The easiest way is by creating a new stylesheet file in your docs directory: mkdir docs/stylesheets touch docs/stylesheets/extra.css Then, add the following line to your mkdocs.yml : extra_css : - 'stylesheets/extra.css' Spin up the development server with mkdocs serve and start typing your changes in your additional stylesheet file \u2013 you can see them instantly after saving, as the MkDocs development server implements live reloading. Additional JavaScript \u00b6 The same is true for additional JavaScript. If you want to integrate another syntax highlighter or add some custom logic to your theme, create a new JavaScript file in your docs directory: mkdir docs/javascripts touch docs/javascripts/extra.js Then, add the following line to your mkdocs.yml : extra_javascript : - 'javascripts/extra.js' Further assistance can be found in the MkDocs documentation . Extending the theme \u00b6 If you want to alter the HTML source (e.g. add or remove some part), you can extend the theme. From version 0.16 on MkDocs implements theme extension , an easy way to override parts of a theme without forking and changing the main theme. Setup and theme structure \u00b6 Reference the Material theme as usual in your mkdocs.yml , and create a new folder for overrides, e.g. theme , which you reference using custom_dir : theme : name : 'material' custom_dir : 'theme' Theme extension prerequisites As the custom_dir variable is used for the theme extension process, the Material theme needs to be installed via pip and referenced with the name parameter in your mkdocs.yml . The structure in the theme directory must mirror the directory structure of the original theme, as any file in the theme directory will replace the file with the same name which is part of the original theme. Besides, further assets may also be put in the theme directory. The directory layout of the Material theme is as follows: . \u251c\u2500 assets/ \u2502 \u251c\u2500 images/ # Images and icons \u2502 \u251c\u2500 javascripts/ # JavaScript \u2502 \u2514\u2500 stylesheets/ # Stylesheets \u251c\u2500 partials/ \u2502 \u251c\u2500 integrations/ # 3rd-party integrations \u2502 \u251c\u2500 language/ # Localized languages \u2502 \u251c\u2500 footer.html # Footer bar \u2502 \u251c\u2500 header.html # Header bar \u2502 \u251c\u2500 hero.html # Hero teaser \u2502 \u251c\u2500 language.html # Localized labels \u2502 \u251c\u2500 nav-item.html # Main navigation item \u2502 \u251c\u2500 nav.html # Main navigation \u2502 \u251c\u2500 search.html # Search box \u2502 \u251c\u2500 social.html # Social links \u2502 \u251c\u2500 source.html # Repository information \u2502 \u251c\u2500 tabs-item.html # Tabs navigation item \u2502 \u251c\u2500 tabs.html # Tabs navigation \u2502 \u251c\u2500 toc-item.html # Table of contents item \u2502 \u2514\u2500 toc.html # Table of contents \u251c\u2500 404 .html # 404 error page \u251c\u2500 base.html # Base template \u2514\u2500 main.html # Default page Overriding partials \u00b6 In order to override the footer, we can replace the footer.html partial with our own partial. To do this, create the file partials/footer.html in the theme directory. MkDocs will now use the new partial when rendering the theme. This can be done with any file. Overriding template blocks \u00b6 Besides overriding partials, one can also override so called template blocks, which are defined inside the Material theme and wrap specific features. To override a template block, create a main.html inside the theme directory and define the block, e.g.: {% extends \"base.html\" %} {% block htmltitle %} <title>Lorem ipsum dolor sit amet</title> {% endblock %} The Material theme provides the following template blocks: Block name Wrapped contents analytics Wraps the Google Analytics integration content Wraps the main content disqus Wraps the disqus integration extrahead Empty block to define additional meta tags fonts Wraps the webfont definitions footer Wraps the footer with navigation and copyright header Wraps the fixed header bar hero Wraps the hero teaser htmltitle Wraps the <title> tag libs Wraps the JavaScript libraries, e.g. Modernizr scripts Wraps the JavaScript application logic source Wraps the linked source files site_meta Wraps the meta tags in the document head site_nav Wraps the site navigation and table of contents styles Wraps the stylesheets (also extra sources) For more on this topic refer to the MkDocs documentation Theme development \u00b6 The Material theme uses Webpack as a build tool to leverage modern web technologies like Babel and SASS . If you want to make more fundamental changes, it may be necessary to make the adjustments directly in the source of the Material theme and recompile it. This is fairly easy. Environment setup \u00b6 In order to start development on the Material theme, a Node.js version of at least 8 is required. First, clone the repository: git clone https://github.com/squidfunk/mkdocs-material Next, all dependencies need to be installed, which is done with: cd mkdocs-material pip install -r requirements.txt npm install If you're on Windows, you may also need to install GNU Make Development mode \u00b6 The development server can be started with: npm run watch This will also start the MkDocs development server which will monitor changes on assets, templates and documentation. Point your browser to localhost:8000 and you should see this documentation in front of you. For example, changing the color palette is as simple as changing the $md-color-primary and $md-color-accent variables in src/assets/stylesheets/_config.scss : $ md-color-primary : $ clr-red-400 ; $ md-color-accent : $ clr-teal-a700 ; Automatically generated files Never make any changes in the material directory, as the contents of this directory are automatically generated from the src directory and will be overridden when the theme is built. Build process \u00b6 When you've finished making your changes, you can build the theme by invoking: npm run build This triggers the production-level compilation and minification of all stylesheets and JavaScript sources. When the command exits, the final theme is located in the material directory. Add the theme_dir variable pointing to the aforementioned directory in your original mkdocs.yml . Now you can run mkdocs build and you should see your documentation with your changes to the original Material theme.","title":"Customization"},{"location":"customization/#customization","text":"","title":"Customization"},{"location":"customization/#a-great-starting-point","text":"Project documentation is as diverse as the projects themselves and the Material theme is a good starting point for making it look great. However, as you write your documentation, you may reach a point where some small adjustments are necessary to preserve the desired style.","title":"A great starting point"},{"location":"customization/#adding-assets","text":"MkDocs provides several ways to interfere with themes. In order to make a few tweaks to an existing theme, you can just add your stylesheets and JavaScript files to the docs directory.","title":"Adding assets"},{"location":"customization/#additional-stylesheets","text":"If you want to tweak some colors or change the spacing of certain elements, you can do this in a separate stylesheet. The easiest way is by creating a new stylesheet file in your docs directory: mkdir docs/stylesheets touch docs/stylesheets/extra.css Then, add the following line to your mkdocs.yml : extra_css : - 'stylesheets/extra.css' Spin up the development server with mkdocs serve and start typing your changes in your additional stylesheet file \u2013 you can see them instantly after saving, as the MkDocs development server implements live reloading.","title":"Additional stylesheets"},{"location":"customization/#additional-javascript","text":"The same is true for additional JavaScript. If you want to integrate another syntax highlighter or add some custom logic to your theme, create a new JavaScript file in your docs directory: mkdir docs/javascripts touch docs/javascripts/extra.js Then, add the following line to your mkdocs.yml : extra_javascript : - 'javascripts/extra.js' Further assistance can be found in the MkDocs documentation .","title":"Additional JavaScript"},{"location":"customization/#extending-the-theme","text":"If you want to alter the HTML source (e.g. add or remove some part), you can extend the theme. From version 0.16 on MkDocs implements theme extension , an easy way to override parts of a theme without forking and changing the main theme.","title":"Extending the theme"},{"location":"customization/#setup-and-theme-structure","text":"Reference the Material theme as usual in your mkdocs.yml , and create a new folder for overrides, e.g. theme , which you reference using custom_dir : theme : name : 'material' custom_dir : 'theme' Theme extension prerequisites As the custom_dir variable is used for the theme extension process, the Material theme needs to be installed via pip and referenced with the name parameter in your mkdocs.yml . The structure in the theme directory must mirror the directory structure of the original theme, as any file in the theme directory will replace the file with the same name which is part of the original theme. Besides, further assets may also be put in the theme directory. The directory layout of the Material theme is as follows: . \u251c\u2500 assets/ \u2502 \u251c\u2500 images/ # Images and icons \u2502 \u251c\u2500 javascripts/ # JavaScript \u2502 \u2514\u2500 stylesheets/ # Stylesheets \u251c\u2500 partials/ \u2502 \u251c\u2500 integrations/ # 3rd-party integrations \u2502 \u251c\u2500 language/ # Localized languages \u2502 \u251c\u2500 footer.html # Footer bar \u2502 \u251c\u2500 header.html # Header bar \u2502 \u251c\u2500 hero.html # Hero teaser \u2502 \u251c\u2500 language.html # Localized labels \u2502 \u251c\u2500 nav-item.html # Main navigation item \u2502 \u251c\u2500 nav.html # Main navigation \u2502 \u251c\u2500 search.html # Search box \u2502 \u251c\u2500 social.html # Social links \u2502 \u251c\u2500 source.html # Repository information \u2502 \u251c\u2500 tabs-item.html # Tabs navigation item \u2502 \u251c\u2500 tabs.html # Tabs navigation \u2502 \u251c\u2500 toc-item.html # Table of contents item \u2502 \u2514\u2500 toc.html # Table of contents \u251c\u2500 404 .html # 404 error page \u251c\u2500 base.html # Base template \u2514\u2500 main.html # Default page","title":"Setup and theme structure"},{"location":"customization/#overriding-partials","text":"In order to override the footer, we can replace the footer.html partial with our own partial. To do this, create the file partials/footer.html in the theme directory. MkDocs will now use the new partial when rendering the theme. This can be done with any file.","title":"Overriding partials"},{"location":"customization/#overriding-template-blocks","text":"Besides overriding partials, one can also override so called template blocks, which are defined inside the Material theme and wrap specific features. To override a template block, create a main.html inside the theme directory and define the block, e.g.: {% extends \"base.html\" %} {% block htmltitle %} <title>Lorem ipsum dolor sit amet</title> {% endblock %} The Material theme provides the following template blocks: Block name Wrapped contents analytics Wraps the Google Analytics integration content Wraps the main content disqus Wraps the disqus integration extrahead Empty block to define additional meta tags fonts Wraps the webfont definitions footer Wraps the footer with navigation and copyright header Wraps the fixed header bar hero Wraps the hero teaser htmltitle Wraps the <title> tag libs Wraps the JavaScript libraries, e.g. Modernizr scripts Wraps the JavaScript application logic source Wraps the linked source files site_meta Wraps the meta tags in the document head site_nav Wraps the site navigation and table of contents styles Wraps the stylesheets (also extra sources) For more on this topic refer to the MkDocs documentation","title":"Overriding template blocks"},{"location":"customization/#theme-development","text":"The Material theme uses Webpack as a build tool to leverage modern web technologies like Babel and SASS . If you want to make more fundamental changes, it may be necessary to make the adjustments directly in the source of the Material theme and recompile it. This is fairly easy.","title":"Theme development"},{"location":"customization/#environment-setup","text":"In order to start development on the Material theme, a Node.js version of at least 8 is required. First, clone the repository: git clone https://github.com/squidfunk/mkdocs-material Next, all dependencies need to be installed, which is done with: cd mkdocs-material pip install -r requirements.txt npm install If you're on Windows, you may also need to install GNU Make","title":"Environment setup"},{"location":"customization/#development-mode","text":"The development server can be started with: npm run watch This will also start the MkDocs development server which will monitor changes on assets, templates and documentation. Point your browser to localhost:8000 and you should see this documentation in front of you. For example, changing the color palette is as simple as changing the $md-color-primary and $md-color-accent variables in src/assets/stylesheets/_config.scss : $ md-color-primary : $ clr-red-400 ; $ md-color-accent : $ clr-teal-a700 ; Automatically generated files Never make any changes in the material directory, as the contents of this directory are automatically generated from the src directory and will be overridden when the theme is built.","title":"Development mode"},{"location":"customization/#build-process","text":"When you've finished making your changes, you can build the theme by invoking: npm run build This triggers the production-level compilation and minification of all stylesheets and JavaScript sources. When the command exits, the final theme is located in the material directory. Add the theme_dir variable pointing to the aforementioned directory in your original mkdocs.yml . Now you can run mkdocs build and you should see your documentation with your changes to the original Material theme.","title":"Build process"},{"location":"getting-started/","text":"Getting started \u00b6 Installation \u00b6 Installing MkDocs \u00b6 Before installing MkDocs , you need to make sure you have Python and pip \u2013 the Python package manager \u2013 up and running. You can verify if you're already good to go with the following commands: python --version # Python 3.8.0 pip --version # pip 19.3.1 Installing and verifying MkDocs is as simple as: pip install mkdocs && mkdocs --version # mkdocs, version 1.0.4 Material requires MkDocs >= 1.0.0. Installing Material \u00b6 using pip \u00b6 Material can be installed with pip : pip install mkdocs-material using choco \u00b6 If you're on Windows you can use Chocolatey to install Material : choco install mkdocs-material This will install all required dependencies like Python and MkDocs . cloning from GitHub \u00b6 Material can also be used without a system-wide installation by cloning the repository into a subfolder of your project's root directory: git clone https://github.com/squidfunk/mkdocs-material.git This is especially useful if you want to extend the theme and override some parts of the theme. The theme will reside in the folder mkdocs-material/material . Troubleshooting \u00b6 Installation on macOS When you're running the pre-installed version of Python on macOS, pip tries to install packages in a folder for which your user might not have the adequate permissions. There are two possible solutions for this: Installing in user space (recommended): Provide the --user flag to the install command and pip will install the package in a user-site location. This is the recommended way. Switching to a homebrewed Python : Upgrade your Python installation to a self-contained solution by installing Python with Homebrew. This should eliminate a lot of problems you may be having with pip . Error: unrecognized theme 'material' If you run into this error, the most common reason is that you installed MkDocs through some package manager (e.g. Homebrew or apt-get ) and the Material theme through pip , so both packages end up in different locations. MkDocs only checks its install location for themes. Alternative: Using Docker \u00b6 If you're familiar with Docker, the official Docker image for Material comes with all dependencies pre-installed and ready-to-use with the latest version published on PyPI, packaged in a very small image. Pull it with: docker pull squidfunk/mkdocs-material The mkdocs executable is provided as an entrypoint, serve is the default command. Start the development server in your project root with: docker run --rm -it -p 8000:8000 -v ${PWD}:/docs squidfunk/mkdocs-material If you're using Windows command prompt ( cmd.exe ), substitute ${PWD} with \"%cd%\" . Usage \u00b6 In order to enable the theme just add one of the following lines to your project's mkdocs.yml . If you installed Material using a package manager: theme : name : 'material' If you cloned Material from GitHub: theme : name : null custom_dir : 'mkdocs-material/material' MkDocs includes a development server, so you can review your changes as you go. The development server can be started with the following command: mkdocs serve Now you can point your browser to http://localhost:8000 and the Material theme should be visible. From here on, you can start writing your documentation, or read on and customize the theme. Configuration \u00b6 Color palette \u00b6 A default hue is defined for every primary and accent color on Google's Material Design color palette , which makes it very easy to change the overall look of the theme. Just set the primary and accent colors using the following variables: theme : palette : primary : 'indigo' accent : 'indigo' Color names are case-insensitive, but must match the names of the Material Design color palette. Valid values are: red , pink , purple , deep purple , indigo , blue , light blue , cyan , teal , green , light green , lime , yellow , amber , orange , deep orange , brown , grey , blue grey and white . The last four colors can only be used as a primary color. If the color is set via this configuration, an additional CSS file that defines the color palette is automatically included. If you want to keep things lean, clone the repository and recompile the theme with your custom colors set. See the guide on customization for more information. Primary colors \u00b6 Default: indigo Click on a tile to change the primary color of the theme: Red Pink Purple Deep Purple Indigo Blue Light Blue Cyan Teal Green Light Green Lime Yellow Amber Orange Deep Orange Brown Grey Blue Grey Black White var buttons = document.querySelectorAll(\"button[data-md-color-primary]\"); Array.prototype.forEach.call(buttons, function(button) { button.addEventListener(\"click\", function() { document.body.dataset.mdColorPrimary = this.dataset.mdColorPrimary; }) }) Accent colors \u00b6 Default: indigo Click on a tile to change the accent color of the theme: Red Pink Purple Deep Purple Indigo Blue Light Blue Cyan Teal Green Light Green Lime Yellow Amber Orange Deep Orange var buttons = document.querySelectorAll(\"button[data-md-color-accent]\"); Array.prototype.forEach.call(buttons, function(button) { button.addEventListener(\"click\", function() { document.body.dataset.mdColorAccent = this.dataset.mdColorAccent; }) }) Font family \u00b6 Default: Roboto and Roboto Mono By default the Roboto font family is included with the theme, specifically the regular sans-serif type for text and the monospaced type for code. Both fonts are loaded from Google Fonts and can be changed to other fonts, like for example the Ubuntu font family : theme : font : text : 'Ubuntu' code : 'Ubuntu Mono' The text font will be loaded in weights 400 and 700 , the monospaced font in regular weight. If you want to load fonts from other destinations or don't want to use the Google Fonts loading magic, just set font to false : theme : font : false Logo \u00b6 Default icon: school Your logo should have rectangular shape with a minimum resolution of 128x128, leave some room towards the edges and be composed of high contrast areas on a transparent ground, as it will be placed on the colored header bar and drawer. Simply create the folder docs/images , add your logo and embed it with: theme : logo : 'images/logo.svg' Additionally, the default icon can be changed by setting an arbitrary ligature (or Unicode code point) from the Material Design icon font , e.g. theme : logo : icon : 'cloud' Language \u00b6 Call for Contributions: Add languages/translations to Material Help translate Material into more languages - it's just one click and takes approximately 2 minutes : click here Localization \u00b6 Default: en Material for MkDocs supports internationalization (i18n) and provides translations for all template variables and labels in the following languages: Available languages af / Afrikaans ar / Arabic ca / Catalan cs / Czech da / Danish nl / Dutch en / English et / Estonian fi / Finnish fr / French gl / Galician de / German gr / Greek he / Hebrew hi / Hindi hr / Croatian hu / Hungarian id / Indonesian it / Italian ja / Japanese kr / Korean no / Norwegian nn / Norwegian (Nynorsk) fa / Persian pl / Polish pt / Portugese ro / Romanian ru / Russian sr / Serbian sh / Serbo-Croatian sk / Slovak si / Slovenian es / Spanish sv / Swedish th / Thai tr / Turkish uk / Ukrainian vi / Vietnamese zh / Chinese (Simplified) zh-Hant / Chinese (Traditional) zh-TW / Chinese (Taiwanese) Submit a new language Specify the language with: theme : language : 'en' If the language is not specified, Material falls back to English. To create a translation for another language, copy the localization file of an existing language, name the new file using the 2-letter language code and adjust all translations: cp partials/language/en.html partials/language/jp.html Text direction \u00b6 Default: best match for given theme language, automatically set Material supports both, left-to-right ( ltr ) and right-to-left ( rtl ) text direction. This enables more languages like Arabic, Hebrew, Syriac and others to be used with the theme: theme : direction : 'rtl' Site search \u00b6 Default: best match for given theme language, automatically set Site search is implemented using lunr.js , which includes stemmers for the English language by default, while stemmers for other languages are included with lunr-languages , both of which are integrated with this theme. Material selects the matching (or best-matching) stemmer for the given theme language. Multilingual search can be activated in your project's mkdocs.yml by explicitly defining the search language(s): extra : search : language : 'en, de, ru' At the time of writing, the following languages are supported: Available language stemmers da / Danish du / Dutch en / English fi / Finnish fr / French de / German hu / Hungarian it / Italian ja / Japanese no / Norwegian pt / Portugese ro / Romanian ru / Russian es / Spanish sv / Swedish tr / Turkish MkDocs 1.0 compatibility While MkDocs 1.0 supports prebuilding the search index, Material currently doesn't support this setting as the default search behavior of the original theme was heavily modified for the sake of a better UX. Integration is possible, but a small subset of the features Material provides will not be portable to the prebuilt index mainly due to missing localization. Only specify the languages you really need Be aware that including support for other languages increases the general JavaScript payload by around 20kb (without gzip) and by another 15-30kb per language. The separator for tokenization can be customized which makes it possible to index parts of words that are separated by - or . : extra : search : tokenizer : '[\\s\\-\\.]+' Favicon \u00b6 Default: assets/images/favicon.png The default favicon can be changed by setting the favicon variable to an .ico or image file: theme : favicon : 'assets/images/favicon.ico' Features \u00b6 Tabs \u00b6 Default: false By default, the entire navigation is rendered on the left side using collapsible sections (different from the default MkDocs theme which renders the top-level sections in the header), because horizontal navigation is often problematic on smaller screens. However, for large documentation projects it's sometimes desirable to add another navigation layer to separate top-level sections. Material achieves this with the tabs feature, which can be enabled by setting the respective feature flag to true : theme : feature : tabs : true When tabs are enabled, top-level sections will be rendered in an additional layer directly below the header. The navigation on the left side will only include the pages contained within the selected section. Furthermore, top-level pages defined inside your project's mkdocs.yml will be grouped under the first tab which will receive the title of the first page. Customization \u00b6 Adding a source repository \u00b6 To include a link to the repository of your project within your documentation, set the following variables via your project's mkdocs.yml : repo_name : 'squidfunk/mkdocs-material' repo_url : 'https://github.com/squidfunk/mkdocs-material' The name of the repository will be rendered next to the search bar on big screens and as part of the main navigation drawer on smaller screen sizes. Furthermore, if repo_url points to a GitHub, BitBucket or GitLab repository, the respective service logo will be shown next to the name of the repository. Additionally, for GitHub, the number of stars and forks is shown. If the repository is hosted in a private environment, the service logo can be set explicitly by setting extra.repo_icon to github , gitlab or bitbucket . Why is there an edit button at the top of every article? If the repo_url is set to a GitHub or BitBucket repository, and the repo_name is set to GitHub or BitBucket (implied by default), an edit button will appear at the top of every article. This is the automatic behavior that MkDocs implements. See the MkDocs documentation on more guidance regarding the edit_uri attribute, which defines whether the edit button is shown or not. Adding social links \u00b6 Social accounts can be linked in the footer of the documentation using the automatically included FontAwesome webfont. The type must denote the name of the social service, e.g. github , twitter or linkedin and the link must contain the URL you want to link to: extra : social : - type : 'github' link : 'https://github.com/squidfunk' - type : 'twitter' link : 'https://twitter.com/squidfunk' - type : 'linkedin' link : 'https://www.linkedin.com/in/squidfunk' The links are generated in order and the type of the links must match the name of the FontAwesome glyph. The fa is automatically added, so github will result in fa fa-github . Adding a Web App Manifest \u00b6 A Web App Manifest is a simple JSON file that tells the browser about your web application and how it should behave when installed on the user's mobile device or desktop. You can specify a manifest in your mkdocs.yml : extra : manifest : 'manifest.webmanifest' More advanced customization \u00b6 If you want to change the general appearance of the Material theme, see this article for more information on advanced customization. Integrations \u00b6 Google Analytics \u00b6 MkDocs makes it easy to integrate site tracking with Google Analytics. Besides basic tracking, clicks on all outgoing links can be tracked as well as how site search is used. Tracking can be activated in your project's mkdocs.yml : google_analytics : - 'UA-XXXXXXXX-X' - 'auto' Disqus \u00b6 Material for MkDocs is integrated with Disqus , so if you want to add a comments section to your documentation set the shortname of your Disqus project in your mkdocs.yml : extra : disqus : 'your-shortname' The comments section is inserted on every page, except the index page . Additionally, a new entry at the bottom of the table of contents is generated that is linking to the comments section. The necessary JavaScript is automatically included. Requirements site_url value must be set in mkdocs.yml for the Disqus integration to load properly. Disqus can also be enabled or disabled for specific pages using Metadata . Extensions \u00b6 MkDocs supports several Markdown extensions . The following extensions are not enabled by default (see the link for which are enabled by default) but highly recommended, so they should be switched on at all times: markdown_extensions : - admonition - codehilite : guess_lang : false - toc : permalink : true For more information, see the following list of extensions supported by the Material theme including more information regarding installation and usage: Admonition Codehilite Footnotes Metadata Permalinks PyMdown Extensions Plugins \u00b6 MkDocs's plugin architecture makes it possible to add pre- or post-processing steps that sit between the theme and your documentation. For more information, see the following list of plugins tested and supported by the Material theme including more information regarding installation and usage: Minify HTML Revision date Search The MkDocs wiki contains a list of all available plugins . Remember to re-add the search plugin If you have no plugins entry in your config file yet, you'll likely also want to add the search plugin when adding additional plugins. MkDocs enables it by default if there is no plugins entry set. Full example \u00b6 Below is a full example configuration for a mkdocs.yml : # Project information site_name : 'Material for MkDocs' site_description : 'A Material Design theme for MkDocs' site_author : 'Martin Donath' site_url : 'https://squidfunk.github.io/mkdocs-material/' # Repository repo_name : 'squidfunk/mkdocs-material' repo_url : 'https://github.com/squidfunk/mkdocs-material' # Copyright copyright : 'Copyright &copy; 2016 - 2017 Martin Donath' # Configuration theme : name : 'material' language : 'en' palette : primary : 'indigo' accent : 'indigo' font : text : 'Roboto' code : 'Roboto Mono' # Customization extra : manifest : 'manifest.webmanifest' social : - type : 'github' link : 'https://github.com/squidfunk' - type : 'twitter' link : 'https://twitter.com/squidfunk' - type : 'linkedin' link : 'https://www.linkedin.com/in/squidfunk' # Google Analytics google_analytics : - 'UA-XXXXXXXX-X' - 'auto' # Extensions markdown_extensions : - admonition - codehilite : guess_lang : false - toc : permalink : true","title":"Getting started"},{"location":"getting-started/#getting-started","text":"","title":"Getting started"},{"location":"getting-started/#installation","text":"","title":"Installation"},{"location":"getting-started/#installing-mkdocs","text":"Before installing MkDocs , you need to make sure you have Python and pip \u2013 the Python package manager \u2013 up and running. You can verify if you're already good to go with the following commands: python --version # Python 3.8.0 pip --version # pip 19.3.1 Installing and verifying MkDocs is as simple as: pip install mkdocs && mkdocs --version # mkdocs, version 1.0.4 Material requires MkDocs >= 1.0.0.","title":"Installing MkDocs"},{"location":"getting-started/#installing-material","text":"","title":"Installing Material"},{"location":"getting-started/#using-pip","text":"Material can be installed with pip : pip install mkdocs-material","title":"using pip"},{"location":"getting-started/#using-choco","text":"If you're on Windows you can use Chocolatey to install Material : choco install mkdocs-material This will install all required dependencies like Python and MkDocs .","title":"using choco"},{"location":"getting-started/#cloning-from-github","text":"Material can also be used without a system-wide installation by cloning the repository into a subfolder of your project's root directory: git clone https://github.com/squidfunk/mkdocs-material.git This is especially useful if you want to extend the theme and override some parts of the theme. The theme will reside in the folder mkdocs-material/material .","title":"cloning from GitHub"},{"location":"getting-started/#troubleshooting","text":"Installation on macOS When you're running the pre-installed version of Python on macOS, pip tries to install packages in a folder for which your user might not have the adequate permissions. There are two possible solutions for this: Installing in user space (recommended): Provide the --user flag to the install command and pip will install the package in a user-site location. This is the recommended way. Switching to a homebrewed Python : Upgrade your Python installation to a self-contained solution by installing Python with Homebrew. This should eliminate a lot of problems you may be having with pip . Error: unrecognized theme 'material' If you run into this error, the most common reason is that you installed MkDocs through some package manager (e.g. Homebrew or apt-get ) and the Material theme through pip , so both packages end up in different locations. MkDocs only checks its install location for themes.","title":"Troubleshooting"},{"location":"getting-started/#alternative-using-docker","text":"If you're familiar with Docker, the official Docker image for Material comes with all dependencies pre-installed and ready-to-use with the latest version published on PyPI, packaged in a very small image. Pull it with: docker pull squidfunk/mkdocs-material The mkdocs executable is provided as an entrypoint, serve is the default command. Start the development server in your project root with: docker run --rm -it -p 8000:8000 -v ${PWD}:/docs squidfunk/mkdocs-material If you're using Windows command prompt ( cmd.exe ), substitute ${PWD} with \"%cd%\" .","title":"Alternative: Using Docker"},{"location":"getting-started/#usage","text":"In order to enable the theme just add one of the following lines to your project's mkdocs.yml . If you installed Material using a package manager: theme : name : 'material' If you cloned Material from GitHub: theme : name : null custom_dir : 'mkdocs-material/material' MkDocs includes a development server, so you can review your changes as you go. The development server can be started with the following command: mkdocs serve Now you can point your browser to http://localhost:8000 and the Material theme should be visible. From here on, you can start writing your documentation, or read on and customize the theme.","title":"Usage"},{"location":"getting-started/#configuration","text":"","title":"Configuration"},{"location":"getting-started/#color-palette","text":"A default hue is defined for every primary and accent color on Google's Material Design color palette , which makes it very easy to change the overall look of the theme. Just set the primary and accent colors using the following variables: theme : palette : primary : 'indigo' accent : 'indigo' Color names are case-insensitive, but must match the names of the Material Design color palette. Valid values are: red , pink , purple , deep purple , indigo , blue , light blue , cyan , teal , green , light green , lime , yellow , amber , orange , deep orange , brown , grey , blue grey and white . The last four colors can only be used as a primary color. If the color is set via this configuration, an additional CSS file that defines the color palette is automatically included. If you want to keep things lean, clone the repository and recompile the theme with your custom colors set. See the guide on customization for more information.","title":"Color palette"},{"location":"getting-started/#primary-colors","text":"Default: indigo Click on a tile to change the primary color of the theme: Red Pink Purple Deep Purple Indigo Blue Light Blue Cyan Teal Green Light Green Lime Yellow Amber Orange Deep Orange Brown Grey Blue Grey Black White var buttons = document.querySelectorAll(\"button[data-md-color-primary]\"); Array.prototype.forEach.call(buttons, function(button) { button.addEventListener(\"click\", function() { document.body.dataset.mdColorPrimary = this.dataset.mdColorPrimary; }) })","title":"Primary colors"},{"location":"getting-started/#accent-colors","text":"Default: indigo Click on a tile to change the accent color of the theme: Red Pink Purple Deep Purple Indigo Blue Light Blue Cyan Teal Green Light Green Lime Yellow Amber Orange Deep Orange var buttons = document.querySelectorAll(\"button[data-md-color-accent]\"); Array.prototype.forEach.call(buttons, function(button) { button.addEventListener(\"click\", function() { document.body.dataset.mdColorAccent = this.dataset.mdColorAccent; }) })","title":"Accent colors"},{"location":"getting-started/#font-family","text":"Default: Roboto and Roboto Mono By default the Roboto font family is included with the theme, specifically the regular sans-serif type for text and the monospaced type for code. Both fonts are loaded from Google Fonts and can be changed to other fonts, like for example the Ubuntu font family : theme : font : text : 'Ubuntu' code : 'Ubuntu Mono' The text font will be loaded in weights 400 and 700 , the monospaced font in regular weight. If you want to load fonts from other destinations or don't want to use the Google Fonts loading magic, just set font to false : theme : font : false","title":"Font family"},{"location":"getting-started/#logo","text":"Default icon: school Your logo should have rectangular shape with a minimum resolution of 128x128, leave some room towards the edges and be composed of high contrast areas on a transparent ground, as it will be placed on the colored header bar and drawer. Simply create the folder docs/images , add your logo and embed it with: theme : logo : 'images/logo.svg' Additionally, the default icon can be changed by setting an arbitrary ligature (or Unicode code point) from the Material Design icon font , e.g. theme : logo : icon : 'cloud'","title":"Logo"},{"location":"getting-started/#language","text":"Call for Contributions: Add languages/translations to Material Help translate Material into more languages - it's just one click and takes approximately 2 minutes : click here","title":"Language"},{"location":"getting-started/#localization","text":"Default: en Material for MkDocs supports internationalization (i18n) and provides translations for all template variables and labels in the following languages: Available languages af / Afrikaans ar / Arabic ca / Catalan cs / Czech da / Danish nl / Dutch en / English et / Estonian fi / Finnish fr / French gl / Galician de / German gr / Greek he / Hebrew hi / Hindi hr / Croatian hu / Hungarian id / Indonesian it / Italian ja / Japanese kr / Korean no / Norwegian nn / Norwegian (Nynorsk) fa / Persian pl / Polish pt / Portugese ro / Romanian ru / Russian sr / Serbian sh / Serbo-Croatian sk / Slovak si / Slovenian es / Spanish sv / Swedish th / Thai tr / Turkish uk / Ukrainian vi / Vietnamese zh / Chinese (Simplified) zh-Hant / Chinese (Traditional) zh-TW / Chinese (Taiwanese) Submit a new language Specify the language with: theme : language : 'en' If the language is not specified, Material falls back to English. To create a translation for another language, copy the localization file of an existing language, name the new file using the 2-letter language code and adjust all translations: cp partials/language/en.html partials/language/jp.html","title":"Localization"},{"location":"getting-started/#text-direction","text":"Default: best match for given theme language, automatically set Material supports both, left-to-right ( ltr ) and right-to-left ( rtl ) text direction. This enables more languages like Arabic, Hebrew, Syriac and others to be used with the theme: theme : direction : 'rtl'","title":"Text direction"},{"location":"getting-started/#site-search","text":"Default: best match for given theme language, automatically set Site search is implemented using lunr.js , which includes stemmers for the English language by default, while stemmers for other languages are included with lunr-languages , both of which are integrated with this theme. Material selects the matching (or best-matching) stemmer for the given theme language. Multilingual search can be activated in your project's mkdocs.yml by explicitly defining the search language(s): extra : search : language : 'en, de, ru' At the time of writing, the following languages are supported: Available language stemmers da / Danish du / Dutch en / English fi / Finnish fr / French de / German hu / Hungarian it / Italian ja / Japanese no / Norwegian pt / Portugese ro / Romanian ru / Russian es / Spanish sv / Swedish tr / Turkish MkDocs 1.0 compatibility While MkDocs 1.0 supports prebuilding the search index, Material currently doesn't support this setting as the default search behavior of the original theme was heavily modified for the sake of a better UX. Integration is possible, but a small subset of the features Material provides will not be portable to the prebuilt index mainly due to missing localization. Only specify the languages you really need Be aware that including support for other languages increases the general JavaScript payload by around 20kb (without gzip) and by another 15-30kb per language. The separator for tokenization can be customized which makes it possible to index parts of words that are separated by - or . : extra : search : tokenizer : '[\\s\\-\\.]+'","title":"Site search"},{"location":"getting-started/#favicon","text":"Default: assets/images/favicon.png The default favicon can be changed by setting the favicon variable to an .ico or image file: theme : favicon : 'assets/images/favicon.ico'","title":"Favicon"},{"location":"getting-started/#features","text":"","title":"Features"},{"location":"getting-started/#tabs","text":"Default: false By default, the entire navigation is rendered on the left side using collapsible sections (different from the default MkDocs theme which renders the top-level sections in the header), because horizontal navigation is often problematic on smaller screens. However, for large documentation projects it's sometimes desirable to add another navigation layer to separate top-level sections. Material achieves this with the tabs feature, which can be enabled by setting the respective feature flag to true : theme : feature : tabs : true When tabs are enabled, top-level sections will be rendered in an additional layer directly below the header. The navigation on the left side will only include the pages contained within the selected section. Furthermore, top-level pages defined inside your project's mkdocs.yml will be grouped under the first tab which will receive the title of the first page.","title":"Tabs"},{"location":"getting-started/#customization","text":"","title":"Customization"},{"location":"getting-started/#adding-a-source-repository","text":"To include a link to the repository of your project within your documentation, set the following variables via your project's mkdocs.yml : repo_name : 'squidfunk/mkdocs-material' repo_url : 'https://github.com/squidfunk/mkdocs-material' The name of the repository will be rendered next to the search bar on big screens and as part of the main navigation drawer on smaller screen sizes. Furthermore, if repo_url points to a GitHub, BitBucket or GitLab repository, the respective service logo will be shown next to the name of the repository. Additionally, for GitHub, the number of stars and forks is shown. If the repository is hosted in a private environment, the service logo can be set explicitly by setting extra.repo_icon to github , gitlab or bitbucket . Why is there an edit button at the top of every article? If the repo_url is set to a GitHub or BitBucket repository, and the repo_name is set to GitHub or BitBucket (implied by default), an edit button will appear at the top of every article. This is the automatic behavior that MkDocs implements. See the MkDocs documentation on more guidance regarding the edit_uri attribute, which defines whether the edit button is shown or not.","title":"Adding a source repository"},{"location":"getting-started/#adding-social-links","text":"Social accounts can be linked in the footer of the documentation using the automatically included FontAwesome webfont. The type must denote the name of the social service, e.g. github , twitter or linkedin and the link must contain the URL you want to link to: extra : social : - type : 'github' link : 'https://github.com/squidfunk' - type : 'twitter' link : 'https://twitter.com/squidfunk' - type : 'linkedin' link : 'https://www.linkedin.com/in/squidfunk' The links are generated in order and the type of the links must match the name of the FontAwesome glyph. The fa is automatically added, so github will result in fa fa-github .","title":"Adding social links"},{"location":"getting-started/#adding-a-web-app-manifest","text":"A Web App Manifest is a simple JSON file that tells the browser about your web application and how it should behave when installed on the user's mobile device or desktop. You can specify a manifest in your mkdocs.yml : extra : manifest : 'manifest.webmanifest'","title":"Adding a Web App Manifest"},{"location":"getting-started/#more-advanced-customization","text":"If you want to change the general appearance of the Material theme, see this article for more information on advanced customization.","title":"More advanced customization"},{"location":"getting-started/#integrations","text":"","title":"Integrations"},{"location":"getting-started/#google-analytics","text":"MkDocs makes it easy to integrate site tracking with Google Analytics. Besides basic tracking, clicks on all outgoing links can be tracked as well as how site search is used. Tracking can be activated in your project's mkdocs.yml : google_analytics : - 'UA-XXXXXXXX-X' - 'auto'","title":"Google Analytics"},{"location":"getting-started/#disqus","text":"Material for MkDocs is integrated with Disqus , so if you want to add a comments section to your documentation set the shortname of your Disqus project in your mkdocs.yml : extra : disqus : 'your-shortname' The comments section is inserted on every page, except the index page . Additionally, a new entry at the bottom of the table of contents is generated that is linking to the comments section. The necessary JavaScript is automatically included. Requirements site_url value must be set in mkdocs.yml for the Disqus integration to load properly. Disqus can also be enabled or disabled for specific pages using Metadata .","title":"Disqus"},{"location":"getting-started/#extensions","text":"MkDocs supports several Markdown extensions . The following extensions are not enabled by default (see the link for which are enabled by default) but highly recommended, so they should be switched on at all times: markdown_extensions : - admonition - codehilite : guess_lang : false - toc : permalink : true For more information, see the following list of extensions supported by the Material theme including more information regarding installation and usage: Admonition Codehilite Footnotes Metadata Permalinks PyMdown Extensions","title":"Extensions"},{"location":"getting-started/#plugins","text":"MkDocs's plugin architecture makes it possible to add pre- or post-processing steps that sit between the theme and your documentation. For more information, see the following list of plugins tested and supported by the Material theme including more information regarding installation and usage: Minify HTML Revision date Search The MkDocs wiki contains a list of all available plugins . Remember to re-add the search plugin If you have no plugins entry in your config file yet, you'll likely also want to add the search plugin when adding additional plugins. MkDocs enables it by default if there is no plugins entry set.","title":"Plugins"},{"location":"getting-started/#full-example","text":"Below is a full example configuration for a mkdocs.yml : # Project information site_name : 'Material for MkDocs' site_description : 'A Material Design theme for MkDocs' site_author : 'Martin Donath' site_url : 'https://squidfunk.github.io/mkdocs-material/' # Repository repo_name : 'squidfunk/mkdocs-material' repo_url : 'https://github.com/squidfunk/mkdocs-material' # Copyright copyright : 'Copyright &copy; 2016 - 2017 Martin Donath' # Configuration theme : name : 'material' language : 'en' palette : primary : 'indigo' accent : 'indigo' font : text : 'Roboto' code : 'Roboto Mono' # Customization extra : manifest : 'manifest.webmanifest' social : - type : 'github' link : 'https://github.com/squidfunk' - type : 'twitter' link : 'https://twitter.com/squidfunk' - type : 'linkedin' link : 'https://www.linkedin.com/in/squidfunk' # Google Analytics google_analytics : - 'UA-XXXXXXXX-X' - 'auto' # Extensions markdown_extensions : - admonition - codehilite : guess_lang : false - toc : permalink : true","title":"Full example"},{"location":"license/","text":"License \u00b6 MIT License Copyright \u00a9 2016 - 2020 Martin Donath Permission is hereby granted, free of charge, to any person obtaining a copy of this software and associated documentation files (the \"Software\"), to deal in the Software without restriction, including without limitation the rights to use, copy, modify, merge, publish, distribute, sublicense, and/or sell copies of the Software, and to permit persons to whom the Software is furnished to do so, subject to the following conditions: The above copyright notice and this permission notice shall be included in all copies or substantial portions of the Software. THE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND NON-INFRINGEMENT. IN NO EVENT SHALL THE AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM, OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE SOFTWARE.","title":"License"},{"location":"license/#license","text":"MIT License Copyright \u00a9 2016 - 2020 Martin Donath Permission is hereby granted, free of charge, to any person obtaining a copy of this software and associated documentation files (the \"Software\"), to deal in the Software without restriction, including without limitation the rights to use, copy, modify, merge, publish, distribute, sublicense, and/or sell copies of the Software, and to permit persons to whom the Software is furnished to do so, subject to the following conditions: The above copyright notice and this permission notice shall be included in all copies or substantial portions of the Software. THE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND NON-INFRINGEMENT. IN NO EVENT SHALL THE AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM, OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE SOFTWARE.","title":"License"},{"location":"markdown/","text":"Ordered list \u00b6 This a list: Lis1. List2. Unordered \u00b6 This is a list item 1 This ia a list item 2","title":"Markdown"},{"location":"markdown/#ordered-list","text":"This a list: Lis1. List2.","title":"Ordered list"},{"location":"markdown/#unordered","text":"This is a list item 1 This ia a list item 2","title":"Unordered"},{"location":"release-notes/","text":"Release notes \u00b6 Upgrading \u00b6 To upgrade Material to the latest version, use pip : pip install --upgrade mkdocs-material To inspect the currently installed version, use the following command: pip show mkdocs-material Material 3.x to 4.x \u00b6 Material for MkDocs 4.x finally fixes incorrect layout on Chinese systems. The fix includes a mandatory change of the base font-size from 10px to 20px which means all rem values needed to be updated. Within the theme, px to rem calculation is now encapsulated in a new function called px2rem which is part of the SASS code base. If you use Material with custom CSS that is based on rem values, note that those values must now be divided by 2. Now, 1.0rem doesn't map to 10px , but 20px . To learn more about the problem and implications, please refer to the issue in which the problem was discovered and fixed. Material 2.x to 3.x \u00b6 Material for MkDocs 3.x requires MkDocs 1.0 because the way paths are resolved internally changed significantly. Furthermore, pages was renamed to nav , so remember to adjust your mkdocs.yml file. All extended templates should continue to work but in order to make them future-proof the url filter should be introduced on all paths. Please see the official release notes for further guidance. Material 1.x to 2.x \u00b6 Material for MkDocs 2.x requires MkDocs 0.17.1, as this version introduced changes to the way themes can define options. The following variables inside your project's mkdocs.yml need to be renamed: extra.feature becomes theme.feature extra.palette becomes theme.palette extra.font becomes theme.font extra.logo becomes theme.logo Favicon support has been dropped by MkDocs, it must now be defined in theme.favicon (previously site_favicon ). Localization is now separated into theme language and search language. While there can only be a single language on theme-level, the search supports multiple languages which can be separated by commas. See the getting started guide for more guidance. The search tokenizer can now be set through extra.search.tokenizer . Changelog \u00b6 4.6.3 _ February 14, 2020 \u00b6 Removed optional third-party plugins from requirements.txt Updated Docker image to contain all supported third-party plugins 4.6.2 _ February 8, 2020 \u00b6 Added Romanian translations Fixed #1451 : Inconsistent spacing for fenced code blocks 4.6.1 _ February 8, 2020 \u00b6 Fixed #1324 : Metadata author only rendering first character Fixed #1393 : Set tabindex to 0 for skip to content link Fixed code blocks after Markdown 3.2 release Fixed errors in Japanese translations Improved Google Lighthouse score 4.6.0 _ December 11, 2019 \u00b6 Added support for mkdocs-git-revision-date-localized-plugin Fixed invalid character in Google Fonts URL 4.5.1 _ December 2, 2019 \u00b6 Added Thai translations Fixed missing assets in GitHub release .zip and .tar.gz 4.5.0 _ November 16, 2019 \u00b6 Upgraded EmojiOne to Tweomji due to licensing issues Temporarily pinned PyMdown and Markdown due to upcoming changes Improved GitHub statistics retrieval Fixed errors in Greek translations 4.4.3 _ October 3, 2019 \u00b6 Added Estonian translations Fixed removal of copyright banners in minified JavaScript Removed unnecessary title attributes from links in table of contents 4.4.2 _ August 27, 2019 \u00b6 Added Afrikaans translations Fixed broken page title when h1 contained HTML tags Improved accessibility for IE users Removed unnecessary title attributes from links in navigation 4.4.1 _ August 22, 2019 \u00b6 Added support for black as a primary color Fixed broken footer bar when h1 contained HTML tags 4.4.0 _ June 15, 2019 \u00b6 Added Slovenian translations Reverted template minification in favor of mkdocs-minify-plugin Fixed #1114 : Tabs don't reappear when default font-size is smaller than 16 4.3.1 _ May 23, 2019 \u00b6 Fixed spelling error in Danish translations 4.3.0 _ May 17, 2019 \u00b6 Added support for changing header through metadata title property Added font-display: swap to Google Font loading logic Removed whitespace from templates, saving 4kb ( .7kb gzipped) per request Fixed alignment of repository icons on tablet and desktop 4.2.0 _ April 28, 2019 \u00b6 Added Norwegian (Nynorsk) translations Fixed loss of focus in non-form input elements due to search hotkeys Fixed #1067 : Search hotkeys not working for mobile/tablet screensize Fixed #1068 : Search not correctly aligned for tablet screensize 4.1.2 _ April 16, 2019 \u00b6 Fixed #1072 : HTML tags appearing in navigation link titles 4.1.1 _ March 28, 2019 \u00b6 Fixed minor CSS errors detected during validation 4.1.0 _ March 22, 2019 \u00b6 Fixed #1023 : Search for Asian languages broken after Lunr.js update Fixed #1026 : contenteditable elements loose focus on hotkeys 4.0.2 _ March 1, 2019 \u00b6 Fixed #1012 : HTML character entities appear in search result titles 4.0.1 _ February 13, 2019 \u00b6 Fixed #762 , #816 : Glitch in sidebar when collapsing items Fixed #869 : Automatically expand details before printing 4.0.0 _ February 13, 2019 \u00b6 Added background on hover for table rows Removed Google Tag Manager and reverted to Google Analytics Removed blocks in partials - Jinja doesn't support them Fixed #911 : Chrome breaks layout if system language is Chinese [BREAKING] Fixed #976 : Removed FastClick 3.3.0 _ January 29, 2019 \u00b6 Moved Google Analytics integration into head using Google Tag Manager Fixed #972 : Unicode slugifier breaks table of contents blur on scroll Fixed #974 : Additional links in table of contents break blur on scroll 3.2.0 _ December 28, 2018 \u00b6 Added support for redirects using metadata refresh Fixed #921 : Load Google Analytics snippet asynchronously 3.1.0 _ November 17, 2018 \u00b6 Added support for Progressive Web App Manifest Fixed #915 : Search bug in Safari (upgraded Lunr.js) 3.0.6 _ October 26, 2018 \u00b6 Added Taiwanese translations Fixed #906 : JavaScript code blocks evaluated in search results 3.0.5 _ October 23, 2018 \u00b6 Added Croatian and Indonesian translations Fixed #899 : Skip-to-content link invalid from 2 nd level on Fixed #902 : Missing URL filter in footer for FontAwesome link 3.0.4 _ September 3, 2018 \u00b6 Updated Dutch translations Fixed #856 : Removed preconnect meta tag if Google Fonts are disabled 3.0.3 _ August 7, 2018 \u00b6 Fixed #841 : Additional path levels for extra CSS and JS 3.0.2 _ August 6, 2018 \u00b6 Fixed #839 : Lunr.js stemmer imports incorrect 3.0.1 _ August 5, 2018 \u00b6 Fixed #838 : Search result links incorrect 3.0.0 _ August 5, 2018 \u00b6 Upgraded MkDocs to 1.0 [BREAKING] Upgraded Python in official Docker image to 3.6 Added Serbian and Serbo-Croatian translations 2.9.4 _ July 29, 2018 \u00b6 Fixed build error after MkDocs upgrade 2.9.3 _ July 29, 2018 \u00b6 Added link to home for logo in drawer Fixed dependency problems between MkDocs and Tornado 2.9.2 _ June 29, 2018 \u00b6 Added Hindi and Czech translations 2.9.1 _ June 18, 2018 \u00b6 Added support for different spellings for theme color Fixed #799 : Added support for web font minification in production Fixed #800 : Added .highlighttable as an alias for .codehilitetable 2.9.0 _ June 13, 2018 \u00b6 Added support for theme color on Android Fixed #796 : Rendering of nested tabbed code blocks 2.8.0 _ June 10, 2018 \u00b6 Added support for grouping code blocks with tabs Added Material and FontAwesome icon fonts to distribution files (GDPR) Added note on compliance with GDPR Added Slovak translations Fixed #790 : Prefixed id attributes with __ to avoid name clashes 2.7.3 _ April 26, 2018 \u00b6 Added Finnish translations 2.7.2 _ April 9, 2018 \u00b6 Fixed rendering issue for details on Edge 2.7.1 _ March 21, 2018 \u00b6 Added Galician translations Fixed #730 : Scroll chasing error on home page if Disqus is enabled Fixed #736 : Reset drawer and search upon back button invocation 2.7.0 _ March 6, 2018 \u00b6 Added ability to set absolute URL for logo Added Hebrew translations 2.6.6 _ February 22, 2018 \u00b6 Added preconnect for Google Fonts for faster loading Fixed #710 : With tabs sidebar disappears if JavaScript is not available 2.6.5 _ February 22, 2018 \u00b6 Reverted --dev-addr flag removal from Dockerfile 2.6.4 _ February 21, 2018 \u00b6 Added Catalan translations Fixed incorrect margins for buttons in Firefox and Safari Replaced package manager yarn with npm 5.6 Reverted GitHub stars rounding method Removed --dev-addr flag from Dockerfile for Windows compatibility 2.6.3 _ February 18, 2018 \u00b6 Added Vietnamese translations 2.6.2 _ February 12, 2018 \u00b6 Added Arabic translations Fixed incorrect rounding of amount of GitHub stars Fixed double-layered borders for tables 2.6.1 _ February 11, 2018 \u00b6 Added ability to override Disqus integration using metadata Fixed #690 : Duplicate slashes in source file URLs Fixed #696 : Active page highlight not working with default palette Adjusted German translations 2.6.0 _ February 2, 2018 \u00b6 Moved default search configuration to default translation (English) Added support to automatically set text direction from translation Added support to disable search stop word filter in translation Added support to disable search trimmer in translation Added Persian translations Fixed support for Polish search Fixed disappearing GitHub, GitLab and Bitbucket repository icons 2.5.5 _ January 31, 2018 \u00b6 Added Hungarian translations 2.5.4 _ January 29, 2018 \u00b6 Fixed #683 : gh-deploy fails inside Docker 2.5.3 _ January 25, 2018 \u00b6 Added Ukrainian translations 2.5.2 _ January 22, 2018 \u00b6 Added default search language mappings for all localizations Fixed #673 : Error loading non-existent search language Fixed #675 : Uncaught reference error when search plugin disabled 2.5.1 _ January 20, 2018 \u00b6 Fixed permalink for main headline Improved missing translation handling with English as a fallback Improved accessibility with skip-to-content link 2.5.0 _ January 13, 2018 \u00b6 Added support for right-to-left languages 2.4.0 _ January 11, 2018 \u00b6 Added focus state for clipboard buttons Fixed #400 : Search bar steals tab focus Fixed search not closing on Enter when result is selected Fixed search not closing when losing focus due to Tab Fixed collapsed navigation links getting focus Fixed outline being cut off on Tab focus of navigation links Fixed bug with first search result navigation being ignored Removed search result navigation via Tab (use Up and Down ) Removed outline resets for links Improved general tabbing behavior on desktop 2.3.0 _ January 9, 2018 \u00b6 Added example (synonym: snippet ) style for Admonition Added synonym abstract for summary style for Admonition 2.2.6 _ December 27, 2017 \u00b6 Added Turkish translations Fixed unclickable area below header in case JavaScript is not available 2.2.5 _ December 18, 2017 \u00b6 Fixed #639 : Broken default favicon 2.2.4 _ December 18, 2017 \u00b6 Fixed #638 : Build breaks with Jinja < 2.9 2.2.3 _ December 13, 2017 \u00b6 Fixed #630 : Admonition sets padding on any last child Adjusted Chinese (Traditional) translations 2.2.2 _ December 8, 2017 \u00b6 Added Dutch translations Adjusted targeted link and footnote offsets Simplified Admonition styles and fixed padding bug 2.2.1 _ December 2, 2017 \u00b6 Fixed #616 : Minor styling error with title-only admonition blocks Removed border for table of contents and improved spacing 2.2.0 _ November 22, 2017 \u00b6 Added support for hero teaser Added Portuguese translations Fixed #586 : Footnote backref target offset regression Fixed #605 : Search stemmers not correctly loaded 2.1.1 _ November 21, 2017 \u00b6 Replaced deprecated babel-preset-es2015 with babel-preset-env Refactored Gulp build pipeline with Webpack Removed right border on sidebars Fixed broken color transition on header 2.1.0 _ November 19, 2017 \u00b6 Added support for white as a primary color Added support for sliding site name and title Fixed redundant clipboard button when using line numbers on code blocks Improved header appearance by making it taller Improved tabs appearance Improved CSS customizability by leveraging inheritance Removed scroll shadows via background-attachment 2.0.4 _ November 5, 2017 \u00b6 Fixed details not opening with footnote reference 2.0.3 _ November 5, 2017 \u00b6 Added Japanese translations Fixed #540 : Jumping to anchor inside details doesn't open it Fixed active link colors in footer 2.0.2 _ November 1, 2017 \u00b6 Added Russian translations Fixed #542 : Horizontal scrollbar between 1220px and 1234px Fixed #553 : Metadata values only rendering first character Fixed #558 : Flash of unstyled content Fixed favicon regression caused by deprecation upstream 2.0.1 _ October 31, 2017 \u00b6 Fixed error when initializing search Fixed styles for link to edit the current page Fixed styles on nested admonition in details 2.0.0 _ October 31, 2017 \u00b6 Added support for MkDocs 0.17.1 theme configuration options Added support for easier configuration of search tokenizer Added support to disable search Added Korean translations Removed support for MkDocs 0.16.x [BREAKING] 1.12.2 _ October 26, 2017 \u00b6 Added Italian, Norwegian, French and Chinese translations 1.12.1 _ October 22, 2017 \u00b6 Added Polish, Swedish and Spanish translations Improved downward compatibility with custom partials Temporarily pinned MkDocs version within Docker image to 0.16.3 Fixed #519 : Missing theme configuration file 1.12.0 _ October 20, 2017 \u00b6 Added support for setting language(s) via mkdocs.yml Added support for default localization Added German and Danish translations Fixed #374 : Search bar misalignment on big screens 1.11.0 _ October 19, 2017 \u00b6 Added localization to clipboard Refactored localization logic 1.10.4 _ October 18, 2017 \u00b6 Improved print styles of code blocks Improved search UX (don't close on enter if no selection) Fixed #495 : Vertical scrollbar on short pages 1.10.3 _ October 11, 2017 \u00b6 Fixed #484 : Vertical scrollbar on some MathJax formulas Fixed #483 : Footnote backref target offset regression 1.10.2 _ October 6, 2017 \u00b6 Fixed #468 : Sidebar shows scrollbar if content is shorter (in Safari) 1.10.1 _ September 14, 2017 \u00b6 Fixed #455 : Bold code blocks rendered with normal font weight 1.10.0 _ September 1, 2017 \u00b6 Added support to make logo default icon configurable Fixed uninitialized overflow scrolling on main pane for iOS Fixed error in mobile navigation in case JavaScript is not available Fixed incorrect color transition for nested panes in mobile navigation Improved checkbox styles for Tasklist from PyMdown Extension package 1.9.0 _ August 29, 2017 \u00b6 Added info (synonym: todo ) style for Admonition Added question (synonym: help , faq ) style for Admonition Added support for Details from PyMdown Extensions package Improved Admonition styles to match Details Improved styles for social links in footer Replaced ligatures with Unicode code points to avoid broken layout Upgraded PyMdown Extensions package dependency to >= 3.4 1.8.1 _ August 7, 2017 \u00b6 Fixed #421 : Missing pagination for GitHub API 1.8.0 _ August 2, 2017 \u00b6 Added support for lazy-loading of search results for better performance Added support for customization of search tokenizer/separator Fixed #424 : Search doesn't handle capital letters anymore Fixed #419 : Search doesn't work on whole words 1.7.5 _ July 25, 2017 \u00b6 Fixed #398 : Forms broken due to search shortcuts Improved search overall user experience Improved search matching and highlighting Improved search accessibility 1.7.4 _ June 21, 2017 \u00b6 Fixed functional link colors in table of contents for active palette Fixed #368 : Compatibility issues with IE11 1.7.3 _ June 7, 2017 \u00b6 Fixed error when setting language to Japanese for site search 1.7.2 _ June 6, 2017 \u00b6 Fixed offset of search box when repo_url is not set Fixed non-disappearing tooltip 1.7.1 _ June 1, 2017 \u00b6 Fixed wrong z-index order of header, overlay and drawer Fixed wrong offset of targeted footnote back references 1.7.0 _ June 1, 2017 \u00b6 Added \"copy to clipboard\" buttons to code blocks Added support for multilingual site search Fixed search term highlighting for non-latin languages 1.6.4 _ May 24, 2017 \u00b6 Fixed #337 : JavaScript error for GitHub organization URLs 1.6.3 _ May 16, 2017 \u00b6 Fixed #329 : Broken source stats for private or unknown GitHub repos 1.6.2 _ May 15, 2017 \u00b6 Fixed #316 : Fatal error for git clone on Windows Fixed #320 : Chrome 58 creates double underline for abbr tags Fixed #323 : Ligatures rendered inside code blocks Fixed miscalculated sidebar height due to missing margin collapse Changed deprecated MathJax CDN to Cloudflare 1.6.1 _ April 23, 2017 \u00b6 Fixed following of active/focused element if search input is focused Fixed layer order of search component elements 1.6.0 _ April 22, 2017 \u00b6 Added build test for Docker image on Travis Added search overlay for better user experience (focus) Added language from localizations to html tag Fixed #270 : source links broken for absolute URLs Fixed missing top spacing for first targeted element in content Fixed too small footnote divider when using larger font sizes 1.5.5 _ April 20, 2017 \u00b6 Fixed #282 : Browser search ( Meta + F ) is hijacked 1.5.4 _ April 8, 2017 \u00b6 Fixed broken highlighting for two or more search terms Fixed missing search results when only a h1 is present Fixed unresponsive overlay on Android 1.5.3 _ April 7, 2017 \u00b6 Fixed deprecated calls for template variables Fixed wrong palette color for focused search result Fixed JavaScript errors on 404 page Fixed missing top spacing on 404 page Fixed missing right spacing on overflow of source container 1.5.2 _ April 5, 2017 \u00b6 Added requirements as explicit dependencies in setup.py Fixed non-synchronized transitions in search form 1.5.1 _ March 30, 2017 \u00b6 Fixed rendering and offset of targetted footnotes Fixed #238 : Link on logo is not set to site_url 1.5.0 _ March 24, 2017 \u00b6 Added support for localization of search placeholder Added keyboard events for quick access of search Added keyboard events for search control Added opacity on hover for search buttons Added git hook to skip CI build on non-src changes Fixed non-resetting search placeholder when input is cleared Fixed error for unescaped parentheses in search term Fixed #229 : Button to clear search missing Fixed #231 : Escape key doesn't exit search Removed old-style figures from font feature settings 1.4.1 _ March 16, 2017 \u00b6 Fixed invalid destructuring attempt on NodeList (in Safari, Edge, IE) 1.4.0 _ March 16, 2017 \u00b6 Added support for grouping searched sections by documents Added support for highlighting of search terms Added support for localization of search results Fixed #216 : table of contents icon doesn't show if h1 is not present Reworked style and layout of search results for better usability 1.3.0 _ March 11, 2017 \u00b6 Added support for page-specific title and description using metadata Added support for linking source files to documentation Fixed jitter and offset of sidebar when zooming browser Fixed incorrectly initialized tablet sidebar height Fixed regression for #1 : GitHub stars break if repo_url ends with a / Fixed undesired white line below copyright footer due to base font scaling Fixed issue with whitespace in path for scripts Fixed #205 : support non-fixed (static) header Refactored footnote references for better visibility Reduced repaints to a minimum for non-tabs configuration Reduced contrast of edit button (slightly) 1.2.0 _ March 3, 2017 \u00b6 Added quote (synonym: cite ) style for Admonition Added help message to build pipeline Fixed wrong navigation link colors when applying palette Fixed #197 : Link missing in tabs navigation on deeply nested items Removed unnecessary dev dependencies 1.1.1 _ February 26, 2017 \u00b6 Fixed incorrectly displayed nested lists when using tabs 1.1.0 _ February 26, 2017 \u00b6 Added tabs navigation feature (optional) Added Disqus integration (optional) Added a high resolution Favicon with the new logo Added static type checking using Facebook's Flow Fixed #173 : Dictionary elements have no bottom spacing Fixed #175 : Tables cannot be set to 100% width Fixed race conditions in build related to asset revisioning Fixed accidentally re-introduced Permalink on top-level headline Fixed alignment of logo in drawer on IE11 Refactored styles related to tables Refactored and automated Docker build and PyPI release Refactored build scripts 1.0.5 _ February 18, 2017 \u00b6 Fixed #153 : Sidebar flows out of constrained area in Chrome 56 Fixed #159 : Footer jitter due to JavaScript if content is short 1.0.4 _ February 16, 2017 \u00b6 Fixed #142 : Documentation build errors if h1 is defined as raw HTML Fixed #164 : PyPI release does not build and install Fixed offsets of targeted headlines Increased sidebar font size by 0.12rem 1.0.3 _ January 22, 2017 \u00b6 Fixed #117 : Table of contents items don't blur on fast scrolling Refactored sidebar positioning logic Further reduction of repaints 1.0.2 _ January 15, 2017 \u00b6 Fixed #108 : Horizontal scrollbar in content area 1.0.1 _ January 14, 2017 \u00b6 Fixed massive repaints happening when scrolling Fixed footer back reference positions in case of overflow Fixed header logo from showing when the menu icon is rendered Changed scrollbar behavior to only show when content overflows 1.0.0 _ January 13, 2017 \u00b6 Introduced Webpack for more sophisticated JavaScript bundling Introduced ESLint and Stylelint for code style checks Introduced more accurate Material Design colors and shadows Introduced modular scales for harmonic font sizing Introduced git-hooks for better development workflow Rewrite of CSS using the BEM methodology and SassDoc guidelines Rewrite of JavaScript using ES6 and Babel as a transpiler Rewrite of Admonition, Permalinks and CodeHilite integration Rewrite of the complete typographical system Rewrite of Gulp asset pipeline in ES6 and separation of tasks Removed Bower as a dependency in favor of NPM Removed custom icon build in favor of the Material Design iconset Removed _blank targets on links due to vulnerability: http://bit.ly/1Mk2Rtw Removed unversioned assets from build directory Restructured templates into base templates and partials Added build and watch scripts in package.json Added support for Metadata and Footnotes Markdown extensions Added support for PyMdown Extensions package Added support for collapsible sections in navigation Added support for separate table of contents Added support for better accessibility through REM-based layout Added icons for GitHub, GitLab and BitBucket integrations Added more detailed documentation on specimen, extensions etc. Added a 404.html error page for deployment on GitHub Pages Fixed live reload chain in watch mode when saving a template Fixed variable references to work with MkDocs 0.16 0.2.4 _ June 26, 2016 \u00b6 Fixed improperly set default favicon Fixed #33 : Protocol relative URL for webfonts doesn't work with file:// Fixed #34 : IE11 on Windows 7 doesn't honor max-width on main tag Fixed #35 : Add styling for blockquotes 0.2.3 _ May 16, 2016 \u00b6 Fixed #25 : Highlight inline fenced blocks Fixed #26 : Better highlighting for keystrokes Fixed #30 : Suboptimal syntax highlighting for PHP 0.2.2 _ March 20, 2016 \u00b6 Fixed #15 : Document Pygments dependency for CodeHilite Fixed #16 : Favicon could not be set through mkdocs.yml Fixed #17 : Put version into own container for styling Fixed #20 : Fix rounded borders for tables 0.2.1 _ March 12, 2016 \u00b6 Fixed #10 : Invisible header after closing search bar with ESC key Fixed #13 : Table cells don't wrap Fixed empty list in table of contents when no headline is defined Corrected wrong path for static asset monitoring in Gulpfile.js Set up tracking of site search for Google Analytics 0.2.0 _ February 24, 2016 \u00b6 Fixed #6 : Include multiple color palettes via mkdocs.yml Fixed #7 : Better colors for links inside admonition notes and warnings Fixed #9 : Text for prev/next footer navigation should be customizable Refactored templates (replaced if / else with modifiers where possible) 0.1.3 _ February 21, 2016 \u00b6 Fixed #3 : Ordered lists within an unordered list have ::before content Fixed #4 : Click on Logo/Title without Github-Repository: \"None\" Fixed #5 : Page without headlines renders empty list in table of contents Moved Modernizr to top to ensure basic usability in IE8 0.1.2 _ February 16, 2016 \u00b6 Fixed styles for deep navigational hierarchies Fixed webfont delivery problem when hosted in subdirectories Fixed print styles in mobile/tablet configuration Added option to configure fonts in mkdocs.yml with fallbacks Changed styles for admonition notes and warnings Set download link to latest version if available Set up tracking of outgoing links and actions for Google Analytics 0.1.1 _ February 11, 2016 \u00b6 Fixed #1 : GitHub stars don't work if the repo_url ends with a / Updated NPM and Bower dependencies to most recent versions Changed footer/copyright link to Material theme to GitHub pages Made MkDocs building/serving in build process optional Set up continuous integration with Travis 0.1.0 _ February 9, 2016 \u00b6 Initial release","title":"Release notes"},{"location":"release-notes/#release-notes","text":"","title":"Release notes"},{"location":"release-notes/#upgrading","text":"To upgrade Material to the latest version, use pip : pip install --upgrade mkdocs-material To inspect the currently installed version, use the following command: pip show mkdocs-material","title":"Upgrading"},{"location":"release-notes/#material-3x-to-4x","text":"Material for MkDocs 4.x finally fixes incorrect layout on Chinese systems. The fix includes a mandatory change of the base font-size from 10px to 20px which means all rem values needed to be updated. Within the theme, px to rem calculation is now encapsulated in a new function called px2rem which is part of the SASS code base. If you use Material with custom CSS that is based on rem values, note that those values must now be divided by 2. Now, 1.0rem doesn't map to 10px , but 20px . To learn more about the problem and implications, please refer to the issue in which the problem was discovered and fixed.","title":"Material 3.x to 4.x"},{"location":"release-notes/#material-2x-to-3x","text":"Material for MkDocs 3.x requires MkDocs 1.0 because the way paths are resolved internally changed significantly. Furthermore, pages was renamed to nav , so remember to adjust your mkdocs.yml file. All extended templates should continue to work but in order to make them future-proof the url filter should be introduced on all paths. Please see the official release notes for further guidance.","title":"Material 2.x to 3.x"},{"location":"release-notes/#material-1x-to-2x","text":"Material for MkDocs 2.x requires MkDocs 0.17.1, as this version introduced changes to the way themes can define options. The following variables inside your project's mkdocs.yml need to be renamed: extra.feature becomes theme.feature extra.palette becomes theme.palette extra.font becomes theme.font extra.logo becomes theme.logo Favicon support has been dropped by MkDocs, it must now be defined in theme.favicon (previously site_favicon ). Localization is now separated into theme language and search language. While there can only be a single language on theme-level, the search supports multiple languages which can be separated by commas. See the getting started guide for more guidance. The search tokenizer can now be set through extra.search.tokenizer .","title":"Material 1.x to 2.x"},{"location":"release-notes/#changelog","text":"","title":"Changelog"},{"location":"release-notes/#463-_-february-14-2020","text":"Removed optional third-party plugins from requirements.txt Updated Docker image to contain all supported third-party plugins","title":"4.6.3 _ February 14, 2020"},{"location":"release-notes/#462-_-february-8-2020","text":"Added Romanian translations Fixed #1451 : Inconsistent spacing for fenced code blocks","title":"4.6.2 _ February 8, 2020"},{"location":"release-notes/#461-_-february-8-2020","text":"Fixed #1324 : Metadata author only rendering first character Fixed #1393 : Set tabindex to 0 for skip to content link Fixed code blocks after Markdown 3.2 release Fixed errors in Japanese translations Improved Google Lighthouse score","title":"4.6.1 _ February 8, 2020"},{"location":"release-notes/#460-_-december-11-2019","text":"Added support for mkdocs-git-revision-date-localized-plugin Fixed invalid character in Google Fonts URL","title":"4.6.0 _ December 11, 2019"},{"location":"release-notes/#451-_-december-2-2019","text":"Added Thai translations Fixed missing assets in GitHub release .zip and .tar.gz","title":"4.5.1 _ December 2, 2019"},{"location":"release-notes/#450-_-november-16-2019","text":"Upgraded EmojiOne to Tweomji due to licensing issues Temporarily pinned PyMdown and Markdown due to upcoming changes Improved GitHub statistics retrieval Fixed errors in Greek translations","title":"4.5.0 _ November 16, 2019"},{"location":"release-notes/#443-_-october-3-2019","text":"Added Estonian translations Fixed removal of copyright banners in minified JavaScript Removed unnecessary title attributes from links in table of contents","title":"4.4.3 _ October 3, 2019"},{"location":"release-notes/#442-_-august-27-2019","text":"Added Afrikaans translations Fixed broken page title when h1 contained HTML tags Improved accessibility for IE users Removed unnecessary title attributes from links in navigation","title":"4.4.2 _ August 27, 2019"},{"location":"release-notes/#441-_-august-22-2019","text":"Added support for black as a primary color Fixed broken footer bar when h1 contained HTML tags","title":"4.4.1 _ August 22, 2019"},{"location":"release-notes/#440-_-june-15-2019","text":"Added Slovenian translations Reverted template minification in favor of mkdocs-minify-plugin Fixed #1114 : Tabs don't reappear when default font-size is smaller than 16","title":"4.4.0 _ June 15, 2019"},{"location":"release-notes/#431-_-may-23-2019","text":"Fixed spelling error in Danish translations","title":"4.3.1 _ May 23, 2019"},{"location":"release-notes/#430-_-may-17-2019","text":"Added support for changing header through metadata title property Added font-display: swap to Google Font loading logic Removed whitespace from templates, saving 4kb ( .7kb gzipped) per request Fixed alignment of repository icons on tablet and desktop","title":"4.3.0 _ May 17, 2019"},{"location":"release-notes/#420-_-april-28-2019","text":"Added Norwegian (Nynorsk) translations Fixed loss of focus in non-form input elements due to search hotkeys Fixed #1067 : Search hotkeys not working for mobile/tablet screensize Fixed #1068 : Search not correctly aligned for tablet screensize","title":"4.2.0 _ April 28, 2019"},{"location":"release-notes/#412-_-april-16-2019","text":"Fixed #1072 : HTML tags appearing in navigation link titles","title":"4.1.2 _ April 16, 2019"},{"location":"release-notes/#411-_-march-28-2019","text":"Fixed minor CSS errors detected during validation","title":"4.1.1 _ March 28, 2019"},{"location":"release-notes/#410-_-march-22-2019","text":"Fixed #1023 : Search for Asian languages broken after Lunr.js update Fixed #1026 : contenteditable elements loose focus on hotkeys","title":"4.1.0 _ March 22, 2019"},{"location":"release-notes/#402-_-march-1-2019","text":"Fixed #1012 : HTML character entities appear in search result titles","title":"4.0.2 _ March 1, 2019"},{"location":"release-notes/#401-_-february-13-2019","text":"Fixed #762 , #816 : Glitch in sidebar when collapsing items Fixed #869 : Automatically expand details before printing","title":"4.0.1 _ February 13, 2019"},{"location":"release-notes/#400-_-february-13-2019","text":"Added background on hover for table rows Removed Google Tag Manager and reverted to Google Analytics Removed blocks in partials - Jinja doesn't support them Fixed #911 : Chrome breaks layout if system language is Chinese [BREAKING] Fixed #976 : Removed FastClick","title":"4.0.0 _ February 13, 2019"},{"location":"release-notes/#330-_-january-29-2019","text":"Moved Google Analytics integration into head using Google Tag Manager Fixed #972 : Unicode slugifier breaks table of contents blur on scroll Fixed #974 : Additional links in table of contents break blur on scroll","title":"3.3.0 _ January 29, 2019"},{"location":"release-notes/#320-_-december-28-2018","text":"Added support for redirects using metadata refresh Fixed #921 : Load Google Analytics snippet asynchronously","title":"3.2.0 _ December 28, 2018"},{"location":"release-notes/#310-_-november-17-2018","text":"Added support for Progressive Web App Manifest Fixed #915 : Search bug in Safari (upgraded Lunr.js)","title":"3.1.0 _ November 17, 2018"},{"location":"release-notes/#306-_-october-26-2018","text":"Added Taiwanese translations Fixed #906 : JavaScript code blocks evaluated in search results","title":"3.0.6 _ October 26, 2018"},{"location":"release-notes/#305-_-october-23-2018","text":"Added Croatian and Indonesian translations Fixed #899 : Skip-to-content link invalid from 2 nd level on Fixed #902 : Missing URL filter in footer for FontAwesome link","title":"3.0.5 _ October 23, 2018"},{"location":"release-notes/#304-_-september-3-2018","text":"Updated Dutch translations Fixed #856 : Removed preconnect meta tag if Google Fonts are disabled","title":"3.0.4 _ September 3, 2018"},{"location":"release-notes/#303-_-august-7-2018","text":"Fixed #841 : Additional path levels for extra CSS and JS","title":"3.0.3 _ August 7, 2018"},{"location":"release-notes/#302-_-august-6-2018","text":"Fixed #839 : Lunr.js stemmer imports incorrect","title":"3.0.2 _ August 6, 2018"},{"location":"release-notes/#301-_-august-5-2018","text":"Fixed #838 : Search result links incorrect","title":"3.0.1 _ August 5, 2018"},{"location":"release-notes/#300-_-august-5-2018","text":"Upgraded MkDocs to 1.0 [BREAKING] Upgraded Python in official Docker image to 3.6 Added Serbian and Serbo-Croatian translations","title":"3.0.0 _ August 5, 2018"},{"location":"release-notes/#294-_-july-29-2018","text":"Fixed build error after MkDocs upgrade","title":"2.9.4 _ July 29, 2018"},{"location":"release-notes/#293-_-july-29-2018","text":"Added link to home for logo in drawer Fixed dependency problems between MkDocs and Tornado","title":"2.9.3 _ July 29, 2018"},{"location":"release-notes/#292-_-june-29-2018","text":"Added Hindi and Czech translations","title":"2.9.2 _ June 29, 2018"},{"location":"release-notes/#291-_-june-18-2018","text":"Added support for different spellings for theme color Fixed #799 : Added support for web font minification in production Fixed #800 : Added .highlighttable as an alias for .codehilitetable","title":"2.9.1 _ June 18, 2018"},{"location":"release-notes/#290-_-june-13-2018","text":"Added support for theme color on Android Fixed #796 : Rendering of nested tabbed code blocks","title":"2.9.0 _ June 13, 2018"},{"location":"release-notes/#280-_-june-10-2018","text":"Added support for grouping code blocks with tabs Added Material and FontAwesome icon fonts to distribution files (GDPR) Added note on compliance with GDPR Added Slovak translations Fixed #790 : Prefixed id attributes with __ to avoid name clashes","title":"2.8.0 _ June 10, 2018"},{"location":"release-notes/#273-_-april-26-2018","text":"Added Finnish translations","title":"2.7.3 _ April 26, 2018"},{"location":"release-notes/#272-_-april-9-2018","text":"Fixed rendering issue for details on Edge","title":"2.7.2 _ April 9, 2018"},{"location":"release-notes/#271-_-march-21-2018","text":"Added Galician translations Fixed #730 : Scroll chasing error on home page if Disqus is enabled Fixed #736 : Reset drawer and search upon back button invocation","title":"2.7.1 _ March 21, 2018"},{"location":"release-notes/#270-_-march-6-2018","text":"Added ability to set absolute URL for logo Added Hebrew translations","title":"2.7.0 _ March 6, 2018"},{"location":"release-notes/#266-_-february-22-2018","text":"Added preconnect for Google Fonts for faster loading Fixed #710 : With tabs sidebar disappears if JavaScript is not available","title":"2.6.6 _ February 22, 2018"},{"location":"release-notes/#265-_-february-22-2018","text":"Reverted --dev-addr flag removal from Dockerfile","title":"2.6.5 _ February 22, 2018"},{"location":"release-notes/#264-_-february-21-2018","text":"Added Catalan translations Fixed incorrect margins for buttons in Firefox and Safari Replaced package manager yarn with npm 5.6 Reverted GitHub stars rounding method Removed --dev-addr flag from Dockerfile for Windows compatibility","title":"2.6.4 _ February 21, 2018"},{"location":"release-notes/#263-_-february-18-2018","text":"Added Vietnamese translations","title":"2.6.3 _ February 18, 2018"},{"location":"release-notes/#262-_-february-12-2018","text":"Added Arabic translations Fixed incorrect rounding of amount of GitHub stars Fixed double-layered borders for tables","title":"2.6.2 _ February 12, 2018"},{"location":"release-notes/#261-_-february-11-2018","text":"Added ability to override Disqus integration using metadata Fixed #690 : Duplicate slashes in source file URLs Fixed #696 : Active page highlight not working with default palette Adjusted German translations","title":"2.6.1 _ February 11, 2018"},{"location":"release-notes/#260-_-february-2-2018","text":"Moved default search configuration to default translation (English) Added support to automatically set text direction from translation Added support to disable search stop word filter in translation Added support to disable search trimmer in translation Added Persian translations Fixed support for Polish search Fixed disappearing GitHub, GitLab and Bitbucket repository icons","title":"2.6.0 _ February 2, 2018"},{"location":"release-notes/#255-_-january-31-2018","text":"Added Hungarian translations","title":"2.5.5 _ January 31, 2018"},{"location":"release-notes/#254-_-january-29-2018","text":"Fixed #683 : gh-deploy fails inside Docker","title":"2.5.4 _ January 29, 2018"},{"location":"release-notes/#253-_-january-25-2018","text":"Added Ukrainian translations","title":"2.5.3 _ January 25, 2018"},{"location":"release-notes/#252-_-january-22-2018","text":"Added default search language mappings for all localizations Fixed #673 : Error loading non-existent search language Fixed #675 : Uncaught reference error when search plugin disabled","title":"2.5.2 _ January 22, 2018"},{"location":"release-notes/#251-_-january-20-2018","text":"Fixed permalink for main headline Improved missing translation handling with English as a fallback Improved accessibility with skip-to-content link","title":"2.5.1 _ January 20, 2018"},{"location":"release-notes/#250-_-january-13-2018","text":"Added support for right-to-left languages","title":"2.5.0 _ January 13, 2018"},{"location":"release-notes/#240-_-january-11-2018","text":"Added focus state for clipboard buttons Fixed #400 : Search bar steals tab focus Fixed search not closing on Enter when result is selected Fixed search not closing when losing focus due to Tab Fixed collapsed navigation links getting focus Fixed outline being cut off on Tab focus of navigation links Fixed bug with first search result navigation being ignored Removed search result navigation via Tab (use Up and Down ) Removed outline resets for links Improved general tabbing behavior on desktop","title":"2.4.0 _ January 11, 2018"},{"location":"release-notes/#230-_-january-9-2018","text":"Added example (synonym: snippet ) style for Admonition Added synonym abstract for summary style for Admonition","title":"2.3.0 _ January 9, 2018"},{"location":"release-notes/#226-_-december-27-2017","text":"Added Turkish translations Fixed unclickable area below header in case JavaScript is not available","title":"2.2.6 _ December 27, 2017"},{"location":"release-notes/#225-_-december-18-2017","text":"Fixed #639 : Broken default favicon","title":"2.2.5 _ December 18, 2017"},{"location":"release-notes/#224-_-december-18-2017","text":"Fixed #638 : Build breaks with Jinja < 2.9","title":"2.2.4 _ December 18, 2017"},{"location":"release-notes/#223-_-december-13-2017","text":"Fixed #630 : Admonition sets padding on any last child Adjusted Chinese (Traditional) translations","title":"2.2.3 _ December 13, 2017"},{"location":"release-notes/#222-_-december-8-2017","text":"Added Dutch translations Adjusted targeted link and footnote offsets Simplified Admonition styles and fixed padding bug","title":"2.2.2 _ December 8, 2017"},{"location":"release-notes/#221-_-december-2-2017","text":"Fixed #616 : Minor styling error with title-only admonition blocks Removed border for table of contents and improved spacing","title":"2.2.1 _ December 2, 2017"},{"location":"release-notes/#220-_-november-22-2017","text":"Added support for hero teaser Added Portuguese translations Fixed #586 : Footnote backref target offset regression Fixed #605 : Search stemmers not correctly loaded","title":"2.2.0 _ November 22, 2017"},{"location":"release-notes/#211-_-november-21-2017","text":"Replaced deprecated babel-preset-es2015 with babel-preset-env Refactored Gulp build pipeline with Webpack Removed right border on sidebars Fixed broken color transition on header","title":"2.1.1 _ November 21, 2017"},{"location":"release-notes/#210-_-november-19-2017","text":"Added support for white as a primary color Added support for sliding site name and title Fixed redundant clipboard button when using line numbers on code blocks Improved header appearance by making it taller Improved tabs appearance Improved CSS customizability by leveraging inheritance Removed scroll shadows via background-attachment","title":"2.1.0 _ November 19, 2017"},{"location":"release-notes/#204-_-november-5-2017","text":"Fixed details not opening with footnote reference","title":"2.0.4 _ November 5, 2017"},{"location":"release-notes/#203-_-november-5-2017","text":"Added Japanese translations Fixed #540 : Jumping to anchor inside details doesn't open it Fixed active link colors in footer","title":"2.0.3 _ November 5, 2017"},{"location":"release-notes/#202-_-november-1-2017","text":"Added Russian translations Fixed #542 : Horizontal scrollbar between 1220px and 1234px Fixed #553 : Metadata values only rendering first character Fixed #558 : Flash of unstyled content Fixed favicon regression caused by deprecation upstream","title":"2.0.2 _ November 1, 2017"},{"location":"release-notes/#201-_-october-31-2017","text":"Fixed error when initializing search Fixed styles for link to edit the current page Fixed styles on nested admonition in details","title":"2.0.1 _ October 31, 2017"},{"location":"release-notes/#200-_-october-31-2017","text":"Added support for MkDocs 0.17.1 theme configuration options Added support for easier configuration of search tokenizer Added support to disable search Added Korean translations Removed support for MkDocs 0.16.x [BREAKING]","title":"2.0.0 _ October 31, 2017"},{"location":"release-notes/#1122-_-october-26-2017","text":"Added Italian, Norwegian, French and Chinese translations","title":"1.12.2 _ October 26, 2017"},{"location":"release-notes/#1121-_-october-22-2017","text":"Added Polish, Swedish and Spanish translations Improved downward compatibility with custom partials Temporarily pinned MkDocs version within Docker image to 0.16.3 Fixed #519 : Missing theme configuration file","title":"1.12.1 _ October 22, 2017"},{"location":"release-notes/#1120-_-october-20-2017","text":"Added support for setting language(s) via mkdocs.yml Added support for default localization Added German and Danish translations Fixed #374 : Search bar misalignment on big screens","title":"1.12.0 _ October 20, 2017"},{"location":"release-notes/#1110-_-october-19-2017","text":"Added localization to clipboard Refactored localization logic","title":"1.11.0 _ October 19, 2017"},{"location":"release-notes/#1104-_-october-18-2017","text":"Improved print styles of code blocks Improved search UX (don't close on enter if no selection) Fixed #495 : Vertical scrollbar on short pages","title":"1.10.4 _ October 18, 2017"},{"location":"release-notes/#1103-_-october-11-2017","text":"Fixed #484 : Vertical scrollbar on some MathJax formulas Fixed #483 : Footnote backref target offset regression","title":"1.10.3 _ October 11, 2017"},{"location":"release-notes/#1102-_-october-6-2017","text":"Fixed #468 : Sidebar shows scrollbar if content is shorter (in Safari)","title":"1.10.2 _ October 6, 2017"},{"location":"release-notes/#1101-_-september-14-2017","text":"Fixed #455 : Bold code blocks rendered with normal font weight","title":"1.10.1 _ September 14, 2017"},{"location":"release-notes/#1100-_-september-1-2017","text":"Added support to make logo default icon configurable Fixed uninitialized overflow scrolling on main pane for iOS Fixed error in mobile navigation in case JavaScript is not available Fixed incorrect color transition for nested panes in mobile navigation Improved checkbox styles for Tasklist from PyMdown Extension package","title":"1.10.0 _ September 1, 2017"},{"location":"release-notes/#190-_-august-29-2017","text":"Added info (synonym: todo ) style for Admonition Added question (synonym: help , faq ) style for Admonition Added support for Details from PyMdown Extensions package Improved Admonition styles to match Details Improved styles for social links in footer Replaced ligatures with Unicode code points to avoid broken layout Upgraded PyMdown Extensions package dependency to >= 3.4","title":"1.9.0 _ August 29, 2017"},{"location":"release-notes/#181-_-august-7-2017","text":"Fixed #421 : Missing pagination for GitHub API","title":"1.8.1 _ August 7, 2017"},{"location":"release-notes/#180-_-august-2-2017","text":"Added support for lazy-loading of search results for better performance Added support for customization of search tokenizer/separator Fixed #424 : Search doesn't handle capital letters anymore Fixed #419 : Search doesn't work on whole words","title":"1.8.0 _ August 2, 2017"},{"location":"release-notes/#175-_-july-25-2017","text":"Fixed #398 : Forms broken due to search shortcuts Improved search overall user experience Improved search matching and highlighting Improved search accessibility","title":"1.7.5 _ July 25, 2017"},{"location":"release-notes/#174-_-june-21-2017","text":"Fixed functional link colors in table of contents for active palette Fixed #368 : Compatibility issues with IE11","title":"1.7.4 _ June 21, 2017"},{"location":"release-notes/#173-_-june-7-2017","text":"Fixed error when setting language to Japanese for site search","title":"1.7.3 _ June 7, 2017"},{"location":"release-notes/#172-_-june-6-2017","text":"Fixed offset of search box when repo_url is not set Fixed non-disappearing tooltip","title":"1.7.2 _ June 6, 2017"},{"location":"release-notes/#171-_-june-1-2017","text":"Fixed wrong z-index order of header, overlay and drawer Fixed wrong offset of targeted footnote back references","title":"1.7.1 _ June 1, 2017"},{"location":"release-notes/#170-_-june-1-2017","text":"Added \"copy to clipboard\" buttons to code blocks Added support for multilingual site search Fixed search term highlighting for non-latin languages","title":"1.7.0 _ June 1, 2017"},{"location":"release-notes/#164-_-may-24-2017","text":"Fixed #337 : JavaScript error for GitHub organization URLs","title":"1.6.4 _ May 24, 2017"},{"location":"release-notes/#163-_-may-16-2017","text":"Fixed #329 : Broken source stats for private or unknown GitHub repos","title":"1.6.3 _ May 16, 2017"},{"location":"release-notes/#162-_-may-15-2017","text":"Fixed #316 : Fatal error for git clone on Windows Fixed #320 : Chrome 58 creates double underline for abbr tags Fixed #323 : Ligatures rendered inside code blocks Fixed miscalculated sidebar height due to missing margin collapse Changed deprecated MathJax CDN to Cloudflare","title":"1.6.2 _ May 15, 2017"},{"location":"release-notes/#161-_-april-23-2017","text":"Fixed following of active/focused element if search input is focused Fixed layer order of search component elements","title":"1.6.1 _ April 23, 2017"},{"location":"release-notes/#160-_-april-22-2017","text":"Added build test for Docker image on Travis Added search overlay for better user experience (focus) Added language from localizations to html tag Fixed #270 : source links broken for absolute URLs Fixed missing top spacing for first targeted element in content Fixed too small footnote divider when using larger font sizes","title":"1.6.0 _ April 22, 2017"},{"location":"release-notes/#155-_-april-20-2017","text":"Fixed #282 : Browser search ( Meta + F ) is hijacked","title":"1.5.5 _ April 20, 2017"},{"location":"release-notes/#154-_-april-8-2017","text":"Fixed broken highlighting for two or more search terms Fixed missing search results when only a h1 is present Fixed unresponsive overlay on Android","title":"1.5.4 _ April 8, 2017"},{"location":"release-notes/#153-_-april-7-2017","text":"Fixed deprecated calls for template variables Fixed wrong palette color for focused search result Fixed JavaScript errors on 404 page Fixed missing top spacing on 404 page Fixed missing right spacing on overflow of source container","title":"1.5.3 _ April 7, 2017"},{"location":"release-notes/#152-_-april-5-2017","text":"Added requirements as explicit dependencies in setup.py Fixed non-synchronized transitions in search form","title":"1.5.2 _ April 5, 2017"},{"location":"release-notes/#151-_-march-30-2017","text":"Fixed rendering and offset of targetted footnotes Fixed #238 : Link on logo is not set to site_url","title":"1.5.1 _ March 30, 2017"},{"location":"release-notes/#150-_-march-24-2017","text":"Added support for localization of search placeholder Added keyboard events for quick access of search Added keyboard events for search control Added opacity on hover for search buttons Added git hook to skip CI build on non-src changes Fixed non-resetting search placeholder when input is cleared Fixed error for unescaped parentheses in search term Fixed #229 : Button to clear search missing Fixed #231 : Escape key doesn't exit search Removed old-style figures from font feature settings","title":"1.5.0 _ March 24, 2017"},{"location":"release-notes/#141-_-march-16-2017","text":"Fixed invalid destructuring attempt on NodeList (in Safari, Edge, IE)","title":"1.4.1 _ March 16, 2017"},{"location":"release-notes/#140-_-march-16-2017","text":"Added support for grouping searched sections by documents Added support for highlighting of search terms Added support for localization of search results Fixed #216 : table of contents icon doesn't show if h1 is not present Reworked style and layout of search results for better usability","title":"1.4.0 _ March 16, 2017"},{"location":"release-notes/#130-_-march-11-2017","text":"Added support for page-specific title and description using metadata Added support for linking source files to documentation Fixed jitter and offset of sidebar when zooming browser Fixed incorrectly initialized tablet sidebar height Fixed regression for #1 : GitHub stars break if repo_url ends with a / Fixed undesired white line below copyright footer due to base font scaling Fixed issue with whitespace in path for scripts Fixed #205 : support non-fixed (static) header Refactored footnote references for better visibility Reduced repaints to a minimum for non-tabs configuration Reduced contrast of edit button (slightly)","title":"1.3.0 _ March 11, 2017"},{"location":"release-notes/#120-_-march-3-2017","text":"Added quote (synonym: cite ) style for Admonition Added help message to build pipeline Fixed wrong navigation link colors when applying palette Fixed #197 : Link missing in tabs navigation on deeply nested items Removed unnecessary dev dependencies","title":"1.2.0 _ March 3, 2017"},{"location":"release-notes/#111-_-february-26-2017","text":"Fixed incorrectly displayed nested lists when using tabs","title":"1.1.1 _ February 26, 2017"},{"location":"release-notes/#110-_-february-26-2017","text":"Added tabs navigation feature (optional) Added Disqus integration (optional) Added a high resolution Favicon with the new logo Added static type checking using Facebook's Flow Fixed #173 : Dictionary elements have no bottom spacing Fixed #175 : Tables cannot be set to 100% width Fixed race conditions in build related to asset revisioning Fixed accidentally re-introduced Permalink on top-level headline Fixed alignment of logo in drawer on IE11 Refactored styles related to tables Refactored and automated Docker build and PyPI release Refactored build scripts","title":"1.1.0 _ February 26, 2017"},{"location":"release-notes/#105-_-february-18-2017","text":"Fixed #153 : Sidebar flows out of constrained area in Chrome 56 Fixed #159 : Footer jitter due to JavaScript if content is short","title":"1.0.5 _ February 18, 2017"},{"location":"release-notes/#104-_-february-16-2017","text":"Fixed #142 : Documentation build errors if h1 is defined as raw HTML Fixed #164 : PyPI release does not build and install Fixed offsets of targeted headlines Increased sidebar font size by 0.12rem","title":"1.0.4 _ February 16, 2017"},{"location":"release-notes/#103-_-january-22-2017","text":"Fixed #117 : Table of contents items don't blur on fast scrolling Refactored sidebar positioning logic Further reduction of repaints","title":"1.0.3 _ January 22, 2017"},{"location":"release-notes/#102-_-january-15-2017","text":"Fixed #108 : Horizontal scrollbar in content area","title":"1.0.2 _ January 15, 2017"},{"location":"release-notes/#101-_-january-14-2017","text":"Fixed massive repaints happening when scrolling Fixed footer back reference positions in case of overflow Fixed header logo from showing when the menu icon is rendered Changed scrollbar behavior to only show when content overflows","title":"1.0.1 _ January 14, 2017"},{"location":"release-notes/#100-_-january-13-2017","text":"Introduced Webpack for more sophisticated JavaScript bundling Introduced ESLint and Stylelint for code style checks Introduced more accurate Material Design colors and shadows Introduced modular scales for harmonic font sizing Introduced git-hooks for better development workflow Rewrite of CSS using the BEM methodology and SassDoc guidelines Rewrite of JavaScript using ES6 and Babel as a transpiler Rewrite of Admonition, Permalinks and CodeHilite integration Rewrite of the complete typographical system Rewrite of Gulp asset pipeline in ES6 and separation of tasks Removed Bower as a dependency in favor of NPM Removed custom icon build in favor of the Material Design iconset Removed _blank targets on links due to vulnerability: http://bit.ly/1Mk2Rtw Removed unversioned assets from build directory Restructured templates into base templates and partials Added build and watch scripts in package.json Added support for Metadata and Footnotes Markdown extensions Added support for PyMdown Extensions package Added support for collapsible sections in navigation Added support for separate table of contents Added support for better accessibility through REM-based layout Added icons for GitHub, GitLab and BitBucket integrations Added more detailed documentation on specimen, extensions etc. Added a 404.html error page for deployment on GitHub Pages Fixed live reload chain in watch mode when saving a template Fixed variable references to work with MkDocs 0.16","title":"1.0.0 _ January 13, 2017"},{"location":"release-notes/#024-_-june-26-2016","text":"Fixed improperly set default favicon Fixed #33 : Protocol relative URL for webfonts doesn't work with file:// Fixed #34 : IE11 on Windows 7 doesn't honor max-width on main tag Fixed #35 : Add styling for blockquotes","title":"0.2.4 _ June 26, 2016"},{"location":"release-notes/#023-_-may-16-2016","text":"Fixed #25 : Highlight inline fenced blocks Fixed #26 : Better highlighting for keystrokes Fixed #30 : Suboptimal syntax highlighting for PHP","title":"0.2.3 _ May 16, 2016"},{"location":"release-notes/#022-_-march-20-2016","text":"Fixed #15 : Document Pygments dependency for CodeHilite Fixed #16 : Favicon could not be set through mkdocs.yml Fixed #17 : Put version into own container for styling Fixed #20 : Fix rounded borders for tables","title":"0.2.2 _ March 20, 2016"},{"location":"release-notes/#021-_-march-12-2016","text":"Fixed #10 : Invisible header after closing search bar with ESC key Fixed #13 : Table cells don't wrap Fixed empty list in table of contents when no headline is defined Corrected wrong path for static asset monitoring in Gulpfile.js Set up tracking of site search for Google Analytics","title":"0.2.1 _ March 12, 2016"},{"location":"release-notes/#020-_-february-24-2016","text":"Fixed #6 : Include multiple color palettes via mkdocs.yml Fixed #7 : Better colors for links inside admonition notes and warnings Fixed #9 : Text for prev/next footer navigation should be customizable Refactored templates (replaced if / else with modifiers where possible)","title":"0.2.0 _ February 24, 2016"},{"location":"release-notes/#013-_-february-21-2016","text":"Fixed #3 : Ordered lists within an unordered list have ::before content Fixed #4 : Click on Logo/Title without Github-Repository: \"None\" Fixed #5 : Page without headlines renders empty list in table of contents Moved Modernizr to top to ensure basic usability in IE8","title":"0.1.3 _ February 21, 2016"},{"location":"release-notes/#012-_-february-16-2016","text":"Fixed styles for deep navigational hierarchies Fixed webfont delivery problem when hosted in subdirectories Fixed print styles in mobile/tablet configuration Added option to configure fonts in mkdocs.yml with fallbacks Changed styles for admonition notes and warnings Set download link to latest version if available Set up tracking of outgoing links and actions for Google Analytics","title":"0.1.2 _ February 16, 2016"},{"location":"release-notes/#011-_-february-11-2016","text":"Fixed #1 : GitHub stars don't work if the repo_url ends with a / Updated NPM and Bower dependencies to most recent versions Changed footer/copyright link to Material theme to GitHub pages Made MkDocs building/serving in build process optional Set up continuous integration with Travis","title":"0.1.1 _ February 11, 2016"},{"location":"release-notes/#010-_-february-9-2016","text":"Initial release","title":"0.1.0 _ February 9, 2016"},{"location":"specimen/","text":"Specimen1 \u00b6 Body copy1 \u00b6 Lorem ipsum dolor sit amet, consectetur adipiscing elit. Cras arcu libero, mollis sed massa vel, ornare viverra ex . Mauris a ullamcorper lacus. Nullam urna elit, malesuada eget finibus ut, ullamcorper ac tortor. Vestibulum sodales pulvinar nisl, pharetra aliquet est. Quisque volutpat erat ac nisi accumsan tempor. Sed suscipit , orci non pretium pretium, quam mi gravida metus, vel venenatis justo est condimentum diam. Maecenas non ornare justo. Nam a ipsum eros. Nulla aliquam orci sit amet nisl posuere malesuada. Proin aliquet nulla velit, quis ultricies orci feugiat et. Ut tincidunt sollicitudin tincidunt. Aenean ullamcorper sit amet nulla at interdum. Headings \u00b6 The 3 rd level \u00b6 The 4 th level \u00b6 The 5 th level \u00b6 The 6 th level \u00b6 Headings with secondary text \u00b6 The 3 rd level with secondary text \u00b6 The 4 th level with secondary text \u00b6 The 5 th level with secondary text \u00b6 The 6 th level with secondary text \u00b6 Blockquotes \u00b6 Morbi eget dapibus felis. Vivamus venenatis porttitor tortor sit amet rutrum. Pellentesque aliquet quam enim, eu volutpat urna rutrum a. Nam vehicula nunc mauris, a ultricies libero efficitur sed. Class aptent taciti sociosqu ad litora torquent per conubia nostra, per inceptos himenaeos. Sed molestie imperdiet consectetur. Blockquote nesting \u00b6 Sed aliquet , neque at rutrum mollis, neque nisi tincidunt nibh, vitae faucibus lacus nunc at lacus. Nunc scelerisque, quam id cursus sodales, lorem libero fermentum urna, ut efficitur elit ligula et nunc. Mauris dictum mi lacus, sit amet pellentesque urna vehicula fringilla. Ut sit amet placerat ante. Proin sed elementum nulla. Nunc vitae sem odio. Suspendisse ac eros arcu. Vivamus orci erat, volutpat a tempor et, rutrum. eu odio. Suspendisse rutrum facilisis risus , eu posuere neque commodo a. Interdum et malesuada fames ac ante ipsum primis in faucibus. Sed nec leo bibendum, sodales mauris ut, tincidunt massa. Other content blocks \u00b6 Vestibulum vitae orci quis ante viverra ultricies ut eget turpis. Sed eu lectus dapibus, eleifend nulla varius, lobortis turpis. In ac hendrerit nisl, sit amet laoreet nibh. var _extends = function ( target ) { for ( var i = 1 ; i < arguments . length ; i ++ ) { var source = arguments [ i ]; for ( var key in source ) { target [ key ] = source [ key ]; } } return target ; }; Praesent at return target , sodales nibh vel, tempor felis. Fusce vel lacinia lacus. Suspendisse rhoncus nunc non nisi iaculis ultrices. Donec consectetur mauris non neque imperdiet, eget volutpat libero. Lists \u00b6 Unordered lists \u00b6 Sed sagittis eleifend rutrum. Donec vitae suscipit est. Nullam tempus tellus non sem sollicitudin, quis rutrum leo facilisis. Nulla tempor lobortis orci, at elementum urna sodales vitae. In in vehicula nulla, quis ornare libero. Duis mollis est eget nibh volutpat, fermentum aliquet dui mollis. Nam vulputate tincidunt fringilla. Nullam dignissim ultrices urna non auctor. Aliquam metus eros, pretium sed nulla venenatis, faucibus auctor ex. Proin ut eros sed sapien ullamcorper consequat. Nunc ligula ante, fringilla at aliquam ac, aliquet sed mauris. Nulla et rhoncus turpis. Mauris ultricies elementum leo. Duis efficitur accumsan nibh eu mattis. Vivamus tempus velit eros, porttitor placerat nibh lacinia sed. Aenean in finibus diam. Ordered lists \u00b6 Integer vehicula feugiat magna, a mollis tellus. Nam mollis ex ante, quis elementum eros tempor rutrum. Aenean efficitur lobortis lacinia. Nulla consectetur feugiat sodales. Cum sociis natoque penatibus et magnis dis parturient montes, nascetur ridiculus mus. Aliquam ornare feugiat quam et egestas. Nunc id erat et quam pellentesque lacinia eu vel odio. Vivamus venenatis porttitor tortor sit amet rutrum. Pellentesque aliquet quam enim, eu volutpat urna rutrum a. Nam vehicula nunc mauris, a ultricies libero efficitur sed. Mauris dictum mi lacus Ut sit amet placerat ante Suspendisse ac eros arcu Morbi eget dapibus felis. Vivamus venenatis porttitor tortor sit amet rutrum. Pellentesque aliquet quam enim, eu volutpat urna rutrum a. Sed aliquet, neque at rutrum mollis, neque nisi tincidunt nibh. Pellentesque eget var _extends ornare tellus, ut gravida mi. var _extends = function ( target ) { for ( var i = 1 ; i < arguments . length ; i ++ ) { var source = arguments [ i ]; for ( var key in source ) { target [ key ] = source [ key ]; } } return target ; }; Vivamus id mi enim. Integer id turpis sapien. Ut condimentum lobortis sagittis. Aliquam purus tellus, faucibus eget urna at, iaculis venenatis nulla. Vivamus a pharetra leo. Definition lists \u00b6 Lorem ipsum dolor sit amet Sed sagittis eleifend rutrum. Donec vitae suscipit est. Nullam tempus tellus non sem sollicitudin, quis rutrum leo facilisis. Nulla tempor lobortis orci, at elementum urna sodales vitae. In in vehicula nulla. Duis mollis est eget nibh volutpat, fermentum aliquet dui mollis. Nam vulputate tincidunt fringilla. Nullam dignissim ultrices urna non auctor. Cras arcu libero Aliquam metus eros, pretium sed nulla venenatis, faucibus auctor ex. Proin ut eros sed sapien ullamcorper consequat. Nunc ligula ante, fringilla at aliquam ac, aliquet sed mauris. Code blocks \u00b6 Inline \u00b6 Morbi eget dapibus felis . Vivamus venenatis porttitor tortor sit amet rutrum. Class aptent taciti sociosqu ad litora torquent per conubia nostra, per inceptos himenaeos. Pellentesque aliquet quam enim , eu volutpat urna rutrum a. Nam vehicula nunc return target mauris, a ultricies libero efficitur sed. Sed molestie imperdiet consectetur. Vivamus a pharetra leo. Pellentesque eget ornare tellus, ut gravida mi. Fusce vel lacinia lacus. Listing \u00b6 1 2 3 4 5 6 7 8 9 var _extends = function ( target ) { for ( var i = 1 ; i < arguments . length ; i ++ ) { var source = arguments [ i ]; for ( var key in source ) { target [ key ] = source [ key ]; } } return target ; }; Horizontal rules \u00b6 Aenean in finibus diam. Duis mollis est eget nibh volutpat, fermentum aliquet dui mollis. Nam vulputate tincidunt fringilla. Nullam dignissim ultrices urna non auctor. Integer vehicula feugiat magna, a mollis tellus. Nam mollis ex ante, quis elementum eros tempor rutrum. Aenean efficitur lobortis lacinia. Nulla consectetur feugiat sodales. Data tables \u00b6 Sollicitudo / Pellentesi consectetur adipiscing elit arcu sed Vivamus a pharetra yes yes yes yes yes Ornare viverra ex yes yes yes yes yes Mauris a ullamcorper yes yes partial yes yes Nullam urna elit yes yes yes yes yes Malesuada eget finibus yes yes yes yes yes Ullamcorper yes yes yes yes yes Vestibulum sodales yes - yes - yes Pulvinar nisl yes yes yes - - Pharetra aliquet est yes yes yes yes yes Sed suscipit yes yes yes yes yes Orci non pretium yes partial - - - Sed sagittis eleifend rutrum. Donec vitae suscipit est. Nullam tempus tellus non sem sollicitudin, quis rutrum leo facilisis. Nulla tempor lobortis orci, at elementum urna sodales vitae. In in vehicula nulla, quis ornare libero. Left Center Right Lorem dolor amet ipsum sit Vestibulum vitae orci quis ante viverra ultricies ut eget turpis. Sed eu lectus dapibus, eleifend nulla varius, lobortis turpis. In ac hendrerit nisl, sit amet laoreet nibh. Table with colgroups (Pandoc) Lorem ipsum dolor sit amet. Sed sagittis eleifend rutrum. Donec vitae suscipit est.","title":"Specimen"},{"location":"specimen/#specimen1","text":"","title":"Specimen1"},{"location":"specimen/#body-copy1","text":"Lorem ipsum dolor sit amet, consectetur adipiscing elit. Cras arcu libero, mollis sed massa vel, ornare viverra ex . Mauris a ullamcorper lacus. Nullam urna elit, malesuada eget finibus ut, ullamcorper ac tortor. Vestibulum sodales pulvinar nisl, pharetra aliquet est. Quisque volutpat erat ac nisi accumsan tempor. Sed suscipit , orci non pretium pretium, quam mi gravida metus, vel venenatis justo est condimentum diam. Maecenas non ornare justo. Nam a ipsum eros. Nulla aliquam orci sit amet nisl posuere malesuada. Proin aliquet nulla velit, quis ultricies orci feugiat et. Ut tincidunt sollicitudin tincidunt. Aenean ullamcorper sit amet nulla at interdum.","title":"Body copy1"},{"location":"specimen/#headings","text":"","title":"Headings"},{"location":"specimen/#the-3rd-level","text":"","title":"The 3rd level"},{"location":"specimen/#the-4th-level","text":"","title":"The 4th level"},{"location":"specimen/#the-5th-level","text":"","title":"The 5th level"},{"location":"specimen/#the-6th-level","text":"","title":"The 6th level"},{"location":"specimen/#headings-with-secondary-text","text":"","title":"Headings with secondary text"},{"location":"specimen/#the-3rd-level-with-secondary-text","text":"","title":"The 3rd level with secondary text"},{"location":"specimen/#the-4th-level-with-secondary-text","text":"","title":"The 4th level with secondary text"},{"location":"specimen/#the-5th-level-with-secondary-text","text":"","title":"The 5th level with secondary text"},{"location":"specimen/#the-6th-level-with-secondary-text","text":"","title":"The 6th level with secondary text"},{"location":"specimen/#blockquotes","text":"Morbi eget dapibus felis. Vivamus venenatis porttitor tortor sit amet rutrum. Pellentesque aliquet quam enim, eu volutpat urna rutrum a. Nam vehicula nunc mauris, a ultricies libero efficitur sed. Class aptent taciti sociosqu ad litora torquent per conubia nostra, per inceptos himenaeos. Sed molestie imperdiet consectetur.","title":"Blockquotes"},{"location":"specimen/#blockquote-nesting","text":"Sed aliquet , neque at rutrum mollis, neque nisi tincidunt nibh, vitae faucibus lacus nunc at lacus. Nunc scelerisque, quam id cursus sodales, lorem libero fermentum urna, ut efficitur elit ligula et nunc. Mauris dictum mi lacus, sit amet pellentesque urna vehicula fringilla. Ut sit amet placerat ante. Proin sed elementum nulla. Nunc vitae sem odio. Suspendisse ac eros arcu. Vivamus orci erat, volutpat a tempor et, rutrum. eu odio. Suspendisse rutrum facilisis risus , eu posuere neque commodo a. Interdum et malesuada fames ac ante ipsum primis in faucibus. Sed nec leo bibendum, sodales mauris ut, tincidunt massa.","title":"Blockquote nesting"},{"location":"specimen/#other-content-blocks","text":"Vestibulum vitae orci quis ante viverra ultricies ut eget turpis. Sed eu lectus dapibus, eleifend nulla varius, lobortis turpis. In ac hendrerit nisl, sit amet laoreet nibh. var _extends = function ( target ) { for ( var i = 1 ; i < arguments . length ; i ++ ) { var source = arguments [ i ]; for ( var key in source ) { target [ key ] = source [ key ]; } } return target ; }; Praesent at return target , sodales nibh vel, tempor felis. Fusce vel lacinia lacus. Suspendisse rhoncus nunc non nisi iaculis ultrices. Donec consectetur mauris non neque imperdiet, eget volutpat libero.","title":"Other content blocks"},{"location":"specimen/#lists","text":"","title":"Lists"},{"location":"specimen/#unordered-lists","text":"Sed sagittis eleifend rutrum. Donec vitae suscipit est. Nullam tempus tellus non sem sollicitudin, quis rutrum leo facilisis. Nulla tempor lobortis orci, at elementum urna sodales vitae. In in vehicula nulla, quis ornare libero. Duis mollis est eget nibh volutpat, fermentum aliquet dui mollis. Nam vulputate tincidunt fringilla. Nullam dignissim ultrices urna non auctor. Aliquam metus eros, pretium sed nulla venenatis, faucibus auctor ex. Proin ut eros sed sapien ullamcorper consequat. Nunc ligula ante, fringilla at aliquam ac, aliquet sed mauris. Nulla et rhoncus turpis. Mauris ultricies elementum leo. Duis efficitur accumsan nibh eu mattis. Vivamus tempus velit eros, porttitor placerat nibh lacinia sed. Aenean in finibus diam.","title":"Unordered lists"},{"location":"specimen/#ordered-lists","text":"Integer vehicula feugiat magna, a mollis tellus. Nam mollis ex ante, quis elementum eros tempor rutrum. Aenean efficitur lobortis lacinia. Nulla consectetur feugiat sodales. Cum sociis natoque penatibus et magnis dis parturient montes, nascetur ridiculus mus. Aliquam ornare feugiat quam et egestas. Nunc id erat et quam pellentesque lacinia eu vel odio. Vivamus venenatis porttitor tortor sit amet rutrum. Pellentesque aliquet quam enim, eu volutpat urna rutrum a. Nam vehicula nunc mauris, a ultricies libero efficitur sed. Mauris dictum mi lacus Ut sit amet placerat ante Suspendisse ac eros arcu Morbi eget dapibus felis. Vivamus venenatis porttitor tortor sit amet rutrum. Pellentesque aliquet quam enim, eu volutpat urna rutrum a. Sed aliquet, neque at rutrum mollis, neque nisi tincidunt nibh. Pellentesque eget var _extends ornare tellus, ut gravida mi. var _extends = function ( target ) { for ( var i = 1 ; i < arguments . length ; i ++ ) { var source = arguments [ i ]; for ( var key in source ) { target [ key ] = source [ key ]; } } return target ; }; Vivamus id mi enim. Integer id turpis sapien. Ut condimentum lobortis sagittis. Aliquam purus tellus, faucibus eget urna at, iaculis venenatis nulla. Vivamus a pharetra leo.","title":"Ordered lists"},{"location":"specimen/#definition-lists","text":"Lorem ipsum dolor sit amet Sed sagittis eleifend rutrum. Donec vitae suscipit est. Nullam tempus tellus non sem sollicitudin, quis rutrum leo facilisis. Nulla tempor lobortis orci, at elementum urna sodales vitae. In in vehicula nulla. Duis mollis est eget nibh volutpat, fermentum aliquet dui mollis. Nam vulputate tincidunt fringilla. Nullam dignissim ultrices urna non auctor. Cras arcu libero Aliquam metus eros, pretium sed nulla venenatis, faucibus auctor ex. Proin ut eros sed sapien ullamcorper consequat. Nunc ligula ante, fringilla at aliquam ac, aliquet sed mauris.","title":"Definition lists"},{"location":"specimen/#code-blocks","text":"","title":"Code blocks"},{"location":"specimen/#inline","text":"Morbi eget dapibus felis . Vivamus venenatis porttitor tortor sit amet rutrum. Class aptent taciti sociosqu ad litora torquent per conubia nostra, per inceptos himenaeos. Pellentesque aliquet quam enim , eu volutpat urna rutrum a. Nam vehicula nunc return target mauris, a ultricies libero efficitur sed. Sed molestie imperdiet consectetur. Vivamus a pharetra leo. Pellentesque eget ornare tellus, ut gravida mi. Fusce vel lacinia lacus.","title":"Inline"},{"location":"specimen/#listing","text":"1 2 3 4 5 6 7 8 9 var _extends = function ( target ) { for ( var i = 1 ; i < arguments . length ; i ++ ) { var source = arguments [ i ]; for ( var key in source ) { target [ key ] = source [ key ]; } } return target ; };","title":"Listing"},{"location":"specimen/#horizontal-rules","text":"Aenean in finibus diam. Duis mollis est eget nibh volutpat, fermentum aliquet dui mollis. Nam vulputate tincidunt fringilla. Nullam dignissim ultrices urna non auctor. Integer vehicula feugiat magna, a mollis tellus. Nam mollis ex ante, quis elementum eros tempor rutrum. Aenean efficitur lobortis lacinia. Nulla consectetur feugiat sodales.","title":"Horizontal rules"},{"location":"specimen/#data-tables","text":"Sollicitudo / Pellentesi consectetur adipiscing elit arcu sed Vivamus a pharetra yes yes yes yes yes Ornare viverra ex yes yes yes yes yes Mauris a ullamcorper yes yes partial yes yes Nullam urna elit yes yes yes yes yes Malesuada eget finibus yes yes yes yes yes Ullamcorper yes yes yes yes yes Vestibulum sodales yes - yes - yes Pulvinar nisl yes yes yes - - Pharetra aliquet est yes yes yes yes yes Sed suscipit yes yes yes yes yes Orci non pretium yes partial - - - Sed sagittis eleifend rutrum. Donec vitae suscipit est. Nullam tempus tellus non sem sollicitudin, quis rutrum leo facilisis. Nulla tempor lobortis orci, at elementum urna sodales vitae. In in vehicula nulla, quis ornare libero. Left Center Right Lorem dolor amet ipsum sit Vestibulum vitae orci quis ante viverra ultricies ut eget turpis. Sed eu lectus dapibus, eleifend nulla varius, lobortis turpis. In ac hendrerit nisl, sit amet laoreet nibh. Table with colgroups (Pandoc) Lorem ipsum dolor sit amet. Sed sagittis eleifend rutrum. Donec vitae suscipit est.","title":"Data tables"},{"location":"en/","text":"Wallarm Overview \u00b6 Wallarm is a DevOps-friendly Web Application Firewall (WAF) uniquely suited to protect your cloud applications and APIs. Wallarm's hybrid architecture safeguards your resources by offering: Protection from hacker attacks. Automatic detection of vulnerabilities . Wallarm does the following: Discovers Discovers your company's hosts, domains, and services accessible from the outside by combining deep scanning and accessing data from external sources. Analyzes Applies machine learning to reconstruct the application logic and API schema based on the resource's traffic. Creates dynamic blocking rules based on abnormal data patterns. Protects Blocks unauthorized access, evaluates attacks, and alerts on high-risk attempts targeted at the validated vulnerabilities. Applies virtual patches. Verifies Analyzes and actively replays the applications' input/output payloads to determine if an exploit is possible. Test tabs \u00b6 Tab 1 Markdown content . Multiple paragraphs. Tab 2 More Markdown content . list item a list item b Tab A Different tab set. Tab B More content. Feedback \u00b6 Twitter @wallarm Email request@wallarm.com Support support@wallarm.com","title":"Home"},{"location":"en/#wallarm-overview","text":"Wallarm is a DevOps-friendly Web Application Firewall (WAF) uniquely suited to protect your cloud applications and APIs. Wallarm's hybrid architecture safeguards your resources by offering: Protection from hacker attacks. Automatic detection of vulnerabilities . Wallarm does the following: Discovers Discovers your company's hosts, domains, and services accessible from the outside by combining deep scanning and accessing data from external sources. Analyzes Applies machine learning to reconstruct the application logic and API schema based on the resource's traffic. Creates dynamic blocking rules based on abnormal data patterns. Protects Blocks unauthorized access, evaluates attacks, and alerts on high-risk attempts targeted at the validated vulnerabilities. Applies virtual patches. Verifies Analyzes and actively replays the applications' input/output payloads to determine if an exploit is possible.","title":"Wallarm Overview"},{"location":"en/#test-tabs","text":"Tab 1 Markdown content . Multiple paragraphs. Tab 2 More Markdown content . list item a list item b Tab A Different tab set. Tab B More content.","title":"Test tabs"},{"location":"en/#feedback","text":"Twitter @wallarm Email request@wallarm.com Support support@wallarm.com","title":"Feedback"},{"location":"en/SUMMARY-envoy-unhidden/","text":"Summary \u00b6 Wallarm Overview Quick Start \u00b6 How Wallarm Works Prerequisites Installation Creating the Wallarm Account Install the Filter Node (NGINX) Configure Traffic Proxying Check the Filter Node Operation Administrator Guide \u00b6 Introduction Installation Supported Platforms NGINX Installation Options Overview Installing as a Dynamic Module for NGINX Installing as a Dynamic Module with NGINX from Debian/CentOS Repositories Installing with NGINX Plus Installing with Docker Envoy Installing with Docker Kubernetes Installing Wallarm Ingress Controller Installing NGINX Ingress Controller with Integrated Wallarm Services Installing NGINX Plus Ingress Controller with Integrated Wallarm Services Introduction Building the Wallarm NGINX Plus Ingress Controller Deploying the Wallarm NGINX Plus Ingress Controller Creating an Ingress Resource Checking the Operation of the Wallarm Services Installing Wallarm Sidecar Container How It Works Kubernetes Deployment Based on Helm Charts Kubernetes Deployment Based on Manifests Cloud Platforms Installation Options Overview Installing on Amazon AWS Creating and Configuring the Wallarm Filter Node Instance Creating an Amazon Machine Image Setting Up Filter Node Auto-Scaling Overview Setting Up Filter Node Auto-Scaling Setting Up Incoming Request Balancing Installing on the Google Cloud Platform Creating and Configuring the Wallarm Filter Node Instance Creating an Image with the Wallarm Filter Node Setting Up Filter Node Auto-Scaling Overview Creating a Filter Node Instance Template Creating a Managed Instance Group with Enabled Auto-Scaling Setting up Incoming Request Balancing Installing on Heroku Installing on the Kong Platform Installing on Linux [DEPRECATED] Separate Postanalytics Installation Checking the Filter Node Operation Configuration Configuration Options (NGINX) Configuration Options (Envoy) Filtering Mode Configuration Configuring and Working with the Statistics Service Fine-tuning of Wallarm Ingress Controller Analyzing Mirrored Traffic with NGINX Blocking Part of a Website Settings for Using a Balancer or Proxy Masking Sensitive Data Filter Node and Cloud Synchronization Configuration Working with Filter Node Logs Using Single Sign-On (SSO) Introduction Connecting SSO with G Suite Overview Step 1: Generating Parameters on the Wallarm Side Step 2: Creating and Configuring an Application in G Suite Step 3: Transferring G Suite Metadata to the Wallarm Setup Wizard Step 4: Allowing Access to the Wallarm Application on the G Suite Side Connecting SSO with Okta Overview Step 1: Generating Parameters on the Wallarm Side Step 2: Creating and Configuring an Application in Okta Step 3: Transferring Okta Metadata to the Wallarm Setup Wizard Step 4: Allowing Access to the Wallarm Application on the Okta Side Configuring SSO Authentication for Users Disabling and Removing the Configured SSO Provider Integration Configuring a Failover Method Blocking by IP Address Methods of Blocking by IP Address Blocking with iptables Blocking with NGINX Using a Mirrored Wallarm Repository How to Mirror the Wallarm Repository for CentOS How to Install Wallarm Packages from the Local JFrog Artifactory Repository for CentOS Monitoring the Filter Node Introduction How to Fetch Metrics Available Metrics Examples of Exporting and Working with Metrics Grafana Exporting Metrics to InfluxDB via the collectd Network Plugin Exporting Metrics to Graphite via the collectd Write Plugin Working with the Filter Node Metrics in Grafana Nagios Exporting Metrics to Nagios via the collectd-nagios Utility Working with the Filter Node Metrics in Nagios Zabbix Exporting Metrics to Zabbix via the collectd-nagios Utility Working with the Filter Node in Zabbix Updating and Migrating Updating on Linux Updating the Separately Installed Postanalytics Module Updating Docker Migrating the Filter Node 2.12 to 2.14 on Linux Operations Changing Tarantool Memory Allocation Wallarm User Acceptance Testing Checklist Troubleshooting Filter Node Errors out with \u00ablibproton error: did not allocate memory\u00bb [DEPRECATED] File Download Scenarios Fail Wallarm API Support of the Scanner Operation Disabling the IP Address Blocking of the Wallarm Scanner Scanner Addresses Scanner Addresses for EU Cloud Scanner Addresses for US Cloud Contacting Wallarm Support to Stop the Scanner User guide \u00b6 Introduction Dashboards Overview The \u201cWAF\u201d Dashboard The \u201cScanner\u201d Dashboard Events Checking Events Analyzing Attacks Working with False Attacks Verifying Attacks Vulnerabilities Checking Vulnerabilities Analyzing Vulnerabilities Closing and Opening Vulnerabilities Rechecking Vulnerabilities Working with False Vulnerabilities Search and Filters Using Search Using Filters Creating a Custom Report Scanner Scanner Overview Working with the Scope Reserved Domains Scanner Settings Configuring Scanner Modules Nodes Nodes Overview Creating and Managing a Node Rules Application Profile Rules Inspecting Application Profile Rules Adding Rules in the Application Profile Compilation and Update Of Security Rules How Wallarm Analyzes Requests Filter Mode Rule Rules for Data Masking Virtual Patching User-Defined Detection Rules Triggers What are Triggers Creating Triggers Disabling Triggers Deleting Triggers IP Address Blacklist Settings Profile General Subscriptions Applications Markers Users Activity Log Integrations Integrations Overview Email Reports and Notifications Slack Notifications Telegram Reports and Notifications OpsGenie Notifications PagerDuty Notifications Splunk Notifications Sumo Logic Notifications Guide to Using SSO Authentication to Log in to Wallarm Partner Guide \u00b6 Introduction Signing up with Wallarm Getting your UUID and Secret Key Installing the Filter Node Creating a Tenant Configuring Traffic Processing Release Notes \u00b6 Version 2.14 Version 2.12 Version 2.10 Version 2.8 Version 2.6 Version 2.4 Version 2.2 Appendix \u00b6 Glossary Attacks and Vulnerabilities List Contacting the Support Team","title":"Summary"},{"location":"en/SUMMARY-envoy-unhidden/#summary","text":"Wallarm Overview","title":"Summary"},{"location":"en/SUMMARY-envoy-unhidden/#quick-start","text":"How Wallarm Works Prerequisites Installation Creating the Wallarm Account Install the Filter Node (NGINX) Configure Traffic Proxying Check the Filter Node Operation","title":"Quick Start"},{"location":"en/SUMMARY-envoy-unhidden/#administrator-guide","text":"Introduction Installation Supported Platforms NGINX Installation Options Overview Installing as a Dynamic Module for NGINX Installing as a Dynamic Module with NGINX from Debian/CentOS Repositories Installing with NGINX Plus Installing with Docker Envoy Installing with Docker Kubernetes Installing Wallarm Ingress Controller Installing NGINX Ingress Controller with Integrated Wallarm Services Installing NGINX Plus Ingress Controller with Integrated Wallarm Services Introduction Building the Wallarm NGINX Plus Ingress Controller Deploying the Wallarm NGINX Plus Ingress Controller Creating an Ingress Resource Checking the Operation of the Wallarm Services Installing Wallarm Sidecar Container How It Works Kubernetes Deployment Based on Helm Charts Kubernetes Deployment Based on Manifests Cloud Platforms Installation Options Overview Installing on Amazon AWS Creating and Configuring the Wallarm Filter Node Instance Creating an Amazon Machine Image Setting Up Filter Node Auto-Scaling Overview Setting Up Filter Node Auto-Scaling Setting Up Incoming Request Balancing Installing on the Google Cloud Platform Creating and Configuring the Wallarm Filter Node Instance Creating an Image with the Wallarm Filter Node Setting Up Filter Node Auto-Scaling Overview Creating a Filter Node Instance Template Creating a Managed Instance Group with Enabled Auto-Scaling Setting up Incoming Request Balancing Installing on Heroku Installing on the Kong Platform Installing on Linux [DEPRECATED] Separate Postanalytics Installation Checking the Filter Node Operation Configuration Configuration Options (NGINX) Configuration Options (Envoy) Filtering Mode Configuration Configuring and Working with the Statistics Service Fine-tuning of Wallarm Ingress Controller Analyzing Mirrored Traffic with NGINX Blocking Part of a Website Settings for Using a Balancer or Proxy Masking Sensitive Data Filter Node and Cloud Synchronization Configuration Working with Filter Node Logs Using Single Sign-On (SSO) Introduction Connecting SSO with G Suite Overview Step 1: Generating Parameters on the Wallarm Side Step 2: Creating and Configuring an Application in G Suite Step 3: Transferring G Suite Metadata to the Wallarm Setup Wizard Step 4: Allowing Access to the Wallarm Application on the G Suite Side Connecting SSO with Okta Overview Step 1: Generating Parameters on the Wallarm Side Step 2: Creating and Configuring an Application in Okta Step 3: Transferring Okta Metadata to the Wallarm Setup Wizard Step 4: Allowing Access to the Wallarm Application on the Okta Side Configuring SSO Authentication for Users Disabling and Removing the Configured SSO Provider Integration Configuring a Failover Method Blocking by IP Address Methods of Blocking by IP Address Blocking with iptables Blocking with NGINX Using a Mirrored Wallarm Repository How to Mirror the Wallarm Repository for CentOS How to Install Wallarm Packages from the Local JFrog Artifactory Repository for CentOS Monitoring the Filter Node Introduction How to Fetch Metrics Available Metrics Examples of Exporting and Working with Metrics Grafana Exporting Metrics to InfluxDB via the collectd Network Plugin Exporting Metrics to Graphite via the collectd Write Plugin Working with the Filter Node Metrics in Grafana Nagios Exporting Metrics to Nagios via the collectd-nagios Utility Working with the Filter Node Metrics in Nagios Zabbix Exporting Metrics to Zabbix via the collectd-nagios Utility Working with the Filter Node in Zabbix Updating and Migrating Updating on Linux Updating the Separately Installed Postanalytics Module Updating Docker Migrating the Filter Node 2.12 to 2.14 on Linux Operations Changing Tarantool Memory Allocation Wallarm User Acceptance Testing Checklist Troubleshooting Filter Node Errors out with \u00ablibproton error: did not allocate memory\u00bb [DEPRECATED] File Download Scenarios Fail Wallarm API Support of the Scanner Operation Disabling the IP Address Blocking of the Wallarm Scanner Scanner Addresses Scanner Addresses for EU Cloud Scanner Addresses for US Cloud Contacting Wallarm Support to Stop the Scanner","title":"Administrator Guide"},{"location":"en/SUMMARY-envoy-unhidden/#user-guide","text":"Introduction Dashboards Overview The \u201cWAF\u201d Dashboard The \u201cScanner\u201d Dashboard Events Checking Events Analyzing Attacks Working with False Attacks Verifying Attacks Vulnerabilities Checking Vulnerabilities Analyzing Vulnerabilities Closing and Opening Vulnerabilities Rechecking Vulnerabilities Working with False Vulnerabilities Search and Filters Using Search Using Filters Creating a Custom Report Scanner Scanner Overview Working with the Scope Reserved Domains Scanner Settings Configuring Scanner Modules Nodes Nodes Overview Creating and Managing a Node Rules Application Profile Rules Inspecting Application Profile Rules Adding Rules in the Application Profile Compilation and Update Of Security Rules How Wallarm Analyzes Requests Filter Mode Rule Rules for Data Masking Virtual Patching User-Defined Detection Rules Triggers What are Triggers Creating Triggers Disabling Triggers Deleting Triggers IP Address Blacklist Settings Profile General Subscriptions Applications Markers Users Activity Log Integrations Integrations Overview Email Reports and Notifications Slack Notifications Telegram Reports and Notifications OpsGenie Notifications PagerDuty Notifications Splunk Notifications Sumo Logic Notifications Guide to Using SSO Authentication to Log in to Wallarm","title":"User guide"},{"location":"en/SUMMARY-envoy-unhidden/#partner-guide","text":"Introduction Signing up with Wallarm Getting your UUID and Secret Key Installing the Filter Node Creating a Tenant Configuring Traffic Processing","title":"Partner Guide"},{"location":"en/SUMMARY-envoy-unhidden/#release-notes","text":"Version 2.14 Version 2.12 Version 2.10 Version 2.8 Version 2.6 Version 2.4 Version 2.2","title":"Release Notes"},{"location":"en/SUMMARY-envoy-unhidden/#appendix","text":"Glossary Attacks and Vulnerabilities List Contacting the Support Team","title":"Appendix"},{"location":"en/SUMMARY/","text":"Summary \u00b6 Wallarm Overview Quick Start \u00b6 How Wallarm Works Prerequisites Installation Creating the Wallarm Account Install the Filter Node (NGINX) Configure Traffic Proxying Check the Filter Node Operation Administrator Guide \u00b6 Introduction Installation Supported Platforms NGINX Installation Options Overview Installing as a Dynamic Module for NGINX Installing as a Dynamic Module with NGINX from Debian/CentOS Repositories Installing with NGINX Plus Installing with Docker Kubernetes Installing Wallarm Ingress Controller Installing NGINX Ingress Controller with Integrated Wallarm Services Installing NGINX Plus Ingress Controller with Integrated Wallarm Services Introduction Building the Wallarm NGINX Plus Ingress Controller Deploying the Wallarm NGINX Plus Ingress Controller Creating an Ingress Resource Checking the Operation of the Wallarm Services Installing Wallarm Sidecar Container How It Works Kubernetes Deployment Based on Helm Charts Kubernetes Deployment Based on Manifests Cloud Platforms Installation Options Overview Installing on Amazon AWS Creating and Configuring the Wallarm Filter Node Instance Creating an Amazon Machine Image Setting Up Filter Node Auto-Scaling Overview Setting Up Filter Node Auto-Scaling Setting Up Incoming Request Balancing Installing on the Google Cloud Platform Creating and Configuring the Wallarm Filter Node Instance Creating an Image with the Wallarm Filter Node Setting Up Filter Node Auto-Scaling Overview Creating a Filter Node Instance Template Creating a Managed Instance Group with Enabled Auto-Scaling Setting up Incoming Request Balancing Installing on Heroku Installing on the Kong Platform Installing on Linux [DEPRECATED] Separate Postanalytics Installation Checking the Filter Node Operation Configuration Configuration Options (NGINX) Filtering Mode Configuration Configuring and Working with the Statistics Service Fine-tuning of Wallarm Ingress Controller Analyzing Mirrored Traffic with NGINX Blocking Part of a Website Settings for Using a Balancer or Proxy Masking Sensitive Data Filter Node and Cloud Synchronization Configuration Working with Filter Node Logs Using Single Sign-On (SSO) Introduction Connecting SSO with G Suite Overview Step 1: Generating Parameters on the Wallarm Side Step 2: Creating and Configuring an Application in G Suite Step 3: Transferring G Suite Metadata to the Wallarm Setup Wizard Step 4: Allowing Access to the Wallarm Application on the G Suite Side Connecting SSO with Okta Overview Step 1: Generating Parameters on the Wallarm Side Step 2: Creating and Configuring an Application in Okta Step 3: Transferring Okta Metadata to the Wallarm Setup Wizard Step 4: Allowing Access to the Wallarm Application on the Okta Side Configuring SSO Authentication for Users Disabling and Removing the Configured SSO Provider Integration Configuring a Failover Method Blocking by IP Address Methods of Blocking by IP Address Blocking with iptables Blocking with NGINX Using a Mirrored Wallarm Repository How to Mirror the Wallarm Repository for CentOS How to Install Wallarm Packages from the Local JFrog Artifactory Repository for CentOS Monitoring the Filter Node Introduction How to Fetch Metrics Available Metrics Examples of Exporting and Working with Metrics Grafana Exporting Metrics to InfluxDB via the collectd Network Plugin Exporting Metrics to Graphite via the collectd Write Plugin Working with the Filter Node Metrics in Grafana Nagios Exporting Metrics to Nagios via the collectd-nagios Utility Working with the Filter Node Metrics in Nagios Zabbix Exporting Metrics to Zabbix via the collectd-nagios Utility Working with the Filter Node in Zabbix Updating and Migrating Updating on Linux Updating the Separately Installed Postanalytics Module Updating Docker Migrating the Filter Node 2.12 to 2.14 on Linux Operations Configuring SELinux Changing Tarantool Memory Allocation Wallarm User Acceptance Testing Checklist Troubleshooting Filter Node Errors out with \u00ablibproton error: did not allocate memory\u00bb [DEPRECATED] File Download Scenarios Fail Wallarm API Support of the Scanner Operation Disabling the IP Address Blocking of the Wallarm Scanner Scanner Addresses Scanner Addresses for EU Cloud Scanner Addresses for US Cloud Contacting Wallarm Support to Stop the Scanner User guide \u00b6 Introduction Dashboards Overview The \u201cWAF\u201d Dashboard The \u201cScanner\u201d Dashboard Events Checking Events Analyzing Attacks Working with False Attacks Verifying Attacks Vulnerabilities Checking Vulnerabilities Analyzing Vulnerabilities Closing and Opening Vulnerabilities Rechecking Vulnerabilities Working with False Vulnerabilities Search and Filters Using Search Using Filters Creating a Custom Report Scanner Scanner Overview Working with the Scope Reserved Domains Scanner Settings Configuring Scanner Modules Nodes Nodes Overview Creating and Managing a Node Rules Application Profile Rules Inspecting Application Profile Rules Adding Rules in the Application Profile Compilation and Update Of Security Rules How Wallarm Analyzes Requests Filter Mode Rule Rules for Data Masking Virtual Patching User-Defined Detection Rules Triggers What are Triggers Creating Triggers Disabling Triggers Deleting Triggers IP Address Blacklist Settings Profile General Subscriptions Applications Markers Users Activity Log Integrations Integrations Overview Email Reports and Notifications Slack Notifications Telegram Reports and Notifications OpsGenie Notifications PagerDuty Notifications Splunk Notifications Sumo Logic Notifications Guide to Using SSO Authentication to Log in to Wallarm Partner Guide \u00b6 Introduction Signing up with Wallarm Getting your UUID and Secret Key Installing the Filter Node Creating a Tenant Configuring Traffic Processing Release Notes \u00b6 Version 2.14 Version 2.12 Version 2.10 Version 2.8 Version 2.6 Version 2.4 Version 2.2 Appendix \u00b6 Glossary Attacks and Vulnerabilities List Contacting the Support Team Envoy Installing with Docker Configuration Options (Envoy)","title":"Summary"},{"location":"en/SUMMARY/#summary","text":"Wallarm Overview","title":"Summary"},{"location":"en/SUMMARY/#quick-start","text":"How Wallarm Works Prerequisites Installation Creating the Wallarm Account Install the Filter Node (NGINX) Configure Traffic Proxying Check the Filter Node Operation","title":"Quick Start"},{"location":"en/SUMMARY/#administrator-guide","text":"Introduction Installation Supported Platforms NGINX Installation Options Overview Installing as a Dynamic Module for NGINX Installing as a Dynamic Module with NGINX from Debian/CentOS Repositories Installing with NGINX Plus Installing with Docker Kubernetes Installing Wallarm Ingress Controller Installing NGINX Ingress Controller with Integrated Wallarm Services Installing NGINX Plus Ingress Controller with Integrated Wallarm Services Introduction Building the Wallarm NGINX Plus Ingress Controller Deploying the Wallarm NGINX Plus Ingress Controller Creating an Ingress Resource Checking the Operation of the Wallarm Services Installing Wallarm Sidecar Container How It Works Kubernetes Deployment Based on Helm Charts Kubernetes Deployment Based on Manifests Cloud Platforms Installation Options Overview Installing on Amazon AWS Creating and Configuring the Wallarm Filter Node Instance Creating an Amazon Machine Image Setting Up Filter Node Auto-Scaling Overview Setting Up Filter Node Auto-Scaling Setting Up Incoming Request Balancing Installing on the Google Cloud Platform Creating and Configuring the Wallarm Filter Node Instance Creating an Image with the Wallarm Filter Node Setting Up Filter Node Auto-Scaling Overview Creating a Filter Node Instance Template Creating a Managed Instance Group with Enabled Auto-Scaling Setting up Incoming Request Balancing Installing on Heroku Installing on the Kong Platform Installing on Linux [DEPRECATED] Separate Postanalytics Installation Checking the Filter Node Operation Configuration Configuration Options (NGINX) Filtering Mode Configuration Configuring and Working with the Statistics Service Fine-tuning of Wallarm Ingress Controller Analyzing Mirrored Traffic with NGINX Blocking Part of a Website Settings for Using a Balancer or Proxy Masking Sensitive Data Filter Node and Cloud Synchronization Configuration Working with Filter Node Logs Using Single Sign-On (SSO) Introduction Connecting SSO with G Suite Overview Step 1: Generating Parameters on the Wallarm Side Step 2: Creating and Configuring an Application in G Suite Step 3: Transferring G Suite Metadata to the Wallarm Setup Wizard Step 4: Allowing Access to the Wallarm Application on the G Suite Side Connecting SSO with Okta Overview Step 1: Generating Parameters on the Wallarm Side Step 2: Creating and Configuring an Application in Okta Step 3: Transferring Okta Metadata to the Wallarm Setup Wizard Step 4: Allowing Access to the Wallarm Application on the Okta Side Configuring SSO Authentication for Users Disabling and Removing the Configured SSO Provider Integration Configuring a Failover Method Blocking by IP Address Methods of Blocking by IP Address Blocking with iptables Blocking with NGINX Using a Mirrored Wallarm Repository How to Mirror the Wallarm Repository for CentOS How to Install Wallarm Packages from the Local JFrog Artifactory Repository for CentOS Monitoring the Filter Node Introduction How to Fetch Metrics Available Metrics Examples of Exporting and Working with Metrics Grafana Exporting Metrics to InfluxDB via the collectd Network Plugin Exporting Metrics to Graphite via the collectd Write Plugin Working with the Filter Node Metrics in Grafana Nagios Exporting Metrics to Nagios via the collectd-nagios Utility Working with the Filter Node Metrics in Nagios Zabbix Exporting Metrics to Zabbix via the collectd-nagios Utility Working with the Filter Node in Zabbix Updating and Migrating Updating on Linux Updating the Separately Installed Postanalytics Module Updating Docker Migrating the Filter Node 2.12 to 2.14 on Linux Operations Configuring SELinux Changing Tarantool Memory Allocation Wallarm User Acceptance Testing Checklist Troubleshooting Filter Node Errors out with \u00ablibproton error: did not allocate memory\u00bb [DEPRECATED] File Download Scenarios Fail Wallarm API Support of the Scanner Operation Disabling the IP Address Blocking of the Wallarm Scanner Scanner Addresses Scanner Addresses for EU Cloud Scanner Addresses for US Cloud Contacting Wallarm Support to Stop the Scanner","title":"Administrator Guide"},{"location":"en/SUMMARY/#user-guide","text":"Introduction Dashboards Overview The \u201cWAF\u201d Dashboard The \u201cScanner\u201d Dashboard Events Checking Events Analyzing Attacks Working with False Attacks Verifying Attacks Vulnerabilities Checking Vulnerabilities Analyzing Vulnerabilities Closing and Opening Vulnerabilities Rechecking Vulnerabilities Working with False Vulnerabilities Search and Filters Using Search Using Filters Creating a Custom Report Scanner Scanner Overview Working with the Scope Reserved Domains Scanner Settings Configuring Scanner Modules Nodes Nodes Overview Creating and Managing a Node Rules Application Profile Rules Inspecting Application Profile Rules Adding Rules in the Application Profile Compilation and Update Of Security Rules How Wallarm Analyzes Requests Filter Mode Rule Rules for Data Masking Virtual Patching User-Defined Detection Rules Triggers What are Triggers Creating Triggers Disabling Triggers Deleting Triggers IP Address Blacklist Settings Profile General Subscriptions Applications Markers Users Activity Log Integrations Integrations Overview Email Reports and Notifications Slack Notifications Telegram Reports and Notifications OpsGenie Notifications PagerDuty Notifications Splunk Notifications Sumo Logic Notifications Guide to Using SSO Authentication to Log in to Wallarm","title":"User guide"},{"location":"en/SUMMARY/#partner-guide","text":"Introduction Signing up with Wallarm Getting your UUID and Secret Key Installing the Filter Node Creating a Tenant Configuring Traffic Processing","title":"Partner Guide"},{"location":"en/SUMMARY/#release-notes","text":"Version 2.14 Version 2.12 Version 2.10 Version 2.8 Version 2.6 Version 2.4 Version 2.2","title":"Release Notes"},{"location":"en/SUMMARY/#appendix","text":"Glossary Attacks and Vulnerabilities List Contacting the Support Team Envoy Installing with Docker Configuration Options (Envoy)","title":"Appendix"},{"location":"en/attacks-vulns-list/","text":"Attacks and Vulnerabilities List \u00b6 The Wallarm filter node can detect many attacks and vulnerabilities. These attacks and vulnerabilities are listed below . Each entity in the list is tagged with either \u201cAttack,\u201d \u201cVulnerability,\u201d or both. The name of a particular attack can be the same as the name of the vulnerability this attack exploits. In this case, such an entity will be tagged with the combined \u201cVulnerability/Attack\u201d tag. has the Wallarm code that corresponds to this entity. Most of the vulnerabilities and attacks on this list are also accompanied by one or more codes from the list of software weakness types, also known as the Common Weakness Enumeration or CWE. Additionally, the Wallarm filter node employs several special attack and vulnerability types for the internal purpose of marking processed traffic. Such entities are not accompanied by CWE codes but are listed separately . The Main List of Attacks and Vulnerabilities \u00b6 Attack on XML External Entity (XXE) \u00b6 Vulnerability/Attack CWE code: CWE-611 Wallarm code: xxe Description \u00b6 The XXE vulnerability allows an attacker to inject an external entity in an XML document to be evaluated by an XML parser and then executed on the target web server. As the result of a successful attack, an attacker will be able to get access to the web application's confidential data scan internal data networks read the files located on the web server perform an SSRF attack perform a Denial of Service (DoS) attack This vulnerability occurs due to a lack of restriction on the parsing of XML external entities in a web application. Remediation \u00b6 You may follow these recommendations: Disable the parsing of XML external entities when working with the XML documents supplied by a user. Apply the recommendations from the OWASP XXE Prevention Cheat Sheet . Brute-Force Attack \u00b6 Attack CWE codes: CWE-307 , CWE-521 , CWE-799 Wallarm code: brute Description \u00b6 A brute-force attack occurs when a massive number of requests with a predefined payload are sent to the server. These payloads may be generated by some means or taken from a dictionary. The server's response is then analyzed to find the right combination of the data in the payload. A successful brute-force attack can potentially bypass authentication and authorization mechanisms and/or reveal a web application's hidden resources (such as directories, files, website parts, etc.), thus granting the ability to conduct other malicious actions. Remediation \u00b6 You may follow these recommendations: Limit the number of requests per a certain time period for a web application. Limit the number of authentication/authorization attempts per a certain time period for a web application. Block new authentication/authorization attempts after a certain number of the failed attempts. Restrict a web application from accessing any files or directories on the server it runs on, except those within the scope of the application. Resource Scanning \u00b6 Attack CWE code: none Wallarm code: scanner Description \u00b6 The scanner code is assigned to an HTTP request if this request is believed to be part of third-party scanner software activity that is targeted to attack or scan a protected resource. The Wallarm scanner's requests are not considered to be a resource scanning attack. For example, an intruder can use port scanner software to enumerate all open network ports and then map services to well-known port numbers. This information may be used later to attack these services. Remediation \u00b6 You may follow these recommendations: Limit the possibility of a network perimeter scan by employing IP address whitelisting and blacklisting along with authentication/authorization mechanisms. Minimize the scan surface by placing the network perimeter behind a firewall. Define a necessary and sufficient set of ports to be opened for your services to operate. Restrict the usage of ICMP protocol on the network level. Periodically update your IT infrastructure equipment. This includes firmware of servers and other equipment operating systems other software Server-Side Template Injection (SSTI) \u00b6 Vulnerability/Attack CWE codes: CWE-94 , CWE-159 Wallarm code: ssti Description \u00b6 An intruder can inject an executable code into a user-filled form on a web server vulnerable to SSTI attacks so that code will be parsed and executed by the web server. A successful attack may render a vulnerable web server completely compromised, potentially allowing an intruder to execute arbitrary requests, explore the server's file systems, and, under certain conditions, remotely execute arbitrary code (see \u201cRCE attack\u201d for details), as well as many other things. This vulnerability arises from the incorrect validation and parsing of user input. Remediation \u00b6 You may follow the recommendation to sanitize and filter all user input to prevent an entity in the input from being executed. Logic Bomb \u00b6 Attack CWE code: CWE-511 Wallarm code: logic_bomb Description \u00b6 A logic bomb is a piece of malicious code that runs under certain conditions to perform some malicious actions. A \u201ctime bomb\u201d is a variety of logic bomb that goes off at a certain time or date. An example of a logic bomb is a program that is in control of a company's salary calculation system and which attacks the company if a particular employee gets fired. Remediation \u00b6 You may follow these recommendations: Use both static and dynamic code analyzers to inspect the produced code. Meticulously audit all code that is not covered by tests. Validate the integrity of any software being installed (e.g., check the software's digital signature). Cross-Site Request Forgery (CSRF) \u00b6 Vulnerability/Attack CWE code: CWE-352 Wallarm code: csrf Description \u00b6 A CSRF attack allows an intruder to send requests to a vulnerable application on behalf of a legitimate user. The corresponding vulnerability occurs due to the user's browser automatically adding cookies that are set for the target domain name while performing the cross-site request. As a result, the intruder can send a request to the vulnerable web application from a malicious website by posing as a legitimate user who is authenticated on the vulnerable site; the intruder does not even need to have access to that user's cookies. Remediation \u00b6 You may follow these recommendations: Employ anti-CSRF protection mechanisms, such as CSRF tokens and others. Set the SameSite cookie attribute. Apply the recommendations from the OWASP CSRF Prevention Cheat Sheet . Cross-site Scripting (XSS) \u00b6 Vulnerability/Attack CWE code: CWE-79 Wallarm code: xss Description \u00b6 A cross-site scripting attack allows an intruder to execute a prepared arbitrary code in a user's browser. There are a few XSS attack types: Stored XSS is when a malicious code is pre-embedded in the web application's page. If the web application is vulnerable to the stored XSS attack, then it is possible for an attacker to inject a malicious code into the web application's HTML page; moreover, this code will persist and be executed by the browser of any user who requests the infected webpage. Reflected XSS is when an intruder tricks a user into opening a specially crafted link. DOM-based XSS is when a JavaScript code snippet built into the web application's page parses the input and executes it as a JavaScript command due to errors in this code snippet. Exploiting any of the vulnerabilities listed above leads to the execution of an arbitrary JavaScript code. Provided that the XSS attack was successful, an intruder may steal a user's session or credentials, make requests on behalf of the user, and perform other malicious actions. This class of vulnerabilities occurs due to the incorrect validation and parsing of user input. Remediation \u00b6 You may follow these recommendations: Sanitize and filter all parameters that a web application receives as input to prevent an entity in the input from being executed. While forming the web application's pages, sanitize and escape any entities that are formed dynamically. Apply the recommendations from the OWASP XXS Prevention Cheat Sheet . Insecure Direct Object References (IDOR) \u00b6 Vulnerability CWE code: CWE-639 Wallarm code: idor Description \u00b6 With the IDOR vulnerability, the authentication and authorization mechanisms of a vulnerable web application do not prevent a user from accessing the data or resources of another user. This vulnerability occurs due to the web application granting the ability to access an object (e.g., a file, a directory, a database entry) by changing part of the request string and not implementing proper access control mechanisms. To exploit this vulnerability, an intruder manipulates the request string to gain unauthorized access to confidential information that belongs either to the vulnerable web application or to its users. Remediation \u00b6 You may follow these recommendations: Implement proper access control mechanisms for the web application's resources. Implement role-based access control mechanisms to grant access to resources based on roles that are assigned to the users. Use indirect object references. Apply the recommendations from the OWASP IDOR Prevention Cheat Sheet . Open Redirect \u00b6 Attack CWE code: CWE-601 Wallarm code: redir Description \u00b6 An intruder can use an open redirect attack to redirect a user to a malicious web page via a legitimate web application. Vulnerability to this attack occurs due to incorrect filtering of URL inputs. Remediation \u00b6 You may follow these recommendations: Sanitize and filter all parameters that a web application receives as input to prevent an entity in the input from being executed. Notify users about all pending redirects, and ask for explicit permission. Server-Side Request Forgery (SSRF) \u00b6 Vulnerability/Attack CWE code: CWE-918 Wallarm code: ssrf Description \u00b6 A successful SSRF attack may allow an intruder to make requests on behalf of the attacked web server; this potentially leads to revealing the web application's network ports in use, scanning the internal networks, and bypassing authorization. Remediation \u00b6 You may follow these recommendations: Sanitize and filter all parameters that a web application receives as input to prevent an entity in the input from being executed. Apply the recommendations from the OWASP SSRF Prevention Cheat Sheet . Forced Browsing \u00b6 Attack CWE code: CWE-425 Wallarm code: dirbust Description \u00b6 This attack belongs to the class of brute-force attacks. The purpose of this attack is to detect a web application's hidden resources, namely directories and files. This is achieved by trying different file and directory names that are either generated based on some template or extracted from a prepared dictionary file. A successful forced browsing attack potentially grants access to hidden resources that are not explicitly available from the web application interface but are exposed when accessed directly. Remediation \u00b6 You may follow these recommendations: Restrict or limit users' acess to those resources they are not supposed to have direct access to (e.g., by employing some authentication or authorization mechanisms). Limit the number of requests per a certain time period for the web application. Limit the number of authentication/authorization attempts per a certain time period for the web application. Block new authentication/authorization attempts after a certain number of failed attempts. Set necessary and sufficient access rights for the web application's files and directories. Information Exposure \u00b6 Vulnerability CWE codes: CWE-200 (see also: CWE-209 , CWE-215 , CWE-538 , CWE-541 , CWE-548 ) Wallarm code: info Description \u00b6 The vulnerable web application either intentionally or unintentionally discloses confidential information to a subject that is not authorized to access it. Remediation \u00b6 You may follow the recommendation to prohibit a web application from having the ability to display any confidential information. Remote Code Execution (RCE) \u00b6 Vulnerability/Attack CWE codes: CWE-78 , CWE-94 and others Wallarm code: rce Description \u00b6 An intruder can inject malicious code into a request to a web application, and the application will execute this code. Also, the intruder can try to execute certain commands for the operating system that the vulnerable web application runs on. Provided that an RCE attack is successful, an intruder can perform a wide range of actions, including Compromising the confidentiality, accessibility, and integrity of the vulnerable web application's data. Taking control of the operating system and the server that the web application runs on. Other possible actions. This vulnerability occurs due to incorrect validation and parsing of user input. Remediation \u00b6 You may follow the recommendation to sanitize and filter all user input to prevent an entity in the input from being executed. Authentication Bypass \u00b6 Vulnerability CWE code: CWE-288 Wallarm code: auth Description \u00b6 Despite having authentication mechanisms in place, a web application can have alternative authentication methods that allow either bypassing the main authentication mechanism or exploiting its weaknesses. This combination of factors may result in an attacker gaining access with user or administrator permissions. A successful authentication bypass attack potentially leads to disclosing users' confidential data or taking control of the vulnerable application with administrator permissions. Remediation \u00b6 You may follow these recommendations: Improve and strengthen existing authentication mechanisms. Eliminate any alternative authentication methods that may allow attackers to access an application while bypassing the required authentication procedure via pre-defined mechanisms. Apply the recommendations from the OWASP Authentication Cheat Sheet . CRLF Injection \u00b6 Attack CWE code: CWE-93 Wallarm code: crlf Description \u00b6 CRLF injections represent a class of attacks that allow an intruder to inject the Carriage Return (CR) and Line Feed (LF) characters into a request to a server (e.g., HTTP request). Combined with other factors, such CR/LF character injection can help to exploit a variety of vulnerabilities (e.g., \u201cHTTP Response Splitting\u201d CWE-113 , \u201cHTTP Response Smuggling\u201d CWE-444 ). A successful CRLF injection attack may give an intruder the ability to bypass firewalls, perform cache poisoning, replace legitimate web pages with malicious ones, perform the an \u201cOpen Redirect\u201d attack, and plenty of other actions. This vulnerability occurs due to the incorrect validation and parsing of user input. Remediation \u00b6 You may follow the recommendation to sanitize and filter all user input to prevent an entity in the input from being executed. LDAP Injection \u00b6 Vulnerability/Attack CWE code: CWE-90 Wallarm code: ldapi Description \u00b6 LDAP injections represent a class of attacks that allow an intruder to alter LDAP search filters by modifying requests to an LDAP server. A successful LDAP injection attack potentially grants access to the read and write operations on confidential data about LDAP users and hosts. This vulnerability occurs due to the incorrect validation and parsing of user input. Remediation \u00b6 You may follow these recommendations: Sanitize and filter all parameters that a web application receives as input to prevent an entity in the input from being executed. Apply the recommendations from the OWASP LDAP Injection Prevention Cheat Sheet . NoSQL Injection \u00b6 Vulnerability/Attack CWE code: CWE-943 Wallarm code: nosqli Description \u00b6 Vulnerability to this attack occurs due to insufficient filtering of user input. A NoSQL injection attack is performed by injecting a specially crafted query to a NoSQL database. Remediation \u00b6 You may follow the recommendation to sanitize and filter all user input to prevent an entity in the input from being executed. Path Traversal \u00b6 Vulnerability/Attack CWE code: CWE-22 Wallarm code: ptrav Description \u00b6 A path traversal attack allows an intruder to access files and directories with confidential data stored in the file system where the vulnerable web application resides by altering existing paths via the web application's parameters. Vulnerability to this attack occurs due to insufficient filtering of user input when a user requests a file or directory via the web application. Remediation \u00b6 You may follow these recommendations: Sanitize and filter all parameters that a web application receives as input to prevent an entity in the input from being executed. Additional recommendations for mitigating such attacks are available here . SQL Injection \u00b6 Vulnerability/Attack CWE code: CWE-89 Wallarm code: sqli Description \u00b6 Vulnerability to this attack occurs due to insufficient filtration of user input. An SQL injection attack is performed by injecting a specially crafted query to an SQL database. An SQL injection attack allows an intruder to inject arbitrary SQL code into an SQL query. This potentially leads to the attacker being granted access to read and modify confidential data as well as to DBMS administrator rights. Remediation \u00b6 You may follow these recommendations: Sanitize and filter all parameters that a web application receives as input to prevent an entity in the input from being executed. Apply the recommendations from the OWASP SQL Injection Prevention Cheat Sheet . The List of Special Attacks and Vulnerabilities \u00b6 Anomaly Request \u00b6 Vulnerability Wallarm code: anomaly Description \u00b6 A request is marked as an anomaly if the filter node considers it anomalous for the given application under protection. An encountered anomalous request may signal that the application is under attack. Virtual Patch \u00b6 Attack Wallarm code: vpatch Description \u00b6 A request is marked as a vpatch if it is part of an attack that was mitigated by the virtual patch mechanism . Unsafe XML Header \u00b6 Attack Wallarm code: xml_unsafe_header Description \u00b6 A request is marked as an xml_unsafe_header if its body contains an XML document and the document encoding differs from the encoding stated in the XML header. Marker \u00b6 Attack Wallarm code: marker Description \u00b6 The marker code is used by the Wallarm filter node while uploading information about attacks in the Wallarm cloud. Overlimiting of Computational Resources \u00b6 Attack Wallarm code: overlimit_res Description \u00b6 The filter node is configured in such a way that it should spend no more than N milliseconds on incoming request processing (default value: 1000 ). If the request is not processed during the specified timeframe, then the processing of the request will be stopped and the request marked as an overlimit_res attack. You can specify the desired timeframe for the request to be processed by using the wallarm_process_time_limit Wallarm directive.","title":"Attacks and Vulnerabilities List"},{"location":"en/attacks-vulns-list/#attacks-and-vulnerabilities-list","text":"The Wallarm filter node can detect many attacks and vulnerabilities. These attacks and vulnerabilities are listed below . Each entity in the list is tagged with either \u201cAttack,\u201d \u201cVulnerability,\u201d or both. The name of a particular attack can be the same as the name of the vulnerability this attack exploits. In this case, such an entity will be tagged with the combined \u201cVulnerability/Attack\u201d tag. has the Wallarm code that corresponds to this entity. Most of the vulnerabilities and attacks on this list are also accompanied by one or more codes from the list of software weakness types, also known as the Common Weakness Enumeration or CWE. Additionally, the Wallarm filter node employs several special attack and vulnerability types for the internal purpose of marking processed traffic. Such entities are not accompanied by CWE codes but are listed separately .","title":"Attacks and Vulnerabilities List"},{"location":"en/attacks-vulns-list/#the-main-list-of-attacks-and-vulnerabilities","text":"","title":"The Main List of Attacks and Vulnerabilities"},{"location":"en/attacks-vulns-list/#attack-on-xml-external-entity-xxe","text":"Vulnerability/Attack CWE code: CWE-611 Wallarm code: xxe","title":"Attack on XML External Entity (XXE)"},{"location":"en/attacks-vulns-list/#description","text":"The XXE vulnerability allows an attacker to inject an external entity in an XML document to be evaluated by an XML parser and then executed on the target web server. As the result of a successful attack, an attacker will be able to get access to the web application's confidential data scan internal data networks read the files located on the web server perform an SSRF attack perform a Denial of Service (DoS) attack This vulnerability occurs due to a lack of restriction on the parsing of XML external entities in a web application.","title":"Description"},{"location":"en/attacks-vulns-list/#remediation","text":"You may follow these recommendations: Disable the parsing of XML external entities when working with the XML documents supplied by a user. Apply the recommendations from the OWASP XXE Prevention Cheat Sheet .","title":"Remediation"},{"location":"en/attacks-vulns-list/#brute-force-attack","text":"Attack CWE codes: CWE-307 , CWE-521 , CWE-799 Wallarm code: brute","title":"Brute-Force Attack"},{"location":"en/attacks-vulns-list/#description_1","text":"A brute-force attack occurs when a massive number of requests with a predefined payload are sent to the server. These payloads may be generated by some means or taken from a dictionary. The server's response is then analyzed to find the right combination of the data in the payload. A successful brute-force attack can potentially bypass authentication and authorization mechanisms and/or reveal a web application's hidden resources (such as directories, files, website parts, etc.), thus granting the ability to conduct other malicious actions.","title":"Description"},{"location":"en/attacks-vulns-list/#remediation_1","text":"You may follow these recommendations: Limit the number of requests per a certain time period for a web application. Limit the number of authentication/authorization attempts per a certain time period for a web application. Block new authentication/authorization attempts after a certain number of the failed attempts. Restrict a web application from accessing any files or directories on the server it runs on, except those within the scope of the application.","title":"Remediation"},{"location":"en/attacks-vulns-list/#resource-scanning","text":"Attack CWE code: none Wallarm code: scanner","title":"Resource Scanning"},{"location":"en/attacks-vulns-list/#description_2","text":"The scanner code is assigned to an HTTP request if this request is believed to be part of third-party scanner software activity that is targeted to attack or scan a protected resource. The Wallarm scanner's requests are not considered to be a resource scanning attack. For example, an intruder can use port scanner software to enumerate all open network ports and then map services to well-known port numbers. This information may be used later to attack these services.","title":"Description"},{"location":"en/attacks-vulns-list/#remediation_2","text":"You may follow these recommendations: Limit the possibility of a network perimeter scan by employing IP address whitelisting and blacklisting along with authentication/authorization mechanisms. Minimize the scan surface by placing the network perimeter behind a firewall. Define a necessary and sufficient set of ports to be opened for your services to operate. Restrict the usage of ICMP protocol on the network level. Periodically update your IT infrastructure equipment. This includes firmware of servers and other equipment operating systems other software","title":"Remediation"},{"location":"en/attacks-vulns-list/#server-side-template-injection-ssti","text":"Vulnerability/Attack CWE codes: CWE-94 , CWE-159 Wallarm code: ssti","title":"Server-Side Template Injection (SSTI)"},{"location":"en/attacks-vulns-list/#description_3","text":"An intruder can inject an executable code into a user-filled form on a web server vulnerable to SSTI attacks so that code will be parsed and executed by the web server. A successful attack may render a vulnerable web server completely compromised, potentially allowing an intruder to execute arbitrary requests, explore the server's file systems, and, under certain conditions, remotely execute arbitrary code (see \u201cRCE attack\u201d for details), as well as many other things. This vulnerability arises from the incorrect validation and parsing of user input.","title":"Description"},{"location":"en/attacks-vulns-list/#remediation_3","text":"You may follow the recommendation to sanitize and filter all user input to prevent an entity in the input from being executed.","title":"Remediation"},{"location":"en/attacks-vulns-list/#logic-bomb","text":"Attack CWE code: CWE-511 Wallarm code: logic_bomb","title":"Logic Bomb"},{"location":"en/attacks-vulns-list/#description_4","text":"A logic bomb is a piece of malicious code that runs under certain conditions to perform some malicious actions. A \u201ctime bomb\u201d is a variety of logic bomb that goes off at a certain time or date. An example of a logic bomb is a program that is in control of a company's salary calculation system and which attacks the company if a particular employee gets fired.","title":"Description"},{"location":"en/attacks-vulns-list/#remediation_4","text":"You may follow these recommendations: Use both static and dynamic code analyzers to inspect the produced code. Meticulously audit all code that is not covered by tests. Validate the integrity of any software being installed (e.g., check the software's digital signature).","title":"Remediation"},{"location":"en/attacks-vulns-list/#cross-site-request-forgery-csrf","text":"Vulnerability/Attack CWE code: CWE-352 Wallarm code: csrf","title":"Cross-Site Request Forgery (CSRF)"},{"location":"en/attacks-vulns-list/#description_5","text":"A CSRF attack allows an intruder to send requests to a vulnerable application on behalf of a legitimate user. The corresponding vulnerability occurs due to the user's browser automatically adding cookies that are set for the target domain name while performing the cross-site request. As a result, the intruder can send a request to the vulnerable web application from a malicious website by posing as a legitimate user who is authenticated on the vulnerable site; the intruder does not even need to have access to that user's cookies.","title":"Description"},{"location":"en/attacks-vulns-list/#remediation_5","text":"You may follow these recommendations: Employ anti-CSRF protection mechanisms, such as CSRF tokens and others. Set the SameSite cookie attribute. Apply the recommendations from the OWASP CSRF Prevention Cheat Sheet .","title":"Remediation"},{"location":"en/attacks-vulns-list/#cross-site-scripting-xss","text":"Vulnerability/Attack CWE code: CWE-79 Wallarm code: xss","title":"Cross-site Scripting (XSS)"},{"location":"en/attacks-vulns-list/#description_6","text":"A cross-site scripting attack allows an intruder to execute a prepared arbitrary code in a user's browser. There are a few XSS attack types: Stored XSS is when a malicious code is pre-embedded in the web application's page. If the web application is vulnerable to the stored XSS attack, then it is possible for an attacker to inject a malicious code into the web application's HTML page; moreover, this code will persist and be executed by the browser of any user who requests the infected webpage. Reflected XSS is when an intruder tricks a user into opening a specially crafted link. DOM-based XSS is when a JavaScript code snippet built into the web application's page parses the input and executes it as a JavaScript command due to errors in this code snippet. Exploiting any of the vulnerabilities listed above leads to the execution of an arbitrary JavaScript code. Provided that the XSS attack was successful, an intruder may steal a user's session or credentials, make requests on behalf of the user, and perform other malicious actions. This class of vulnerabilities occurs due to the incorrect validation and parsing of user input.","title":"Description"},{"location":"en/attacks-vulns-list/#remediation_6","text":"You may follow these recommendations: Sanitize and filter all parameters that a web application receives as input to prevent an entity in the input from being executed. While forming the web application's pages, sanitize and escape any entities that are formed dynamically. Apply the recommendations from the OWASP XXS Prevention Cheat Sheet .","title":"Remediation"},{"location":"en/attacks-vulns-list/#insecure-direct-object-references-idor","text":"Vulnerability CWE code: CWE-639 Wallarm code: idor","title":"Insecure Direct Object References (IDOR)"},{"location":"en/attacks-vulns-list/#description_7","text":"With the IDOR vulnerability, the authentication and authorization mechanisms of a vulnerable web application do not prevent a user from accessing the data or resources of another user. This vulnerability occurs due to the web application granting the ability to access an object (e.g., a file, a directory, a database entry) by changing part of the request string and not implementing proper access control mechanisms. To exploit this vulnerability, an intruder manipulates the request string to gain unauthorized access to confidential information that belongs either to the vulnerable web application or to its users.","title":"Description"},{"location":"en/attacks-vulns-list/#remediation_7","text":"You may follow these recommendations: Implement proper access control mechanisms for the web application's resources. Implement role-based access control mechanisms to grant access to resources based on roles that are assigned to the users. Use indirect object references. Apply the recommendations from the OWASP IDOR Prevention Cheat Sheet .","title":"Remediation"},{"location":"en/attacks-vulns-list/#open-redirect","text":"Attack CWE code: CWE-601 Wallarm code: redir","title":"Open Redirect"},{"location":"en/attacks-vulns-list/#description_8","text":"An intruder can use an open redirect attack to redirect a user to a malicious web page via a legitimate web application. Vulnerability to this attack occurs due to incorrect filtering of URL inputs.","title":"Description"},{"location":"en/attacks-vulns-list/#remediation_8","text":"You may follow these recommendations: Sanitize and filter all parameters that a web application receives as input to prevent an entity in the input from being executed. Notify users about all pending redirects, and ask for explicit permission.","title":"Remediation"},{"location":"en/attacks-vulns-list/#server-side-request-forgery-ssrf","text":"Vulnerability/Attack CWE code: CWE-918 Wallarm code: ssrf","title":"Server-Side Request Forgery (SSRF)"},{"location":"en/attacks-vulns-list/#description_9","text":"A successful SSRF attack may allow an intruder to make requests on behalf of the attacked web server; this potentially leads to revealing the web application's network ports in use, scanning the internal networks, and bypassing authorization.","title":"Description"},{"location":"en/attacks-vulns-list/#remediation_9","text":"You may follow these recommendations: Sanitize and filter all parameters that a web application receives as input to prevent an entity in the input from being executed. Apply the recommendations from the OWASP SSRF Prevention Cheat Sheet .","title":"Remediation"},{"location":"en/attacks-vulns-list/#forced-browsing","text":"Attack CWE code: CWE-425 Wallarm code: dirbust","title":"Forced Browsing"},{"location":"en/attacks-vulns-list/#description_10","text":"This attack belongs to the class of brute-force attacks. The purpose of this attack is to detect a web application's hidden resources, namely directories and files. This is achieved by trying different file and directory names that are either generated based on some template or extracted from a prepared dictionary file. A successful forced browsing attack potentially grants access to hidden resources that are not explicitly available from the web application interface but are exposed when accessed directly.","title":"Description"},{"location":"en/attacks-vulns-list/#remediation_10","text":"You may follow these recommendations: Restrict or limit users' acess to those resources they are not supposed to have direct access to (e.g., by employing some authentication or authorization mechanisms). Limit the number of requests per a certain time period for the web application. Limit the number of authentication/authorization attempts per a certain time period for the web application. Block new authentication/authorization attempts after a certain number of failed attempts. Set necessary and sufficient access rights for the web application's files and directories.","title":"Remediation"},{"location":"en/attacks-vulns-list/#information-exposure","text":"Vulnerability CWE codes: CWE-200 (see also: CWE-209 , CWE-215 , CWE-538 , CWE-541 , CWE-548 ) Wallarm code: info","title":"Information Exposure"},{"location":"en/attacks-vulns-list/#description_11","text":"The vulnerable web application either intentionally or unintentionally discloses confidential information to a subject that is not authorized to access it.","title":"Description"},{"location":"en/attacks-vulns-list/#remediation_11","text":"You may follow the recommendation to prohibit a web application from having the ability to display any confidential information.","title":"Remediation"},{"location":"en/attacks-vulns-list/#remote-code-execution-rce","text":"Vulnerability/Attack CWE codes: CWE-78 , CWE-94 and others Wallarm code: rce","title":"Remote Code Execution (RCE)"},{"location":"en/attacks-vulns-list/#description_12","text":"An intruder can inject malicious code into a request to a web application, and the application will execute this code. Also, the intruder can try to execute certain commands for the operating system that the vulnerable web application runs on. Provided that an RCE attack is successful, an intruder can perform a wide range of actions, including Compromising the confidentiality, accessibility, and integrity of the vulnerable web application's data. Taking control of the operating system and the server that the web application runs on. Other possible actions. This vulnerability occurs due to incorrect validation and parsing of user input.","title":"Description"},{"location":"en/attacks-vulns-list/#remediation_12","text":"You may follow the recommendation to sanitize and filter all user input to prevent an entity in the input from being executed.","title":"Remediation"},{"location":"en/attacks-vulns-list/#authentication-bypass","text":"Vulnerability CWE code: CWE-288 Wallarm code: auth","title":"Authentication Bypass"},{"location":"en/attacks-vulns-list/#description_13","text":"Despite having authentication mechanisms in place, a web application can have alternative authentication methods that allow either bypassing the main authentication mechanism or exploiting its weaknesses. This combination of factors may result in an attacker gaining access with user or administrator permissions. A successful authentication bypass attack potentially leads to disclosing users' confidential data or taking control of the vulnerable application with administrator permissions.","title":"Description"},{"location":"en/attacks-vulns-list/#remediation_13","text":"You may follow these recommendations: Improve and strengthen existing authentication mechanisms. Eliminate any alternative authentication methods that may allow attackers to access an application while bypassing the required authentication procedure via pre-defined mechanisms. Apply the recommendations from the OWASP Authentication Cheat Sheet .","title":"Remediation"},{"location":"en/attacks-vulns-list/#crlf-injection","text":"Attack CWE code: CWE-93 Wallarm code: crlf","title":"CRLF Injection"},{"location":"en/attacks-vulns-list/#description_14","text":"CRLF injections represent a class of attacks that allow an intruder to inject the Carriage Return (CR) and Line Feed (LF) characters into a request to a server (e.g., HTTP request). Combined with other factors, such CR/LF character injection can help to exploit a variety of vulnerabilities (e.g., \u201cHTTP Response Splitting\u201d CWE-113 , \u201cHTTP Response Smuggling\u201d CWE-444 ). A successful CRLF injection attack may give an intruder the ability to bypass firewalls, perform cache poisoning, replace legitimate web pages with malicious ones, perform the an \u201cOpen Redirect\u201d attack, and plenty of other actions. This vulnerability occurs due to the incorrect validation and parsing of user input.","title":"Description"},{"location":"en/attacks-vulns-list/#remediation_14","text":"You may follow the recommendation to sanitize and filter all user input to prevent an entity in the input from being executed.","title":"Remediation"},{"location":"en/attacks-vulns-list/#ldap-injection","text":"Vulnerability/Attack CWE code: CWE-90 Wallarm code: ldapi","title":"LDAP Injection"},{"location":"en/attacks-vulns-list/#description_15","text":"LDAP injections represent a class of attacks that allow an intruder to alter LDAP search filters by modifying requests to an LDAP server. A successful LDAP injection attack potentially grants access to the read and write operations on confidential data about LDAP users and hosts. This vulnerability occurs due to the incorrect validation and parsing of user input.","title":"Description"},{"location":"en/attacks-vulns-list/#remediation_15","text":"You may follow these recommendations: Sanitize and filter all parameters that a web application receives as input to prevent an entity in the input from being executed. Apply the recommendations from the OWASP LDAP Injection Prevention Cheat Sheet .","title":"Remediation"},{"location":"en/attacks-vulns-list/#nosql-injection","text":"Vulnerability/Attack CWE code: CWE-943 Wallarm code: nosqli","title":"NoSQL Injection"},{"location":"en/attacks-vulns-list/#description_16","text":"Vulnerability to this attack occurs due to insufficient filtering of user input. A NoSQL injection attack is performed by injecting a specially crafted query to a NoSQL database.","title":"Description"},{"location":"en/attacks-vulns-list/#remediation_16","text":"You may follow the recommendation to sanitize and filter all user input to prevent an entity in the input from being executed.","title":"Remediation"},{"location":"en/attacks-vulns-list/#path-traversal","text":"Vulnerability/Attack CWE code: CWE-22 Wallarm code: ptrav","title":"Path Traversal"},{"location":"en/attacks-vulns-list/#description_17","text":"A path traversal attack allows an intruder to access files and directories with confidential data stored in the file system where the vulnerable web application resides by altering existing paths via the web application's parameters. Vulnerability to this attack occurs due to insufficient filtering of user input when a user requests a file or directory via the web application.","title":"Description"},{"location":"en/attacks-vulns-list/#remediation_17","text":"You may follow these recommendations: Sanitize and filter all parameters that a web application receives as input to prevent an entity in the input from being executed. Additional recommendations for mitigating such attacks are available here .","title":"Remediation"},{"location":"en/attacks-vulns-list/#sql-injection","text":"Vulnerability/Attack CWE code: CWE-89 Wallarm code: sqli","title":"SQL Injection"},{"location":"en/attacks-vulns-list/#description_18","text":"Vulnerability to this attack occurs due to insufficient filtration of user input. An SQL injection attack is performed by injecting a specially crafted query to an SQL database. An SQL injection attack allows an intruder to inject arbitrary SQL code into an SQL query. This potentially leads to the attacker being granted access to read and modify confidential data as well as to DBMS administrator rights.","title":"Description"},{"location":"en/attacks-vulns-list/#remediation_18","text":"You may follow these recommendations: Sanitize and filter all parameters that a web application receives as input to prevent an entity in the input from being executed. Apply the recommendations from the OWASP SQL Injection Prevention Cheat Sheet .","title":"Remediation"},{"location":"en/attacks-vulns-list/#the-list-of-special-attacks-and-vulnerabilities","text":"","title":"The List of Special Attacks and Vulnerabilities"},{"location":"en/attacks-vulns-list/#anomaly-request","text":"Vulnerability Wallarm code: anomaly","title":"Anomaly Request"},{"location":"en/attacks-vulns-list/#description_19","text":"A request is marked as an anomaly if the filter node considers it anomalous for the given application under protection. An encountered anomalous request may signal that the application is under attack.","title":"Description"},{"location":"en/attacks-vulns-list/#virtual-patch","text":"Attack Wallarm code: vpatch","title":"Virtual Patch"},{"location":"en/attacks-vulns-list/#description_20","text":"A request is marked as a vpatch if it is part of an attack that was mitigated by the virtual patch mechanism .","title":"Description"},{"location":"en/attacks-vulns-list/#unsafe-xml-header","text":"Attack Wallarm code: xml_unsafe_header","title":"Unsafe XML Header"},{"location":"en/attacks-vulns-list/#description_21","text":"A request is marked as an xml_unsafe_header if its body contains an XML document and the document encoding differs from the encoding stated in the XML header.","title":"Description"},{"location":"en/attacks-vulns-list/#marker","text":"Attack Wallarm code: marker","title":"Marker"},{"location":"en/attacks-vulns-list/#description_22","text":"The marker code is used by the Wallarm filter node while uploading information about attacks in the Wallarm cloud.","title":"Description"},{"location":"en/attacks-vulns-list/#overlimiting-of-computational-resources","text":"Attack Wallarm code: overlimit_res","title":"Overlimiting of Computational Resources"},{"location":"en/attacks-vulns-list/#description_23","text":"The filter node is configured in such a way that it should spend no more than N milliseconds on incoming request processing (default value: 1000 ). If the request is not processed during the specified timeframe, then the processing of the request will be stopped and the request marked as an overlimit_res attack. You can specify the desired timeframe for the request to be processed by using the wallarm_process_time_limit Wallarm directive.","title":"Description"},{"location":"en/glossary-en/","text":"Glossary \u00b6 MITM \u00b6 A man in the middle (MITM) attack consists of an attacker secretly relaying the communication between two parties who believe they are directly communicating with each other. See OWASP . Attack Vector \u00b6 An attack vector is a path or means by which a hacker can gain access to a network resource to deliver a payload. Security Incident \u00b6 A security incident is an occurrence of a vulnerability exploitation. An incident is an attack targeted at a confirmed vulnerability. An incident, just like an attack, is an entity external to your system and is a characteristic of the outside Internet, not the system itself. Despite the fact that the attacks targeted at existing vulnerabilities are a minority, they are of the utmost importance in terms of information security. Wallarm automatically detects the attacks targeted at existing vulnerabilities and displays them as a separate object. Circular Buffer \u00b6 A circular buffer is a data structure that uses a single, fixed-size buffer as if it were connected end-to-end. See Wikipedia . LOM \u00b6 LOM stands for Local Objective Model. LOM is a set of rules for a particular web application. The set of rules is generated based on user requests to the web application and the application's responses. Invalid Request \u00b6 A request that was checked by filter node and does not match LOM rules. Reverse Proxy \u00b6 A reverse proxy is a type of proxy server that retrieves resources on behalf of a client from a server and returns the resources to the client as if they originated from the Web server itself. See Wikipedia . Certificate Authority \u00b6 A certificate authority is an entity that issues digital certificates. See Wikipedia . Vulnerability \u00b6 A vulnerability is an error made due to negligence or inadequate information when building or implementing a web application that can lead to an information security risk. The information security risks are: Unauthorized data access; for example, access to read and modify user data. Denial of service. Data corruption and other. A vulnerability is not a characteristic of the Internet. A vulnerability is a characteristic of your system. Whether or not you have vulnerabilities does not depend on your Internet traffic. The Internet traffic, however, can be used to detect the vulnerabilities, which is what Wallarm does, among other functions.","title":"Glossary"},{"location":"en/glossary-en/#glossary","text":"","title":"Glossary"},{"location":"en/glossary-en/#mitm","text":"A man in the middle (MITM) attack consists of an attacker secretly relaying the communication between two parties who believe they are directly communicating with each other. See OWASP .","title":"MITM"},{"location":"en/glossary-en/#attack-vector","text":"An attack vector is a path or means by which a hacker can gain access to a network resource to deliver a payload.","title":"Attack Vector"},{"location":"en/glossary-en/#security-incident","text":"A security incident is an occurrence of a vulnerability exploitation. An incident is an attack targeted at a confirmed vulnerability. An incident, just like an attack, is an entity external to your system and is a characteristic of the outside Internet, not the system itself. Despite the fact that the attacks targeted at existing vulnerabilities are a minority, they are of the utmost importance in terms of information security. Wallarm automatically detects the attacks targeted at existing vulnerabilities and displays them as a separate object.","title":"Security Incident"},{"location":"en/glossary-en/#circular-buffer","text":"A circular buffer is a data structure that uses a single, fixed-size buffer as if it were connected end-to-end. See Wikipedia .","title":"Circular Buffer"},{"location":"en/glossary-en/#lom","text":"LOM stands for Local Objective Model. LOM is a set of rules for a particular web application. The set of rules is generated based on user requests to the web application and the application's responses.","title":"LOM"},{"location":"en/glossary-en/#invalid-request","text":"A request that was checked by filter node and does not match LOM rules.","title":"Invalid Request"},{"location":"en/glossary-en/#reverse-proxy","text":"A reverse proxy is a type of proxy server that retrieves resources on behalf of a client from a server and returns the resources to the client as if they originated from the Web server itself. See Wikipedia .","title":"Reverse Proxy"},{"location":"en/glossary-en/#certificate-authority","text":"A certificate authority is an entity that issues digital certificates. See Wikipedia .","title":"Certificate Authority"},{"location":"en/glossary-en/#vulnerability","text":"A vulnerability is an error made due to negligence or inadequate information when building or implementing a web application that can lead to an information security risk. The information security risks are: Unauthorized data access; for example, access to read and modify user data. Denial of service. Data corruption and other. A vulnerability is not a characteristic of the Internet. A vulnerability is a characteristic of your system. Whether or not you have vulnerabilities does not depend on your Internet traffic. The Internet traffic, however, can be used to detect the vulnerabilities, which is what Wallarm does, among other functions.","title":"Vulnerability"},{"location":"en/_layouts/","text":"","title":"Index"},{"location":"en/admin-en/admin-intro-en/","text":"Introduction \u00b6 This guide provides information on the Wallarm configuration options and infrastructure integration. You must have administrator access to perform most of the operations described in this guide. You can set the administrator access on the Settings \u2013> Users tab on --8\u2190 \"en/cloud-include/wallarm-portal.md\". Note Lorem ipsum dolor sit amet, consectetur adipiscing elit. Nulla et euismod nulla. Curabitur feugiat, tortor non consequat finibus, justo purus auctor massa, nec semper lorem quam in massa. See also User guide","title":"Introduction"},{"location":"en/admin-en/admin-intro-en/#introduction","text":"This guide provides information on the Wallarm configuration options and infrastructure integration. You must have administrator access to perform most of the operations described in this guide. You can set the administrator access on the Settings \u2013> Users tab on --8\u2190 \"en/cloud-include/wallarm-portal.md\". Note Lorem ipsum dolor sit amet, consectetur adipiscing elit. Nulla et euismod nulla. Curabitur feugiat, tortor non consequat finibus, justo purus auctor massa, nec semper lorem quam in massa. See also User guide","title":"Introduction"},{"location":"en/admin-en/api-en/","text":"Wallarm API \u00b6 Wallarm API provides interaction between components of the Wallarm system. You can use Wallarm API methods to create, get or update the following instances: vulnerabilities, attacks, incidents, users, clients, filter nodes, etc. Description of API methods is given in the API Reference by the link: https://apiconsole.eu1.wallarm.com/ for the EU cloud https://apiconsole.us1.wallarm.com/ for the US cloud API Endpoint \u00b6 API requests are sent to the following URL: https://api.wallarm.com/ for the EU cloud https://us1.api.wallarm.com/ for the US cloud Authentication of API Requests \u00b6 The method of API requests authentication depends on the client sending the request: API Reference UI Your own client API Reference UI \u00b6 Token is used for requests authentication. The token is generated after successful authentication in your Wallarm account. Sign in to your Wallarm account by the link: https://my.wallarm.com/ for the EU cloud, https://us1.my.wallarm.com/ for the US cloud. Refresh the API Reference page by the link: https://apiconsole.eu1.wallarm.com/ for the EU cloud, https://apiconsole.us1.wallarm.com/ for the US cloud. Go to the required API method > the Try it out section, input parameter values and Execute the request. Your Own Client \u00b6 Your UUID and secret key are used. Sign in to your Wallarm account by the link: https://my.wallarm.com/ for the EU cloud, https://us1.my.wallarm.com/ for the US cloud. Refresh the API Reference page by the link: https://apiconsole.eu1.wallarm.com/ for the EU cloud, https://apiconsole.us1.wallarm.com/ for the US cloud. Send the POST /v1/user request from the API Reference UI and copy the uuid value from the response. Send the POST /v1/user/renew_secret request from the API Reference UI and copy the secret value from the response. Send the required request from your own client passing the following values: uuid in the X-WallarmAPI-UUID header parameter, secret in the X-WallarmAPI-Secret header parameter. API Restrictions \u00b6 Currently Wallarm does not limit the rate of API calls. At the same time Wallarm closely monitors the API usage and may introduce a rate limiting for abusing users. API Request Examples \u00b6 Get first 50 attacks detected in the last 24 hours {% termtabs name=\"EU cloud\" -%} curl -v -X POST \" https://api.wallarm.com/v1/objects/attack \" -H \"X-WallarmAPI-UUID: YOUR_UUID\" -H \"X-WallarmAPI-Secret: YOUR_SECRET_KEY\" -H \"accept: application/json\" -H \"Content-Type: application/json\" -d \"{ \\\"filter\\\": { \\\"clientid\\\": [YOUR_CLIENT_ID], \\\"time\\\": [CURRENT_TIMESTAMP] }, \\\"offset\\\": 0, \\\"limit\\\": 50, \\\"order_by\\\": \\\"last_time\\\", \\\"order_desc\\\": true}\" \u00b6 {%- tab name=\"US cloud\" -%} curl -v -X POST \" https://us1.api.wallarm.com/v1/objects/attack \" -H \"X-WallarmAPI-UUID: YOUR_UUID\" -H \"X-WallarmAPI-Secret: YOUR_SECRET_KEY\" -H \"accept: application/json\" -H \"Content-Type: application/json\" -d \"{ \\\"filter\\\": { \\\"clientid\\\": [YOUR_CLIENT_ID], \\\"time\\\": [CURRENT_TIMESTAMP] }, \\\"offset\\\": 0, \\\"limit\\\": 50, \\\"order_by\\\": \\\"last_time\\\", \\\"order_desc\\\": true}\" \u00b6 {%- endtermtabs %} Get first 50 incidents confirmed in the last 24 hours {% termtabs name=\"EU cloud\" -%} curl -v -X POST \" https://api.wallarm.com/v1/objects/attack \" -H \"X-WallarmAPI-UUID: YOUR_UUID\" -H \"X-WallarmAPI-Secret: YOUR_SECRET_KEY\" -H \"accept: application/json\" -H \"Content-Type: application/json\" -d \"{ \\\"filter\\\": { \\\"clientid\\\": [YOUR_CLIENT_ID], \\\"!vulnid\\\": null, \\\"time\\\": [CURRENT_TIMESTAMP] }, \\\"offset\\\": 0, \\\"limit\\\": 50, \\\"order_by\\\": \\\"last_time\\\", \\\"order_desc\\\": true}\" \u00b6 {%- tab name=\"US cloud\" -%} curl -v -X POST \" https://us1.api.wallarm.com/v1/objects/attack \" -H \"X-WallarmAPI-UUID: YOUR_UUID\" -H \"X-WallarmAPI-Secret: YOUR_SECRET_KEY\" -H \"accept: application/json\" -H \"Content-Type: application/json\" -d \"{ \\\"filter\\\": { \\\"clientid\\\": [YOUR_CLIENT_ID], \\\"!vulnid\\\": null, \\\"time\\\": [CURRENT_TIMESTAMP] }, \\\"offset\\\": 0, \\\"limit\\\": 50, \\\"order_by\\\": \\\"last_time\\\", \\\"order_desc\\\": true}\" \u00b6 {%- endtermtabs %} Create the rule to block all requests sent to /my/api/* {% termtabs name=\"EU cloud\" -%} curl -v -X POST \" https://api.wallarm.com/v1/objects/hint/create \" -H \"X-WallarmAPI-UUID: YOUR_UUID\" -H \"X-WallarmAPI-Secret: YOUR_SECRET_KEY\" -H \"accept: application/json\" -H \"Content-Type: application/json\" -d \"{ \\\"clientid\\\": YOUR_CLIENT_ID, \\\"type\\\": \\\"vpatch\\\", \\\"action\\\": [ {\\\"type\\\":\\\"equal\\\",\\\"value\\\":\\\"my\\\",\\\"point\\\":[\\\"path\\\",0]}, {\\\"type\\\":\\\"equal\\\",\\\"value\\\":\\\"api\\\",\\\"point\\\":[\\\"path\\\",1]}, {\\\"type\\\":\\\"equal\\\",\\\"value\\\":\\\"endpoint\\\",\\\"point\\\":[\\\"header\\\",\\\"2\\\"]}], \\\"validated\\\": false, \\\"point\\\": [ [ \\\"header\\\", \\\"HOST\\\" ] ], \\\"attack_type\\\": \\\"any\\\"}\" \u00b6 {%- tab name=\"US cloud\" -%} curl -v -X POST \" https://us1.api.wallarm.com/v1/objects/hint/create \" -H \"X-WallarmAPI-UUID: YOUR_UUID\" -H \"X-WallarmAPI-Secret: YOUR_SECRET_KEY\" -H \"accept: application/json\" -H \"Content-Type: application/json\" -d \"{ \\\"clientid\\\": YOUR_CLIENT_ID, \\\"type\\\": \\\"vpatch\\\", \\\"action\\\": [ {\\\"type\\\":\\\"equal\\\",\\\"value\\\":\\\"my\\\",\\\"point\\\":[\\\"path\\\",0]}, {\\\"type\\\":\\\"equal\\\",\\\"value\\\":\\\"api\\\",\\\"point\\\":[\\\"path\\\",1]}, {\\\"type\\\":\\\"equal\\\",\\\"value\\\":\\\"endpoint\\\",\\\"point\\\":[\\\"header\\\",\\\"2\\\"]}], \\\"validated\\\": false, \\\"point\\\": [ [ \\\"header\\\", \\\"HOST\\\" ] ], \\\"attack_type\\\": \\\"any\\\"}\" \u00b6 {%- endtermtabs %}","title":"Wallarm API"},{"location":"en/admin-en/api-en/#wallarm-api","text":"Wallarm API provides interaction between components of the Wallarm system. You can use Wallarm API methods to create, get or update the following instances: vulnerabilities, attacks, incidents, users, clients, filter nodes, etc. Description of API methods is given in the API Reference by the link: https://apiconsole.eu1.wallarm.com/ for the EU cloud https://apiconsole.us1.wallarm.com/ for the US cloud","title":"Wallarm API"},{"location":"en/admin-en/api-en/#api-endpoint","text":"API requests are sent to the following URL: https://api.wallarm.com/ for the EU cloud https://us1.api.wallarm.com/ for the US cloud","title":"API Endpoint"},{"location":"en/admin-en/api-en/#authentication-of-api-requests","text":"The method of API requests authentication depends on the client sending the request: API Reference UI Your own client","title":"Authentication of API Requests"},{"location":"en/admin-en/api-en/#api-reference-ui","text":"Token is used for requests authentication. The token is generated after successful authentication in your Wallarm account. Sign in to your Wallarm account by the link: https://my.wallarm.com/ for the EU cloud, https://us1.my.wallarm.com/ for the US cloud. Refresh the API Reference page by the link: https://apiconsole.eu1.wallarm.com/ for the EU cloud, https://apiconsole.us1.wallarm.com/ for the US cloud. Go to the required API method > the Try it out section, input parameter values and Execute the request.","title":"API Reference UI"},{"location":"en/admin-en/api-en/#your-own-client","text":"Your UUID and secret key are used. Sign in to your Wallarm account by the link: https://my.wallarm.com/ for the EU cloud, https://us1.my.wallarm.com/ for the US cloud. Refresh the API Reference page by the link: https://apiconsole.eu1.wallarm.com/ for the EU cloud, https://apiconsole.us1.wallarm.com/ for the US cloud. Send the POST /v1/user request from the API Reference UI and copy the uuid value from the response. Send the POST /v1/user/renew_secret request from the API Reference UI and copy the secret value from the response. Send the required request from your own client passing the following values: uuid in the X-WallarmAPI-UUID header parameter, secret in the X-WallarmAPI-Secret header parameter.","title":"Your Own Client"},{"location":"en/admin-en/api-en/#api-restrictions","text":"Currently Wallarm does not limit the rate of API calls. At the same time Wallarm closely monitors the API usage and may introduce a rate limiting for abusing users.","title":"API Restrictions"},{"location":"en/admin-en/api-en/#api-request-examples","text":"Get first 50 attacks detected in the last 24 hours {% termtabs name=\"EU cloud\" -%}","title":"API Request Examples"},{"location":"en/admin-en/api-en/#curl-v-x-post-httpsapiwallarmcomv1objectsattack-h-x-wallarmapi-uuid-your_uuid-h-x-wallarmapi-secret-your_secret_key-h-accept-applicationjson-h-content-type-applicationjson-d-filter-clientid-your_client_id-time-current_timestamp-offset-0-limit-50-order_by-last_time-order_desc-true","text":"{%- tab name=\"US cloud\" -%}","title":"curl -v -X POST \"https://api.wallarm.com/v1/objects/attack\" -H \"X-WallarmAPI-UUID: YOUR_UUID\" -H \"X-WallarmAPI-Secret: YOUR_SECRET_KEY\" -H \"accept: application/json\" -H \"Content-Type: application/json\" -d \"{ \\\"filter\\\": { \\\"clientid\\\": [YOUR_CLIENT_ID], \\\"time\\\": [CURRENT_TIMESTAMP] }, \\\"offset\\\": 0, \\\"limit\\\": 50, \\\"order_by\\\": \\\"last_time\\\", \\\"order_desc\\\": true}\""},{"location":"en/admin-en/api-en/#curl-v-x-post-httpsus1apiwallarmcomv1objectsattack-h-x-wallarmapi-uuid-your_uuid-h-x-wallarmapi-secret-your_secret_key-h-accept-applicationjson-h-content-type-applicationjson-d-filter-clientid-your_client_id-time-current_timestamp-offset-0-limit-50-order_by-last_time-order_desc-true","text":"{%- endtermtabs %} Get first 50 incidents confirmed in the last 24 hours {% termtabs name=\"EU cloud\" -%}","title":"curl -v -X POST \"https://us1.api.wallarm.com/v1/objects/attack\" -H \"X-WallarmAPI-UUID: YOUR_UUID\" -H \"X-WallarmAPI-Secret: YOUR_SECRET_KEY\" -H \"accept: application/json\"  -H \"Content-Type: application/json\" -d \"{ \\\"filter\\\": { \\\"clientid\\\": [YOUR_CLIENT_ID], \\\"time\\\": [CURRENT_TIMESTAMP] }, \\\"offset\\\": 0, \\\"limit\\\": 50, \\\"order_by\\\": \\\"last_time\\\", \\\"order_desc\\\": true}\""},{"location":"en/admin-en/api-en/#curl-v-x-post-httpsapiwallarmcomv1objectsattack-h-x-wallarmapi-uuid-your_uuid-h-x-wallarmapi-secret-your_secret_key-h-accept-applicationjson-h-content-type-applicationjson-d-filter-clientid-your_client_id-vulnid-null-time-current_timestamp-offset-0-limit-50-order_by-last_time-order_desc-true","text":"{%- tab name=\"US cloud\" -%}","title":"curl -v -X POST \"https://api.wallarm.com/v1/objects/attack\" -H \"X-WallarmAPI-UUID: YOUR_UUID\" -H \"X-WallarmAPI-Secret: YOUR_SECRET_KEY\" -H \"accept: application/json\" -H \"Content-Type: application/json\" -d \"{ \\\"filter\\\": { \\\"clientid\\\": [YOUR_CLIENT_ID], \\\"!vulnid\\\": null, \\\"time\\\": [CURRENT_TIMESTAMP] }, \\\"offset\\\": 0, \\\"limit\\\": 50, \\\"order_by\\\": \\\"last_time\\\", \\\"order_desc\\\": true}\""},{"location":"en/admin-en/api-en/#curl-v-x-post-httpsus1apiwallarmcomv1objectsattack-h-x-wallarmapi-uuid-your_uuid-h-x-wallarmapi-secret-your_secret_key-h-accept-applicationjson-h-content-type-applicationjson-d-filter-clientid-your_client_id-vulnid-null-time-current_timestamp-offset-0-limit-50-order_by-last_time-order_desc-true","text":"{%- endtermtabs %} Create the rule to block all requests sent to /my/api/* {% termtabs name=\"EU cloud\" -%}","title":"curl -v -X POST \"https://us1.api.wallarm.com/v1/objects/attack\" -H \"X-WallarmAPI-UUID: YOUR_UUID\" -H \"X-WallarmAPI-Secret: YOUR_SECRET_KEY\" -H \"accept: application/json\"  -H \"Content-Type: application/json\" -d \"{ \\\"filter\\\": { \\\"clientid\\\": [YOUR_CLIENT_ID], \\\"!vulnid\\\": null, \\\"time\\\": [CURRENT_TIMESTAMP] }, \\\"offset\\\": 0, \\\"limit\\\": 50, \\\"order_by\\\": \\\"last_time\\\", \\\"order_desc\\\": true}\""},{"location":"en/admin-en/api-en/#curl-v-x-post-httpsapiwallarmcomv1objectshintcreate-h-x-wallarmapi-uuid-your_uuid-h-x-wallarmapi-secret-your_secret_key-h-accept-applicationjson-h-content-type-applicationjson-d-clientid-your_client_id-type-vpatch-action-typeequalvaluemypointpath0-typeequalvalueapipointpath1-typeequalvalueendpointpointheader2-validated-false-point-header-host-attack_type-any","text":"{%- tab name=\"US cloud\" -%}","title":"curl -v -X POST \"https://api.wallarm.com/v1/objects/hint/create\" -H \"X-WallarmAPI-UUID: YOUR_UUID\" -H \"X-WallarmAPI-Secret: YOUR_SECRET_KEY\" -H \"accept: application/json\" -H \"Content-Type: application/json\" -d \"{ \\\"clientid\\\": YOUR_CLIENT_ID, \\\"type\\\": \\\"vpatch\\\", \\\"action\\\": [ {\\\"type\\\":\\\"equal\\\",\\\"value\\\":\\\"my\\\",\\\"point\\\":[\\\"path\\\",0]}, {\\\"type\\\":\\\"equal\\\",\\\"value\\\":\\\"api\\\",\\\"point\\\":[\\\"path\\\",1]}, {\\\"type\\\":\\\"equal\\\",\\\"value\\\":\\\"endpoint\\\",\\\"point\\\":[\\\"header\\\",\\\"2\\\"]}], \\\"validated\\\": false, \\\"point\\\": [ [ \\\"header\\\", \\\"HOST\\\" ] ], \\\"attack_type\\\": \\\"any\\\"}\""},{"location":"en/admin-en/api-en/#curl-v-x-post-httpsus1apiwallarmcomv1objectshintcreate-h-x-wallarmapi-uuid-your_uuid-h-x-wallarmapi-secret-your_secret_key-h-accept-applicationjson-h-content-type-applicationjson-d-clientid-your_client_id-type-vpatch-action-typeequalvaluemypointpath0-typeequalvalueapipointpath1-typeequalvalueendpointpointheader2-validated-false-point-header-host-attack_type-any","text":"{%- endtermtabs %}","title":"curl -v -X POST \"https://us1.api.wallarm.com/v1/objects/hint/create\" -H \"X-WallarmAPI-UUID: YOUR_UUID\" -H \"X-WallarmAPI-Secret: YOUR_SECRET_KEY\" -H \"accept: application/json\" -H \"Content-Type: application/json\" -d \"{ \\\"clientid\\\": YOUR_CLIENT_ID, \\\"type\\\": \\\"vpatch\\\", \\\"action\\\": [ {\\\"type\\\":\\\"equal\\\",\\\"value\\\":\\\"my\\\",\\\"point\\\":[\\\"path\\\",0]}, {\\\"type\\\":\\\"equal\\\",\\\"value\\\":\\\"api\\\",\\\"point\\\":[\\\"path\\\",1]}, {\\\"type\\\":\\\"equal\\\",\\\"value\\\":\\\"endpoint\\\",\\\"point\\\":[\\\"header\\\",\\\"2\\\"]}], \\\"validated\\\": false, \\\"point\\\": [ [ \\\"header\\\", \\\"HOST\\\" ] ], \\\"attack_type\\\": \\\"any\\\"}\""},{"location":"en/admin-en/block-part-en/","text":"Blocking Part of a Website \u00b6 You can enable blocking of a part of a website by using the Wallarm-NGINX configuration file. To enable blocking, use the directives: location \u2013 an NGINX directive. wallarm_mode block \u2013 a Wallarm directive. Configuring blocking of a part of a website: Open for editing the configuration file in the /etc/nginx-wallarm directory. Set the blocking rules in the $wallarm_mode_real variable and the location to apply the rules in the location block: http { ... map $remote_addr $wallarm_mode_real { default block; 1.1.1.1/24 monitoring; 2.2.2.2 off; } ... server { ... location /<some_location>/ { wallarm_mode $wallarm_mode_real; } } } The blocking rules in the $wallarm_mode_real variable apply to requests that target URLs containing /some_location/ as substrings: * default block \u2014 by default, process all the requests and block all the attacks; * 1.1.1.1/24 monitoring \u2014 process all the requests coming from an IP-address from the \u00ab1.1.1.1\u00bb \u2014 \u00ab1.1.1.254\u00bb pool, but do not block any, even if an attack is detected; * 2.2.2.2 off \u2014 do not filter any requests coming from the \u00ab2.2.2.2\u00bb IP-address. #### Warning:: Disable Blocking of the Wallarm Scanner IP Addresses Note that if you use the blocking mode by default (`default block;`) when detecting malicious requests, you must explicitly specify for the Wallarm scanner a list of IP addresses from which requests should not be blocked. You can read more about disabling the blocking mode for scanner IP addresses [here](scanner-ips-whitelisting.md).","title":"Blocking Part of a Website"},{"location":"en/admin-en/block-part-en/#blocking-part-of-a-website","text":"You can enable blocking of a part of a website by using the Wallarm-NGINX configuration file. To enable blocking, use the directives: location \u2013 an NGINX directive. wallarm_mode block \u2013 a Wallarm directive. Configuring blocking of a part of a website: Open for editing the configuration file in the /etc/nginx-wallarm directory. Set the blocking rules in the $wallarm_mode_real variable and the location to apply the rules in the location block: http { ... map $remote_addr $wallarm_mode_real { default block; 1.1.1.1/24 monitoring; 2.2.2.2 off; } ... server { ... location /<some_location>/ { wallarm_mode $wallarm_mode_real; } } } The blocking rules in the $wallarm_mode_real variable apply to requests that target URLs containing /some_location/ as substrings: * default block \u2014 by default, process all the requests and block all the attacks; * 1.1.1.1/24 monitoring \u2014 process all the requests coming from an IP-address from the \u00ab1.1.1.1\u00bb \u2014 \u00ab1.1.1.254\u00bb pool, but do not block any, even if an attack is detected; * 2.2.2.2 off \u2014 do not filter any requests coming from the \u00ab2.2.2.2\u00bb IP-address. #### Warning:: Disable Blocking of the Wallarm Scanner IP Addresses Note that if you use the blocking mode by default (`default block;`) when detecting malicious requests, you must explicitly specify for the Wallarm scanner a list of IP addresses from which requests should not be blocked. You can read more about disabling the blocking mode for scanner IP addresses [here](scanner-ips-whitelisting.md).","title":"Blocking Part of a Website"},{"location":"en/admin-en/configure-backup-en/","text":"Configuring a Failover Method \u00b6 Deploying a filter node as a reverse proxy requires that the filter node is highly available. The filter node failure, for example due to power outage, limits the web application's operation. To ensure the high availability of Wallarm, you are recommended to use one of the failover methods described in this section. A failover method introduces additional nodes to which the traffic is automatically forwarded if the main filter node fails. Data Center Failover \u00b6 If the web application and filter nodes are in a data center, use the data center's \"Failover IP\" service VRRP or CARP \u00b6 On each filter node, start a keepalived or ucarp daemon that monitors the availability of the nodes and starts forwarding traffic if the nodes go down. This is a standard high availability method that can also be used for traffic load balancing by starting a failover-IP on each node and distributing the traffic with DNS balancing. Working with NGINX Plus Wallarm can be set up to work on NGINX Plus with a custom VRRP wrapper. Most of the Linux distributions, including CentOS and Debian, have custom packages that can install this build. To find out about installation of Wallarm with NGINX Plus, see detailed instructions on the \u00abInstalling with NGINX Plus\u00bb page. Hardware L3 or L4 Load Balancer \u00b6 A layer 3 or layer 4 load balancer is a good high availability solution. DNS Load Balancing \u00b6 Specify several IP addresses in the DNS settings. While this method targets load balancing, you may also find it useful as high availability method.","title":"Configuring a Failover Method"},{"location":"en/admin-en/configure-backup-en/#configuring-a-failover-method","text":"Deploying a filter node as a reverse proxy requires that the filter node is highly available. The filter node failure, for example due to power outage, limits the web application's operation. To ensure the high availability of Wallarm, you are recommended to use one of the failover methods described in this section. A failover method introduces additional nodes to which the traffic is automatically forwarded if the main filter node fails.","title":"Configuring a Failover Method"},{"location":"en/admin-en/configure-backup-en/#data-center-failover","text":"If the web application and filter nodes are in a data center, use the data center's \"Failover IP\" service","title":"Data Center Failover"},{"location":"en/admin-en/configure-backup-en/#vrrp-or-carp","text":"On each filter node, start a keepalived or ucarp daemon that monitors the availability of the nodes and starts forwarding traffic if the nodes go down. This is a standard high availability method that can also be used for traffic load balancing by starting a failover-IP on each node and distributing the traffic with DNS balancing. Working with NGINX Plus Wallarm can be set up to work on NGINX Plus with a custom VRRP wrapper. Most of the Linux distributions, including CentOS and Debian, have custom packages that can install this build. To find out about installation of Wallarm with NGINX Plus, see detailed instructions on the \u00abInstalling with NGINX Plus\u00bb page.","title":"VRRP or CARP"},{"location":"en/admin-en/configure-backup-en/#hardware-l3-or-l4-load-balancer","text":"A layer 3 or layer 4 load balancer is a good high availability solution.","title":"Hardware L3 or L4 Load Balancer"},{"location":"en/admin-en/configure-backup-en/#dns-load-balancing","text":"Specify several IP addresses in the DNS settings. While this method targets load balancing, you may also find it useful as high availability method.","title":"DNS Load Balancing"},{"location":"en/admin-en/configure-cloud-node-synchronization-en/","text":"Filter Node and Cloud Synchronization Configuration \u00b6 #### Warning:: This document describes the variables specified in the Wallarm cloud synchronization configuration file. This file is only created for nodes that were installed in the following clouds: * [Amazon Web Services][link-aws-installation], * [Google Cloud][link-gcloud-installation]. The /etc/wallarm/syncnode file contains environment variables that define the way the cloud node will synchronize with the Wallarm cloud. You can configure the synchronization process by adding desired environment variables to this file and assigning your own values to them. The wallarm-synccloud service applies the changes made to the /etc/wallarm/syncnode file to the synchronization process and runs the synchronization with the new configuration. Run the following command to get the list of the environment variables which can be used to configure the synchronization: $ /usr/share/wallarm-common/synccloud --help Configuring Filter Node and Cloud Synchronization \u00b6 To modify necessary synchronization parameters, proceed with the following steps: Make changes to the /etc/wallarm/syncnode file by adding the necessary environment variables from the list in the Available Environment Variables section of this document to the file and assigning the desired values to them. The following example demonstrates the valid /etc/wallarm/syncnode contents: WALLARM_API_TOKEN=K85iHWi0SXRxJTb+xxxxxxxxxxxxxxxxxxxxfiwo9twr9I5/+sjZ9v2UlRRgwwMD WALLARM_SYNCNODE_INTERVAL=800 WALLARM_SYNCNODE_TIMEOUT=600 Launch the following command to update synchronization parameters: # /bin/systemctl restart wallarm-synccloud The process will apply the values, that were assigned to the environment variables in the /etc/wallarm/syncnode file, as new parameters for node and Wallarm cloud synchronization. After the command execution, the filter node will be performing the synchronization procedure according to the new parameters. Available Environment Variables \u00b6 The following environment variables can be used for synchronization configuration: WALLARM_API_HOST \u2014 Wallarm API host domain name. If you are using the https://my.wallarm.com/ cloud, the default value will be api.wallarm.com . If you are using the https://us1.my.wallarm.com/ cloud, the default value will be us1.api.wallarm.com . WALLARM_API_PORT \u2014 Wallarm API port (default value: 444 ). WALLARM_API_TOKEN \u2014 Wallarm Cloud Node token to access the Wallarm API. WALLARM_API_USE_SSL \u2014 enable/disable TLS to connect to the Wallarm API (default value: yes ). This variable accepts the following values: true , yes , and 1 to enable TLS. Any other value to disable TLS. WALLARM_API_CA_VERIFY \u2014 enable/disable Wallarm API server certificate verification (default value: yes ). This variable accepts the following values: true , yes , and 1 to enable verification. Any other value to disable verification. WALLARM_API_CA_PATH \u2014 path to the Wallarm API certificate authority file. WALLARM_SYNCNODE \u2014 enable/disable node-specific data synchronization (default value: yes ). If the synchronization is enabled, the files for the cloud node operation (such as LOM file ) will be periodically downloaded from the cloud. If the synchronization is disabled, the files for the cloud node operation will not be downloaded. This variable accepts the following values: true , yes , and 1 to enable synchronization. Any other value to disable synchronization. WALLARM_SYNCNODE_INTERVAL \u2014 interval between synchronizations in seconds (default value: 600 ). WALLARM_SYNCNODE_RAND_DELAY \u2014 synchronization delay jitter in seconds (default value: 300 ). WALLARM_SYNCNODE_TIMEOUT \u2014 synchronization duration limit (default value: 900 ). This limit allows interrupting the synchronization if any issues occur during the process of downloading the files for the cloud node operation. For example, such issues can be caused by network outages. WALLARM_SYNCNODE_OWNER \u2014 owner for the files needed for the cloud node operation (default value: root ). WALLARM_SYNCNODE_GROUP \u2014 group for the files needed for the cloud node operation (default value: wallarm ). WALLARM_SYNCNODE_MODE \u2014 access rights to the files needed for the cloud node operation (default value: 0640 ). #### Warning:: Configuration of the access rights to the files needed for the cloud node operation Make sure that after configuring access rights using the WALLARM_SYNCNODE_OWNER , WALLARM_SYNCNODE_GROUP , and WALLARM_SYNCNODE_MODE variables, the wallarm-worker and nginx services can read content of the files needed for the cloud node operation.","title":"Filter Node and Cloud Synchronization Configuration"},{"location":"en/admin-en/configure-cloud-node-synchronization-en/#filter-node-and-cloud-synchronization-configuration","text":"#### Warning:: This document describes the variables specified in the Wallarm cloud synchronization configuration file. This file is only created for nodes that were installed in the following clouds: * [Amazon Web Services][link-aws-installation], * [Google Cloud][link-gcloud-installation]. The /etc/wallarm/syncnode file contains environment variables that define the way the cloud node will synchronize with the Wallarm cloud. You can configure the synchronization process by adding desired environment variables to this file and assigning your own values to them. The wallarm-synccloud service applies the changes made to the /etc/wallarm/syncnode file to the synchronization process and runs the synchronization with the new configuration. Run the following command to get the list of the environment variables which can be used to configure the synchronization: $ /usr/share/wallarm-common/synccloud --help","title":"Filter Node and Cloud Synchronization Configuration"},{"location":"en/admin-en/configure-cloud-node-synchronization-en/#configuring-filter-node-and-cloud-synchronization","text":"To modify necessary synchronization parameters, proceed with the following steps: Make changes to the /etc/wallarm/syncnode file by adding the necessary environment variables from the list in the Available Environment Variables section of this document to the file and assigning the desired values to them. The following example demonstrates the valid /etc/wallarm/syncnode contents: WALLARM_API_TOKEN=K85iHWi0SXRxJTb+xxxxxxxxxxxxxxxxxxxxfiwo9twr9I5/+sjZ9v2UlRRgwwMD WALLARM_SYNCNODE_INTERVAL=800 WALLARM_SYNCNODE_TIMEOUT=600 Launch the following command to update synchronization parameters: # /bin/systemctl restart wallarm-synccloud The process will apply the values, that were assigned to the environment variables in the /etc/wallarm/syncnode file, as new parameters for node and Wallarm cloud synchronization. After the command execution, the filter node will be performing the synchronization procedure according to the new parameters.","title":"Configuring Filter Node and Cloud Synchronization"},{"location":"en/admin-en/configure-cloud-node-synchronization-en/#available-environment-variables","text":"The following environment variables can be used for synchronization configuration: WALLARM_API_HOST \u2014 Wallarm API host domain name. If you are using the https://my.wallarm.com/ cloud, the default value will be api.wallarm.com . If you are using the https://us1.my.wallarm.com/ cloud, the default value will be us1.api.wallarm.com . WALLARM_API_PORT \u2014 Wallarm API port (default value: 444 ). WALLARM_API_TOKEN \u2014 Wallarm Cloud Node token to access the Wallarm API. WALLARM_API_USE_SSL \u2014 enable/disable TLS to connect to the Wallarm API (default value: yes ). This variable accepts the following values: true , yes , and 1 to enable TLS. Any other value to disable TLS. WALLARM_API_CA_VERIFY \u2014 enable/disable Wallarm API server certificate verification (default value: yes ). This variable accepts the following values: true , yes , and 1 to enable verification. Any other value to disable verification. WALLARM_API_CA_PATH \u2014 path to the Wallarm API certificate authority file. WALLARM_SYNCNODE \u2014 enable/disable node-specific data synchronization (default value: yes ). If the synchronization is enabled, the files for the cloud node operation (such as LOM file ) will be periodically downloaded from the cloud. If the synchronization is disabled, the files for the cloud node operation will not be downloaded. This variable accepts the following values: true , yes , and 1 to enable synchronization. Any other value to disable synchronization. WALLARM_SYNCNODE_INTERVAL \u2014 interval between synchronizations in seconds (default value: 600 ). WALLARM_SYNCNODE_RAND_DELAY \u2014 synchronization delay jitter in seconds (default value: 300 ). WALLARM_SYNCNODE_TIMEOUT \u2014 synchronization duration limit (default value: 900 ). This limit allows interrupting the synchronization if any issues occur during the process of downloading the files for the cloud node operation. For example, such issues can be caused by network outages. WALLARM_SYNCNODE_OWNER \u2014 owner for the files needed for the cloud node operation (default value: root ). WALLARM_SYNCNODE_GROUP \u2014 group for the files needed for the cloud node operation (default value: wallarm ). WALLARM_SYNCNODE_MODE \u2014 access rights to the files needed for the cloud node operation (default value: 0640 ). #### Warning:: Configuration of the access rights to the files needed for the cloud node operation Make sure that after configuring access rights using the WALLARM_SYNCNODE_OWNER , WALLARM_SYNCNODE_GROUP , and WALLARM_SYNCNODE_MODE variables, the wallarm-worker and nginx services can read content of the files needed for the cloud node operation.","title":"Available Environment Variables"},{"location":"en/admin-en/configure-ip-blocking-en/","text":"Blocking by IP Address \u00b6 Typically, blocking malicious requests on a request-by-request basis is preferable than blocking by IP addresses. However, in some cases, using IP blacklists is necessary. IP blacklists should be used in the following cases: There is a need to reduce system load that was caused by the analysis of malicious requests. Traffic processing is performed asynchronously. There are extra resources that are not protected with WAF. Blocking Methods \u00b6 All methods have advantages and disadvantages. Blocking with Wallarm Web Interface \u00b6 This is the most intuitive method providing the user with a convenient graphical interface to view and modify the blacklist. Read more... Blocking with NGINX \u00b6 This method is the most resource-intensive one. However, it allows customizing the message that the user sees when the request is blocked. Read more... . Blocking by iptables \u00b6 This method does not allow you to configure the error message, but it affects server performance less. Read more... . Blocking by External Firewall \u00b6 This method does not create any load on the server but requires additional integration of blacklist and firewall. #### Warning:: Exclude the IP Address Blocking of the Wallarm Scanner Please note that if you use additional facilities (software or hardware) to automatically filter and block traffic, you should add the IP addresses for the scanner to the whitelist of the corresponding filtering facility in order for the Wallarm scanner to be able to freely check your resources for vulnerabilities. Lists of the IP addresses of the scanner: * [for the EU cloud](scanner-address-en.md) * [for the US cloud](scanner-address-us-en.md).","title":"Methods of Blocking by IP Address"},{"location":"en/admin-en/configure-ip-blocking-en/#blocking-by-ip-address","text":"Typically, blocking malicious requests on a request-by-request basis is preferable than blocking by IP addresses. However, in some cases, using IP blacklists is necessary. IP blacklists should be used in the following cases: There is a need to reduce system load that was caused by the analysis of malicious requests. Traffic processing is performed asynchronously. There are extra resources that are not protected with WAF.","title":"Blocking by IP Address"},{"location":"en/admin-en/configure-ip-blocking-en/#blocking-methods","text":"All methods have advantages and disadvantages.","title":"Blocking Methods"},{"location":"en/admin-en/configure-ip-blocking-en/#blocking-with-wallarm-web-interface","text":"This is the most intuitive method providing the user with a convenient graphical interface to view and modify the blacklist. Read more...","title":"Blocking with Wallarm Web Interface"},{"location":"en/admin-en/configure-ip-blocking-en/#blocking-with-nginx","text":"This method is the most resource-intensive one. However, it allows customizing the message that the user sees when the request is blocked. Read more... .","title":"Blocking with NGINX"},{"location":"en/admin-en/configure-ip-blocking-en/#blocking-by-iptables","text":"This method does not allow you to configure the error message, but it affects server performance less. Read more... .","title":"Blocking by iptables"},{"location":"en/admin-en/configure-ip-blocking-en/#blocking-by-external-firewall","text":"This method does not create any load on the server but requires additional integration of blacklist and firewall. #### Warning:: Exclude the IP Address Blocking of the Wallarm Scanner Please note that if you use additional facilities (software or hardware) to automatically filter and block traffic, you should add the IP addresses for the scanner to the whitelist of the corresponding filtering facility in order for the Wallarm scanner to be able to freely check your resources for vulnerabilities. Lists of the IP addresses of the scanner: * [for the EU cloud](scanner-address-en.md) * [for the US cloud](scanner-address-us-en.md).","title":"Blocking by External Firewall"},{"location":"en/admin-en/configure-ip-blocking-iptables-en/","text":"Blocking by iptables \u00b6 In most cases, blocking by request is preferred over blocking by IP address. However, there are a number of cases when you need to block by IP address: To reduce the traffic that the attacker requests generate. To handle asynchronous traffic. In the presence of additional resources not protected by WAF. To block by IP address, use the block_with_iptables.rb script, which is modifiable. To effectively use the script, the filter node must regularly download from the Wallarm cloud an updated list of the IP addresses to be blocked. Whitelist You can whitelist an IP address. A whitelisted IP address is allowed to request the web application's server and bypasses the blacklist check. Set up Blocking by IP Address \u00b6 Contact Wallarm Support and request to create a system user with access to the blacklists. Install the wallarm_extra_scripts package. This package is in the Wallarm repository. Run the command: {% termtabs name=\"Debian 8.x (jessie)\" -%} apt-get install wallarm-extra-scripts \u00b6 {%- tab name=\"Debian 9.x (stretch)\" -%} apt-get install wallarm-extra-scripts \u00b6 {%- tab name=\"Debian 10.x (buster)\" -%} apt-get install wallarm-extra-scripts \u00b6 {%- tab name=\"Ubuntu 14.04 LTS (trusty)\" -%} apt-get install wallarm-extra-scripts \u00b6 {%- tab name=\"Ubuntu 16.04 LTS (xenial)\" -%} apt-get install wallarm-extra-scripts \u00b6 {%- tab name=\"Ubuntu 18.04 LTS (bionic)\" -%} apt-get install wallarm-extra-scripts \u00b6 {%- tab name=\"CentOS 6.x\" -%} yum install wallarm-extra-scripts \u00b6 {%- tab name=\"CentOS 7.x\" -%} yum install wallarm-extra-scripts \u00b6 {%- tab name=\"Amazon Linux 2\" -%} yum install wallarm-extra-scripts \u00b6 {%- endtermtabs %} The block_with_iptables.rb script will be installed automatically. On each start, the script creates or updates the wallarm_blacklist chain in the table filter . Each blocked IP address gets the rule REJECT . Create and configure the iptables to specify what traffic must be blocked. For example, to block all traffic on port 80 and port 443, run: # iptables -N wallarm_check # iptables -N wallarm_blacklist # iptables -A INPUT -p tcp --dport 80 -j wallarm_check # iptables -A INPUT -p tcp --dport 443 -j wallarm_check # iptables -A wallarm_check -j wallarm_blacklist Set up regular execution of the script by using the cron utility: Open the root user's crontab file for editing: # crontab -e 2. Add the following lines to the file (replace the /path/to/log entry with the actual path to a log file, so that the script can write the logs into it): PATH=/bin:/sbin:/usr/bin:/usr/sbin */5 * * * * root timeout 90 /usr/share/wallarm-extra-scripts/block_with_iptables.rb >> /path/to/log 2>&1 These lines define the following behavior of a cron job: * The block_with_iptables.rb script will be executed every fifth minute on behalf of the root user. * If the script does not finish within the 90 second timeout, then its execution will be explicitly terminated. * The script's logs will be written in the specified log file (e.g, /path/to/log ); the stderr error output stream will be redirected to the stdout standard output stream. If necessary, set up script monitoring. You can monitor the script by checking the modification time mtime of the file /tmp/.wallarm.blacklist-sync.last because it changes every time the script starts successfully. Whitelisting IP addresses. To whitelist several IP addresses, run the following command for the range of IP addresses. Replace 1.2.3.4/30 with the necessary value: # iptables -I wallarm_check -s 1.2.3.4/30 -j RETURN To whitelist one IP address, replace 1.2.3.4 with the necessary value: # iptables -I wallarm_check -s 1.2.3.4 -j RETURN","title":"Blocking with iptables"},{"location":"en/admin-en/configure-ip-blocking-iptables-en/#blocking-by-iptables","text":"In most cases, blocking by request is preferred over blocking by IP address. However, there are a number of cases when you need to block by IP address: To reduce the traffic that the attacker requests generate. To handle asynchronous traffic. In the presence of additional resources not protected by WAF. To block by IP address, use the block_with_iptables.rb script, which is modifiable. To effectively use the script, the filter node must regularly download from the Wallarm cloud an updated list of the IP addresses to be blocked. Whitelist You can whitelist an IP address. A whitelisted IP address is allowed to request the web application's server and bypasses the blacklist check.","title":"Blocking by iptables"},{"location":"en/admin-en/configure-ip-blocking-iptables-en/#set-up-blocking-by-ip-address","text":"Contact Wallarm Support and request to create a system user with access to the blacklists. Install the wallarm_extra_scripts package. This package is in the Wallarm repository. Run the command: {% termtabs name=\"Debian 8.x (jessie)\" -%}","title":"Set up Blocking by IP Address"},{"location":"en/admin-en/configure-ip-blocking-iptables-en/#apt-get-install-wallarm-extra-scripts","text":"{%- tab name=\"Debian 9.x (stretch)\" -%}","title":"apt-get install wallarm-extra-scripts"},{"location":"en/admin-en/configure-ip-blocking-iptables-en/#apt-get-install-wallarm-extra-scripts_1","text":"{%- tab name=\"Debian 10.x (buster)\" -%}","title":"apt-get install wallarm-extra-scripts"},{"location":"en/admin-en/configure-ip-blocking-iptables-en/#apt-get-install-wallarm-extra-scripts_2","text":"{%- tab name=\"Ubuntu 14.04 LTS (trusty)\" -%}","title":"apt-get install wallarm-extra-scripts"},{"location":"en/admin-en/configure-ip-blocking-iptables-en/#apt-get-install-wallarm-extra-scripts_3","text":"{%- tab name=\"Ubuntu 16.04 LTS (xenial)\" -%}","title":"apt-get install wallarm-extra-scripts"},{"location":"en/admin-en/configure-ip-blocking-iptables-en/#apt-get-install-wallarm-extra-scripts_4","text":"{%- tab name=\"Ubuntu 18.04 LTS (bionic)\" -%}","title":"apt-get install wallarm-extra-scripts"},{"location":"en/admin-en/configure-ip-blocking-iptables-en/#apt-get-install-wallarm-extra-scripts_5","text":"{%- tab name=\"CentOS 6.x\" -%}","title":"apt-get install wallarm-extra-scripts"},{"location":"en/admin-en/configure-ip-blocking-iptables-en/#yum-install-wallarm-extra-scripts","text":"{%- tab name=\"CentOS 7.x\" -%}","title":"yum install wallarm-extra-scripts"},{"location":"en/admin-en/configure-ip-blocking-iptables-en/#yum-install-wallarm-extra-scripts_1","text":"{%- tab name=\"Amazon Linux 2\" -%}","title":"yum install wallarm-extra-scripts"},{"location":"en/admin-en/configure-ip-blocking-iptables-en/#yum-install-wallarm-extra-scripts_2","text":"{%- endtermtabs %} The block_with_iptables.rb script will be installed automatically. On each start, the script creates or updates the wallarm_blacklist chain in the table filter . Each blocked IP address gets the rule REJECT . Create and configure the iptables to specify what traffic must be blocked. For example, to block all traffic on port 80 and port 443, run: # iptables -N wallarm_check # iptables -N wallarm_blacklist # iptables -A INPUT -p tcp --dport 80 -j wallarm_check # iptables -A INPUT -p tcp --dport 443 -j wallarm_check # iptables -A wallarm_check -j wallarm_blacklist Set up regular execution of the script by using the cron utility: Open the root user's crontab file for editing: # crontab -e 2. Add the following lines to the file (replace the /path/to/log entry with the actual path to a log file, so that the script can write the logs into it): PATH=/bin:/sbin:/usr/bin:/usr/sbin */5 * * * * root timeout 90 /usr/share/wallarm-extra-scripts/block_with_iptables.rb >> /path/to/log 2>&1 These lines define the following behavior of a cron job: * The block_with_iptables.rb script will be executed every fifth minute on behalf of the root user. * If the script does not finish within the 90 second timeout, then its execution will be explicitly terminated. * The script's logs will be written in the specified log file (e.g, /path/to/log ); the stderr error output stream will be redirected to the stdout standard output stream. If necessary, set up script monitoring. You can monitor the script by checking the modification time mtime of the file /tmp/.wallarm.blacklist-sync.last because it changes every time the script starts successfully. Whitelisting IP addresses. To whitelist several IP addresses, run the following command for the range of IP addresses. Replace 1.2.3.4/30 with the necessary value: # iptables -I wallarm_check -s 1.2.3.4/30 -j RETURN To whitelist one IP address, replace 1.2.3.4 with the necessary value: # iptables -I wallarm_check -s 1.2.3.4 -j RETURN","title":"yum install wallarm-extra-scripts"},{"location":"en/admin-en/configure-ip-blocking-nginx-en/","text":"Blocking with NGINX \u00b6 Supported version This feature is supported starting Wallarm Node 2.8 By default, blocking by IP address is turned off. To activate it, proceed to the following steps: Go to the folder that contains the NGINX configuration files. To do this, select and run the command that corresponds with your filter node installation method from the tabs below. {% termtabs name=\"Dynamic NGINX module\" -%} $ cd /etc/nginx/conf.d {%- tab name=\"Dynamic NGINX module from OS repositories\" -%} $ cd /etc/nginx/conf.d {%- tab name=\"NGINX Plus module\" -%} $ cd /etc/nginx/conf.d {%- tab name=\"NGINX-Wallarm module (DEPRECATED)\" -%} $ cd /etc/nginx-wallarm/conf.d {%- endtermtabs %} In the current folder, create a file named /etc/nginx/conf.d/wallarm-acl.conf with the following content: wallarm_acl_db default { wallarm_acl_path <path-to-wallarm-acl-folder>; wallarm_acl_mapsize 64m; } server { listen 127.0.0.9:80; server_name localhost; allow 127.0.0.0/8; deny all; access_log off; location /wallarm-acl { wallarm_acl default; wallarm_acl_api on; } } In the configuration above, <path-to-wallarm-acl-folder> is a path to an empty directory, in which the nginx user can create subdirectories and files for storing access control lists. Checking the nginx user rights Run the following command to check whether the nginx user has rights to perform actions on the directory: sudo -u nginx [ -r <path-to-directory> ] && [ -w <path-to-directory> ] && echo \"\u041e\u041a\" In this command, <path-to-directory> is the path to the directory, access to which you need to check. Due to the sudo -u nginx prefix, this command is executed using the nginx user. The command first checks whether the user has permission to read the directory (the [ -r <path-to-directory> ] part). Next, it checks whether the user has permission to write into the directory (the [ -w <path-to-directory> ] part). If the nginx user has permission to read and write into the directory specified in the command, the terminal outputs the OK message. The specified directory can be used as a wallarm_acl_path value. If the nginx user does not have the required permission, the terminal output is empty. Example: Directories that are valid for access control list storage depend on the filter node installation method you used and your OS. The valid directories to specify in the wallarm_acl_path directive are as follows: * Dynamic NGINX module: {% termtabs name=\"Debian 8.x (jessie)\" -%} /var/cache/nginx/wallarm_acl_default {%- tab name=\"Debian 9.x (stretch)\" -%} /var/cache/nginx/wallarm_acl_default {%- tab name=\"Debian 10.x (buster)\" -%} /var/cache/nginx/wallarm_acl_default {%- tab name=\"Ubuntu 14.04 LTS (trusty)\" -%} /var/cache/nginx/wallarm_acl_default {%- tab name=\"Ubuntu 16.04 LTS (xenial)\" -%} /var/cache/nginx/wallarm_acl_default {%- tab name=\"Ubuntu 18.04 LTS (bionic)\" -%} /var/cache/nginx/wallarm_acl_default {%- tab name=\"CentOS 6.x\" -%} /var/cache/nginx/wallarm_acl_default {%- tab name=\"CentOS 7.x\" -%} /var/lib/nginx/wallarm_acl_default {%- tab name=\"Amazon Linux 2\" -%} /var/lib/nginx/wallarm_acl_default {%- endtermtabs %} Dynamic NGINX module from OS repositories: {% termtabs name=\"Debian 8.x (jessie)\" -%} /var/lib/nginx/wallarm_acl_default {%- tab name=\"Debian 9.x (stretch)\" -%} /var/lib/nginx/wallarm_acl_default {%- tab name=\"Debian 10.x (buster)\" -%} /var/lib/nginx/wallarm_acl_default {%- tab name=\"Ubuntu 14.04 LTS (trusty)\" -%} /var/lib/nginx/wallarm_acl_default {%- tab name=\"Ubuntu 16.04 LTS (xenial)\" -%} /var/lib/nginx/wallarm_acl_default {%- tab name=\"Ubuntu 18.04 LTS (bionic)\" -%} /var/lib/nginx/wallarm_acl_default {%- tab name=\"CentOS 6.x\" -%} /var/lib/nginx/wallarm_acl_default {%- tab name=\"CentOS 7.x\" -%} /var/lib/nginx/wallarm_acl_default {%- tab name=\"Amazon Linux 2\" -%} /var/lib/nginx/wallarm_acl_default {%- endtermtabs %} NGINX Plus module: {% termtabs name=\"Debian 8.x (jessie)\" -%} /var/lib/nginx/wallarm_acl_default {%- tab name=\"Debian 9.x (stretch)\" -%} /var/lib/nginx/wallarm_acl_default {%- tab name=\"Debian 10.x (buster)\" -%} /var/lib/nginx/wallarm_acl_default {%- tab name=\"Ubuntu 14.04 LTS (trusty)\" -%} /var/lib/nginx/wallarm_acl_default {%- tab name=\"Ubuntu 16.04 LTS (xenial)\" -%} /var/lib/nginx/wallarm_acl_default {%- tab name=\"Ubuntu 18.04 LTS (bionic)\" -%} /var/lib/nginx/wallarm_acl_default {%- tab name=\"CentOS 6.x\" -%} /var/lib/nginx/wallarm_acl_default {%- tab name=\"CentOS 7.x\" -%} /var/lib/nginx/wallarm_acl_default {%- tab name=\"Amazon Linux 2\" -%} /var/lib/nginx/wallarm_acl_default {%- endtermtabs %} NGINX-Wallarm module (DEPRECATED): {% termtabs name=\"Debian 8.x (jessie)\" -%} /var/lib/nginx-wallarm/wallarm_acl_default {%- tab name=\"Debian 9.x (stretch)\" -%} /var/lib/nginx-wallarm/wallarm_acl_default {%- tab name=\"Debian 10.x (buster)\" -%} /var/lib/nginx-wallarm/wallarm_acl_default {%- tab name=\"Ubuntu 14.04 LTS (trusty)\" -%} /var/lib/nginx-wallarm/wallarm_acl_default {%- tab name=\"Ubuntu 16.04 LTS (xenial)\" -%} /var/lib/nginx-wallarm/wallarm_acl_default {%- tab name=\"Ubuntu 18.04 LTS (bionic)\" -%} /var/lib/nginx-wallarm/wallarm_acl_default {%- tab name=\"CentOS 6.x\" -%} /var/cache/nginx-wallarm/wallarm_acl_default {%- tab name=\"CentOS 7.x\" -%} /var/cache/nginx-wallarm/wallarm_acl_default {%- tab name=\"Amazon Linux 2\" -%} /var/cache/nginx-wallarm/wallarm_acl_default {%- endtermtabs %} Turn on blocking for the particular vhosts and/or locations by adding the following lines to their configuration files: server { ... wallarm_acl default; ... } Add the following lines to the /etc/wallarm/node.yaml file: sync_blacklist: nginx_url: http://127.0.0.9/wallarm-acl Activate the blacklist synchronization. One way to do this is to uncomment the line containing sync-blacklist as a substring in the /etc/cron.d/wallarm-node-nginx file by removing the # symbol at the beginning of the line. You can also do this by running the following command: # sed -i -Ee 's/^#(.*sync-blacklist.*)/\\1/' /etc/cron.d/wallarm-node-nginx Using the sed command Sed is a stream editor. By default, sed writes to standard output. The -i option means that the file will be edited in-place. The -eE option comprises two options: * The -e option means the following: * The first non-option parameter will be used as a script to run on the input. * The second non-option parameter will be used as an input file. * The -E option means that the script following this option uses the extended regular expression syntax . The script that follows the options replaces the lines that satisfy the ^#(.*sync-blacklist.*) regular expression with the string that satisfies the subexpression in parenthesis in the /etc/cron.d/wallarm-node-nginx file. The \\1 back-reference of the sed command means that the subexpression in the first parenthesis should be used as a replacement. The line that satisfies the ^#(.*sync-blacklist.*) regular expression * starts with the # symbol. * contains sync-blacklist as a substring. The replacement for the described line is the substring of this line without the # symbol at the beginning of the line. This command uncomments the line that enables blacklist synchronization. Thus, the blacklist synchronization will be activated. You can learn more about sed by proceeding with the link . You can add IP addresses to the whitelist to skip checking of the blacklist upon receiving a request from them. For example, the following lines in the vhost or location configuration file add the 1.2.3.4/32 IP address pool to its whitelist: server { ... wallarm_acl default; allow 1.2.3.4/32; satisfy any; ... }","title":"Blocking with NGINX"},{"location":"en/admin-en/configure-ip-blocking-nginx-en/#blocking-with-nginx","text":"Supported version This feature is supported starting Wallarm Node 2.8 By default, blocking by IP address is turned off. To activate it, proceed to the following steps: Go to the folder that contains the NGINX configuration files. To do this, select and run the command that corresponds with your filter node installation method from the tabs below. {% termtabs name=\"Dynamic NGINX module\" -%} $ cd /etc/nginx/conf.d {%- tab name=\"Dynamic NGINX module from OS repositories\" -%} $ cd /etc/nginx/conf.d {%- tab name=\"NGINX Plus module\" -%} $ cd /etc/nginx/conf.d {%- tab name=\"NGINX-Wallarm module (DEPRECATED)\" -%} $ cd /etc/nginx-wallarm/conf.d {%- endtermtabs %} In the current folder, create a file named /etc/nginx/conf.d/wallarm-acl.conf with the following content: wallarm_acl_db default { wallarm_acl_path <path-to-wallarm-acl-folder>; wallarm_acl_mapsize 64m; } server { listen 127.0.0.9:80; server_name localhost; allow 127.0.0.0/8; deny all; access_log off; location /wallarm-acl { wallarm_acl default; wallarm_acl_api on; } } In the configuration above, <path-to-wallarm-acl-folder> is a path to an empty directory, in which the nginx user can create subdirectories and files for storing access control lists. Checking the nginx user rights Run the following command to check whether the nginx user has rights to perform actions on the directory: sudo -u nginx [ -r <path-to-directory> ] && [ -w <path-to-directory> ] && echo \"\u041e\u041a\" In this command, <path-to-directory> is the path to the directory, access to which you need to check. Due to the sudo -u nginx prefix, this command is executed using the nginx user. The command first checks whether the user has permission to read the directory (the [ -r <path-to-directory> ] part). Next, it checks whether the user has permission to write into the directory (the [ -w <path-to-directory> ] part). If the nginx user has permission to read and write into the directory specified in the command, the terminal outputs the OK message. The specified directory can be used as a wallarm_acl_path value. If the nginx user does not have the required permission, the terminal output is empty. Example: Directories that are valid for access control list storage depend on the filter node installation method you used and your OS. The valid directories to specify in the wallarm_acl_path directive are as follows: * Dynamic NGINX module: {% termtabs name=\"Debian 8.x (jessie)\" -%} /var/cache/nginx/wallarm_acl_default {%- tab name=\"Debian 9.x (stretch)\" -%} /var/cache/nginx/wallarm_acl_default {%- tab name=\"Debian 10.x (buster)\" -%} /var/cache/nginx/wallarm_acl_default {%- tab name=\"Ubuntu 14.04 LTS (trusty)\" -%} /var/cache/nginx/wallarm_acl_default {%- tab name=\"Ubuntu 16.04 LTS (xenial)\" -%} /var/cache/nginx/wallarm_acl_default {%- tab name=\"Ubuntu 18.04 LTS (bionic)\" -%} /var/cache/nginx/wallarm_acl_default {%- tab name=\"CentOS 6.x\" -%} /var/cache/nginx/wallarm_acl_default {%- tab name=\"CentOS 7.x\" -%} /var/lib/nginx/wallarm_acl_default {%- tab name=\"Amazon Linux 2\" -%} /var/lib/nginx/wallarm_acl_default {%- endtermtabs %} Dynamic NGINX module from OS repositories: {% termtabs name=\"Debian 8.x (jessie)\" -%} /var/lib/nginx/wallarm_acl_default {%- tab name=\"Debian 9.x (stretch)\" -%} /var/lib/nginx/wallarm_acl_default {%- tab name=\"Debian 10.x (buster)\" -%} /var/lib/nginx/wallarm_acl_default {%- tab name=\"Ubuntu 14.04 LTS (trusty)\" -%} /var/lib/nginx/wallarm_acl_default {%- tab name=\"Ubuntu 16.04 LTS (xenial)\" -%} /var/lib/nginx/wallarm_acl_default {%- tab name=\"Ubuntu 18.04 LTS (bionic)\" -%} /var/lib/nginx/wallarm_acl_default {%- tab name=\"CentOS 6.x\" -%} /var/lib/nginx/wallarm_acl_default {%- tab name=\"CentOS 7.x\" -%} /var/lib/nginx/wallarm_acl_default {%- tab name=\"Amazon Linux 2\" -%} /var/lib/nginx/wallarm_acl_default {%- endtermtabs %} NGINX Plus module: {% termtabs name=\"Debian 8.x (jessie)\" -%} /var/lib/nginx/wallarm_acl_default {%- tab name=\"Debian 9.x (stretch)\" -%} /var/lib/nginx/wallarm_acl_default {%- tab name=\"Debian 10.x (buster)\" -%} /var/lib/nginx/wallarm_acl_default {%- tab name=\"Ubuntu 14.04 LTS (trusty)\" -%} /var/lib/nginx/wallarm_acl_default {%- tab name=\"Ubuntu 16.04 LTS (xenial)\" -%} /var/lib/nginx/wallarm_acl_default {%- tab name=\"Ubuntu 18.04 LTS (bionic)\" -%} /var/lib/nginx/wallarm_acl_default {%- tab name=\"CentOS 6.x\" -%} /var/lib/nginx/wallarm_acl_default {%- tab name=\"CentOS 7.x\" -%} /var/lib/nginx/wallarm_acl_default {%- tab name=\"Amazon Linux 2\" -%} /var/lib/nginx/wallarm_acl_default {%- endtermtabs %} NGINX-Wallarm module (DEPRECATED): {% termtabs name=\"Debian 8.x (jessie)\" -%} /var/lib/nginx-wallarm/wallarm_acl_default {%- tab name=\"Debian 9.x (stretch)\" -%} /var/lib/nginx-wallarm/wallarm_acl_default {%- tab name=\"Debian 10.x (buster)\" -%} /var/lib/nginx-wallarm/wallarm_acl_default {%- tab name=\"Ubuntu 14.04 LTS (trusty)\" -%} /var/lib/nginx-wallarm/wallarm_acl_default {%- tab name=\"Ubuntu 16.04 LTS (xenial)\" -%} /var/lib/nginx-wallarm/wallarm_acl_default {%- tab name=\"Ubuntu 18.04 LTS (bionic)\" -%} /var/lib/nginx-wallarm/wallarm_acl_default {%- tab name=\"CentOS 6.x\" -%} /var/cache/nginx-wallarm/wallarm_acl_default {%- tab name=\"CentOS 7.x\" -%} /var/cache/nginx-wallarm/wallarm_acl_default {%- tab name=\"Amazon Linux 2\" -%} /var/cache/nginx-wallarm/wallarm_acl_default {%- endtermtabs %} Turn on blocking for the particular vhosts and/or locations by adding the following lines to their configuration files: server { ... wallarm_acl default; ... } Add the following lines to the /etc/wallarm/node.yaml file: sync_blacklist: nginx_url: http://127.0.0.9/wallarm-acl Activate the blacklist synchronization. One way to do this is to uncomment the line containing sync-blacklist as a substring in the /etc/cron.d/wallarm-node-nginx file by removing the # symbol at the beginning of the line. You can also do this by running the following command: # sed -i -Ee 's/^#(.*sync-blacklist.*)/\\1/' /etc/cron.d/wallarm-node-nginx Using the sed command Sed is a stream editor. By default, sed writes to standard output. The -i option means that the file will be edited in-place. The -eE option comprises two options: * The -e option means the following: * The first non-option parameter will be used as a script to run on the input. * The second non-option parameter will be used as an input file. * The -E option means that the script following this option uses the extended regular expression syntax . The script that follows the options replaces the lines that satisfy the ^#(.*sync-blacklist.*) regular expression with the string that satisfies the subexpression in parenthesis in the /etc/cron.d/wallarm-node-nginx file. The \\1 back-reference of the sed command means that the subexpression in the first parenthesis should be used as a replacement. The line that satisfies the ^#(.*sync-blacklist.*) regular expression * starts with the # symbol. * contains sync-blacklist as a substring. The replacement for the described line is the substring of this line without the # symbol at the beginning of the line. This command uncomments the line that enables blacklist synchronization. Thus, the blacklist synchronization will be activated. You can learn more about sed by proceeding with the link . You can add IP addresses to the whitelist to skip checking of the blacklist upon receiving a request from them. For example, the following lines in the vhost or location configuration file add the 1.2.3.4/32 IP address pool to its whitelist: server { ... wallarm_acl default; allow 1.2.3.4/32; satisfy any; ... }","title":"Blocking with NGINX"},{"location":"en/admin-en/configure-kubernetes-en/","text":"Fine-tuning of Wallarm Ingress Controller \u00b6 Official documentation for NGINX Ingress Controller The fine-tuning of Wallarm Ingress Controller is quite similar to that of NGINX Ingress Controller described in the [official documentation](https://kubernetes.github.io/ingress-nginx/user-guide/nginx-configuration/). When working with Wallarm, all options for setting up the original NGINX Ingress Controller are available. Additional Settings for Helm Chart \u00b6 The settings are performed via the values.yaml file. By default, the file looks as follows: wallarm: enabled: false apiHost: api.wallarm.com apiPort: 444 apiSSL: true token: \"\" tarantool: kind: Deployment service: annotations: {} replicaCount: 1 arena: \"0.2\" livenessProbe: failureThreshold: 3 initialDelaySeconds: 10 periodSeconds: 10 successThreshold: 1 timeoutSeconds: 1 resources: {} metrics: enabled: false service: annotations: prometheus.io/scrape: \"true\" prometheus.io/path: /wallarm-metrics prometheus.io/port: \"18080\" ## List of IP addresses at which the stats-exporter service is available ## Ref: https://kubernetes.io/docs/user-guide/services/#external-ips ## externalIPs: [] loadBalancerIP: \"\" loadBalancerSourceRanges: [] servicePort: 9913 type: ClusterIP synccloud: resources: {} collectd: resources: {} acl: enabled: false resources: {} Description of main parameters you can set up is provided below. Other parameters always have default value or need to be changed rarely, its description is provided by the link . wallarm.enabled \u00b6 Allows you to enable or disable Wallarm functions. Default value : false wallarm.apiHost \u00b6 Wallarm API endpoint. Can be: api.wallarm.com for the EU cloud , us1.api.wallarm.com for the US cloud . Default value : api.wallarm.com wallarm.token \u00b6 The Cloud Node token is created on the Wallarm portal in the EU or US cloud . It is required to access to Wallarm API. Default value : not specified wallarm.tarantool.replicaCount \u00b6 The number of running pods for postanalytics. Postanalytics is used for the behavior-based attack detection. Default value : 1 wallarm.tarantool.arena \u00b6 Specifies the amount of memory allocated for postanalytics service. It is recommended to set up a value sufficient to store requests data for the last 5-15 minutes. Default value : 0.2 wallarm.metrics.enabled \u00b6 This switch toggles information and metrics collection. If Prometheus is installed in the Kubernetes cluster, no additional configuration is required. Default value : false Global Controller Settings \u00b6 Implemented via ConfigMap . Besides the standard ones, the following additional parameters are supported: enable-wallarm - enables the Wallarm module in NGINX wallarm-upstream-connect-attempts wallarm-upstream-reconnect-interval wallarm-process-time-limit wallarm-process-time-limit-block wallarm-request-memory-limit enable-wallarm-acl - enables blocking by IP addresses specified in your Wallarm account wallarm-acl-mapsize Ingress Annotations \u00b6 These annotations are used for setting up parameters for processing individual instances of Ingress. Besides the standard ones , the following additional annotations are supported: nginx.ingress.kubernetes.io/wallarm-mode , default: off nginx.ingress.kubernetes.io/wallarm-mode-allow-override nginx.ingress.kubernetes.io/wallarm-fallback nginx.ingress.kubernetes.io/wallarm-instance nginx.ingress.kubernetes.io/wallarm-block-page nginx.ingress.kubernetes.io/wallarm-parse-response nginx.ingress.kubernetes.io/wallarm-parse-websocket nginx.ingress.kubernetes.io/wallarm-unpack-response nginx.ingress.kubernetes.io/wallarm-parser-disable nginx.ingress.kubernetes.io/wallarm-acl To apply the settings to your Ingress, please use the following command: # kubectl annotate --overwrite ingress YOUR_INGRESS_NAME ANNOTATION_NAME=VALUE YOUR_INGRESS_NAME is the name of your Ingress, ANNOTATION_NAME is the name of the annotation from the list above, VALUE is the value of the annotation from the list above. For example, to enable IP blocking, create the addresses list in your Wallarm account and execute the following command: # kubectl annotate --overwrite ingress YOUR_INGRESS_NAME nginx.ingress.kubernetes.io/wallarm-acl=on","title":"Fine-tuning of Wallarm Ingress Controller"},{"location":"en/admin-en/configure-kubernetes-en/#fine-tuning-of-wallarm-ingress-controller","text":"Official documentation for NGINX Ingress Controller The fine-tuning of Wallarm Ingress Controller is quite similar to that of NGINX Ingress Controller described in the [official documentation](https://kubernetes.github.io/ingress-nginx/user-guide/nginx-configuration/). When working with Wallarm, all options for setting up the original NGINX Ingress Controller are available.","title":"Fine-tuning of Wallarm Ingress Controller"},{"location":"en/admin-en/configure-kubernetes-en/#additional-settings-for-helm-chart","text":"The settings are performed via the values.yaml file. By default, the file looks as follows: wallarm: enabled: false apiHost: api.wallarm.com apiPort: 444 apiSSL: true token: \"\" tarantool: kind: Deployment service: annotations: {} replicaCount: 1 arena: \"0.2\" livenessProbe: failureThreshold: 3 initialDelaySeconds: 10 periodSeconds: 10 successThreshold: 1 timeoutSeconds: 1 resources: {} metrics: enabled: false service: annotations: prometheus.io/scrape: \"true\" prometheus.io/path: /wallarm-metrics prometheus.io/port: \"18080\" ## List of IP addresses at which the stats-exporter service is available ## Ref: https://kubernetes.io/docs/user-guide/services/#external-ips ## externalIPs: [] loadBalancerIP: \"\" loadBalancerSourceRanges: [] servicePort: 9913 type: ClusterIP synccloud: resources: {} collectd: resources: {} acl: enabled: false resources: {} Description of main parameters you can set up is provided below. Other parameters always have default value or need to be changed rarely, its description is provided by the link .","title":"Additional Settings for Helm Chart"},{"location":"en/admin-en/configure-kubernetes-en/#wallarmenabled","text":"Allows you to enable or disable Wallarm functions. Default value : false","title":"wallarm.enabled"},{"location":"en/admin-en/configure-kubernetes-en/#wallarmapihost","text":"Wallarm API endpoint. Can be: api.wallarm.com for the EU cloud , us1.api.wallarm.com for the US cloud . Default value : api.wallarm.com","title":"wallarm.apiHost"},{"location":"en/admin-en/configure-kubernetes-en/#wallarmtoken","text":"The Cloud Node token is created on the Wallarm portal in the EU or US cloud . It is required to access to Wallarm API. Default value : not specified","title":"wallarm.token"},{"location":"en/admin-en/configure-kubernetes-en/#wallarmtarantoolreplicacount","text":"The number of running pods for postanalytics. Postanalytics is used for the behavior-based attack detection. Default value : 1","title":"wallarm.tarantool.replicaCount"},{"location":"en/admin-en/configure-kubernetes-en/#wallarmtarantoolarena","text":"Specifies the amount of memory allocated for postanalytics service. It is recommended to set up a value sufficient to store requests data for the last 5-15 minutes. Default value : 0.2","title":"wallarm.tarantool.arena"},{"location":"en/admin-en/configure-kubernetes-en/#wallarmmetricsenabled","text":"This switch toggles information and metrics collection. If Prometheus is installed in the Kubernetes cluster, no additional configuration is required. Default value : false","title":"wallarm.metrics.enabled"},{"location":"en/admin-en/configure-kubernetes-en/#global-controller-settings","text":"Implemented via ConfigMap . Besides the standard ones, the following additional parameters are supported: enable-wallarm - enables the Wallarm module in NGINX wallarm-upstream-connect-attempts wallarm-upstream-reconnect-interval wallarm-process-time-limit wallarm-process-time-limit-block wallarm-request-memory-limit enable-wallarm-acl - enables blocking by IP addresses specified in your Wallarm account wallarm-acl-mapsize","title":"Global Controller Settings"},{"location":"en/admin-en/configure-kubernetes-en/#ingress-annotations","text":"These annotations are used for setting up parameters for processing individual instances of Ingress. Besides the standard ones , the following additional annotations are supported: nginx.ingress.kubernetes.io/wallarm-mode , default: off nginx.ingress.kubernetes.io/wallarm-mode-allow-override nginx.ingress.kubernetes.io/wallarm-fallback nginx.ingress.kubernetes.io/wallarm-instance nginx.ingress.kubernetes.io/wallarm-block-page nginx.ingress.kubernetes.io/wallarm-parse-response nginx.ingress.kubernetes.io/wallarm-parse-websocket nginx.ingress.kubernetes.io/wallarm-unpack-response nginx.ingress.kubernetes.io/wallarm-parser-disable nginx.ingress.kubernetes.io/wallarm-acl To apply the settings to your Ingress, please use the following command: # kubectl annotate --overwrite ingress YOUR_INGRESS_NAME ANNOTATION_NAME=VALUE YOUR_INGRESS_NAME is the name of your Ingress, ANNOTATION_NAME is the name of the annotation from the list above, VALUE is the value of the annotation from the list above. For example, to enable IP blocking, create the addresses list in your Wallarm account and execute the following command: # kubectl annotate --overwrite ingress YOUR_INGRESS_NAME nginx.ingress.kubernetes.io/wallarm-acl=on","title":"Ingress Annotations"},{"location":"en/admin-en/configure-logging/","text":"Working with Filter Node Logs \u00b6 Where Filter Node Logs are Stored \u00b6 A filter node stores the following log files in the /var/log/wallarm directory: brute-detect.log and sync-brute-clusters.log : the log of fetching the brute force attack-related counters in the filter node cluster. export-attacks.log : the log of exporting the attacks' data from the postanalytics module to the Wallarm cloud. export-clusterization-data.log : the log of exporting the filter node cluster's data. export-counters.log : the log of exporting the counters' data (see \u201cMonitoring the Filter Node\u201d ). export-spots.log : the log of exporting the requests' metrics. sync-markers.log : the log of fetching the markers from the Wallarm cloud. syncnode.log : the log of syncing the filter node with the Wallarm cloud (this includes fetching the LOM and proton.db files from the cloud). tarantool.log : the log of the postanalytics module operations. Configuring Extended Logging for the NGINX-Based Filter Node \u00b6 NGINX writes logs of the processed requests (access logs) into a separate log file, using the predefined combined logging format by default. log_format combined '$remote_addr - $remote_user [$time_local] ' '\"$request\" $request_id $status $body_bytes_sent ' '\"$http_referer\" \"$http_user_agent\"'; You can define and use a custom logging format by including one or several filter node variables (as well as other NGINX variables if needed). The NGINX log file will allow for much faster filter node diagnostics. Filter Node Variables \u00b6 You may use the following filter node variables when defining the NGINX logging format: Name Type Value request_id String Request identifier Has the following value form: a79199bcea606040cc79f913325401fb wallarm_request_time Float Request execution time in seconds wallarm_serialized_size Integer Size of the serialized request in bytes wallarm_is_input_valid Integer Request validity 0 : request is valid. The request has been checked by filter node and matches LOM rules. 1 : request is invalid. The request has been checked by filter node and does not match LOM rules. wallarm_attack_type Integer Attack types represented in the request in bit string format 0x00000000 : no attack: \"0\" 0x00000001 : agressive mode flag: \"1\" 0x00000002 : xss: \"2\" 0x00000004 : sqli: \"4\" 0x00000008 : rce: \"8\" 0x00000010 : xxe: \"16\" 0x00000020 : ptrav: \"32\" 0x00000040 : crlf: \"64\" 0x00000080 : redir: \"128\" 0x00000100 : nosqli: \"256\" 0x00000200 : infoleak: \"512\" 0x00001000 : marker: \"4096\" 0x20000000 : overlimit_res: \"536870912\" 0x40000000 : zip_bomb: \"1073741824\" 0x80000000 : vpatch: \"2147483648\" Configuration Example \u00b6 Let us assume that you need to specify the extended logging format named wallarm_combined that includes the following variables: all variables used in the combined format all filter node variables To do this, perform the following actions: The lines below describe the desired logging format. Add them into the http block of the NGINX configuration file. log_format wallarm_combined '$remote_addr - $remote_user [$time_local] ' '\"$request\" $request_id $status $body_bytes_sent ' '\"$http_referer\" \"$http_user_agent\"' '$wallarm_request_time $wallarm_serialized_size $wallarm_is_input_valid $wallarm_attack_type'; Enable the extended logging format by adding the following directive into the same block as in the first step: access_log /var/log/nginx/access.log wallarm_combined; Processed request logs will be written in the wallarm_combined format into the /var/log/nginx/access.log file. Debian 8.x (jessie) systemctl restart nginx Debian 9.x (stretch) systemctl restart nginx Debian 10.x (buster) systemctl restart nginx Ubuntu 14.04 LTS (trusty) service nginx restart Ubuntu 16.04 LTS (xenial) service nginx restart Ubuntu 18.04 LTS (bionic) service nginx restart CentOS 6.x service nginx restart CentOS 7.x systemctl restart nginx Amazon Linux 2 systemctl restart nginx #### Info:: Detailed information To see detailed information about configuring logging in NGINX, proceed to this [link][link-nginx-logging-docs].","title":"Working with Filter Node Logs"},{"location":"en/admin-en/configure-logging/#working-with-filter-node-logs","text":"","title":"Working with Filter Node Logs"},{"location":"en/admin-en/configure-logging/#where-filter-node-logs-are-stored","text":"A filter node stores the following log files in the /var/log/wallarm directory: brute-detect.log and sync-brute-clusters.log : the log of fetching the brute force attack-related counters in the filter node cluster. export-attacks.log : the log of exporting the attacks' data from the postanalytics module to the Wallarm cloud. export-clusterization-data.log : the log of exporting the filter node cluster's data. export-counters.log : the log of exporting the counters' data (see \u201cMonitoring the Filter Node\u201d ). export-spots.log : the log of exporting the requests' metrics. sync-markers.log : the log of fetching the markers from the Wallarm cloud. syncnode.log : the log of syncing the filter node with the Wallarm cloud (this includes fetching the LOM and proton.db files from the cloud). tarantool.log : the log of the postanalytics module operations.","title":"Where Filter Node Logs are Stored"},{"location":"en/admin-en/configure-logging/#configuring-extended-logging-for-the-nginx-based-filter-node","text":"NGINX writes logs of the processed requests (access logs) into a separate log file, using the predefined combined logging format by default. log_format combined '$remote_addr - $remote_user [$time_local] ' '\"$request\" $request_id $status $body_bytes_sent ' '\"$http_referer\" \"$http_user_agent\"'; You can define and use a custom logging format by including one or several filter node variables (as well as other NGINX variables if needed). The NGINX log file will allow for much faster filter node diagnostics.","title":"Configuring Extended Logging for the NGINX-Based Filter Node"},{"location":"en/admin-en/configure-logging/#filter-node-variables","text":"You may use the following filter node variables when defining the NGINX logging format: Name Type Value request_id String Request identifier Has the following value form: a79199bcea606040cc79f913325401fb wallarm_request_time Float Request execution time in seconds wallarm_serialized_size Integer Size of the serialized request in bytes wallarm_is_input_valid Integer Request validity 0 : request is valid. The request has been checked by filter node and matches LOM rules. 1 : request is invalid. The request has been checked by filter node and does not match LOM rules. wallarm_attack_type Integer Attack types represented in the request in bit string format 0x00000000 : no attack: \"0\" 0x00000001 : agressive mode flag: \"1\" 0x00000002 : xss: \"2\" 0x00000004 : sqli: \"4\" 0x00000008 : rce: \"8\" 0x00000010 : xxe: \"16\" 0x00000020 : ptrav: \"32\" 0x00000040 : crlf: \"64\" 0x00000080 : redir: \"128\" 0x00000100 : nosqli: \"256\" 0x00000200 : infoleak: \"512\" 0x00001000 : marker: \"4096\" 0x20000000 : overlimit_res: \"536870912\" 0x40000000 : zip_bomb: \"1073741824\" 0x80000000 : vpatch: \"2147483648\"","title":"Filter Node Variables"},{"location":"en/admin-en/configure-logging/#configuration-example","text":"Let us assume that you need to specify the extended logging format named wallarm_combined that includes the following variables: all variables used in the combined format all filter node variables To do this, perform the following actions: The lines below describe the desired logging format. Add them into the http block of the NGINX configuration file. log_format wallarm_combined '$remote_addr - $remote_user [$time_local] ' '\"$request\" $request_id $status $body_bytes_sent ' '\"$http_referer\" \"$http_user_agent\"' '$wallarm_request_time $wallarm_serialized_size $wallarm_is_input_valid $wallarm_attack_type'; Enable the extended logging format by adding the following directive into the same block as in the first step: access_log /var/log/nginx/access.log wallarm_combined; Processed request logs will be written in the wallarm_combined format into the /var/log/nginx/access.log file. Debian 8.x (jessie) systemctl restart nginx Debian 9.x (stretch) systemctl restart nginx Debian 10.x (buster) systemctl restart nginx Ubuntu 14.04 LTS (trusty) service nginx restart Ubuntu 16.04 LTS (xenial) service nginx restart Ubuntu 18.04 LTS (bionic) service nginx restart CentOS 6.x service nginx restart CentOS 7.x systemctl restart nginx Amazon Linux 2 systemctl restart nginx #### Info:: Detailed information To see detailed information about configuring logging in NGINX, proceed to this [link][link-nginx-logging-docs].","title":"Configuration Example"},{"location":"en/admin-en/configure-parameters-en/","text":"Configuration Options for the NGINX-Based Filter Node \u00b6 NGINX official documentation The Wallarm configuration is very similar to the NGINX configuration. See the official NGINX documentation . Along with the Wallarm specific configuration options, you have the full capabilities of NGINX configuration. Wallarm Directives \u00b6 wallarm_acl \u00b6 Allows you to restrict access to resources when a request IP address is in the specified ACL (Access Control List). The specified ACL must be declared with the directive wallarm_acl_db . You can use the satisfy directive to set constraints from both the ACL and other NGINX modules, such as ngx_http_access_module. Setting directive to off disables the ACL check. Example: satisfy any; wallarm_acl wapi; allow 1.2.3.4/0; deny all; #### Info:: This parameter can be set inside the http, server and/or location blocks. wallarm_acl_api \u00b6 If this directive is applied within the location block, than this location can be used to manage ACL content. Example: location / wallarm-acl { allow 127.0.0.1; deny all; wallarm_acl wapi; wallarm_acl_api on; } #### Info:: This parameter can be set inside the http, server and/or location blocks. wallarm_acl_db \u00b6 Allows you to declare and configure an ACL database to restrict access by IP addresses. Example wallarm_acl_db wapi { wallarm_acl_path /var/cache/nginx / wallarm/acl/wapi; } #### Info:: The parameter can only be configured at the main level. wallarm_acl_mapsize \u00b6 Allows you to set the initial memory size to be allocated for the corresponding ACL. When the limit is reached, the memory will be automatically reallocated, but the API request that attempted to change the ACL and caused the overflow, will produce an error and should be repeated. #### Info:: The parameter can only be configured inside the `wallarm_acl_db` block. wallarm_acl_path \u00b6 Specifies the directory that will be used to save the state of the ACL. #### Info:: The parameter can only be configured inside the `wallarm_acl_db` block. wallarm_acl_block_page \u00b6 Lets you set up the response code and the page returned to the client when the request was sent from the blocked IP address. The directive can take any value including: the path to the blocking page file on the server, the name of location , the path to the file with the blocking page template on the machine that runs NGINX, error code. To return a particular page in the response to the blocked request: Create the blocking page and save this file on the server. For example, the blacklist_block.html file. Add the wallarm_acl_block_page directive and specify the path to the blocking page file: wallarm_acl_block_page /path/blacklist_block.html The client with the blacklist IP address will be redirected to the blacklist_block.html page. To apply an existing location configuration to the blocked request: Enter the blocking message into the location block. For example: location @block {'The page is blocked';} Add the wallarm_acl_block_page directive and specify the location block name: wallarm_acl_block_page @block; location @block {'The page is blocked';} The request from the blacklist IP address will be blocked with the The page is blocked message. To return a specific error code along with the blocking page in the response to the blocked request: Create the blocking page and save this file on the server. For example, the 445.htm file. Add the location block with the blocking page settings: location @blocked { root /var/www/errors; # The directory with the 445.htm file rewrite ^(.*)$ /445.htm break; # The redirect to the /445.htm } Add the error_page object and specify the error code and the name of the blocking page location : error_page 445 @blocked; Add the location block with the error code settings: location = /err445 { internal; # The internal location that is not available from the outside return 445; # The 445 response code is returned } Add the wallarm_acl_block_page directive and specify the name of the error code location : wallarm_acl_block_page /err445; After all settings are applied, the configuration file will look like follows: wallarm_block_page /err445; # /err445 \u2013 location to redirect the request to error_page 445 @blocked; # The request that triggered the 445 error is passed to the @blocked location location @blocked { root /var/www/errors; # The directory with the 445.htm file rewrite ^(.*)$ /445.htm break; # The redirect to the /445.htm } location = /err445 { internal; # The internal location that is not available from the outside return 445; # The 445 response code is returned } The client with the blacklist IP address will be redirected to the 445.htm page and will receive the 445 error code in the response to the request. To return the dynamic blocking page in the response to the blocked request: Create a template for the dynamic blocking page and save this file on the machine that runs NGINX, for example, the blacklist_block.html page. You can also use the template provided by Wallarm which is named wallarm_blocked.html . Including NGINX variables in the blocking page template You can include NGINX variables in your blocking page template to display a dynamic value by specifying the name of the NGINX variable starting with the $ symbol. Add the wallarm_acl_block_page directive and specify the path to the template on the machine starting with the & symbol: wallarm_acl_block_page &C:/templates/blacklist_block.html Warning:: Important Information for Debian and CentOS Users \u00b6 If you use an NGINX version lower than 1.11 installed from CentOS/Debian repositories, you should remove the request_id variable from the page code in order to display the dynamic blocking page correctly: UUID ${request_id} # This part of the code should be removed This applies to both wallarm_blocked.html and to your own dynamic page template. Info:: \u00b6 This parameter can be set inside the http, server and location blocks. wallarm_api_conf \u00b6 A path to the node.yaml file, which contains access requirements for the Wallarm API. Example : wallarm_api_conf /etc/wallarm/node.yaml Used to upload serialized requests from the filtering node directly to the Wallarm API (cloud) instead of uploading into the postanalytics module (Tarantool). Only requests with attacks are sent to the API. Requests without attacks are not saved. Example of the node.yaml file content: # API connection credentials hostname: <some name> uuid: <some uuid> secret: <some secret> # API connection parameters (the parameters below are used by default) api: host: api.wallarm.com port: 444 use_ssl: true ca_verify: true wallarm_block_page \u00b6 Lets you set up the response code and page returned to the client when an invalid request has been blocked. The directive can take any value including: the path to the blocking page file on the server, the name of location , the path to the file with the blocking page template on the machine that runs NGINX, error code. To return a particular page in the response to the blocked request: Create the blocking page and save this file on the server. For example, the block.html file. Add the wallarm_block_page directive and specify the path to the blocking page file: wallarm_block_page /path/block.html The client sent the request will be redirected to the block.html page. To apply an existing location configuration to the blocked request: Enter the blocking message into the location block. For example: location @block {'The page is blocked';} Add the wallarm_block_page directive and specify the location block name: wallarm_block_page @block; location @block {'The page is blocked';} The request will be blocked with the The page is blocked message. To return a specific error code along with the blocking page in the response to the blocked request: Create the blocking page and save this file on the server. For example, the 445.htm file. Add the location block with the blocking page settings: location @blocked { root /var/www/errors; # The directory with the 445.htm file rewrite ^(.*)$ /445.htm break; # The redirect to the /445.htm } Add the error_page object and specify the error code and the name of the blocking page location : error_page 445 @blocked; Add the location block with the error code settings: location = /err445 { internal; # The internal location that is not available from the outside return 445; # The 445 response code is returned } Add the wallarm_block_page directive and specify the name of the error code location : wallarm_block_page /err445; After all settings are applied, the configuration file will look like follows: wallarm_block_page /err445; # /err445 \u2013 location to redirect the request to error_page 445 @blocked; # The request that triggered the 445 error is passed to the @blocked location location @blocked { root /var/www/errors; # The directory with the 445.htm file rewrite ^(.*)$ /445.htm break; # The redirect to the /445.htm } location = /err445 { internal; # The internal location that is not available from the outside return 445; # The 445 response code is returned } The client sent the request will be redirected to the 445.htm page and will receive the 445 error code in the response to the request. To return the dynamic blocking page in the response to the blocked request: Create a template for the dynamic blocking page and save this file on the machine that runs NGINX, for example, the block.html page. You can also use the template provided by Wallarm which is named wallarm_blocked.html . Including NGINX variables in the blocking page template You can include NGINX variables in your blocking page template to display a dynamic value by specifying the name of the NGINX variable starting with the $ symbol. Add the wallarm_block_page directive and specify the path to the template on the machine starting with the & symbol: wallarm_block_page &C:/templates/block.html Warning:: Important Information for Debian and CentOS Users \u00b6 If you use an NGINX version lower than 1.11 installed from CentOS/Debian repositories, you should remove the request_id variable from the page code in order to display the dynamic blocking page correctly: UUID ${request_id} # This part of the code should be removed This applies to both wallarm_blocked.html and to your own dynamic page template. Info:: \u00b6 This parameter can be set inside the http, server and location blocks. wallarm_cache_path \u00b6 A directory in which the backup catalog for the proton.db and LOM copy storage is created when the server starts. This directory must be writable for the client that runs NGINX. #### Info:: This parameter is configured inside the http block only. wallarm_fallback \u00b6 With the value set to on , NGINX has the ability to enter an emergency mode: if proton.db or LOM cannot be downloaded, this setting disables the Wallarm module for the http, server, and location blocks, for which the data fails to download. NGINX keeps functioning. #### Info:: This parameter can be set inside the http, server and location blocks. wallarm_force \u00b6 Sets the requests analysis and LOM rules generation based on the NGINX mirrored traffic. See Analyzing mirrored traffic with NGINX . wallarm_global_trainingset_path \u00b6 A path to the proton.db file that has the global settings for requests filtering, which do not depend on the application structure. #### Info:: This parameter can be set inside the http, server and location blocks. **Default value**: `/etc/wallarm/proton.db` wallarm_file_check_interval \u00b6 Defines an interval between checking new data in proton.db and LOM . The unit of measure is specified in the suffix as follows: not specified for minutes, s for seconds, ms for milliseconds. Info:: \u00b6 This parameter is configured inside the http block only. Default value : 1 (1 minute) wallarm_instance \u00b6 An application identifier. The directive is used to visually separate the data of different applications on Dashboard . Numeric values only. The application identifiers are used solely for the convenience of data presentation. To correctly separate the data of different applications, the same application identifiers must be set in the Wallarm interface. Any filter node will filter traffic for any number of applications without additional configuration. #### Info:: This parameter can be set inside the http, server and location blocks. wallarm_key_path \u00b6 A path to the Wallarm license key. #### Info:: **Default value**: `/etc/wallarm/license.key` wallarm_local_trainingset_path \u00b6 A path to the LOM file that contains information on the protected application and the filter node settings. #### Info:: This parameter can be set inside the http, server and location blocks. **Default value**: `/etc/wallarm/lom` wallarm_mode \u00b6 Traffic processing mode: off : requests are not processed. monitoring : all requests are processed, but none of them is blocked even if an attack is detected. block : all requests where an attack was detected are blocked. aggressive : all non-standard requests are blocked. For example, mapping a string in the field usually used for passing a number. Use this mode with extreme caution. The value can include variables that are available after receiving a request string and headers. This can be used for applying various policies for various clients: map $remote_addr $wallarm_mode_real { default block; 1.1.1.1/24 monitoring; 2.2.2.2 off; } ... wallarm_mode $wallarm_mode_real; You can see the detailed example of filtration mode configuration by proceeding to the link . #### Info:: This parameter can be set inside the http, server and location blocks. **Default value**: `off` #### Warning:: Disable Blocking of the Wallarm Scanner IP Addresses Note that if you use the blocking mode by default (`default block;`) when detecting malicious requests, you must explicitly specify for the Wallarm scanner a list of IP addresses from which requests should not be blocked. You can read more about disabling the blocking mode for scanner IP addresses [here](scanner-ips-whitelisting.md). Usage of wallarm_mode can be restricted by the wallarm_mode_allow_override directive. wallarm_mode_allow_override \u00b6 Manages the ability to override the wallarm_mode values via filtering rules downloaded from the Wallarm cloud (LOM): off : the rules set in LOM are ignored. strict : LOM can only strengthen the operation mode. on : it is possible to both strengthen and soften the operation mode. For example, with wallarm_mode monitoring and wallarm_mode_allow_override strict set, the Wallarm cloud can be used to enable blocking of some requests, but the attack analysis cannot be fully disabled. #### Info:: This parameter can be set inside the http, server and location blocks. **Default value**: `on` wallarm_parse_response \u00b6 The mode of processing web server responses; by default, only the client's request to the web server can be processed. Possible values: on : analysis of web server responses by a passive vulnerability scanner without sending requests from the Wallarm cloud). off : responses are not analyzed. Info:: \u00b6 This parameter can be set inside http, server and location blocks. Default value : on #### Warning:: Improve performance You are recommended to disable processing of static files through `location` to improve performance. wallarm_parse_websocket \u00b6 Wallarm has full WebSockets support. By default, the WebSockets messages are not analyzed for attacks. To force the feature, use the wallarm_parse_websocket directive. Possible values: - on : message analyses is enabled - off : message analyses is disabled. #### Info:: This parameter can be set inside the http, server and location blocks. **Default value**: `off` wallarm_parser_disable \u00b6 Allows to disable parsers. The following parsers are currently supported: cookie zlib htmljs json multipart base64 percent urlenc xml Example wallarm_parser_disable base64; wallarm_parser_disable xml; location /ab { wallarm_parser_disable json; wallarm_parser_disable base64; proxy_pass http://example.com; } location /zy { wallarm_parser_disable json; proxy_pass http://example.com; } #### Info:: This parameter can be set inside the http, server and location blocks. wallarm_parse_html_response \u00b6 Lets you enable and disable an HTML parser for responses to requests. Can be: on off Info:: \u00b6 This parameter can be set inside the http, server and location blocks. Default value : on wallarm_stalled_worker_timeout \u00b6 Sets the time limit of a single request processing for NGINX worker in seconds. If the time exceeds the limit, data about NGINX workers is written to the stalled_workers_count and stalled_workers statistic parameters. #### Info:: This parameter can be set inside the http, server and location blocks. **Default value**: `5` (5 seconds) wallarm_process_time_limit \u00b6 Sets the time limit of a single request processing in milliseconds. If the time exceeds the limit, an error is recorded into the log and the request is marked as an overlimit_res attack. The requests are blocked in the blocking mode ( wallarm_mode block; ) and ignored in the monitoring mode ( wallarm_mode monitoring; ). Default value is 1000ms (one second). #### Info:: This parameter can be set inside the http, server and location blocks. wallarm_process_time_limit_block \u00b6 The ability to manage the blocking of requests, which exceed the time limit set in the wallarm_process_time_limit directive: on : the requests are always blocked off : the requests are always ignored attack : depends on the attack blocking mode set in the wallarm-mode directive: monitoring : the requests are ignored block and aggressive : the requests are blocked Info:: \u00b6 This parameter can be set inside the http, server and location blocks. Default value : wallarm_process_time_limit_block attack wallarm_request_memory_limit \u00b6 Set a limit for the maximum amount of memory that can be used for processing of a single request. If the limit is exceeded the request processing will be interrupted and a user will get 500 error. The following suffixes can be used in this parameter: k or K for kilobytes m or M for megabytes g or G for gigabytes Value of 0 turns the limit off. By default, limits are off. #### Info:: This parameter can be set inside the http, server and/or location blocks. wallarm_proton_log_mask_master \u00b6 Settings of the debug logging for the master process NGINX. #### Warning:: Using the directive You need to configure the directive only if you are told to do so by the Wallarm support team member. They will provide you with the value to use with the directive. #### Info:: The parameter can only be configured at the main level. wallarm_proton_log_mask_worker \u00b6 Settings of the debug logging for a worker process NGINX. #### Warning:: Using the directive You need to configure the directive only if you are told to do so by the Wallarm support team member. They will provide you with the value to use with the directive. #### Info:: The parameter can only be configured at the main level. wallarm_request_chunk_size \u00b6 Limits the size of the part of the request that is processed during one iteration. You can set up a custom value of the wallarm_request_chunk_size directive in bytes by assigning an integer to it. The directive also supports the following postfixes: k or K for kilobytes m or M for megabytes g or G for gigabytes Info:: \u00b6 This parameter can be set inside the http, server and location blocks. Default value : 8k (8 kilobytes). wallarm_set_tag \u00b6 Defines the key value pair for label each request. A value can contain variables. Specified tags will be available in postanalytics. Usage: wallarm_set_tag somename $var; #### Info:: This parameter can be set inside the server and/or location blocks. wallarm_tarantool_connect_attempts \u00b6 #### Warning:: Deprecated Use the [`wallarm_upstream_connect_attempts`](#wallarmupstreamconnectattempts) directive instead. wallarm_tarantool_connect_interval \u00b6 #### Warning:: Deprecated Use the [`wallarm_upstream_reconnect_interval`](#wallarmupstreamreconnectinterval) directive instead. wallarm_tarantool_upstream \u00b6 With the wallarm_tarantool_upstream you can balance the requests between several postanalytics servers. Example: upstream wallarm_tarantool { server 127.0.0.1:3313 max_fails=0 fail_timeout=0 max_conns=1; keepalive 1; } ... wallarm_tarantool_upstream wallarm_tarantool; See also Module ngx_http_upstream_module . #### Warning:: Required conditions It is required that the following conditions are satisfied for the `max_conns` and the `keepalive` parameters: * The value of the `keepalive` parameter must not be lower than the number of the tarantool servers. * The value of the `max_conns` parameter must be specified for each of the upstream Tarantool servers to prevent the creation of excessive connections. #### Info:: The parameter is configured inside the http block only. wallarm_timeslice \u00b6 A limit on the time that a filter node spends on one iteration of processing a request before it switches to the next request. Upon reaching the time limit, the filter node proceeds to process the next request in the queue. After performing one iteration on each of the requests in the queue, the node performs the second iteration of processing on the first request in the queue. You can use time intervals suffixes that are described in the nginx documentation to assign different time unit values to the directive. #### Info:: This parameter can be set inside the http, server and location blocks. **Default value**: `0` (time limit for single iteration is disabled). #### Warning:: Due to nginx server limitations, it is necessary to disable the request buffering by assigning the `off` value to the `proxy_request_buffering` nginx directive for the `wallarm_timeslice` directive to work. wallarm_ts_request_memory_limit \u00b6 Set a limit for the maximum amount of memory that can be used by one instance of proton.db and LOM. If the memory limit is exceeded while processing of some request, user will get 500 error. The following suffixes can be used in this parameter: k or K for kilobytes m or M for megabytes g or G for gigabyte Value of 0 turns the limit off. #### Info:: This parameter can be set inside the http, server and/or location blocks. **Default value**: `1` GB wallarm_unpack_response \u00b6 If the backend sends compressed data, the value on decompresses the data before processing. The value off turns off the decompressing. #### Info:: **Default value**: `on`. wallarm_upstream_backend \u00b6 A method for sending serialized requests. Requests can be sent either to the Tarantool or to the API. Possible values of the directive: tarantool api Depending on the other directives, the default value will be assigned as follows: tarantool \u2014if there is no wallarm_api_conf directive in the configuration. api \u2014if there is a wallarm_api_conf directive, but there is no wallarm_tarantool_upstream directive in the configuration. Warning:: Note \u00b6 If the wallarm_api_conf and wallarm_tarantool_upstream directives are present simultaneously in the configuration, a configuration error of the directive ambiguous wallarm upstream backend form will occur. Info:: \u00b6 This parameter can be set inside the http block only. wallarm_upstream_connect_attempts \u00b6 Defines the number of immediate reconnects to the Tarantool or Wallarm API. If a connection to the Tarantool or API is terminated, then the attempt to reconnect will not occur, except when there are no more connections and the serialized request queue is not empty. Note Reconnection may occur through another server because the \u201cupstream\u201d subsystem is responsible for choosing the server. This parameter can be set inside the http block only. wallarm_upstream_reconnect_interval \u00b6 Defines the interval between attempts to reconnect to the Tarantool or Wallarm API after the number of unsuccessful attempts has exceeded the wallarm_upstream_connect_attempts threshold. #### Info:: This parameter can be set inside the http block only. wallarm_upstream_connect_timeout \u00b6 Defines a timeout for connecting to the Tarantool or Wallarm API. #### Info:: This parameter can be set inside the http block only. wallarm_upstream_queue_limit \u00b6 Defines a limit to the number of serialized requests. Simultaneously setting the wallarm_upstream_queue_limit parameter and not setting the wallarm_upstream_queue_memory_limit parameter means that there will be no limit on the latter. #### Info:: This parameter can be set inside the http block only. wallarm_upstream_queue_memory_limit \u00b6 Defines a limit to the total volume of serialized requests. Simultaneously setting the wallarm_upstream_queue_memory_limit parameter and not setting the wallarm_upstream_queue_limit parameter means that there will be no limit on the latter. #### Info:: **Default value:** `100m`. This parameter can be set inside the http block only. wallarm_worker_rlimit_vmem \u00b6 #### Warning:: Deprecated It is now an alias for [wallarm_ts_request_memory_limit](#wallarmtsrequestmemorylimit) directive.","title":"Configuration Options (NGINX)"},{"location":"en/admin-en/configure-parameters-en/#configuration-options-for-the-nginx-based-filter-node","text":"NGINX official documentation The Wallarm configuration is very similar to the NGINX configuration. See the official NGINX documentation . Along with the Wallarm specific configuration options, you have the full capabilities of NGINX configuration.","title":"Configuration Options for the NGINX-Based Filter Node"},{"location":"en/admin-en/configure-parameters-en/#wallarm-directives","text":"","title":"Wallarm Directives"},{"location":"en/admin-en/configure-parameters-en/#wallarm_acl","text":"Allows you to restrict access to resources when a request IP address is in the specified ACL (Access Control List). The specified ACL must be declared with the directive wallarm_acl_db . You can use the satisfy directive to set constraints from both the ACL and other NGINX modules, such as ngx_http_access_module. Setting directive to off disables the ACL check. Example: satisfy any; wallarm_acl wapi; allow 1.2.3.4/0; deny all; #### Info:: This parameter can be set inside the http, server and/or location blocks.","title":"wallarm_acl"},{"location":"en/admin-en/configure-parameters-en/#wallarm_acl_api","text":"If this directive is applied within the location block, than this location can be used to manage ACL content. Example: location / wallarm-acl { allow 127.0.0.1; deny all; wallarm_acl wapi; wallarm_acl_api on; } #### Info:: This parameter can be set inside the http, server and/or location blocks.","title":"wallarm_acl_api"},{"location":"en/admin-en/configure-parameters-en/#wallarm_acl_db","text":"Allows you to declare and configure an ACL database to restrict access by IP addresses. Example wallarm_acl_db wapi { wallarm_acl_path /var/cache/nginx / wallarm/acl/wapi; } #### Info:: The parameter can only be configured at the main level.","title":"wallarm_acl_db"},{"location":"en/admin-en/configure-parameters-en/#wallarm_acl_mapsize","text":"Allows you to set the initial memory size to be allocated for the corresponding ACL. When the limit is reached, the memory will be automatically reallocated, but the API request that attempted to change the ACL and caused the overflow, will produce an error and should be repeated. #### Info:: The parameter can only be configured inside the `wallarm_acl_db` block.","title":"wallarm_acl_mapsize"},{"location":"en/admin-en/configure-parameters-en/#wallarm_acl_path","text":"Specifies the directory that will be used to save the state of the ACL. #### Info:: The parameter can only be configured inside the `wallarm_acl_db` block.","title":"wallarm_acl_path"},{"location":"en/admin-en/configure-parameters-en/#wallarm_acl_block_page","text":"Lets you set up the response code and the page returned to the client when the request was sent from the blocked IP address. The directive can take any value including: the path to the blocking page file on the server, the name of location , the path to the file with the blocking page template on the machine that runs NGINX, error code. To return a particular page in the response to the blocked request: Create the blocking page and save this file on the server. For example, the blacklist_block.html file. Add the wallarm_acl_block_page directive and specify the path to the blocking page file: wallarm_acl_block_page /path/blacklist_block.html The client with the blacklist IP address will be redirected to the blacklist_block.html page. To apply an existing location configuration to the blocked request: Enter the blocking message into the location block. For example: location @block {'The page is blocked';} Add the wallarm_acl_block_page directive and specify the location block name: wallarm_acl_block_page @block; location @block {'The page is blocked';} The request from the blacklist IP address will be blocked with the The page is blocked message. To return a specific error code along with the blocking page in the response to the blocked request: Create the blocking page and save this file on the server. For example, the 445.htm file. Add the location block with the blocking page settings: location @blocked { root /var/www/errors; # The directory with the 445.htm file rewrite ^(.*)$ /445.htm break; # The redirect to the /445.htm } Add the error_page object and specify the error code and the name of the blocking page location : error_page 445 @blocked; Add the location block with the error code settings: location = /err445 { internal; # The internal location that is not available from the outside return 445; # The 445 response code is returned } Add the wallarm_acl_block_page directive and specify the name of the error code location : wallarm_acl_block_page /err445; After all settings are applied, the configuration file will look like follows: wallarm_block_page /err445; # /err445 \u2013 location to redirect the request to error_page 445 @blocked; # The request that triggered the 445 error is passed to the @blocked location location @blocked { root /var/www/errors; # The directory with the 445.htm file rewrite ^(.*)$ /445.htm break; # The redirect to the /445.htm } location = /err445 { internal; # The internal location that is not available from the outside return 445; # The 445 response code is returned } The client with the blacklist IP address will be redirected to the 445.htm page and will receive the 445 error code in the response to the request. To return the dynamic blocking page in the response to the blocked request: Create a template for the dynamic blocking page and save this file on the machine that runs NGINX, for example, the blacklist_block.html page. You can also use the template provided by Wallarm which is named wallarm_blocked.html . Including NGINX variables in the blocking page template You can include NGINX variables in your blocking page template to display a dynamic value by specifying the name of the NGINX variable starting with the $ symbol. Add the wallarm_acl_block_page directive and specify the path to the template on the machine starting with the & symbol: wallarm_acl_block_page &C:/templates/blacklist_block.html","title":"wallarm_acl_block_page"},{"location":"en/admin-en/configure-parameters-en/#warning-important-information-for-debian-and-centos-users","text":"If you use an NGINX version lower than 1.11 installed from CentOS/Debian repositories, you should remove the request_id variable from the page code in order to display the dynamic blocking page correctly: UUID ${request_id} # This part of the code should be removed This applies to both wallarm_blocked.html and to your own dynamic page template.","title":"Warning:: Important Information for Debian and CentOS Users"},{"location":"en/admin-en/configure-parameters-en/#info","text":"This parameter can be set inside the http, server and location blocks.","title":"Info::"},{"location":"en/admin-en/configure-parameters-en/#wallarm_api_conf","text":"A path to the node.yaml file, which contains access requirements for the Wallarm API. Example : wallarm_api_conf /etc/wallarm/node.yaml Used to upload serialized requests from the filtering node directly to the Wallarm API (cloud) instead of uploading into the postanalytics module (Tarantool). Only requests with attacks are sent to the API. Requests without attacks are not saved. Example of the node.yaml file content: # API connection credentials hostname: <some name> uuid: <some uuid> secret: <some secret> # API connection parameters (the parameters below are used by default) api: host: api.wallarm.com port: 444 use_ssl: true ca_verify: true","title":"wallarm_api_conf"},{"location":"en/admin-en/configure-parameters-en/#wallarm_block_page","text":"Lets you set up the response code and page returned to the client when an invalid request has been blocked. The directive can take any value including: the path to the blocking page file on the server, the name of location , the path to the file with the blocking page template on the machine that runs NGINX, error code. To return a particular page in the response to the blocked request: Create the blocking page and save this file on the server. For example, the block.html file. Add the wallarm_block_page directive and specify the path to the blocking page file: wallarm_block_page /path/block.html The client sent the request will be redirected to the block.html page. To apply an existing location configuration to the blocked request: Enter the blocking message into the location block. For example: location @block {'The page is blocked';} Add the wallarm_block_page directive and specify the location block name: wallarm_block_page @block; location @block {'The page is blocked';} The request will be blocked with the The page is blocked message. To return a specific error code along with the blocking page in the response to the blocked request: Create the blocking page and save this file on the server. For example, the 445.htm file. Add the location block with the blocking page settings: location @blocked { root /var/www/errors; # The directory with the 445.htm file rewrite ^(.*)$ /445.htm break; # The redirect to the /445.htm } Add the error_page object and specify the error code and the name of the blocking page location : error_page 445 @blocked; Add the location block with the error code settings: location = /err445 { internal; # The internal location that is not available from the outside return 445; # The 445 response code is returned } Add the wallarm_block_page directive and specify the name of the error code location : wallarm_block_page /err445; After all settings are applied, the configuration file will look like follows: wallarm_block_page /err445; # /err445 \u2013 location to redirect the request to error_page 445 @blocked; # The request that triggered the 445 error is passed to the @blocked location location @blocked { root /var/www/errors; # The directory with the 445.htm file rewrite ^(.*)$ /445.htm break; # The redirect to the /445.htm } location = /err445 { internal; # The internal location that is not available from the outside return 445; # The 445 response code is returned } The client sent the request will be redirected to the 445.htm page and will receive the 445 error code in the response to the request. To return the dynamic blocking page in the response to the blocked request: Create a template for the dynamic blocking page and save this file on the machine that runs NGINX, for example, the block.html page. You can also use the template provided by Wallarm which is named wallarm_blocked.html . Including NGINX variables in the blocking page template You can include NGINX variables in your blocking page template to display a dynamic value by specifying the name of the NGINX variable starting with the $ symbol. Add the wallarm_block_page directive and specify the path to the template on the machine starting with the & symbol: wallarm_block_page &C:/templates/block.html","title":"wallarm_block_page"},{"location":"en/admin-en/configure-parameters-en/#warning-important-information-for-debian-and-centos-users_1","text":"If you use an NGINX version lower than 1.11 installed from CentOS/Debian repositories, you should remove the request_id variable from the page code in order to display the dynamic blocking page correctly: UUID ${request_id} # This part of the code should be removed This applies to both wallarm_blocked.html and to your own dynamic page template.","title":"Warning:: Important Information for Debian and CentOS Users"},{"location":"en/admin-en/configure-parameters-en/#info_1","text":"This parameter can be set inside the http, server and location blocks.","title":"Info::"},{"location":"en/admin-en/configure-parameters-en/#wallarm_cache_path","text":"A directory in which the backup catalog for the proton.db and LOM copy storage is created when the server starts. This directory must be writable for the client that runs NGINX. #### Info:: This parameter is configured inside the http block only.","title":"wallarm_cache_path"},{"location":"en/admin-en/configure-parameters-en/#wallarm_fallback","text":"With the value set to on , NGINX has the ability to enter an emergency mode: if proton.db or LOM cannot be downloaded, this setting disables the Wallarm module for the http, server, and location blocks, for which the data fails to download. NGINX keeps functioning. #### Info:: This parameter can be set inside the http, server and location blocks.","title":"wallarm_fallback"},{"location":"en/admin-en/configure-parameters-en/#wallarm_force","text":"Sets the requests analysis and LOM rules generation based on the NGINX mirrored traffic. See Analyzing mirrored traffic with NGINX .","title":"wallarm_force"},{"location":"en/admin-en/configure-parameters-en/#wallarm_global_trainingset_path","text":"A path to the proton.db file that has the global settings for requests filtering, which do not depend on the application structure. #### Info:: This parameter can be set inside the http, server and location blocks. **Default value**: `/etc/wallarm/proton.db`","title":"wallarm_global_trainingset_path"},{"location":"en/admin-en/configure-parameters-en/#wallarm_file_check_interval","text":"Defines an interval between checking new data in proton.db and LOM . The unit of measure is specified in the suffix as follows: not specified for minutes, s for seconds, ms for milliseconds.","title":"wallarm_file_check_interval"},{"location":"en/admin-en/configure-parameters-en/#info_2","text":"This parameter is configured inside the http block only. Default value : 1 (1 minute)","title":"Info::"},{"location":"en/admin-en/configure-parameters-en/#wallarm_instance","text":"An application identifier. The directive is used to visually separate the data of different applications on Dashboard . Numeric values only. The application identifiers are used solely for the convenience of data presentation. To correctly separate the data of different applications, the same application identifiers must be set in the Wallarm interface. Any filter node will filter traffic for any number of applications without additional configuration. #### Info:: This parameter can be set inside the http, server and location blocks.","title":"wallarm_instance"},{"location":"en/admin-en/configure-parameters-en/#wallarm_key_path","text":"A path to the Wallarm license key. #### Info:: **Default value**: `/etc/wallarm/license.key`","title":"wallarm_key_path"},{"location":"en/admin-en/configure-parameters-en/#wallarm_local_trainingset_path","text":"A path to the LOM file that contains information on the protected application and the filter node settings. #### Info:: This parameter can be set inside the http, server and location blocks. **Default value**: `/etc/wallarm/lom`","title":"wallarm_local_trainingset_path"},{"location":"en/admin-en/configure-parameters-en/#wallarm_mode","text":"Traffic processing mode: off : requests are not processed. monitoring : all requests are processed, but none of them is blocked even if an attack is detected. block : all requests where an attack was detected are blocked. aggressive : all non-standard requests are blocked. For example, mapping a string in the field usually used for passing a number. Use this mode with extreme caution. The value can include variables that are available after receiving a request string and headers. This can be used for applying various policies for various clients: map $remote_addr $wallarm_mode_real { default block; 1.1.1.1/24 monitoring; 2.2.2.2 off; } ... wallarm_mode $wallarm_mode_real; You can see the detailed example of filtration mode configuration by proceeding to the link . #### Info:: This parameter can be set inside the http, server and location blocks. **Default value**: `off` #### Warning:: Disable Blocking of the Wallarm Scanner IP Addresses Note that if you use the blocking mode by default (`default block;`) when detecting malicious requests, you must explicitly specify for the Wallarm scanner a list of IP addresses from which requests should not be blocked. You can read more about disabling the blocking mode for scanner IP addresses [here](scanner-ips-whitelisting.md). Usage of wallarm_mode can be restricted by the wallarm_mode_allow_override directive.","title":"wallarm_mode"},{"location":"en/admin-en/configure-parameters-en/#wallarm_mode_allow_override","text":"Manages the ability to override the wallarm_mode values via filtering rules downloaded from the Wallarm cloud (LOM): off : the rules set in LOM are ignored. strict : LOM can only strengthen the operation mode. on : it is possible to both strengthen and soften the operation mode. For example, with wallarm_mode monitoring and wallarm_mode_allow_override strict set, the Wallarm cloud can be used to enable blocking of some requests, but the attack analysis cannot be fully disabled. #### Info:: This parameter can be set inside the http, server and location blocks. **Default value**: `on`","title":"wallarm_mode_allow_override"},{"location":"en/admin-en/configure-parameters-en/#wallarm_parse_response","text":"The mode of processing web server responses; by default, only the client's request to the web server can be processed. Possible values: on : analysis of web server responses by a passive vulnerability scanner without sending requests from the Wallarm cloud). off : responses are not analyzed.","title":"wallarm_parse_response"},{"location":"en/admin-en/configure-parameters-en/#info_3","text":"This parameter can be set inside http, server and location blocks. Default value : on #### Warning:: Improve performance You are recommended to disable processing of static files through `location` to improve performance.","title":"Info::"},{"location":"en/admin-en/configure-parameters-en/#wallarm_parse_websocket","text":"Wallarm has full WebSockets support. By default, the WebSockets messages are not analyzed for attacks. To force the feature, use the wallarm_parse_websocket directive. Possible values: - on : message analyses is enabled - off : message analyses is disabled. #### Info:: This parameter can be set inside the http, server and location blocks. **Default value**: `off`","title":"wallarm_parse_websocket"},{"location":"en/admin-en/configure-parameters-en/#wallarm_parser_disable","text":"Allows to disable parsers. The following parsers are currently supported: cookie zlib htmljs json multipart base64 percent urlenc xml Example wallarm_parser_disable base64; wallarm_parser_disable xml; location /ab { wallarm_parser_disable json; wallarm_parser_disable base64; proxy_pass http://example.com; } location /zy { wallarm_parser_disable json; proxy_pass http://example.com; } #### Info:: This parameter can be set inside the http, server and location blocks.","title":"wallarm_parser_disable"},{"location":"en/admin-en/configure-parameters-en/#wallarm_parse_html_response","text":"Lets you enable and disable an HTML parser for responses to requests. Can be: on off","title":"wallarm_parse_html_response"},{"location":"en/admin-en/configure-parameters-en/#info_4","text":"This parameter can be set inside the http, server and location blocks. Default value : on","title":"Info::"},{"location":"en/admin-en/configure-parameters-en/#wallarm_stalled_worker_timeout","text":"Sets the time limit of a single request processing for NGINX worker in seconds. If the time exceeds the limit, data about NGINX workers is written to the stalled_workers_count and stalled_workers statistic parameters. #### Info:: This parameter can be set inside the http, server and location blocks. **Default value**: `5` (5 seconds)","title":"wallarm_stalled_worker_timeout"},{"location":"en/admin-en/configure-parameters-en/#wallarm_process_time_limit","text":"Sets the time limit of a single request processing in milliseconds. If the time exceeds the limit, an error is recorded into the log and the request is marked as an overlimit_res attack. The requests are blocked in the blocking mode ( wallarm_mode block; ) and ignored in the monitoring mode ( wallarm_mode monitoring; ). Default value is 1000ms (one second). #### Info:: This parameter can be set inside the http, server and location blocks.","title":"wallarm_process_time_limit"},{"location":"en/admin-en/configure-parameters-en/#wallarm_process_time_limit_block","text":"The ability to manage the blocking of requests, which exceed the time limit set in the wallarm_process_time_limit directive: on : the requests are always blocked off : the requests are always ignored attack : depends on the attack blocking mode set in the wallarm-mode directive: monitoring : the requests are ignored block and aggressive : the requests are blocked","title":"wallarm_process_time_limit_block"},{"location":"en/admin-en/configure-parameters-en/#info_5","text":"This parameter can be set inside the http, server and location blocks. Default value : wallarm_process_time_limit_block attack","title":"Info::"},{"location":"en/admin-en/configure-parameters-en/#wallarm_request_memory_limit","text":"Set a limit for the maximum amount of memory that can be used for processing of a single request. If the limit is exceeded the request processing will be interrupted and a user will get 500 error. The following suffixes can be used in this parameter: k or K for kilobytes m or M for megabytes g or G for gigabytes Value of 0 turns the limit off. By default, limits are off. #### Info:: This parameter can be set inside the http, server and/or location blocks.","title":"wallarm_request_memory_limit"},{"location":"en/admin-en/configure-parameters-en/#wallarm_proton_log_mask_master","text":"Settings of the debug logging for the master process NGINX. #### Warning:: Using the directive You need to configure the directive only if you are told to do so by the Wallarm support team member. They will provide you with the value to use with the directive. #### Info:: The parameter can only be configured at the main level.","title":"wallarm_proton_log_mask_master"},{"location":"en/admin-en/configure-parameters-en/#wallarm_proton_log_mask_worker","text":"Settings of the debug logging for a worker process NGINX. #### Warning:: Using the directive You need to configure the directive only if you are told to do so by the Wallarm support team member. They will provide you with the value to use with the directive. #### Info:: The parameter can only be configured at the main level.","title":"wallarm_proton_log_mask_worker"},{"location":"en/admin-en/configure-parameters-en/#wallarm_request_chunk_size","text":"Limits the size of the part of the request that is processed during one iteration. You can set up a custom value of the wallarm_request_chunk_size directive in bytes by assigning an integer to it. The directive also supports the following postfixes: k or K for kilobytes m or M for megabytes g or G for gigabytes","title":"wallarm_request_chunk_size"},{"location":"en/admin-en/configure-parameters-en/#info_6","text":"This parameter can be set inside the http, server and location blocks. Default value : 8k (8 kilobytes).","title":"Info::"},{"location":"en/admin-en/configure-parameters-en/#wallarm_set_tag","text":"Defines the key value pair for label each request. A value can contain variables. Specified tags will be available in postanalytics. Usage: wallarm_set_tag somename $var; #### Info:: This parameter can be set inside the server and/or location blocks.","title":"wallarm_set_tag"},{"location":"en/admin-en/configure-parameters-en/#wallarm_tarantool_connect_attempts","text":"#### Warning:: Deprecated Use the [`wallarm_upstream_connect_attempts`](#wallarmupstreamconnectattempts) directive instead.","title":"wallarm_tarantool_connect_attempts"},{"location":"en/admin-en/configure-parameters-en/#wallarm_tarantool_connect_interval","text":"#### Warning:: Deprecated Use the [`wallarm_upstream_reconnect_interval`](#wallarmupstreamreconnectinterval) directive instead.","title":"wallarm_tarantool_connect_interval"},{"location":"en/admin-en/configure-parameters-en/#wallarm_tarantool_upstream","text":"With the wallarm_tarantool_upstream you can balance the requests between several postanalytics servers. Example: upstream wallarm_tarantool { server 127.0.0.1:3313 max_fails=0 fail_timeout=0 max_conns=1; keepalive 1; } ... wallarm_tarantool_upstream wallarm_tarantool; See also Module ngx_http_upstream_module . #### Warning:: Required conditions It is required that the following conditions are satisfied for the `max_conns` and the `keepalive` parameters: * The value of the `keepalive` parameter must not be lower than the number of the tarantool servers. * The value of the `max_conns` parameter must be specified for each of the upstream Tarantool servers to prevent the creation of excessive connections. #### Info:: The parameter is configured inside the http block only.","title":"wallarm_tarantool_upstream"},{"location":"en/admin-en/configure-parameters-en/#wallarm_timeslice","text":"A limit on the time that a filter node spends on one iteration of processing a request before it switches to the next request. Upon reaching the time limit, the filter node proceeds to process the next request in the queue. After performing one iteration on each of the requests in the queue, the node performs the second iteration of processing on the first request in the queue. You can use time intervals suffixes that are described in the nginx documentation to assign different time unit values to the directive. #### Info:: This parameter can be set inside the http, server and location blocks. **Default value**: `0` (time limit for single iteration is disabled). #### Warning:: Due to nginx server limitations, it is necessary to disable the request buffering by assigning the `off` value to the `proxy_request_buffering` nginx directive for the `wallarm_timeslice` directive to work.","title":"wallarm_timeslice"},{"location":"en/admin-en/configure-parameters-en/#wallarm_ts_request_memory_limit","text":"Set a limit for the maximum amount of memory that can be used by one instance of proton.db and LOM. If the memory limit is exceeded while processing of some request, user will get 500 error. The following suffixes can be used in this parameter: k or K for kilobytes m or M for megabytes g or G for gigabyte Value of 0 turns the limit off. #### Info:: This parameter can be set inside the http, server and/or location blocks. **Default value**: `1` GB","title":"wallarm_ts_request_memory_limit"},{"location":"en/admin-en/configure-parameters-en/#wallarm_unpack_response","text":"If the backend sends compressed data, the value on decompresses the data before processing. The value off turns off the decompressing. #### Info:: **Default value**: `on`.","title":"wallarm_unpack_response"},{"location":"en/admin-en/configure-parameters-en/#wallarm_upstream_backend","text":"A method for sending serialized requests. Requests can be sent either to the Tarantool or to the API. Possible values of the directive: tarantool api Depending on the other directives, the default value will be assigned as follows: tarantool \u2014if there is no wallarm_api_conf directive in the configuration. api \u2014if there is a wallarm_api_conf directive, but there is no wallarm_tarantool_upstream directive in the configuration.","title":"wallarm_upstream_backend"},{"location":"en/admin-en/configure-parameters-en/#warning-note","text":"If the wallarm_api_conf and wallarm_tarantool_upstream directives are present simultaneously in the configuration, a configuration error of the directive ambiguous wallarm upstream backend form will occur.","title":"Warning:: Note"},{"location":"en/admin-en/configure-parameters-en/#info_7","text":"This parameter can be set inside the http block only.","title":"Info::"},{"location":"en/admin-en/configure-parameters-en/#wallarm_upstream_connect_attempts","text":"Defines the number of immediate reconnects to the Tarantool or Wallarm API. If a connection to the Tarantool or API is terminated, then the attempt to reconnect will not occur, except when there are no more connections and the serialized request queue is not empty. Note Reconnection may occur through another server because the \u201cupstream\u201d subsystem is responsible for choosing the server. This parameter can be set inside the http block only.","title":"wallarm_upstream_connect_attempts"},{"location":"en/admin-en/configure-parameters-en/#wallarm_upstream_reconnect_interval","text":"Defines the interval between attempts to reconnect to the Tarantool or Wallarm API after the number of unsuccessful attempts has exceeded the wallarm_upstream_connect_attempts threshold. #### Info:: This parameter can be set inside the http block only.","title":"wallarm_upstream_reconnect_interval"},{"location":"en/admin-en/configure-parameters-en/#wallarm_upstream_connect_timeout","text":"Defines a timeout for connecting to the Tarantool or Wallarm API. #### Info:: This parameter can be set inside the http block only.","title":"wallarm_upstream_connect_timeout"},{"location":"en/admin-en/configure-parameters-en/#wallarm_upstream_queue_limit","text":"Defines a limit to the number of serialized requests. Simultaneously setting the wallarm_upstream_queue_limit parameter and not setting the wallarm_upstream_queue_memory_limit parameter means that there will be no limit on the latter. #### Info:: This parameter can be set inside the http block only.","title":"wallarm_upstream_queue_limit"},{"location":"en/admin-en/configure-parameters-en/#wallarm_upstream_queue_memory_limit","text":"Defines a limit to the total volume of serialized requests. Simultaneously setting the wallarm_upstream_queue_memory_limit parameter and not setting the wallarm_upstream_queue_limit parameter means that there will be no limit on the latter. #### Info:: **Default value:** `100m`. This parameter can be set inside the http block only.","title":"wallarm_upstream_queue_memory_limit"},{"location":"en/admin-en/configure-parameters-en/#wallarm_worker_rlimit_vmem","text":"#### Warning:: Deprecated It is now an alias for [wallarm_ts_request_memory_limit](#wallarmtsrequestmemorylimit) directive.","title":"wallarm_worker_rlimit_vmem"},{"location":"en/admin-en/configure-selinux/","text":"Configuring SELinux \u00b6 If the SELinux mechanism is enabled on a host with a filter node, it may interfere with the filter node, rendering it inoperable: The filter node's RPS (requests per second) and APS (attacks per second) values will not be exported to the Wallarm cloud. It will not be possible to export filter node metrics to monitoring systems via the TCP protocol (see \u201cMonitoring the Filter Node\u201d ). SELinux is installed and enabled by default on RedHat-based Linux distributions (e.g., CentOS or Amazon Linux 2). SELinux can also be installed on other Linux distributions, such as Debian or Ubuntu. It is mandatory to either disable SELinux or configure SELinux so it does not disrupt the filter node operation. Check SELinux Status \u00b6 Execute the following command: # sestatus Examine the output: SELinux status: enabled SELinux status: disabled Configure SELinux \u00b6 Allow the collectd utility to use a TCP socket to make the filter node operable with SELinux enabled. To do so, execute the following command: # setsebool -P collectd_tcp_network_connect 1 Check if the aforementioned command executed successfully by running the following command: # semanage export | grep collectd_tcp_network_connect The output should contain this string: boolean -m -1 collectd_tcp_network_connect Disable SELinux \u00b6 To set SELinux to a disabled state either execute the setenforce 0 command (SELinux will be disabled until the next reboot) or set the value of the SELINUX variable to disabled in the /etc/selinux/config file, then reboot (SELinux will be disabled permanently).","title":"Configuring SELinux"},{"location":"en/admin-en/configure-selinux/#configuring-selinux","text":"If the SELinux mechanism is enabled on a host with a filter node, it may interfere with the filter node, rendering it inoperable: The filter node's RPS (requests per second) and APS (attacks per second) values will not be exported to the Wallarm cloud. It will not be possible to export filter node metrics to monitoring systems via the TCP protocol (see \u201cMonitoring the Filter Node\u201d ). SELinux is installed and enabled by default on RedHat-based Linux distributions (e.g., CentOS or Amazon Linux 2). SELinux can also be installed on other Linux distributions, such as Debian or Ubuntu. It is mandatory to either disable SELinux or configure SELinux so it does not disrupt the filter node operation.","title":"Configuring SELinux"},{"location":"en/admin-en/configure-selinux/#check-selinux-status","text":"Execute the following command: # sestatus Examine the output: SELinux status: enabled SELinux status: disabled","title":"Check SELinux Status"},{"location":"en/admin-en/configure-selinux/#configure-selinux","text":"Allow the collectd utility to use a TCP socket to make the filter node operable with SELinux enabled. To do so, execute the following command: # setsebool -P collectd_tcp_network_connect 1 Check if the aforementioned command executed successfully by running the following command: # semanage export | grep collectd_tcp_network_connect The output should contain this string: boolean -m -1 collectd_tcp_network_connect","title":"Configure SELinux"},{"location":"en/admin-en/configure-selinux/#disable-selinux","text":"To set SELinux to a disabled state either execute the setenforce 0 command (SELinux will be disabled until the next reboot) or set the value of the SELINUX variable to disabled in the /etc/selinux/config file, then reboot (SELinux will be disabled permanently).","title":"Disable SELinux"},{"location":"en/admin-en/configure-statistics-service/","text":"Configuring and Working with the Statistics Service \u00b6 To obtain statistics about the filter node, use the wallarm_status directive, which is written in the NGINX configuration file. Configuring the Statistics Service \u00b6 #### Warning:: Important. It is highly recommended to configure the statistics service in the separate configuration file `wallarm-status.conf` and not to use the `wallarm_status` directive in other files that you use when setting up NGINX, because the latter may be insecure. Also, it is strongly advised not to alter any of the existing lines of the default `wallarm-status` configuration as it may corrupt the process of metric data upload to the Wallarm cloud. When using the directive, statistics can be given in JSON format or in a format compatible with Prometheus . Usage: wallarm_status [on|off] [format=json|prometheus]; #### Info:: The directive can be configured in the context of `server` and/or `location`. When configuring the wallarm_status directive, you can specify the IP addresses from which you can request statistics. By default, access is denied from anywhere except for the IP addresses 127.0.0.1 and ::1 , which allow executing the request only from the server where Wallarm is installed. An example of a secure configuration of the filter node statistics service ( wallarm-status.conf ) is shown below: server { listen 127.0.0.8:80; server_name localhost; allow 127.0.0.0/8; # Access is only available for loopback addresses of the filter node server deny all; wallarm_mode off; access_log off; location /wallarm-status { wallarm_status on; } } #### Info:: The `listen` directive Note that if you change the IP address of the `listen` directive (in the example above, `127.0.0.8`), you will need to adjust the monitoring settings of the filter node to the new IP address. In addition, you may need to add or change the `allow` directive to allow access from addresses other than loopback addresses (the above configuration file allows access only to loopback addresses). To allow requests from another server, add the allow instruction with the IP address of the desired server in the configuration. For example: allow 10.41.29.0; Working with the Statistics Service \u00b6 To obtain the filter node statistics, make a request from one of the allowed IP addresses (see above): curl http://127.0.0.8/wallarm-status As a result, you will get a response of the type: { \"requests\":0,\"attacks\":0,\"blocked\":0,\"abnormal\":0,\"tnt_errors\":0,\"api_errors\":0, \"requests_lost\":0,\"segfaults\":0,\"memfaults\":0,\"softmemfaults\":0,\"time_detect\":0,\"db_id\":46, \"lom_id\":16767,\"proton_instances\": { \"total\":1,\"success\":1,\"fallback\":0,\"failed\":0 }, \"stalled_workers_count\":0,\"stalled_workers\":[] } The following response parameters are available in filter node version 2.10 and lower: requests : the number of requests that have been processed by the filter node. attacks : the number of recorded attacks. blocked : the number of blocked requests. abnormal : the number of requests the application deems abnormal. requests_lost : the number of requests that were not analyzed in a post-analytics module and transferred to API. For these requests, blocking parameters were applied (i.e., malicious requests were blocked if the system was operating in blocking mode); however, data on these events is not visible in the UI. This parameter is only used when the Wallarm Node works with a local post-analytics module. tnt_errors : the number of requests not analyzed by a post-analytics module. For these requests, the reasons for blocking are recorded, but the requests themselves are not counted in statistics and behavior checks. api_errors : the number of requests that were not submitted to the API for further analysis. For these requests, blocking parameters were applied (i.e., malicious requests were blocked if the system was operating in blocking mode); however, data on these events is not visible in the UI. This parameter is only used when the Wallarm Node works with a local post-analytics module. segfaults : the number of issues that led to the emergency termination of the worker process. memfaults : the number of issues where the virtual memory limits were reached. time_detect : the total time of requests analysis. db_id : proton.db version. lom_id : LOM version. proton_instances : information about proton.db + LOM pairs: total : the number of proton.db + LOM pairs. success : the number of the successfully uploaded proton.db + LOM pairs. fallback : the number of proton.db + LOM pairs loaded from the last saved files. failed : the number of proton.db + LOM pairs that were not initialized and run in the \u201cdo not analyze\u201d mode. The following parameters are available in filter node version 2.12: stalled_workers_count : the quantity of workers that exceeded the time limit for request processing (the limit is set in the wallarm_stalled_worker_timeout directive). stalled_workers : the list of the workers that exceeded the time limit for request processing (the limit is set in the wallarm_stalled_worker_timeout directive) and the amount of time spent on request processing. The data of all counters is accumulated from the moment NGINX is started. If Wallarm has been installed in a ready-made infrastructure with NGINX, the NGINX server must be restarted to start Wallarm.","title":"Configuring and Working with the Statistics Service"},{"location":"en/admin-en/configure-statistics-service/#configuring-and-working-with-the-statistics-service","text":"To obtain statistics about the filter node, use the wallarm_status directive, which is written in the NGINX configuration file.","title":"Configuring and Working with the Statistics Service"},{"location":"en/admin-en/configure-statistics-service/#configuring-the-statistics-service","text":"#### Warning:: Important. It is highly recommended to configure the statistics service in the separate configuration file `wallarm-status.conf` and not to use the `wallarm_status` directive in other files that you use when setting up NGINX, because the latter may be insecure. Also, it is strongly advised not to alter any of the existing lines of the default `wallarm-status` configuration as it may corrupt the process of metric data upload to the Wallarm cloud. When using the directive, statistics can be given in JSON format or in a format compatible with Prometheus . Usage: wallarm_status [on|off] [format=json|prometheus]; #### Info:: The directive can be configured in the context of `server` and/or `location`. When configuring the wallarm_status directive, you can specify the IP addresses from which you can request statistics. By default, access is denied from anywhere except for the IP addresses 127.0.0.1 and ::1 , which allow executing the request only from the server where Wallarm is installed. An example of a secure configuration of the filter node statistics service ( wallarm-status.conf ) is shown below: server { listen 127.0.0.8:80; server_name localhost; allow 127.0.0.0/8; # Access is only available for loopback addresses of the filter node server deny all; wallarm_mode off; access_log off; location /wallarm-status { wallarm_status on; } } #### Info:: The `listen` directive Note that if you change the IP address of the `listen` directive (in the example above, `127.0.0.8`), you will need to adjust the monitoring settings of the filter node to the new IP address. In addition, you may need to add or change the `allow` directive to allow access from addresses other than loopback addresses (the above configuration file allows access only to loopback addresses). To allow requests from another server, add the allow instruction with the IP address of the desired server in the configuration. For example: allow 10.41.29.0;","title":"Configuring the Statistics Service"},{"location":"en/admin-en/configure-statistics-service/#working-with-the-statistics-service","text":"To obtain the filter node statistics, make a request from one of the allowed IP addresses (see above): curl http://127.0.0.8/wallarm-status As a result, you will get a response of the type: { \"requests\":0,\"attacks\":0,\"blocked\":0,\"abnormal\":0,\"tnt_errors\":0,\"api_errors\":0, \"requests_lost\":0,\"segfaults\":0,\"memfaults\":0,\"softmemfaults\":0,\"time_detect\":0,\"db_id\":46, \"lom_id\":16767,\"proton_instances\": { \"total\":1,\"success\":1,\"fallback\":0,\"failed\":0 }, \"stalled_workers_count\":0,\"stalled_workers\":[] } The following response parameters are available in filter node version 2.10 and lower: requests : the number of requests that have been processed by the filter node. attacks : the number of recorded attacks. blocked : the number of blocked requests. abnormal : the number of requests the application deems abnormal. requests_lost : the number of requests that were not analyzed in a post-analytics module and transferred to API. For these requests, blocking parameters were applied (i.e., malicious requests were blocked if the system was operating in blocking mode); however, data on these events is not visible in the UI. This parameter is only used when the Wallarm Node works with a local post-analytics module. tnt_errors : the number of requests not analyzed by a post-analytics module. For these requests, the reasons for blocking are recorded, but the requests themselves are not counted in statistics and behavior checks. api_errors : the number of requests that were not submitted to the API for further analysis. For these requests, blocking parameters were applied (i.e., malicious requests were blocked if the system was operating in blocking mode); however, data on these events is not visible in the UI. This parameter is only used when the Wallarm Node works with a local post-analytics module. segfaults : the number of issues that led to the emergency termination of the worker process. memfaults : the number of issues where the virtual memory limits were reached. time_detect : the total time of requests analysis. db_id : proton.db version. lom_id : LOM version. proton_instances : information about proton.db + LOM pairs: total : the number of proton.db + LOM pairs. success : the number of the successfully uploaded proton.db + LOM pairs. fallback : the number of proton.db + LOM pairs loaded from the last saved files. failed : the number of proton.db + LOM pairs that were not initialized and run in the \u201cdo not analyze\u201d mode. The following parameters are available in filter node version 2.12: stalled_workers_count : the quantity of workers that exceeded the time limit for request processing (the limit is set in the wallarm_stalled_worker_timeout directive). stalled_workers : the list of the workers that exceeded the time limit for request processing (the limit is set in the wallarm_stalled_worker_timeout directive) and the amount of time spent on request processing. The data of all counters is accumulated from the moment NGINX is started. If Wallarm has been installed in a ready-made infrastructure with NGINX, the NGINX server must be restarted to start Wallarm.","title":"Working with the Statistics Service"},{"location":"en/admin-en/configure-tarantool-en/","text":"Changing Tarantool Memory Allocation \u00b6 The amount of memory determines the quality of work of the statistical algorithms. The recommended value is 75% of the total server memory. For example, if the server has 32 GB of memory, the recommended allocation size is 24 GB. Allocate the operating memory size for Tarantool: Open for editing the configuration file of Tarantool: Debian 8.x (jessie) vi /etc/default/wallarm-tarantool Debian 9.x (stretch) vi /etc/default/wallarm-tarantool Debian 10.x (buster) vi /etc/default/wallarm-tarantool Ubuntu 14.04 LTS (trusty) vi /etc/default/wallarm-tarantool Ubuntu 16.04 LTS (xenial) vi /etc/default/wallarm-tarantool Ubuntu 18.04 LTS (bionic) vi /etc/default/wallarm-tarantool CentOS 6.x vi /etc/sysconfig/wallarm-tarantool CentOS 7.x vi /etc/sysconfig/wallarm-tarantool Amazon Linux 2 vi /etc/sysconfig/wallarm-tarantool Set the allocated memory size in the configuration file of Tarantool via the SLAB_ALLOC_ARENA directive. For example: SLAB_ALLOC_ARENA=24 Restart Tarantool: Debian 8.x (jessie) systemctl restart wallarm-tarantool Debian 9.x (stretch) systemctl restart wallarm-tarantool Debian 10.x (buster) systemctl restart wallarm-tarantool Ubuntu 14.04 LTS (trusty) service wallarm-tarantool restart Ubuntu 16.04 LTS (xenial) service wallarm-tarantool restart Ubuntu 18.04 LTS (bionic) service wallarm-tarantool restart CentOS 6.x service wallarm-tarantool restart CentOS 7.x systemctl restart wallarm-tarantool Amazon Linux 2 systemctl restart wallarm-tarantool","title":"Changing Tarantool Memory Allocation"},{"location":"en/admin-en/configure-tarantool-en/#changing-tarantool-memory-allocation","text":"The amount of memory determines the quality of work of the statistical algorithms. The recommended value is 75% of the total server memory. For example, if the server has 32 GB of memory, the recommended allocation size is 24 GB. Allocate the operating memory size for Tarantool: Open for editing the configuration file of Tarantool: Debian 8.x (jessie) vi /etc/default/wallarm-tarantool Debian 9.x (stretch) vi /etc/default/wallarm-tarantool Debian 10.x (buster) vi /etc/default/wallarm-tarantool Ubuntu 14.04 LTS (trusty) vi /etc/default/wallarm-tarantool Ubuntu 16.04 LTS (xenial) vi /etc/default/wallarm-tarantool Ubuntu 18.04 LTS (bionic) vi /etc/default/wallarm-tarantool CentOS 6.x vi /etc/sysconfig/wallarm-tarantool CentOS 7.x vi /etc/sysconfig/wallarm-tarantool Amazon Linux 2 vi /etc/sysconfig/wallarm-tarantool Set the allocated memory size in the configuration file of Tarantool via the SLAB_ALLOC_ARENA directive. For example: SLAB_ALLOC_ARENA=24 Restart Tarantool: Debian 8.x (jessie) systemctl restart wallarm-tarantool Debian 9.x (stretch) systemctl restart wallarm-tarantool Debian 10.x (buster) systemctl restart wallarm-tarantool Ubuntu 14.04 LTS (trusty) service wallarm-tarantool restart Ubuntu 16.04 LTS (xenial) service wallarm-tarantool restart Ubuntu 18.04 LTS (bionic) service wallarm-tarantool restart CentOS 6.x service wallarm-tarantool restart CentOS 7.x systemctl restart wallarm-tarantool Amazon Linux 2 systemctl restart wallarm-tarantool","title":"Changing Tarantool Memory Allocation"},{"location":"en/admin-en/configure-wallarm-mode/","text":"Filtering Mode Configuration \u00b6 You can configure the filtering mode for the Wallarm filter nodes to define their behavior when processing incoming requests. The filtering mode can be configured in the following ways: Assign a value to the wallarm_mode directive in the filter node configuration file . Assign a value to the wallarm_mode_allow_override directive in the filter node configuration file . Define the general filtration rule on the Wallarm cloud . Create a filtration mode rule in the Rules tab of the Wallarm cloud . Available Filtering Modes \u00b6 The available filtering modes are listed in order from the mildest to the strictest in the following list: off : request filtering is not performed monitoring : requests are processed but none are blocked, even if malicious requests are detected block : requests are processed and all detected malicious requests are blocked. The wallarm_mode Directive \u00b6 Using the wallarm_mode directive in the filter node configuration file, you can define filtering modes for different contexts. These contexts are ordered from the most global to the most local in the following list: http : the directives inside the http block are applied to the requests sent to the HTTP server server : the directives inside the server block are applied to the requests sent to the virtual server location : the directives inside the location block are only applied to the requests containing that particular path If different wallarm_mode directive values are defined for the http , server , and location blocks, the most local configuration has the highest priority. The available filtering modes are listed above . The wallarm_mode Directive Usage Example \u00b6 http { wallarm_mode monitoring; server { server_name SERVER_A; } server { server_name SERVER_B; wallarm_mode off; } server { server_name SERVER_C; wallarm_mode off; location /main/content { wallarm_mode monitoring; } location /main/login { wallarm_mode block; } } } In this example, the filtering modes are defined for the resources as follows: The monitoring mode is applied to the requests sent to the HTTP server. The monitoring mode is applied to the requests sent to the virtual server SERVER_A . The off mode is applied to the requests sent to the virtual server SERVER_B . The off mode is applied to the requests sent to the virtual server SERVER_C , except for the requests that contain the /main/content or the /main/login path. The monitoring mode is applied to the requests sent to the virtual server SERVER_C that contain the /main/content path. The block mode is applied to the requests sent to the virtual server SERVER_C that contain the /main/login path. The wallarm_mode_allow_override Directive \u00b6 The wallarm_mode_allow_override directive manages the ability to apply rules that are defined on the Wallarm cloud instead of using the wallarm_mode directive values from the filter node configuration file. The following values are valid for the wallarm_mode_allow_override directive: off : rules specified on the cloud are ignored. Rules specified by the wallarm_mode directive in the configuration file are applied. strict : only the rules specified on the cloud that define stricter filtering modes than those defined by the wallarm_mode directive in the configuration file are applied. The available filtering modes ordered from the mildest to the strictest are listed above . on : rules specified on the cloud are applied. Rules specified by the wallarm_mode directive in the configuration file are ignored. The contexts in which the wallarm_mode_allow_override directive value can be defined, in order from the most global to the most local, are presented in the following list: http : the directives inside the http block are applied to the requests sent to the HTTP server server : the directives inside the server block are applied to the requests sent to the virtual server location : the directives inside the location block are only applied to the requests containing that particular path If different wallarm_mode_allow_override directive values are defined in the http , server , and location blocks, the most local configuration has the highest priority. The wallarm_mode_allow_override Directive Usage Example \u00b6 http { wallarm_mode monitoring; server { server_name SERVER_A; wallarm_mode_allow_override off; } server { server_name SERVER_B; wallarm_mode_allow_override on; location /main/login { wallarm_mode_allow_override strict; } } } This configuration example results in the following applications of the filtering mode rules from the Wallarm cloud: The filtering mode rules defined on the Wallarm cloud are ignored for requests sent to the virtual server SERVER_A . There is no wallarm_mode directive specified in the server block that corresponds to the SERVER_A server, which is why the monitoring filtering mode specified in the http block is applied for such requests. The filtering mode rules defined on the Wallarm cloud are applied to the requests sent to the virtual server SERVER_B except for the requests that contain the /main/login path. For those requests that are sent to the virtual server SERVER_B and contain the /main/login path, the filtering mode rules defined on the Wallarm cloud are only applied if they define a filter mode that is stricter than the monitoring mode. The General Filtration Rule on the Wallarm Cloud \u00b6 The radio buttons in the General tab in the Settings section of the Wallarm web interface define the general filtration mode for all incoming requests. The wallarm_mode directive value defined in the http block in the configuration file has the same action scope as these buttons. The local filter mode settings in the Rules tab of the Wallarm cloud have higher priority than the global settings in the Global tab. The Effect of the Filtering Mode Rules The filtering mode rules defined on the Wallarm cloud are only applied if the wallarm_mode_allow_override directive configuration allows redefining the filtering mode with the rules specified on the Wallarm cloud. Perform the following actions to define the general filtration mode rule on the Wallarm cloud: Sign in to the Wallarm cloud by proceeding to the correct link depending on the cloud version you are using: If you are using the European version of the Wallarm cloud, sign in on this page https://my.wallarm.com/login . If you are using the US version of the Wallarm cloud, sign in on this page https://us1.my.wallarm.com/login . Proceed to the General tab in the Settings section. The link to this page depends on the cloud version you are using: If you are using the European version of the Wallarm cloud, proceed to this page https://my.wallarm.com/settings/general . If you are using the US version of the Wallarm cloud, proceed to this page https://us1.my.wallarm.com/settings/general . In the General tab, you can specify one of the following filtering modes: Local settings (default) : the wallarm_mode_allow_override directive value is ignored and the filtering mode defined using the wallarm_mode directive value is applied. Monitoring : requests are processed but none are blocked, even if malicious requests are detected. Blocking : requests are processed and all the detected malicious requests are blocked. The Wallarm Cloud and Filter Node Synchronization The rules defined on the Wallarm cloud are applied during the Wallarm cloud and filter node synchronization process, which is conducted once every 15 minutes. The Filtering Mode Rules in the Rules Tab \u00b6 You can fine-tune the filtering mode for processing requests that meet your custom conditions in the Rules tab of the Wallarm interface. These rules have higher priority than the general filtering rule set on the Wallarm cloud . The Effect of the Filtering Mode Rules The filtering mode rules defined on the Wallarm cloud are only applied if the wallarm_mode_allow_override directive configuration allows redefining the filtering mode with the rules specified on the Wallarm cloud. For more detailed information about working with rules in the Rules tab, proceed to this link . To see the step-by-step guide for creating a rule that manages the filtration mode, proceed to this link . The Wallarm Cloud and Filter Node Synchronization The rules defined on the Wallarm cloud are applied during the Wallarm cloud and filter node synchronization process, which is conducted once every 15 minutes. The Filtration Mode Configuration Example \u00b6 Let us consider the example of a filter mode configuration that uses all of the methods mentioned above. Setting up Filtering Mode in the Filter Node Configuration File \u00b6 http { wallarm_mode block; server { server_name SERVER_A; wallarm_mode monitoring; wallarm_mode_allow_override off; location /main/login { wallarm_mode block; wallarm_mode_allow_override strict; } location /main/signup { wallarm_mode_allow_override strict; } location /main/apply { wallarm_mode block; wallarm_mode_allow_override on; } } } Setting up Filtering Mode in the Wallarm Cloud \u00b6 General filtering rule: Monitoring . Filtering rules If the request meets the following conditions: Method: POST First part of the path: main Second part of the path: apply , then apply the \u201cDefault\u201d filtering mode. If the request meets the following condition: First part of the path: main , then apply the \u201cBlocking\u201d filtering mode. If the request meets the following conditions: First part of the path: main Second part of the path: login , then apply the \u201cMonitoring\u201d filtering mode. Examples of Requests Sent to the Server SERVER_A \u00b6 Examples of the requests sent to the configured server SERVER_A and the actions that the Wallarm filter node applies to them are the following: The malicious request with the /news path is processed but not blocked due to the wallarm_mode monitoring; setting for the server SERVER_A . The malicious request with the /main path is processed but not blocked due to the wallarm_mode monitoring; setting for the server SERVER_A . The \u201cBlocking\u201d rule defined in the cloud is not applied to it due to the wallarm_mode_allow_override off; setting for the server SERVER_A . The malicious request with the /main/login path is blocked due to the wallarm_mode block; setting for the requests with the /main/login path. The \u201cMonitoring\u201d rule defined in the cloud is not applied to it due to the wallarm_mode_allow_override strict; setting in the filter node configuration file. The malicious request with the /main/signup path is blocked due to the wallarm_mode_allow_override strict; setting for the requests with the /main/signup path and the \u201cBlocking\u201d rule defined on the Wallarm cloud for the requests with the /main path. The malicious request with the /main/apply path and the GET method is blocked due to the wallarm_mode_allow_override on; setting for the requests with the /main/apply path and the \u201cBlocking\u201d rule defined on the Wallarm cloud for the requests with the /main path. The malicious request with the /main/apply path and the POST method is blocked due to the wallarm_mode_allow_override on; setting for those requests with the /main/apply path, the \u201cDefault\u201d rule defined on the Wallarm cloud, and the wallarm_mode block; setting for the requests with the /main/apply path in the filter node configuration file.","title":"Filtering Mode Configuration"},{"location":"en/admin-en/configure-wallarm-mode/#filtering-mode-configuration","text":"You can configure the filtering mode for the Wallarm filter nodes to define their behavior when processing incoming requests. The filtering mode can be configured in the following ways: Assign a value to the wallarm_mode directive in the filter node configuration file . Assign a value to the wallarm_mode_allow_override directive in the filter node configuration file . Define the general filtration rule on the Wallarm cloud . Create a filtration mode rule in the Rules tab of the Wallarm cloud .","title":"Filtering Mode Configuration"},{"location":"en/admin-en/configure-wallarm-mode/#available-filtering-modes","text":"The available filtering modes are listed in order from the mildest to the strictest in the following list: off : request filtering is not performed monitoring : requests are processed but none are blocked, even if malicious requests are detected block : requests are processed and all detected malicious requests are blocked.","title":"Available Filtering Modes"},{"location":"en/admin-en/configure-wallarm-mode/#the-wallarm_mode-directive","text":"Using the wallarm_mode directive in the filter node configuration file, you can define filtering modes for different contexts. These contexts are ordered from the most global to the most local in the following list: http : the directives inside the http block are applied to the requests sent to the HTTP server server : the directives inside the server block are applied to the requests sent to the virtual server location : the directives inside the location block are only applied to the requests containing that particular path If different wallarm_mode directive values are defined for the http , server , and location blocks, the most local configuration has the highest priority. The available filtering modes are listed above .","title":"The wallarm_mode Directive"},{"location":"en/admin-en/configure-wallarm-mode/#the-wallarm_mode-directive-usage-example","text":"http { wallarm_mode monitoring; server { server_name SERVER_A; } server { server_name SERVER_B; wallarm_mode off; } server { server_name SERVER_C; wallarm_mode off; location /main/content { wallarm_mode monitoring; } location /main/login { wallarm_mode block; } } } In this example, the filtering modes are defined for the resources as follows: The monitoring mode is applied to the requests sent to the HTTP server. The monitoring mode is applied to the requests sent to the virtual server SERVER_A . The off mode is applied to the requests sent to the virtual server SERVER_B . The off mode is applied to the requests sent to the virtual server SERVER_C , except for the requests that contain the /main/content or the /main/login path. The monitoring mode is applied to the requests sent to the virtual server SERVER_C that contain the /main/content path. The block mode is applied to the requests sent to the virtual server SERVER_C that contain the /main/login path.","title":"The wallarm_mode Directive Usage Example"},{"location":"en/admin-en/configure-wallarm-mode/#the-wallarm_mode_allow_override-directive","text":"The wallarm_mode_allow_override directive manages the ability to apply rules that are defined on the Wallarm cloud instead of using the wallarm_mode directive values from the filter node configuration file. The following values are valid for the wallarm_mode_allow_override directive: off : rules specified on the cloud are ignored. Rules specified by the wallarm_mode directive in the configuration file are applied. strict : only the rules specified on the cloud that define stricter filtering modes than those defined by the wallarm_mode directive in the configuration file are applied. The available filtering modes ordered from the mildest to the strictest are listed above . on : rules specified on the cloud are applied. Rules specified by the wallarm_mode directive in the configuration file are ignored. The contexts in which the wallarm_mode_allow_override directive value can be defined, in order from the most global to the most local, are presented in the following list: http : the directives inside the http block are applied to the requests sent to the HTTP server server : the directives inside the server block are applied to the requests sent to the virtual server location : the directives inside the location block are only applied to the requests containing that particular path If different wallarm_mode_allow_override directive values are defined in the http , server , and location blocks, the most local configuration has the highest priority.","title":"The wallarm_mode_allow_override Directive"},{"location":"en/admin-en/configure-wallarm-mode/#the-wallarm_mode_allow_override-directive-usage-example","text":"http { wallarm_mode monitoring; server { server_name SERVER_A; wallarm_mode_allow_override off; } server { server_name SERVER_B; wallarm_mode_allow_override on; location /main/login { wallarm_mode_allow_override strict; } } } This configuration example results in the following applications of the filtering mode rules from the Wallarm cloud: The filtering mode rules defined on the Wallarm cloud are ignored for requests sent to the virtual server SERVER_A . There is no wallarm_mode directive specified in the server block that corresponds to the SERVER_A server, which is why the monitoring filtering mode specified in the http block is applied for such requests. The filtering mode rules defined on the Wallarm cloud are applied to the requests sent to the virtual server SERVER_B except for the requests that contain the /main/login path. For those requests that are sent to the virtual server SERVER_B and contain the /main/login path, the filtering mode rules defined on the Wallarm cloud are only applied if they define a filter mode that is stricter than the monitoring mode.","title":"The wallarm_mode_allow_override Directive Usage Example"},{"location":"en/admin-en/configure-wallarm-mode/#the-general-filtration-rule-on-the-wallarm-cloud","text":"The radio buttons in the General tab in the Settings section of the Wallarm web interface define the general filtration mode for all incoming requests. The wallarm_mode directive value defined in the http block in the configuration file has the same action scope as these buttons. The local filter mode settings in the Rules tab of the Wallarm cloud have higher priority than the global settings in the Global tab. The Effect of the Filtering Mode Rules The filtering mode rules defined on the Wallarm cloud are only applied if the wallarm_mode_allow_override directive configuration allows redefining the filtering mode with the rules specified on the Wallarm cloud. Perform the following actions to define the general filtration mode rule on the Wallarm cloud: Sign in to the Wallarm cloud by proceeding to the correct link depending on the cloud version you are using: If you are using the European version of the Wallarm cloud, sign in on this page https://my.wallarm.com/login . If you are using the US version of the Wallarm cloud, sign in on this page https://us1.my.wallarm.com/login . Proceed to the General tab in the Settings section. The link to this page depends on the cloud version you are using: If you are using the European version of the Wallarm cloud, proceed to this page https://my.wallarm.com/settings/general . If you are using the US version of the Wallarm cloud, proceed to this page https://us1.my.wallarm.com/settings/general . In the General tab, you can specify one of the following filtering modes: Local settings (default) : the wallarm_mode_allow_override directive value is ignored and the filtering mode defined using the wallarm_mode directive value is applied. Monitoring : requests are processed but none are blocked, even if malicious requests are detected. Blocking : requests are processed and all the detected malicious requests are blocked. The Wallarm Cloud and Filter Node Synchronization The rules defined on the Wallarm cloud are applied during the Wallarm cloud and filter node synchronization process, which is conducted once every 15 minutes.","title":"The General Filtration Rule on the Wallarm Cloud"},{"location":"en/admin-en/configure-wallarm-mode/#the-filtering-mode-rules-in-the-rules-tab","text":"You can fine-tune the filtering mode for processing requests that meet your custom conditions in the Rules tab of the Wallarm interface. These rules have higher priority than the general filtering rule set on the Wallarm cloud . The Effect of the Filtering Mode Rules The filtering mode rules defined on the Wallarm cloud are only applied if the wallarm_mode_allow_override directive configuration allows redefining the filtering mode with the rules specified on the Wallarm cloud. For more detailed information about working with rules in the Rules tab, proceed to this link . To see the step-by-step guide for creating a rule that manages the filtration mode, proceed to this link . The Wallarm Cloud and Filter Node Synchronization The rules defined on the Wallarm cloud are applied during the Wallarm cloud and filter node synchronization process, which is conducted once every 15 minutes.","title":"The Filtering Mode Rules in the Rules Tab"},{"location":"en/admin-en/configure-wallarm-mode/#the-filtration-mode-configuration-example","text":"Let us consider the example of a filter mode configuration that uses all of the methods mentioned above.","title":"The Filtration Mode Configuration Example"},{"location":"en/admin-en/configure-wallarm-mode/#setting-up-filtering-mode-in-the-filter-node-configuration-file","text":"http { wallarm_mode block; server { server_name SERVER_A; wallarm_mode monitoring; wallarm_mode_allow_override off; location /main/login { wallarm_mode block; wallarm_mode_allow_override strict; } location /main/signup { wallarm_mode_allow_override strict; } location /main/apply { wallarm_mode block; wallarm_mode_allow_override on; } } }","title":"Setting up Filtering Mode in the Filter Node Configuration File"},{"location":"en/admin-en/configure-wallarm-mode/#setting-up-filtering-mode-in-the-wallarm-cloud","text":"General filtering rule: Monitoring . Filtering rules If the request meets the following conditions: Method: POST First part of the path: main Second part of the path: apply , then apply the \u201cDefault\u201d filtering mode. If the request meets the following condition: First part of the path: main , then apply the \u201cBlocking\u201d filtering mode. If the request meets the following conditions: First part of the path: main Second part of the path: login , then apply the \u201cMonitoring\u201d filtering mode.","title":"Setting up Filtering Mode in the Wallarm Cloud"},{"location":"en/admin-en/configure-wallarm-mode/#examples-of-requests-sent-to-the-server-server_a","text":"Examples of the requests sent to the configured server SERVER_A and the actions that the Wallarm filter node applies to them are the following: The malicious request with the /news path is processed but not blocked due to the wallarm_mode monitoring; setting for the server SERVER_A . The malicious request with the /main path is processed but not blocked due to the wallarm_mode monitoring; setting for the server SERVER_A . The \u201cBlocking\u201d rule defined in the cloud is not applied to it due to the wallarm_mode_allow_override off; setting for the server SERVER_A . The malicious request with the /main/login path is blocked due to the wallarm_mode block; setting for the requests with the /main/login path. The \u201cMonitoring\u201d rule defined in the cloud is not applied to it due to the wallarm_mode_allow_override strict; setting in the filter node configuration file. The malicious request with the /main/signup path is blocked due to the wallarm_mode_allow_override strict; setting for the requests with the /main/signup path and the \u201cBlocking\u201d rule defined on the Wallarm cloud for the requests with the /main path. The malicious request with the /main/apply path and the GET method is blocked due to the wallarm_mode_allow_override on; setting for the requests with the /main/apply path and the \u201cBlocking\u201d rule defined on the Wallarm cloud for the requests with the /main path. The malicious request with the /main/apply path and the POST method is blocked due to the wallarm_mode_allow_override on; setting for those requests with the /main/apply path, the \u201cDefault\u201d rule defined on the Wallarm cloud, and the wallarm_mode block; setting for the requests with the /main/apply path in the filter node configuration file.","title":"Examples of Requests Sent to the Server SERVER_A"},{"location":"en/admin-en/file-download-error-en/","text":"File Download Scenarios Fail \u00b6 If your file download scenarios fail after installing a filter node, the issue is in the request size exceeding the limit set in the client_max_body_size directive in the Wallarm configuration file. Change the value in client_max_body_size in the directive location for the address that accepts the file uploads. Changing only the location value protects the main page from getting large requests. Change the value in client_max_body_size : Open for editing the configuration file in the /etc/nginx-wallarm directory. Put in the new value: location /file/upload { client_max_body_size 16m; } where /file/upload is the address that accepts the file uploads. See also The directive description in the official NGINX documentation","title":"File Download Scenarios Fail"},{"location":"en/admin-en/file-download-error-en/#file-download-scenarios-fail","text":"If your file download scenarios fail after installing a filter node, the issue is in the request size exceeding the limit set in the client_max_body_size directive in the Wallarm configuration file. Change the value in client_max_body_size in the directive location for the address that accepts the file uploads. Changing only the location value protects the main page from getting large requests. Change the value in client_max_body_size : Open for editing the configuration file in the /etc/nginx-wallarm directory. Put in the new value: location /file/upload { client_max_body_size 16m; } where /file/upload is the address that accepts the file uploads. See also The directive description in the official NGINX documentation","title":"File Download Scenarios Fail"},{"location":"en/admin-en/installation-ami-en/","text":"Deploying as an Amazon Machine Image (AMI) \u00b6 To deploy an Amazon Machine Image with a filter node, perform the following steps: Log in to your Amazon Web Services account. Create a pair of SSH keys. Create a security group. Launch a filter node instance. Connect to the filter node instance via SSH. Connect the filter node to the Wallarm Cloud. Set up the filter node for using a proxy server. Set up filtering and proxying rules. Allocate instance memory for the Wallarm Node. Configure logging. Restart NGINX. 1. Log In to Your Amazon Web Services Account \u00b6 Log in to aws.amazon.com . 2. Create a Pair of SSH Keys \u00b6 During the deploying process, you will need to connect to the virtual machine via SSH. Amazon EC2 allows creating a named pair of public and private SSH keys that can be used to connect to the instance. To create a key pair, do the following: Navigate to the Key pairs tab on the Amazon EC2 dashboard. Click the Create Key Pair button. Enter a key pair name and click the Create button. A private SSH key in PEM format will automatically start to download. Save the key to connect to the created instance in the future. #### Info:: Creating SSH keys To see detailed information about creating SSH keys, proceed to this [link][link-ssh-keys]. 3. Create a Security Group \u00b6 A Security Group defines allowed and forbidden incoming and outgoing connections for virtual machines. The final list of connections depends on the protected application (e.g., allowing all of the incoming connections to the TCP/80 and TCP/443 ports). #### Warning:: Rules for outgoing connections from the security group When creating a security group, all of the outgoing connections are allowed by default. If you restrict outgoing connections from the filter node, make sure that it is granted access to a Wallarm API server. The choice of a Wallarm API server depends on the Wallarm Cloud you are using: * If you are using the EU cloud, your node needs to be granted access to `api.wallarm.com:444`. * If you are using the US cloud, your node needs to be granted access to `us1.api.wallarm.com:444`. The filter node requires access to a Wallarm API server for proper operation. Create a security group for the filter node. To do this, proceed with the following steps: Navigate to the Security Groups tab on the Amazon EC2 dashboard and click the Create Security Group button. Enter a security group name and an optional description into the dialog window that appears. Select the required VPC. Configure incoming and outgoing connections rules on the Inbound and Outbound tabs. Click the Create button to create the security group. To see detailed information about creating a security group, proceed to this link . 4. Launch a Filter Node Instance \u00b6 To launch an instance with the filter node, proceed to this link . When creating an instance, you need to specify the previously created security group. To do this, perform the following actions: While working with the Launch Instance Wizard, proceed to the 6. Configure Security Group instance launch step by clicking the corresponding tab. Choose the \u201cSelect an existing security group\u201d option in the Assign a security group setting. Select the security group from the list that appears. After specifying all of the required instance settings, click the \u201cReview and Launch\u201d button, make sure that instance is configured correctly, and click the \u201cLaunch\u201d button. In the window that appears, specify the previously created key pair by performing the following actions: In the first drop-down list, select the \u201cChoose an existing key pair\u201d option. In the second drop-down list, select the name of the key pair. Make sure you have access to the private key in PEM format from the key pair you specified in the second drop-down list and tick the checkbox to confirm this. Click the Launch Instances button. The instance will launch with the preinstalled filter node. To see detailed information about launching instances in AWS, proceed to this link . 5. Connect to the Filter Node Instance via SSH \u00b6 You need to use the \u201cadmin\u201d username to connect to the instance. #### Info:: Using the key to connect via SSH Use the private key in PEM format that you [created earlier][anchor2] to connect to the instance via SSH. This must be the private key from the SSH key pair that you specified when creating an instance. To see detailed information about ways to connect to an instance, proceed to this link . 6. Connect the Filter Node to the Wallarm Cloud \u00b6 The filter node interacts with the Wallarm cloud. There are two ways of connecting the node to the cloud: Using the filter node token Using your cloud account login and password Required access rights Make sure that your Wallarm account has the Administrator role enabled and two-factor authentication disabled, therefore allowing you to connect a filter node to the cloud. You can check the aforementioned parameters by navigating to the user account list in the Wallarm console. * If you are using https://my.wallarm.com/ , proceed to the following link to check your user settings. * If you are using https://us1.my.wallarm.com/ , proceed to the following link to check your user settings. Connecting Using the Filter Node Token \u00b6 To connect the node to the cloud using the token, proceed with the following steps: Create a new node on the Nodes tab of Wallarm web interface. Click the Create new node button. In the form that appears, enter the node name into the corresponding field and select the \u201cCloud\u201d type of installation from the drop-down list. Click the Create button. In the window that appears, click the Copy button next to the field with the token to add the token of the newly created filter node to your clipboard. On the virtual machine run the addcloudnode script: Info:: \u00b6 You have to pick which script to run depending on the Cloud you are using. * If you are using https://my.wallarm.com/ , run the script from the EU Cloud tab below. * If you are using https://us1.my.wallarm.com/ , run the script from the US Cloud tab below. {% termtabs name=\"EU Cloud\" -%} /usr/share/wallarm-common/addcloudnode \u00b6 {%- tab name=\"US Cloud\" -%} /usr/share/wallarm-common/addcloudnode -H us1.api.wallarm.com \u00b6 {%- endtermtabs %} Paste the filter node token from your clipboard. Your filter node will now synchronize with the cloud every 5 seconds according to the default synchronization configuration. Node and cloud synchronization configuration After running the addcloudnode script, the /etc/wallarm/syncnode file containing the node and cloud synchronization settings will be created. To learn more about synchronization configuration file content, proceed to the link . Connecting Using Your Cloud Account Login and Password \u00b6 To connect the node to the cloud using your cloud account requisites, proceed with the following steps: On the virtual machine run the addnode script: Info:: \u00b6 You have to pick which script to run depending on the Cloud you are using. * If you are using https://my.wallarm.com/ , run the script from the \u00ab EU Cloud tab below. * If you are using https://us1.my.wallarm.com/ , run the script from the US Cloud tab below. {% termtabs name=\"EU Cloud\" -%} /usr/share/wallarm-common/addnode \u00b6 {%- tab name=\"US Cloud\" -%} /usr/share/wallarm-common/addnode -H us1.api.wallarm.com \u00b6 {%- endtermtabs %} Provide your Wallarm account\u2019s login and password when prompted. API Access The API choice for your filter node depends on the Cloud you are using. Please, select the API accordingly: * If you are using https://my.wallarm.com/ , your node requires access to https://api.wallarm.com:444 . * If you are using https://us1.my.wallarm.com/ , your node requires access to https://us1.api.wallarm.com:444 . Ensure the access is not blocked by a firewall. 7. Set Up the Filter Node for Using a Proxy Server \u00b6 Info This setup step is intended for users who use their own proxy server for the operation of the protected web applications. If you do not use a proxy server, skip this step of the setup. You need to assign new values to the environment variables, which define the proxy server used, to configure Wallarm node for using your proxy server. Add new values of the environment variables to the /etc/environment file: Add https_proxy to define a proxy for the https protocol. Add http_proxy to define a proxy for the http protocol. Add no_proxy to define the list of the resources proxy should not be used for. Assign the <scheme>://<proxy_user>:<proxy_pass>@<host>:<port> string values to the https_proxy and http_proxy variables. <scheme> defines the protocol used. It should match the protocol that the current environment variable sets up proxy for. <proxy_user> defines the username for proxy authorization. <proxy_pass> defines the password for proxy authorization. <host> defines a host of the proxy server. <port> defines a port of the proxy server. Assign a \"<res_1>, <res_2>, <res_3>, <res_4>, ...\" array value, where <res_1> , <res_2> , <res_3> , and <res_4> are the IP addresses and/or domains, to the no_proxy variable to define a list of the resources which proxy should not be used for. This array should consist of IP addresses and/or domains. Resources that need to be addressed without a proxy Add the following IP addresses and domain to the list of the resources that have to be addressed without a proxy for the system to operate correctly: 127.0.0.1 , 127.0.0.8 , 127.0.0.9 , and localhost . The 127.0.0.8 and 127.0.0.9 IP addresses are used for the operation of the Wallarm filter node. The example of the correct /etc/environment file contents below demonstrates the following configuration: HTTPS and HTTP requests are proxied to the 1.2.3.4 host with the 1234 port, using the admin username and the 01234 password for authorization on the proxy server. Proxying is disabled for the requests sent to 127.0.0.1 , 127.0.0.8 , 127.0.0.9 , and localhost . https_proxy=http://admin:01234@1.2.3.4:1234 http_proxy=http://admin:01234@1.2.3.4:1234 no_proxy=\"127.0.0.1, 127.0.0.8, 127.0.0.9, localhost\" 8. Set Up Filtering and Proxying Rules \u00b6 The etc/nginx/conf.d directory contains NGINX and Wallarm filter node configuration files. By default, this directory contains the following configuration files: The default.conf file defines the configuration of NGINX. The wallarm.conf file defines the global configuration of Wallarm filter node. The wallarm-status.conf file defines the Wallarm monitoring configuration. You can create your own configuration files to define the operation of NGINX and Wallarm. It is recommended to create a separate configuration file with the server block for each group of the domains that should be processed in the same way. To see detailed information about working with NGINX configuration files, proceed to the official NGINX documentation . Wallarm directives define the operation logic of the Wallarm filter node. To see the list of Wallarm directives available, proceed to the Wallarm configuration options page. A Configuration File Example \u00b6 Let us suppose that you need to configure the server to work in the following conditions: Only HTTP traffic is processed. There are no HTTPS requests processed. The following domains receive the requests: example.com and www.example.com . All requests must be passed to the server 10.80.0.5 . All incoming requests are considered less than 1MB in size (default setting). The processing of a request takes no more than 60 seconds (default setting). Wallarm must operate in the monitor mode. Clients access the filter node directly, without an intermediate HTTP load balancer. Creating a configuration file You can create a custom NGINX configuration file (e.g. example.com.conf ) or modify the default NGINX configuration file ( default.conf ). When creating a custom configuration file, make sure that NGINX listens to the incoming connections on the free port. To meet the listed conditions, the contents of the configuration file must be the following: server { listen 80; listen [::]:80 ipv6only=on; # the domains for which traffic is processed server_name example.com; server_name www.example.com; # turn on the monitoring mode of traffic processing wallarm_mode monitoring; # wallarm_instance 1; location / { # setting the address for request forwarding proxy_pass http://10.80.0.5; proxy_set_header Host $host; proxy_set_header X-Real-IP $remote_addr; proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for; } } 9. Instance Memory Allocation for the Wallarm Node \u00b6 Filter node uses the in-memory storage Tarantool. By default, the amount of RAM allocated to Tarantool is 75% of the total instance memory. You can change the amount of RAM allocated for Tarantool To allocate the instance RAM to Tarantool: Open the Tarantool configuration file: # vi /etc/default/wallarm-tarantool Set the amount of allocated RAM in the SLAB_ALLOC_ARENA in GB. For example, to set 24 GB: SLAB_ALLOC_ARENA=24 To apply changes, restart the Tarantool daemon: # systemctl restart wallarm-tarantool 10. Configure Logging \u00b6 Configure the filter node variables logging using NGINX. This will allow to perform a quick filter node diagnostics with the help of the NGINX log file. 11. Restart NGINX \u00b6 Restart NGINX by running the following command: # systemctl restart nginx The Installation Is Complete \u00b6 The installation is now complete. Check that the filter node runs and filters the traffic. See Check the filter node operation . #### Info:: Default Settings A freshly installed filter node operates in blocking mode (see the [`wallarm_mode`](../admin-en/configure-parameters-en.html#wallarmmode) directive description) by default. This may result in the inoperable [Wallarm scanner](../user-guides/cloud-ui/scanner/intro.md). If you plan to use the scanner, then you [need to perform additional actions](#adding-wallarm-scanner-addresses-to-the-whitelist) to render scanner operational. Additional Settings \u00b6 The filter node may require some additional configuration after installation. The document below lists a few of the typical setups that you can apply if needed. To get more information about other available settings, proceed to the \u201cConfiguration\u201d section of the Administrator\u2019s Guide . Configuring the Display of the Client's Real IP \u00b6 If the filter node is deployed behind a proxy server or load balancer without any additional configuration, the request source address may not be equal to the actual IP address of the client. Instead, it may be equal to one of the IP addresses of the proxy server or the load balancer. In this case, if you want the filter node to receive the client's IP address as a request source address, you need to perform an additional configuration of the proxy server or the load balancer. Adding Wallarm Scanner Addresses to the Whitelist \u00b6 The Wallarm scanner checks the resources of your company for vulnerabilities. Scanning is conducted using IP addresses from one of the following lists (depending on the type of Wallarm Cloud you are using): EU scanner addresses for EU Cloud users US scanner addresses for US Cloud users If you are using the Wallarm scanner, you need to configure the whitelists on your network scope security software (such as firewalls, intrusion detection systems, etc.) to contain Wallarm scanner IP addresses. For example, a Wallarm filter node with default settings is placed in the blocking mode, thus rendering the Wallarm scanner unable to scan the resources behind the filter node. To make the scanner operational again, whitelist the scanner's IP addresses on this filter node. Limiting the Single Request Processing Time \u00b6 Use the wallarm_process_time_limit Wallarm directive to specify the limit of the duration for processing a single request by the filter node. If processing the request consumes more time than specified in the directive, then the information on the error is entered into the log file and the request is marked as an overlimit_res attack. Limiting the Server Reply Waiting Time \u00b6 Use the proxy_read_timeout NGINX directive to specify the timeout for reading the proxy server reply. If the server sends nothing during this time, the connection is closed. Limiting the Maximum Request Size \u00b6 Use the client_max_body_size NGINX directive to specify the limit for the maximum size of the body of the client's request. If this limit is exceeded, NGINX replies to the client with the 413 ( Payload Too Large ) code, also known as the Request Entity Too Large message.","title":"Creating and Configuring the Wallarm Filter Node Instance"},{"location":"en/admin-en/installation-ami-en/#deploying-as-an-amazon-machine-image-ami","text":"To deploy an Amazon Machine Image with a filter node, perform the following steps: Log in to your Amazon Web Services account. Create a pair of SSH keys. Create a security group. Launch a filter node instance. Connect to the filter node instance via SSH. Connect the filter node to the Wallarm Cloud. Set up the filter node for using a proxy server. Set up filtering and proxying rules. Allocate instance memory for the Wallarm Node. Configure logging. Restart NGINX.","title":"Deploying as an Amazon Machine Image (AMI)"},{"location":"en/admin-en/installation-ami-en/#1-log-in-to-your-amazon-web-services-account","text":"Log in to aws.amazon.com .","title":"1. Log In to Your Amazon Web Services Account"},{"location":"en/admin-en/installation-ami-en/#2-create-a-pair-of-ssh-keys","text":"During the deploying process, you will need to connect to the virtual machine via SSH. Amazon EC2 allows creating a named pair of public and private SSH keys that can be used to connect to the instance. To create a key pair, do the following: Navigate to the Key pairs tab on the Amazon EC2 dashboard. Click the Create Key Pair button. Enter a key pair name and click the Create button. A private SSH key in PEM format will automatically start to download. Save the key to connect to the created instance in the future. #### Info:: Creating SSH keys To see detailed information about creating SSH keys, proceed to this [link][link-ssh-keys].","title":"2. Create a Pair of SSH Keys"},{"location":"en/admin-en/installation-ami-en/#3-create-a-security-group","text":"A Security Group defines allowed and forbidden incoming and outgoing connections for virtual machines. The final list of connections depends on the protected application (e.g., allowing all of the incoming connections to the TCP/80 and TCP/443 ports). #### Warning:: Rules for outgoing connections from the security group When creating a security group, all of the outgoing connections are allowed by default. If you restrict outgoing connections from the filter node, make sure that it is granted access to a Wallarm API server. The choice of a Wallarm API server depends on the Wallarm Cloud you are using: * If you are using the EU cloud, your node needs to be granted access to `api.wallarm.com:444`. * If you are using the US cloud, your node needs to be granted access to `us1.api.wallarm.com:444`. The filter node requires access to a Wallarm API server for proper operation. Create a security group for the filter node. To do this, proceed with the following steps: Navigate to the Security Groups tab on the Amazon EC2 dashboard and click the Create Security Group button. Enter a security group name and an optional description into the dialog window that appears. Select the required VPC. Configure incoming and outgoing connections rules on the Inbound and Outbound tabs. Click the Create button to create the security group. To see detailed information about creating a security group, proceed to this link .","title":"3. Create a Security Group"},{"location":"en/admin-en/installation-ami-en/#4-launch-a-filter-node-instance","text":"To launch an instance with the filter node, proceed to this link . When creating an instance, you need to specify the previously created security group. To do this, perform the following actions: While working with the Launch Instance Wizard, proceed to the 6. Configure Security Group instance launch step by clicking the corresponding tab. Choose the \u201cSelect an existing security group\u201d option in the Assign a security group setting. Select the security group from the list that appears. After specifying all of the required instance settings, click the \u201cReview and Launch\u201d button, make sure that instance is configured correctly, and click the \u201cLaunch\u201d button. In the window that appears, specify the previously created key pair by performing the following actions: In the first drop-down list, select the \u201cChoose an existing key pair\u201d option. In the second drop-down list, select the name of the key pair. Make sure you have access to the private key in PEM format from the key pair you specified in the second drop-down list and tick the checkbox to confirm this. Click the Launch Instances button. The instance will launch with the preinstalled filter node. To see detailed information about launching instances in AWS, proceed to this link .","title":"4. Launch a Filter Node Instance"},{"location":"en/admin-en/installation-ami-en/#5-connect-to-the-filter-node-instance-via-ssh","text":"You need to use the \u201cadmin\u201d username to connect to the instance. #### Info:: Using the key to connect via SSH Use the private key in PEM format that you [created earlier][anchor2] to connect to the instance via SSH. This must be the private key from the SSH key pair that you specified when creating an instance. To see detailed information about ways to connect to an instance, proceed to this link .","title":"5. Connect to the Filter Node Instance via SSH"},{"location":"en/admin-en/installation-ami-en/#6-connect-the-filter-node-to-the-wallarm-cloud","text":"The filter node interacts with the Wallarm cloud. There are two ways of connecting the node to the cloud: Using the filter node token Using your cloud account login and password Required access rights Make sure that your Wallarm account has the Administrator role enabled and two-factor authentication disabled, therefore allowing you to connect a filter node to the cloud. You can check the aforementioned parameters by navigating to the user account list in the Wallarm console. * If you are using https://my.wallarm.com/ , proceed to the following link to check your user settings. * If you are using https://us1.my.wallarm.com/ , proceed to the following link to check your user settings.","title":"6. Connect the Filter Node to the Wallarm Cloud"},{"location":"en/admin-en/installation-ami-en/#connecting-using-the-filter-node-token","text":"To connect the node to the cloud using the token, proceed with the following steps: Create a new node on the Nodes tab of Wallarm web interface. Click the Create new node button. In the form that appears, enter the node name into the corresponding field and select the \u201cCloud\u201d type of installation from the drop-down list. Click the Create button. In the window that appears, click the Copy button next to the field with the token to add the token of the newly created filter node to your clipboard. On the virtual machine run the addcloudnode script:","title":"Connecting Using the Filter Node Token"},{"location":"en/admin-en/installation-ami-en/#info","text":"You have to pick which script to run depending on the Cloud you are using. * If you are using https://my.wallarm.com/ , run the script from the EU Cloud tab below. * If you are using https://us1.my.wallarm.com/ , run the script from the US Cloud tab below. {% termtabs name=\"EU Cloud\" -%}","title":"Info::"},{"location":"en/admin-en/installation-ami-en/#usrsharewallarm-commonaddcloudnode","text":"{%- tab name=\"US Cloud\" -%}","title":"/usr/share/wallarm-common/addcloudnode"},{"location":"en/admin-en/installation-ami-en/#usrsharewallarm-commonaddcloudnode-h-us1apiwallarmcom","text":"{%- endtermtabs %} Paste the filter node token from your clipboard. Your filter node will now synchronize with the cloud every 5 seconds according to the default synchronization configuration. Node and cloud synchronization configuration After running the addcloudnode script, the /etc/wallarm/syncnode file containing the node and cloud synchronization settings will be created. To learn more about synchronization configuration file content, proceed to the link .","title":"/usr/share/wallarm-common/addcloudnode -H us1.api.wallarm.com"},{"location":"en/admin-en/installation-ami-en/#connecting-using-your-cloud-account-login-and-password","text":"To connect the node to the cloud using your cloud account requisites, proceed with the following steps: On the virtual machine run the addnode script:","title":"Connecting Using Your Cloud Account Login and Password"},{"location":"en/admin-en/installation-ami-en/#info_1","text":"You have to pick which script to run depending on the Cloud you are using. * If you are using https://my.wallarm.com/ , run the script from the \u00ab EU Cloud tab below. * If you are using https://us1.my.wallarm.com/ , run the script from the US Cloud tab below. {% termtabs name=\"EU Cloud\" -%}","title":"Info::"},{"location":"en/admin-en/installation-ami-en/#usrsharewallarm-commonaddnode","text":"{%- tab name=\"US Cloud\" -%}","title":"/usr/share/wallarm-common/addnode"},{"location":"en/admin-en/installation-ami-en/#usrsharewallarm-commonaddnode-h-us1apiwallarmcom","text":"{%- endtermtabs %} Provide your Wallarm account\u2019s login and password when prompted. API Access The API choice for your filter node depends on the Cloud you are using. Please, select the API accordingly: * If you are using https://my.wallarm.com/ , your node requires access to https://api.wallarm.com:444 . * If you are using https://us1.my.wallarm.com/ , your node requires access to https://us1.api.wallarm.com:444 . Ensure the access is not blocked by a firewall.","title":"/usr/share/wallarm-common/addnode -H us1.api.wallarm.com"},{"location":"en/admin-en/installation-ami-en/#7-set-up-the-filter-node-for-using-a-proxy-server","text":"Info This setup step is intended for users who use their own proxy server for the operation of the protected web applications. If you do not use a proxy server, skip this step of the setup. You need to assign new values to the environment variables, which define the proxy server used, to configure Wallarm node for using your proxy server. Add new values of the environment variables to the /etc/environment file: Add https_proxy to define a proxy for the https protocol. Add http_proxy to define a proxy for the http protocol. Add no_proxy to define the list of the resources proxy should not be used for. Assign the <scheme>://<proxy_user>:<proxy_pass>@<host>:<port> string values to the https_proxy and http_proxy variables. <scheme> defines the protocol used. It should match the protocol that the current environment variable sets up proxy for. <proxy_user> defines the username for proxy authorization. <proxy_pass> defines the password for proxy authorization. <host> defines a host of the proxy server. <port> defines a port of the proxy server. Assign a \"<res_1>, <res_2>, <res_3>, <res_4>, ...\" array value, where <res_1> , <res_2> , <res_3> , and <res_4> are the IP addresses and/or domains, to the no_proxy variable to define a list of the resources which proxy should not be used for. This array should consist of IP addresses and/or domains. Resources that need to be addressed without a proxy Add the following IP addresses and domain to the list of the resources that have to be addressed without a proxy for the system to operate correctly: 127.0.0.1 , 127.0.0.8 , 127.0.0.9 , and localhost . The 127.0.0.8 and 127.0.0.9 IP addresses are used for the operation of the Wallarm filter node. The example of the correct /etc/environment file contents below demonstrates the following configuration: HTTPS and HTTP requests are proxied to the 1.2.3.4 host with the 1234 port, using the admin username and the 01234 password for authorization on the proxy server. Proxying is disabled for the requests sent to 127.0.0.1 , 127.0.0.8 , 127.0.0.9 , and localhost . https_proxy=http://admin:01234@1.2.3.4:1234 http_proxy=http://admin:01234@1.2.3.4:1234 no_proxy=\"127.0.0.1, 127.0.0.8, 127.0.0.9, localhost\"","title":"7. Set Up the Filter Node for Using a Proxy Server"},{"location":"en/admin-en/installation-ami-en/#8-set-up-filtering-and-proxying-rules","text":"The etc/nginx/conf.d directory contains NGINX and Wallarm filter node configuration files. By default, this directory contains the following configuration files: The default.conf file defines the configuration of NGINX. The wallarm.conf file defines the global configuration of Wallarm filter node. The wallarm-status.conf file defines the Wallarm monitoring configuration. You can create your own configuration files to define the operation of NGINX and Wallarm. It is recommended to create a separate configuration file with the server block for each group of the domains that should be processed in the same way. To see detailed information about working with NGINX configuration files, proceed to the official NGINX documentation . Wallarm directives define the operation logic of the Wallarm filter node. To see the list of Wallarm directives available, proceed to the Wallarm configuration options page.","title":"8. Set Up Filtering and Proxying Rules"},{"location":"en/admin-en/installation-ami-en/#a-configuration-file-example","text":"Let us suppose that you need to configure the server to work in the following conditions: Only HTTP traffic is processed. There are no HTTPS requests processed. The following domains receive the requests: example.com and www.example.com . All requests must be passed to the server 10.80.0.5 . All incoming requests are considered less than 1MB in size (default setting). The processing of a request takes no more than 60 seconds (default setting). Wallarm must operate in the monitor mode. Clients access the filter node directly, without an intermediate HTTP load balancer. Creating a configuration file You can create a custom NGINX configuration file (e.g. example.com.conf ) or modify the default NGINX configuration file ( default.conf ). When creating a custom configuration file, make sure that NGINX listens to the incoming connections on the free port. To meet the listed conditions, the contents of the configuration file must be the following: server { listen 80; listen [::]:80 ipv6only=on; # the domains for which traffic is processed server_name example.com; server_name www.example.com; # turn on the monitoring mode of traffic processing wallarm_mode monitoring; # wallarm_instance 1; location / { # setting the address for request forwarding proxy_pass http://10.80.0.5; proxy_set_header Host $host; proxy_set_header X-Real-IP $remote_addr; proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for; } }","title":"A Configuration File Example"},{"location":"en/admin-en/installation-ami-en/#9-instance-memory-allocation-for-the-wallarm-node","text":"Filter node uses the in-memory storage Tarantool. By default, the amount of RAM allocated to Tarantool is 75% of the total instance memory. You can change the amount of RAM allocated for Tarantool To allocate the instance RAM to Tarantool: Open the Tarantool configuration file: # vi /etc/default/wallarm-tarantool Set the amount of allocated RAM in the SLAB_ALLOC_ARENA in GB. For example, to set 24 GB: SLAB_ALLOC_ARENA=24 To apply changes, restart the Tarantool daemon: # systemctl restart wallarm-tarantool","title":"9. Instance Memory Allocation for the Wallarm Node"},{"location":"en/admin-en/installation-ami-en/#10-configure-logging","text":"Configure the filter node variables logging using NGINX. This will allow to perform a quick filter node diagnostics with the help of the NGINX log file.","title":"10. Configure Logging"},{"location":"en/admin-en/installation-ami-en/#11-restart-nginx","text":"Restart NGINX by running the following command: # systemctl restart nginx","title":"11. Restart NGINX"},{"location":"en/admin-en/installation-ami-en/#the-installation-is-complete","text":"The installation is now complete. Check that the filter node runs and filters the traffic. See Check the filter node operation . #### Info:: Default Settings A freshly installed filter node operates in blocking mode (see the [`wallarm_mode`](../admin-en/configure-parameters-en.html#wallarmmode) directive description) by default. This may result in the inoperable [Wallarm scanner](../user-guides/cloud-ui/scanner/intro.md). If you plan to use the scanner, then you [need to perform additional actions](#adding-wallarm-scanner-addresses-to-the-whitelist) to render scanner operational.","title":"The Installation Is Complete"},{"location":"en/admin-en/installation-ami-en/#additional-settings","text":"The filter node may require some additional configuration after installation. The document below lists a few of the typical setups that you can apply if needed. To get more information about other available settings, proceed to the \u201cConfiguration\u201d section of the Administrator\u2019s Guide .","title":"Additional Settings"},{"location":"en/admin-en/installation-ami-en/#configuring-the-display-of-the-clients-real-ip","text":"If the filter node is deployed behind a proxy server or load balancer without any additional configuration, the request source address may not be equal to the actual IP address of the client. Instead, it may be equal to one of the IP addresses of the proxy server or the load balancer. In this case, if you want the filter node to receive the client's IP address as a request source address, you need to perform an additional configuration of the proxy server or the load balancer.","title":"Configuring the Display of the Client's Real IP"},{"location":"en/admin-en/installation-ami-en/#adding-wallarm-scanner-addresses-to-the-whitelist","text":"The Wallarm scanner checks the resources of your company for vulnerabilities. Scanning is conducted using IP addresses from one of the following lists (depending on the type of Wallarm Cloud you are using): EU scanner addresses for EU Cloud users US scanner addresses for US Cloud users If you are using the Wallarm scanner, you need to configure the whitelists on your network scope security software (such as firewalls, intrusion detection systems, etc.) to contain Wallarm scanner IP addresses. For example, a Wallarm filter node with default settings is placed in the blocking mode, thus rendering the Wallarm scanner unable to scan the resources behind the filter node. To make the scanner operational again, whitelist the scanner's IP addresses on this filter node.","title":"Adding Wallarm Scanner Addresses to the Whitelist"},{"location":"en/admin-en/installation-ami-en/#limiting-the-single-request-processing-time","text":"Use the wallarm_process_time_limit Wallarm directive to specify the limit of the duration for processing a single request by the filter node. If processing the request consumes more time than specified in the directive, then the information on the error is entered into the log file and the request is marked as an overlimit_res attack.","title":"Limiting the Single Request Processing Time"},{"location":"en/admin-en/installation-ami-en/#limiting-the-server-reply-waiting-time","text":"Use the proxy_read_timeout NGINX directive to specify the timeout for reading the proxy server reply. If the server sends nothing during this time, the connection is closed.","title":"Limiting the Server Reply Waiting Time"},{"location":"en/admin-en/installation-ami-en/#limiting-the-maximum-request-size","text":"Use the client_max_body_size NGINX directive to specify the limit for the maximum size of the body of the client's request. If this limit is exceeded, NGINX replies to the client with the 413 ( Payload Too Large ) code, also known as the Request Entity Too Large message.","title":"Limiting the Maximum Request Size"},{"location":"en/admin-en/installation-azure-en/","text":"Deploying on Microsoft Azure \u00b6 Azure Marketplace provides an deployment-ready Linux image with pre-installed filter node software. To deploy a filter node on Microsoft Azure cloud, do the following steps: Create an SSH key pair. Log in to Microsoft Azure portal. Create and run a virtual machine with a filter node software. Connect to the virtual machine via SSH protocol. Set up the filter node for using a proxy server. Connect the filter node to the Wallarm cloud. Set up the proxying and filtering rules for the filter node. Tune the memory allocation policy for the filter node. Configure logging. Restart NGINX. 1. Create an SSH Key Pair \u00b6 During the deployment process you will connect to a virtual machine using the SSH protocol. The Azure cloud defines two means of getting authenticated while using the SSH protocol: either by login and password or by SSH key pair. Authentication with SSH key pair is considered to be more secure compared to login and password authentication method. Azure uses SSH key pair for authentication by default. Create an SSH RSA key pair. For example, you could use ssh-keygen or PuTTYgen tools. See How to use SSH keys with Windows on Azure for more information. 2. Log in to Microsoft Azure Portal \u00b6 Log in to the Azure portal . 3. Create and Run a Virtual Machine with a Filter Node Software \u00b6 To create a virtual machine with a filter node software, do the following: In the upper left corner of the Azure portal homepage select Create a resource . Search for \u201cwallarm\u201d in the search bar. Select \u201cWallarm - Next-Gen Web Application Firewall\u201d. The Wallarm product description page will open. Alternatively, you could reach the same page using Azure Marketplace. To do that, go to the link and select Get it now . Select Create to open a \u201cCreate a virtual machine\u201d wizard. In the \u201cBasics\u201d tab select the correct subscription (from your Azure account), set the name and the size of a virtual machine. Choose an authentication method to be used with the VM. If you choose SSH key pair as an authentication method, provide a user name and the public SSH key you have created earlier . Set up other necessary virtual machine parameters. Select Review + Create . Make sure everything is set up correctly. Select Create to start the virtual machine deployment. After the completion of deployment, select Go to resource . See Quickstart: Create a Linux virtual machine in the Azure portal for more information. 4. Connect to the Virtual Machine via SSH Protocol \u00b6 Select Connect on the virtual machine overview screen to view the IP address and SSH port values. If necessary, change them to appropriate values. Connect to the virtual machine via SSH protocol using the private SSH key you have created earlier . See How to use SSH keys with Windows on Azure for more information. 5. Set up the Filter Node for Using a Proxy Server \u00b6 Info This setup step is intended for users who use their own proxy server for the operation of the protected web applications. If you do not use a proxy server, skip this step of the setup. You need to assign new values to the environment variables, which define the proxy server used, to configure Wallarm node for using your proxy server. Add new values of the environment variables to the /etc/environment file: Add https_proxy to define a proxy for the https protocol. Add http_proxy to define a proxy for the http protocol. Add no_proxy to define the list of the resources proxy should not be used for. Assign the <scheme>://<proxy_user>:<proxy_pass>@<host>:<port> string values to the https_proxy and http_proxy variables. <scheme> defines the protocol used. It should match the protocol that the current environment variable sets up proxy for. <proxy_user> defines the username for proxy authorization. <proxy_pass> defines the password for proxy authorization. <host> defines a host of the proxy server. <port> defines a port of the proxy server. Assign a \"<res_1>, <res_2>, <res_3>, <res_4>, ...\" array value, where <res_1> , <res_2> , <res_3> , and <res_4> are the IP addresses and/or domains, to the no_proxy variable to define a list of the resources which proxy should not be used for. This array should consist of IP addresses and/or domains. Resources that need to be addressed without a proxy Add the following IP addresses and domain to the list of the resources that have to be addressed without a proxy for the system to operate correctly: 127.0.0.1 , 127.0.0.8 , 127.0.0.9 , and localhost . The 127.0.0.8 and 127.0.0.9 IP addresses are used for the operation of the Wallarm filter node. The example of the correct /etc/environment file contents below demonstrates the following configuration: HTTPS and HTTP requests are proxied to the 1.2.3.4 host with the 1234 port, using the admin username and the 01234 password for authorization on the proxy server. Proxying is disabled for the requests sent to 127.0.0.1 , 127.0.0.8 , 127.0.0.9 , and localhost . https_proxy=http://admin:01234@1.2.3.4:1234 http_proxy=http://admin:01234@1.2.3.4:1234 no_proxy=\"127.0.0.1, 127.0.0.8, 127.0.0.9, localhost\" 6. Connect the Filter Node to the Wallarm Cloud \u00b6 The filter node interacts with the Wallarm cloud. There are two ways of connecting the node to the cloud: Using the filter node token Using your cloud account login and password Required access rights Make sure that your Wallarm account has the Administrator role enabled and two-factor authentication disabled, therefore allowing you to connect a filter node to the cloud. You can check the aforementioned parameters by navigating to the user account list in the Wallarm console. * If you are using https://my.wallarm.com/ , proceed to the following link to check your user settings. * If you are using https://us1.my.wallarm.com/ , proceed to the following link to check your user settings. Connecting Using the Filter Node Token \u00b6 To connect the node to the cloud using the token, proceed with the following steps: Create a new node on the Nodes tab of Wallarm web interface. Click the Create new node button. In the form that appears, enter the node name into the corresponding field and select the \u201cCloud\u201d type of installation from the drop-down list. Click the Create button. In the window that appears, click the Copy button next to the field with the token to add the token of the newly created filter node to your clipboard. On the virtual machine run the addcloudnode script: Info:: \u00b6 You have to pick which script to run depending on the Cloud you are using. * If you are using https://my.wallarm.com/ , run the script from the EU Cloud tab below. * If you are using https://us1.my.wallarm.com/ , run the script from the US Cloud tab below. {% termtabs name=\"EU Cloud\" -%} /usr/share/wallarm-common/addcloudnode \u00b6 {%- tab name=\"US Cloud\" -%} /usr/share/wallarm-common/addcloudnode -H us1.api.wallarm.com \u00b6 {%- endtermtabs %} Paste the filter node token from your clipboard. Your filter node will now synchronize with the cloud every 5 seconds according to the default synchronization configuration. Node and cloud synchronization configuration After running the addcloudnode script, the /etc/wallarm/syncnode file containing the node and cloud synchronization settings will be created. To learn more about synchronization configuration file content, proceed to the link . Connecting Using Your Cloud Account Login and Password \u00b6 To connect the node to the cloud using your cloud account requisites, proceed with the following steps: On the virtual machine run the addnode script: Info:: \u00b6 You have to pick which script to run depending on the Cloud you are using. * If you are using https://my.wallarm.com/ , run the script from the \u00ab EU Cloud tab below. * If you are using https://us1.my.wallarm.com/ , run the script from the US Cloud tab below. {% termtabs name=\"EU Cloud\" -%} /usr/share/wallarm-common/addnode \u00b6 {%- tab name=\"US Cloud\" -%} /usr/share/wallarm-common/addnode -H us1.api.wallarm.com \u00b6 {%- endtermtabs %} Provide your Wallarm account\u2019s login and password when prompted. API Access The API choice for your filter node depends on the Cloud you are using. Please, select the API accordingly: * If you are using https://my.wallarm.com/ , your node requires access to https://api.wallarm.com:444 . * If you are using https://us1.my.wallarm.com/ , your node requires access to https://us1.api.wallarm.com:444 . Ensure the access is not blocked by a firewall. 7. Set up the Proxying and Filtering Rules for the Filter Node \u00b6 The etc/nginx/conf.d directory contains NGINX and Wallarm filter node configuration files. By default, this directory contains the following configuration files: The default.conf file defines the configuration of NGINX. The wallarm.conf file defines the global configuration of Wallarm filter node. The wallarm-status.conf file defines the Wallarm monitoring configuration. You can create your own configuration files to define the operation of NGINX and Wallarm. It is recommended to create a separate configuration file with the server block for each group of the domains that should be processed in the same way. To see detailed information about working with NGINX configuration files, proceed to the official NGINX documentation . Wallarm directives define the operation logic of the Wallarm filter node. To see the list of Wallarm directives available, proceed to the Wallarm configuration options page. A Configuration File Example \u00b6 Let us suppose that you need to configure the server to work in the following conditions: Only HTTP traffic is processed. There are no HTTPS requests processed. The following domains receive the requests: example.com and www.example.com . All requests must be passed to the server 10.80.0.5 . All incoming requests are considered less than 1MB in size (default setting). The processing of a request takes no more than 60 seconds (default setting). Wallarm must operate in the monitor mode. Clients access the filter node directly, without an intermediate HTTP load balancer. Creating a configuration file You can create a custom NGINX configuration file (e.g. example.com.conf ) or modify the default NGINX configuration file ( default.conf ). When creating a custom configuration file, make sure that NGINX listens to the incoming connections on the free port. To meet the listed conditions, the contents of the configuration file must be the following: server { listen 80; listen [::]:80 ipv6only=on; # the domains for which traffic is processed server_name example.com; server_name www.example.com; # turn on the monitoring mode of traffic processing wallarm_mode monitoring; # wallarm_instance 1; location / { # setting the address for request forwarding proxy_pass http://10.80.0.5; proxy_set_header Host $host; proxy_set_header X-Real-IP $remote_addr; proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for; } } 8. Tune the Memory Allocation Policy for the Filter Node \u00b6 The filter node uses Tarantool to store data in memory. By default the amount of RAM allocated to the Tarantool is set to 75% of the total virtual machine memory. You could change this value, if needed. To do so, perform the following steps: Open the configuration file /etc/default/wallarm-tarantool : # nano /etc/default/wallarm-tarantool Set the amount of allocated RAM in GB with SLAB_ALLOC_ARENA parameter. For example, if it is necessary to provide 24 GB of memory to the Tarantool, the parameter should be set like: SLAB_ALLOC_ARENA=24 Save your changes and exit from the editor. Restart the Tarantool daemon: # systemctl restart wallarm-tarantool 9. Configure Logging \u00b6 Configure the filter node variables logging using NGINX. This will allow to perform a quick filter node diagnostics with the help of the NGINX log file. 10. Restart NGINX \u00b6 Restart NGINX by running the following command: # systemctl restart nginx The Deployment Is Completed \u00b6 You have completed the deployment process successfully. Check if the filter node is operating normally and proxying the traffic through itself. See Checking the filter node operation for more information. #### Info:: Default Settings A freshly installed filter node operates in blocking mode (see the [`wallarm_mode`](../admin-en/configure-parameters-en.html#wallarmmode) directive description) by default. This may result in the inoperable [Wallarm scanner](../user-guides/cloud-ui/scanner/intro.md). If you plan to use the scanner, then you [need to perform additional actions](#adding-wallarm-scanner-addresses-to-the-whitelist) to render scanner operational. Additional Settings \u00b6 The filter node may require some additional configuration after installation. The document below lists a few of the typical setups that you can apply if needed. To get more information about other available settings, proceed to the \u201cConfiguration\u201d section of the Administrator\u2019s Guide . Configuring the Display of the Client's Real IP \u00b6 If the filter node is deployed behind a proxy server or load balancer without any additional configuration, the request source address may not be equal to the actual IP address of the client. Instead, it may be equal to one of the IP addresses of the proxy server or the load balancer. In this case, if you want the filter node to receive the client's IP address as a request source address, you need to perform an additional configuration of the proxy server or the load balancer. Adding Wallarm Scanner Addresses to the Whitelist \u00b6 The Wallarm scanner checks the resources of your company for vulnerabilities. Scanning is conducted using IP addresses from one of the following lists (depending on the type of Wallarm Cloud you are using): EU scanner addresses for EU Cloud users US scanner addresses for US Cloud users If you are using the Wallarm scanner, you need to configure the whitelists on your network scope security software (such as firewalls, intrusion detection systems, etc.) to contain Wallarm scanner IP addresses. For example, a Wallarm filter node with default settings is placed in the blocking mode, thus rendering the Wallarm scanner unable to scan the resources behind the filter node. To make the scanner operational again, whitelist the scanner's IP addresses on this filter node. Limiting the Single Request Processing Time \u00b6 Use the wallarm_process_time_limit Wallarm directive to specify the limit of the duration for processing a single request by the filter node. If processing the request consumes more time than specified in the directive, then the information on the error is entered into the log file and the request is marked as an overlimit_res attack. Limiting the Server Reply Waiting Time \u00b6 Use the proxy_read_timeout NGINX directive to specify the timeout for reading the proxy server reply. If the server sends nothing during this time, the connection is closed. Limiting the Maximum Request Size \u00b6 Use the client_max_body_size NGINX directive to specify the limit for the maximum size of the body of the client's request. If this limit is exceeded, NGINX replies to the client with the 413 ( Payload Too Large ) code, also known as the Request Entity Too Large message.","title":"Installation azure en"},{"location":"en/admin-en/installation-azure-en/#deploying-on-microsoft-azure","text":"Azure Marketplace provides an deployment-ready Linux image with pre-installed filter node software. To deploy a filter node on Microsoft Azure cloud, do the following steps: Create an SSH key pair. Log in to Microsoft Azure portal. Create and run a virtual machine with a filter node software. Connect to the virtual machine via SSH protocol. Set up the filter node for using a proxy server. Connect the filter node to the Wallarm cloud. Set up the proxying and filtering rules for the filter node. Tune the memory allocation policy for the filter node. Configure logging. Restart NGINX.","title":"Deploying on Microsoft Azure"},{"location":"en/admin-en/installation-azure-en/#1-create-an-ssh-key-pair","text":"During the deployment process you will connect to a virtual machine using the SSH protocol. The Azure cloud defines two means of getting authenticated while using the SSH protocol: either by login and password or by SSH key pair. Authentication with SSH key pair is considered to be more secure compared to login and password authentication method. Azure uses SSH key pair for authentication by default. Create an SSH RSA key pair. For example, you could use ssh-keygen or PuTTYgen tools. See How to use SSH keys with Windows on Azure for more information.","title":"1.  Create an SSH Key Pair"},{"location":"en/admin-en/installation-azure-en/#2-log-in-to-microsoft-azure-portal","text":"Log in to the Azure portal .","title":"2.  Log in to Microsoft Azure Portal"},{"location":"en/admin-en/installation-azure-en/#3-create-and-run-a-virtual-machine-with-a-filter-node-software","text":"To create a virtual machine with a filter node software, do the following: In the upper left corner of the Azure portal homepage select Create a resource . Search for \u201cwallarm\u201d in the search bar. Select \u201cWallarm - Next-Gen Web Application Firewall\u201d. The Wallarm product description page will open. Alternatively, you could reach the same page using Azure Marketplace. To do that, go to the link and select Get it now . Select Create to open a \u201cCreate a virtual machine\u201d wizard. In the \u201cBasics\u201d tab select the correct subscription (from your Azure account), set the name and the size of a virtual machine. Choose an authentication method to be used with the VM. If you choose SSH key pair as an authentication method, provide a user name and the public SSH key you have created earlier . Set up other necessary virtual machine parameters. Select Review + Create . Make sure everything is set up correctly. Select Create to start the virtual machine deployment. After the completion of deployment, select Go to resource . See Quickstart: Create a Linux virtual machine in the Azure portal for more information.","title":"3.  Create and Run a Virtual Machine with a Filter Node Software"},{"location":"en/admin-en/installation-azure-en/#4-connect-to-the-virtual-machine-via-ssh-protocol","text":"Select Connect on the virtual machine overview screen to view the IP address and SSH port values. If necessary, change them to appropriate values. Connect to the virtual machine via SSH protocol using the private SSH key you have created earlier . See How to use SSH keys with Windows on Azure for more information.","title":"4.  Connect to the Virtual Machine via SSH Protocol"},{"location":"en/admin-en/installation-azure-en/#5-set-up-the-filter-node-for-using-a-proxy-server","text":"Info This setup step is intended for users who use their own proxy server for the operation of the protected web applications. If you do not use a proxy server, skip this step of the setup. You need to assign new values to the environment variables, which define the proxy server used, to configure Wallarm node for using your proxy server. Add new values of the environment variables to the /etc/environment file: Add https_proxy to define a proxy for the https protocol. Add http_proxy to define a proxy for the http protocol. Add no_proxy to define the list of the resources proxy should not be used for. Assign the <scheme>://<proxy_user>:<proxy_pass>@<host>:<port> string values to the https_proxy and http_proxy variables. <scheme> defines the protocol used. It should match the protocol that the current environment variable sets up proxy for. <proxy_user> defines the username for proxy authorization. <proxy_pass> defines the password for proxy authorization. <host> defines a host of the proxy server. <port> defines a port of the proxy server. Assign a \"<res_1>, <res_2>, <res_3>, <res_4>, ...\" array value, where <res_1> , <res_2> , <res_3> , and <res_4> are the IP addresses and/or domains, to the no_proxy variable to define a list of the resources which proxy should not be used for. This array should consist of IP addresses and/or domains. Resources that need to be addressed without a proxy Add the following IP addresses and domain to the list of the resources that have to be addressed without a proxy for the system to operate correctly: 127.0.0.1 , 127.0.0.8 , 127.0.0.9 , and localhost . The 127.0.0.8 and 127.0.0.9 IP addresses are used for the operation of the Wallarm filter node. The example of the correct /etc/environment file contents below demonstrates the following configuration: HTTPS and HTTP requests are proxied to the 1.2.3.4 host with the 1234 port, using the admin username and the 01234 password for authorization on the proxy server. Proxying is disabled for the requests sent to 127.0.0.1 , 127.0.0.8 , 127.0.0.9 , and localhost . https_proxy=http://admin:01234@1.2.3.4:1234 http_proxy=http://admin:01234@1.2.3.4:1234 no_proxy=\"127.0.0.1, 127.0.0.8, 127.0.0.9, localhost\"","title":"5.  Set up the Filter Node for Using a Proxy Server"},{"location":"en/admin-en/installation-azure-en/#6-connect-the-filter-node-to-the-wallarm-cloud","text":"The filter node interacts with the Wallarm cloud. There are two ways of connecting the node to the cloud: Using the filter node token Using your cloud account login and password Required access rights Make sure that your Wallarm account has the Administrator role enabled and two-factor authentication disabled, therefore allowing you to connect a filter node to the cloud. You can check the aforementioned parameters by navigating to the user account list in the Wallarm console. * If you are using https://my.wallarm.com/ , proceed to the following link to check your user settings. * If you are using https://us1.my.wallarm.com/ , proceed to the following link to check your user settings.","title":"6.  Connect the Filter Node to the Wallarm Cloud"},{"location":"en/admin-en/installation-azure-en/#connecting-using-the-filter-node-token","text":"To connect the node to the cloud using the token, proceed with the following steps: Create a new node on the Nodes tab of Wallarm web interface. Click the Create new node button. In the form that appears, enter the node name into the corresponding field and select the \u201cCloud\u201d type of installation from the drop-down list. Click the Create button. In the window that appears, click the Copy button next to the field with the token to add the token of the newly created filter node to your clipboard. On the virtual machine run the addcloudnode script:","title":"Connecting Using the Filter Node Token"},{"location":"en/admin-en/installation-azure-en/#info","text":"You have to pick which script to run depending on the Cloud you are using. * If you are using https://my.wallarm.com/ , run the script from the EU Cloud tab below. * If you are using https://us1.my.wallarm.com/ , run the script from the US Cloud tab below. {% termtabs name=\"EU Cloud\" -%}","title":"Info::"},{"location":"en/admin-en/installation-azure-en/#usrsharewallarm-commonaddcloudnode","text":"{%- tab name=\"US Cloud\" -%}","title":"/usr/share/wallarm-common/addcloudnode"},{"location":"en/admin-en/installation-azure-en/#usrsharewallarm-commonaddcloudnode-h-us1apiwallarmcom","text":"{%- endtermtabs %} Paste the filter node token from your clipboard. Your filter node will now synchronize with the cloud every 5 seconds according to the default synchronization configuration. Node and cloud synchronization configuration After running the addcloudnode script, the /etc/wallarm/syncnode file containing the node and cloud synchronization settings will be created. To learn more about synchronization configuration file content, proceed to the link .","title":"/usr/share/wallarm-common/addcloudnode -H us1.api.wallarm.com"},{"location":"en/admin-en/installation-azure-en/#connecting-using-your-cloud-account-login-and-password","text":"To connect the node to the cloud using your cloud account requisites, proceed with the following steps: On the virtual machine run the addnode script:","title":"Connecting Using Your Cloud Account Login and Password"},{"location":"en/admin-en/installation-azure-en/#info_1","text":"You have to pick which script to run depending on the Cloud you are using. * If you are using https://my.wallarm.com/ , run the script from the \u00ab EU Cloud tab below. * If you are using https://us1.my.wallarm.com/ , run the script from the US Cloud tab below. {% termtabs name=\"EU Cloud\" -%}","title":"Info::"},{"location":"en/admin-en/installation-azure-en/#usrsharewallarm-commonaddnode","text":"{%- tab name=\"US Cloud\" -%}","title":"/usr/share/wallarm-common/addnode"},{"location":"en/admin-en/installation-azure-en/#usrsharewallarm-commonaddnode-h-us1apiwallarmcom","text":"{%- endtermtabs %} Provide your Wallarm account\u2019s login and password when prompted. API Access The API choice for your filter node depends on the Cloud you are using. Please, select the API accordingly: * If you are using https://my.wallarm.com/ , your node requires access to https://api.wallarm.com:444 . * If you are using https://us1.my.wallarm.com/ , your node requires access to https://us1.api.wallarm.com:444 . Ensure the access is not blocked by a firewall.","title":"/usr/share/wallarm-common/addnode -H us1.api.wallarm.com"},{"location":"en/admin-en/installation-azure-en/#7-set-up-the-proxying-and-filtering-rules-for-the-filter-node","text":"The etc/nginx/conf.d directory contains NGINX and Wallarm filter node configuration files. By default, this directory contains the following configuration files: The default.conf file defines the configuration of NGINX. The wallarm.conf file defines the global configuration of Wallarm filter node. The wallarm-status.conf file defines the Wallarm monitoring configuration. You can create your own configuration files to define the operation of NGINX and Wallarm. It is recommended to create a separate configuration file with the server block for each group of the domains that should be processed in the same way. To see detailed information about working with NGINX configuration files, proceed to the official NGINX documentation . Wallarm directives define the operation logic of the Wallarm filter node. To see the list of Wallarm directives available, proceed to the Wallarm configuration options page.","title":"7.  Set up the Proxying and Filtering Rules for the Filter Node"},{"location":"en/admin-en/installation-azure-en/#a-configuration-file-example","text":"Let us suppose that you need to configure the server to work in the following conditions: Only HTTP traffic is processed. There are no HTTPS requests processed. The following domains receive the requests: example.com and www.example.com . All requests must be passed to the server 10.80.0.5 . All incoming requests are considered less than 1MB in size (default setting). The processing of a request takes no more than 60 seconds (default setting). Wallarm must operate in the monitor mode. Clients access the filter node directly, without an intermediate HTTP load balancer. Creating a configuration file You can create a custom NGINX configuration file (e.g. example.com.conf ) or modify the default NGINX configuration file ( default.conf ). When creating a custom configuration file, make sure that NGINX listens to the incoming connections on the free port. To meet the listed conditions, the contents of the configuration file must be the following: server { listen 80; listen [::]:80 ipv6only=on; # the domains for which traffic is processed server_name example.com; server_name www.example.com; # turn on the monitoring mode of traffic processing wallarm_mode monitoring; # wallarm_instance 1; location / { # setting the address for request forwarding proxy_pass http://10.80.0.5; proxy_set_header Host $host; proxy_set_header X-Real-IP $remote_addr; proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for; } }","title":"A Configuration File Example"},{"location":"en/admin-en/installation-azure-en/#8-tune-the-memory-allocation-policy-for-the-filter-node","text":"The filter node uses Tarantool to store data in memory. By default the amount of RAM allocated to the Tarantool is set to 75% of the total virtual machine memory. You could change this value, if needed. To do so, perform the following steps: Open the configuration file /etc/default/wallarm-tarantool : # nano /etc/default/wallarm-tarantool Set the amount of allocated RAM in GB with SLAB_ALLOC_ARENA parameter. For example, if it is necessary to provide 24 GB of memory to the Tarantool, the parameter should be set like: SLAB_ALLOC_ARENA=24 Save your changes and exit from the editor. Restart the Tarantool daemon: # systemctl restart wallarm-tarantool","title":"8.  Tune the Memory Allocation Policy for the Filter Node"},{"location":"en/admin-en/installation-azure-en/#9-configure-logging","text":"Configure the filter node variables logging using NGINX. This will allow to perform a quick filter node diagnostics with the help of the NGINX log file.","title":"9. Configure Logging"},{"location":"en/admin-en/installation-azure-en/#10-restart-nginx","text":"Restart NGINX by running the following command: # systemctl restart nginx","title":"10. Restart NGINX"},{"location":"en/admin-en/installation-azure-en/#the-deployment-is-completed","text":"You have completed the deployment process successfully. Check if the filter node is operating normally and proxying the traffic through itself. See Checking the filter node operation for more information. #### Info:: Default Settings A freshly installed filter node operates in blocking mode (see the [`wallarm_mode`](../admin-en/configure-parameters-en.html#wallarmmode) directive description) by default. This may result in the inoperable [Wallarm scanner](../user-guides/cloud-ui/scanner/intro.md). If you plan to use the scanner, then you [need to perform additional actions](#adding-wallarm-scanner-addresses-to-the-whitelist) to render scanner operational.","title":"The Deployment Is Completed"},{"location":"en/admin-en/installation-azure-en/#additional-settings","text":"The filter node may require some additional configuration after installation. The document below lists a few of the typical setups that you can apply if needed. To get more information about other available settings, proceed to the \u201cConfiguration\u201d section of the Administrator\u2019s Guide .","title":"Additional Settings"},{"location":"en/admin-en/installation-azure-en/#configuring-the-display-of-the-clients-real-ip","text":"If the filter node is deployed behind a proxy server or load balancer without any additional configuration, the request source address may not be equal to the actual IP address of the client. Instead, it may be equal to one of the IP addresses of the proxy server or the load balancer. In this case, if you want the filter node to receive the client's IP address as a request source address, you need to perform an additional configuration of the proxy server or the load balancer.","title":"Configuring the Display of the Client's Real IP"},{"location":"en/admin-en/installation-azure-en/#adding-wallarm-scanner-addresses-to-the-whitelist","text":"The Wallarm scanner checks the resources of your company for vulnerabilities. Scanning is conducted using IP addresses from one of the following lists (depending on the type of Wallarm Cloud you are using): EU scanner addresses for EU Cloud users US scanner addresses for US Cloud users If you are using the Wallarm scanner, you need to configure the whitelists on your network scope security software (such as firewalls, intrusion detection systems, etc.) to contain Wallarm scanner IP addresses. For example, a Wallarm filter node with default settings is placed in the blocking mode, thus rendering the Wallarm scanner unable to scan the resources behind the filter node. To make the scanner operational again, whitelist the scanner's IP addresses on this filter node.","title":"Adding Wallarm Scanner Addresses to the Whitelist"},{"location":"en/admin-en/installation-azure-en/#limiting-the-single-request-processing-time","text":"Use the wallarm_process_time_limit Wallarm directive to specify the limit of the duration for processing a single request by the filter node. If processing the request consumes more time than specified in the directive, then the information on the error is entered into the log file and the request is marked as an overlimit_res attack.","title":"Limiting the Single Request Processing Time"},{"location":"en/admin-en/installation-azure-en/#limiting-the-server-reply-waiting-time","text":"Use the proxy_read_timeout NGINX directive to specify the timeout for reading the proxy server reply. If the server sends nothing during this time, the connection is closed.","title":"Limiting the Server Reply Waiting Time"},{"location":"en/admin-en/installation-azure-en/#limiting-the-maximum-request-size","text":"Use the client_max_body_size NGINX directive to specify the limit for the maximum size of the body of the client's request. If this limit is exceeded, NGINX replies to the client with the 413 ( Payload Too Large ) code, also known as the Request Entity Too Large message.","title":"Limiting the Maximum Request Size"},{"location":"en/admin-en/installation-check-operation-en/","text":"Checking the Filter Node Operation \u00b6 If everything is configured correctly, Wallarm filters the requests and proxies the filtered requests in accordance with the configuration file settings. To check the correct operation, you must: Execute the wallarm-status request. Run a test attack. 1. Execute the wallarm-status Request \u00b6 You can get filter node operation statistics by requesting the /wallarm-status URL. Run the command: curl http://127.0.0.8/wallarm-status The output will be like: { \"requests\" : 0 , \"attacks\" : 0 , \"blocked\" : 0 , \"abnormal\" : 0 , \"tnt_errors\" : 0 , \"api_errors\" : 0 , \"requests_lost\" : 0 , \"segfaults\" : 0 , \"memfaults\" : 0 , \"softmemfaults\" : 0 , \"time_detect\" : 0 , \"db_id\" : 46 , \"lom_id\" : 16767 , \"proton_instances\" :{ \"total\" : 1 , \"success\" : 1 , \"fallback\" : 0 , \"failed\" : 0 }, \"stalled_workers_count\" : 0 , \"stalled_workers\" :[] } This means that the filter node statistics service is running and working properly. The Statistics Service You can read more about the statistics service and how to configure it here . 2. Run a Test Attack \u00b6 To check if Wallarm correctly detects attacks, send an invalid request to the protected resource. For example: http://<resource_URL>/?id='or+1=1--a-<script>prompt(1)</script> Wallarm must detect in the request the following: SQLI XSS Now the counter of the number of attacks will increase when a request for wallarm-status is executed, which means that the filter node is operating normally. To learn more about the Wallarm filter node settings, see the Configuration Options chapter.","title":"Checking the Filter Node Operation"},{"location":"en/admin-en/installation-check-operation-en/#checking-the-filter-node-operation","text":"If everything is configured correctly, Wallarm filters the requests and proxies the filtered requests in accordance with the configuration file settings. To check the correct operation, you must: Execute the wallarm-status request. Run a test attack.","title":"Checking the Filter Node Operation"},{"location":"en/admin-en/installation-check-operation-en/#1-execute-the-wallarm-status-request","text":"You can get filter node operation statistics by requesting the /wallarm-status URL. Run the command: curl http://127.0.0.8/wallarm-status The output will be like: { \"requests\" : 0 , \"attacks\" : 0 , \"blocked\" : 0 , \"abnormal\" : 0 , \"tnt_errors\" : 0 , \"api_errors\" : 0 , \"requests_lost\" : 0 , \"segfaults\" : 0 , \"memfaults\" : 0 , \"softmemfaults\" : 0 , \"time_detect\" : 0 , \"db_id\" : 46 , \"lom_id\" : 16767 , \"proton_instances\" :{ \"total\" : 1 , \"success\" : 1 , \"fallback\" : 0 , \"failed\" : 0 }, \"stalled_workers_count\" : 0 , \"stalled_workers\" :[] } This means that the filter node statistics service is running and working properly. The Statistics Service You can read more about the statistics service and how to configure it here .","title":"1. Execute the wallarm-status Request"},{"location":"en/admin-en/installation-check-operation-en/#2-run-a-test-attack","text":"To check if Wallarm correctly detects attacks, send an invalid request to the protected resource. For example: http://<resource_URL>/?id='or+1=1--a-<script>prompt(1)</script> Wallarm must detect in the request the following: SQLI XSS Now the counter of the number of attacks will increase when a request for wallarm-status is executed, which means that the filter node is operating normally. To learn more about the Wallarm filter node settings, see the Configuration Options chapter.","title":"2. Run a Test Attack"},{"location":"en/admin-en/installation-docker-en/","text":"Installing with Docker (Using the NGINX-Based Docker Image) \u00b6 The filter node can be deployed as a Docker container. The Docker container is a fat one and contains all subsystems of the filter node. The functionality of the filter node installed inside the Docker container is completely identical to the functionality of the other deployment options. To deploy the filter node as a Docker container, you must: Deploy the filter node. Connect the filter node to the Wallarm cloud. Configure NGINX-Wallarm. Configure logging. Configure monitoring. Known limitations IP blocking is not supported. Most Wallarm directives cannot be changed through environment variables; these directives must be written in configuration files inside the container. 1. Deploy the Filter Node \u00b6 Run one of the docker run commands depending on the EU or US cloud in use: {% codetabs name=\"EU Cloud\", type=\"sh\" -%} docker run -d -e DEPLOY_USER=\" deploy@example.com \" -e DEPLOY_PASSWORD=\"very_secret\" -e NGINX_BACKEND=example.com -e TARANTOOL_MEMORY_GB=memvalue -p 80:80 wallarm/node {%- language name=\"US Cloud\", type=\"sh\" -%} docker run -d -e WALLARM_API_HOST=us1.api.wallarm.com -e DEPLOY_USER=\" deploy@example.com \" -e DEPLOY_PASSWORD=\"very_secret\" -e NGINX_BACKEND=example.com -e TARANTOOL_MEMORY_GB=memvalue -p 80:80 wallarm/node {%- endcodetabs %} where: example.com \u2014 the protected resource. deploy@example.com \u2014 login to the Wallarm portal in the EU or US cloud . very_secret \u2014 password for the Wallarm portal in the EU or US cloud . memvalue \u2013 amount of memory allocated to Tarantool. After running the command, you will have: The protected resource on port 80. The filter node registered in the Wallarm portal in the EU or US cloud ; the filter node displayed in the Wallarm interface. You can also fine-tune the deployment by putting additional configuration files inside the container. 2. Connect the Filter Node to the Wallarm Cloud \u00b6 The filter node interacts with the Wallarm cloud located on a remote server. To connect the filter node to the Wallarm cloud, you have the following options: Automatic registration. Using credentials. Using a prepared configuration file. Automatic Registration \u00b6 Transfer the environment variables DEPLOY_USER , DEPLOY_PASSWORD with the access credentials to the Wallarm portal in the EU or US cloud . The filter node will try to automatically register itself in the Wallarm cloud on the first start. If a filter node with the same name as the node's container identifier is already registered in the cloud, then the registration process will fail. To avoid this, pass the DEPLOY_FORCE=true environment variable to the container. # docker run -d -e DEPLOY_USER=\"deploy@example.com\" -e DEPLOY_PASSWORD=\"very_secret\" -e NGINX_BACKEND=\"IP address or FQDN\" wallarm/node If the registration process finishes successfully, then the container's /etc/wallarm directory will be populated with the license file ( license.key ), a file with the credentials for the filter node to access the cloud ( node.yaml ), and other files required for proper node operation. On the next start of the same filter node, registration will not be required. The filter node communicates with the cloud using the following artifacts acquired during the automatic registration: The uuid and secret values (they are placed in the /etc/wallarm/node.yaml file). The Wallarm license key (it is placed in the /etc/wallarm/license.key file). To connect the already registered filter node to the cloud, pass to its container either the uuid and secret values via the environment variables and the license.key file or the node.yaml and license.key files. Use of Prepared Credentials \u00b6 Pass to the filter node's container the uuid and secret values via the corresponding NODE_UUID and NODE_SECRET environment variables, and the license.key file via Docker volumes. Run one of the docker run commands depending on the EU or US cloud in use: {% codetabs name=\"EU Cloud\", type=\"sh\" -%} docker run -d -e \"NODE_UUID=00000000-0000-0000-0000-000000000000\" -e NODE_SECRET=\"0000000000000000000000000000000000000000000000000000000000000000\" -e NGINX_BACKEND=93.184.216.34 wallarm/node {%- language name=\"US Cloud\", type=\"sh\" -%} docker run -d -e WALLARM_API_HOST=us1.api.wallarm.com -e \"NODE_UUID=00000000-0000-0000-0000-000000000000\" -e NODE_SECRET=\"0000000000000000000000000000000000000000000000000000000000000000\" -e NGINX_BACKEND=93.184.216.34 wallarm/node {%- endcodetabs %} Commands are in the tabs below: EU Cloud First tab docker run -d \"NODE_UUID=00000000-0000-0000-0000-000000000000\" -e NODE_SECRET=\"0000000000000000000000000000000000000000000000000000000000000000\" -v /path/to/license.key:/etc/wallarm/license.key -e NGINX_BACKEND=192.168.xxx.1 wallarm/node US Cloud Send tab docker run -d -e WALLARM_API_HOST=us1.api.wallarm.com -e \"NODE_UUID=00000000-0000-0000-0000-000000000000\" -e NODE_SECRET=\"0000000000000000000000000000000000000000000000000000000000000000\" -v /path/to/license.key:/etc/wallarm/license.key -e NGINX_BACKEND=192.168.xxx.1 wallarm/node Use of a Prepared Configuration File Containing Credentials \u00b6 Pass the following files to the filter node's container via Docker volumes: the node.yaml file, containing the credentials for the filter node to access the Wallarm cloud, and the license.key file. docker run -d -v /path/to/node.yaml:/etc/wallarm/node.yaml -v /path/to/license.key:/etc/wallarm/license.key -e NGINX_BACKEND = 192 .168.xxx.1 wallarm/node 3. Configure NGINX-Wallarm \u00b6 The filter node configuration is done via the NGINX configuration file. The use of container lets you go through a simplified configuration process by using the environment variables. The simplified process is enabled by transferring the NGINX_BACKEND environment variable. Simplified Process \u00b6 NGINX_BACKEND \u2014 The backend address to which all incoming requests must be transferred. If the address does not have the http:// or https:// , prefix, then http:// is used by default. See details in proxy_pass . Do not use the NGINX_BACKEND variable if you do need the simplified configuration process and if you use your own configuration files. Note that without the NGINX_BACKEND variable, Wallarm will not start automatically. To start Wallarm, configure wallarm_mode monitoring . See details in the wallarm_mode directive description . WALLARM_MODE : The NGINX-Wallarm module operation mode. See details in the wallarm_mode directive description . Configuration Files \u00b6 The directories used by NGINX: /etc/nginx-wallarm/conf.d \u2014 common settings. /etc/nginx-wallarm/sites-enabled \u2014 virtual host settings. /var/www/html \u2014 static files. 4. Configure Logging \u00b6 The logging is enabled by default. The log directories are: /var/log/nginx-wallarm/ \u2014 NGINX logs. /var/log/wallarm/ \u2014 Wallarm logs. Configure Extended Logging \u00b6 Configure the filter node variables logging using NGINX. This will allow to perform a quick filter node diagnostics with the help of the NGINX log file. Configure Log Rotation \u00b6 By default, the logs rotate once every 24 hours. Changing the rotation parameters through environment variables is not possible. To set up the log rotation, change the configuration files in /etc/logrotate.d/ . 5. Configure Monitoring \u00b6 To monitor the filter node, there are Nagios-compatible scripts inside the container. See details in Monitor the filter node . Example of running the scripts: docker exec -it wallarm-node /usr/lib/nagios-plugins/check_wallarm_tarantool_timeframe -w 1800 -c 900 docker exec -it wallarm-node /usr/lib/nagios-plugins/check_wallarm_export_delay -w 120 -c 300 The Installation Is Complete \u00b6 Check that the filter node runs and filters the traffic. See Check the filter node operation . #### Info:: Default Settings A freshly installed filter node operates in blocking mode (see the [`wallarm_mode`](../admin-en/configure-parameters-en.html#wallarmmode) directive description) by default. This may result in the inoperable [Wallarm scanner](../user-guides/cloud-ui/scanner/intro.md). If you plan to use the scanner, then you [need to perform additional actions](#adding-wallarm-scanner-addresses-to-the-whitelist) to render scanner operational. Additional Settings \u00b6 The filter node may require some additional configuration after installation. The document below lists a few of the typical setups that you can apply if needed. To get more information about other available settings, proceed to the \u201cConfiguration\u201d section of the Administrator\u2019s Guide . Configuring the Display of the Client's Real IP \u00b6 If the filter node is deployed behind a proxy server or load balancer without any additional configuration, the request source address may not be equal to the actual IP address of the client. Instead, it may be equal to one of the IP addresses of the proxy server or the load balancer. In this case, if you want the filter node to receive the client's IP address as a request source address, you need to perform an additional configuration of the proxy server or the load balancer. Adding Wallarm Scanner Addresses to the Whitelist \u00b6 The Wallarm scanner checks the resources of your company for vulnerabilities. Scanning is conducted using IP addresses from one of the following lists (depending on the type of Wallarm Cloud you are using): EU scanner addresses for EU Cloud users US scanner addresses for US Cloud users If you are using the Wallarm scanner, you need to configure the whitelists on your network scope security software (such as firewalls, intrusion detection systems, etc.) to contain Wallarm scanner IP addresses. For example, a Wallarm filter node with default settings is placed in the blocking mode, thus rendering the Wallarm scanner unable to scan the resources behind the filter node. To make the scanner operational again, whitelist the scanner's IP addresses on this filter node. Limiting the Single Request Processing Time \u00b6 Use the wallarm_process_time_limit Wallarm directive to specify the limit of the duration for processing a single request by the filter node. If processing the request consumes more time than specified in the directive, then the information on the error is entered into the log file and the request is marked as an overlimit_res attack. Limiting the Server Reply Waiting Time \u00b6 Use the proxy_read_timeout NGINX directive to specify the timeout for reading the proxy server reply. If the server sends nothing during this time, the connection is closed. Limiting the Maximum Request Size \u00b6 Use the client_max_body_size NGINX directive to specify the limit for the maximum size of the body of the client's request. If this limit is exceeded, NGINX replies to the client with the 413 ( Payload Too Large ) code, also known as the Request Entity Too Large message.","title":"Installing with Docker"},{"location":"en/admin-en/installation-docker-en/#installing-with-docker-using-the-nginx-based-docker-image","text":"The filter node can be deployed as a Docker container. The Docker container is a fat one and contains all subsystems of the filter node. The functionality of the filter node installed inside the Docker container is completely identical to the functionality of the other deployment options. To deploy the filter node as a Docker container, you must: Deploy the filter node. Connect the filter node to the Wallarm cloud. Configure NGINX-Wallarm. Configure logging. Configure monitoring. Known limitations IP blocking is not supported. Most Wallarm directives cannot be changed through environment variables; these directives must be written in configuration files inside the container.","title":"Installing with Docker (Using the NGINX-Based Docker Image)"},{"location":"en/admin-en/installation-docker-en/#1-deploy-the-filter-node","text":"Run one of the docker run commands depending on the EU or US cloud in use: {% codetabs name=\"EU Cloud\", type=\"sh\" -%} docker run -d -e DEPLOY_USER=\" deploy@example.com \" -e DEPLOY_PASSWORD=\"very_secret\" -e NGINX_BACKEND=example.com -e TARANTOOL_MEMORY_GB=memvalue -p 80:80 wallarm/node {%- language name=\"US Cloud\", type=\"sh\" -%} docker run -d -e WALLARM_API_HOST=us1.api.wallarm.com -e DEPLOY_USER=\" deploy@example.com \" -e DEPLOY_PASSWORD=\"very_secret\" -e NGINX_BACKEND=example.com -e TARANTOOL_MEMORY_GB=memvalue -p 80:80 wallarm/node {%- endcodetabs %} where: example.com \u2014 the protected resource. deploy@example.com \u2014 login to the Wallarm portal in the EU or US cloud . very_secret \u2014 password for the Wallarm portal in the EU or US cloud . memvalue \u2013 amount of memory allocated to Tarantool. After running the command, you will have: The protected resource on port 80. The filter node registered in the Wallarm portal in the EU or US cloud ; the filter node displayed in the Wallarm interface. You can also fine-tune the deployment by putting additional configuration files inside the container.","title":"1. Deploy the Filter Node"},{"location":"en/admin-en/installation-docker-en/#2-connect-the-filter-node-to-the-wallarm-cloud","text":"The filter node interacts with the Wallarm cloud located on a remote server. To connect the filter node to the Wallarm cloud, you have the following options: Automatic registration. Using credentials. Using a prepared configuration file.","title":"2. Connect the Filter Node to the Wallarm Cloud"},{"location":"en/admin-en/installation-docker-en/#automatic-registration","text":"Transfer the environment variables DEPLOY_USER , DEPLOY_PASSWORD with the access credentials to the Wallarm portal in the EU or US cloud . The filter node will try to automatically register itself in the Wallarm cloud on the first start. If a filter node with the same name as the node's container identifier is already registered in the cloud, then the registration process will fail. To avoid this, pass the DEPLOY_FORCE=true environment variable to the container. # docker run -d -e DEPLOY_USER=\"deploy@example.com\" -e DEPLOY_PASSWORD=\"very_secret\" -e NGINX_BACKEND=\"IP address or FQDN\" wallarm/node If the registration process finishes successfully, then the container's /etc/wallarm directory will be populated with the license file ( license.key ), a file with the credentials for the filter node to access the cloud ( node.yaml ), and other files required for proper node operation. On the next start of the same filter node, registration will not be required. The filter node communicates with the cloud using the following artifacts acquired during the automatic registration: The uuid and secret values (they are placed in the /etc/wallarm/node.yaml file). The Wallarm license key (it is placed in the /etc/wallarm/license.key file). To connect the already registered filter node to the cloud, pass to its container either the uuid and secret values via the environment variables and the license.key file or the node.yaml and license.key files.","title":"Automatic Registration"},{"location":"en/admin-en/installation-docker-en/#use-of-prepared-credentials","text":"Pass to the filter node's container the uuid and secret values via the corresponding NODE_UUID and NODE_SECRET environment variables, and the license.key file via Docker volumes. Run one of the docker run commands depending on the EU or US cloud in use: {% codetabs name=\"EU Cloud\", type=\"sh\" -%} docker run -d -e \"NODE_UUID=00000000-0000-0000-0000-000000000000\" -e NODE_SECRET=\"0000000000000000000000000000000000000000000000000000000000000000\" -e NGINX_BACKEND=93.184.216.34 wallarm/node {%- language name=\"US Cloud\", type=\"sh\" -%} docker run -d -e WALLARM_API_HOST=us1.api.wallarm.com -e \"NODE_UUID=00000000-0000-0000-0000-000000000000\" -e NODE_SECRET=\"0000000000000000000000000000000000000000000000000000000000000000\" -e NGINX_BACKEND=93.184.216.34 wallarm/node {%- endcodetabs %} Commands are in the tabs below: EU Cloud First tab docker run -d \"NODE_UUID=00000000-0000-0000-0000-000000000000\" -e NODE_SECRET=\"0000000000000000000000000000000000000000000000000000000000000000\" -v /path/to/license.key:/etc/wallarm/license.key -e NGINX_BACKEND=192.168.xxx.1 wallarm/node US Cloud Send tab docker run -d -e WALLARM_API_HOST=us1.api.wallarm.com -e \"NODE_UUID=00000000-0000-0000-0000-000000000000\" -e NODE_SECRET=\"0000000000000000000000000000000000000000000000000000000000000000\" -v /path/to/license.key:/etc/wallarm/license.key -e NGINX_BACKEND=192.168.xxx.1 wallarm/node","title":"Use of Prepared Credentials"},{"location":"en/admin-en/installation-docker-en/#use-of-a-prepared-configuration-file-containing-credentials","text":"Pass the following files to the filter node's container via Docker volumes: the node.yaml file, containing the credentials for the filter node to access the Wallarm cloud, and the license.key file. docker run -d -v /path/to/node.yaml:/etc/wallarm/node.yaml -v /path/to/license.key:/etc/wallarm/license.key -e NGINX_BACKEND = 192 .168.xxx.1 wallarm/node","title":"Use of a Prepared Configuration File Containing Credentials"},{"location":"en/admin-en/installation-docker-en/#3-configure-nginx-wallarm","text":"The filter node configuration is done via the NGINX configuration file. The use of container lets you go through a simplified configuration process by using the environment variables. The simplified process is enabled by transferring the NGINX_BACKEND environment variable.","title":"3. Configure NGINX-Wallarm"},{"location":"en/admin-en/installation-docker-en/#simplified-process","text":"NGINX_BACKEND \u2014 The backend address to which all incoming requests must be transferred. If the address does not have the http:// or https:// , prefix, then http:// is used by default. See details in proxy_pass . Do not use the NGINX_BACKEND variable if you do need the simplified configuration process and if you use your own configuration files. Note that without the NGINX_BACKEND variable, Wallarm will not start automatically. To start Wallarm, configure wallarm_mode monitoring . See details in the wallarm_mode directive description . WALLARM_MODE : The NGINX-Wallarm module operation mode. See details in the wallarm_mode directive description .","title":"Simplified Process"},{"location":"en/admin-en/installation-docker-en/#configuration-files","text":"The directories used by NGINX: /etc/nginx-wallarm/conf.d \u2014 common settings. /etc/nginx-wallarm/sites-enabled \u2014 virtual host settings. /var/www/html \u2014 static files.","title":"Configuration Files"},{"location":"en/admin-en/installation-docker-en/#4-configure-logging","text":"The logging is enabled by default. The log directories are: /var/log/nginx-wallarm/ \u2014 NGINX logs. /var/log/wallarm/ \u2014 Wallarm logs.","title":"4. Configure Logging"},{"location":"en/admin-en/installation-docker-en/#configure-extended-logging","text":"Configure the filter node variables logging using NGINX. This will allow to perform a quick filter node diagnostics with the help of the NGINX log file.","title":"Configure Extended Logging"},{"location":"en/admin-en/installation-docker-en/#configure-log-rotation","text":"By default, the logs rotate once every 24 hours. Changing the rotation parameters through environment variables is not possible. To set up the log rotation, change the configuration files in /etc/logrotate.d/ .","title":"Configure Log Rotation"},{"location":"en/admin-en/installation-docker-en/#5-configure-monitoring","text":"To monitor the filter node, there are Nagios-compatible scripts inside the container. See details in Monitor the filter node . Example of running the scripts: docker exec -it wallarm-node /usr/lib/nagios-plugins/check_wallarm_tarantool_timeframe -w 1800 -c 900 docker exec -it wallarm-node /usr/lib/nagios-plugins/check_wallarm_export_delay -w 120 -c 300","title":"5. Configure Monitoring"},{"location":"en/admin-en/installation-docker-en/#the-installation-is-complete","text":"Check that the filter node runs and filters the traffic. See Check the filter node operation . #### Info:: Default Settings A freshly installed filter node operates in blocking mode (see the [`wallarm_mode`](../admin-en/configure-parameters-en.html#wallarmmode) directive description) by default. This may result in the inoperable [Wallarm scanner](../user-guides/cloud-ui/scanner/intro.md). If you plan to use the scanner, then you [need to perform additional actions](#adding-wallarm-scanner-addresses-to-the-whitelist) to render scanner operational.","title":"The Installation Is Complete"},{"location":"en/admin-en/installation-docker-en/#additional-settings","text":"The filter node may require some additional configuration after installation. The document below lists a few of the typical setups that you can apply if needed. To get more information about other available settings, proceed to the \u201cConfiguration\u201d section of the Administrator\u2019s Guide .","title":"Additional Settings"},{"location":"en/admin-en/installation-docker-en/#configuring-the-display-of-the-clients-real-ip","text":"If the filter node is deployed behind a proxy server or load balancer without any additional configuration, the request source address may not be equal to the actual IP address of the client. Instead, it may be equal to one of the IP addresses of the proxy server or the load balancer. In this case, if you want the filter node to receive the client's IP address as a request source address, you need to perform an additional configuration of the proxy server or the load balancer.","title":"Configuring the Display of the Client's Real IP"},{"location":"en/admin-en/installation-docker-en/#adding-wallarm-scanner-addresses-to-the-whitelist","text":"The Wallarm scanner checks the resources of your company for vulnerabilities. Scanning is conducted using IP addresses from one of the following lists (depending on the type of Wallarm Cloud you are using): EU scanner addresses for EU Cloud users US scanner addresses for US Cloud users If you are using the Wallarm scanner, you need to configure the whitelists on your network scope security software (such as firewalls, intrusion detection systems, etc.) to contain Wallarm scanner IP addresses. For example, a Wallarm filter node with default settings is placed in the blocking mode, thus rendering the Wallarm scanner unable to scan the resources behind the filter node. To make the scanner operational again, whitelist the scanner's IP addresses on this filter node.","title":"Adding Wallarm Scanner Addresses to the Whitelist"},{"location":"en/admin-en/installation-docker-en/#limiting-the-single-request-processing-time","text":"Use the wallarm_process_time_limit Wallarm directive to specify the limit of the duration for processing a single request by the filter node. If processing the request consumes more time than specified in the directive, then the information on the error is entered into the log file and the request is marked as an overlimit_res attack.","title":"Limiting the Single Request Processing Time"},{"location":"en/admin-en/installation-docker-en/#limiting-the-server-reply-waiting-time","text":"Use the proxy_read_timeout NGINX directive to specify the timeout for reading the proxy server reply. If the server sends nothing during this time, the connection is closed.","title":"Limiting the Server Reply Waiting Time"},{"location":"en/admin-en/installation-docker-en/#limiting-the-maximum-request-size","text":"Use the client_max_body_size NGINX directive to specify the limit for the maximum size of the body of the client's request. If this limit is exceeded, NGINX replies to the client with the 413 ( Payload Too Large ) code, also known as the Request Entity Too Large message.","title":"Limiting the Maximum Request Size"},{"location":"en/admin-en/installation-gcp-en/","text":"Deploying on Google Cloud Platform (GCP) \u00b6 To deploy a filter node on the Google Cloud Platform, perform the following steps: Log in to your Google Cloud Platform account. Launch a filter node instance. Configure the filter node instance. Connect to the filter node instance via SSH. Connect the filter node to the Wallarm Cloud. Set up the filter node for using a proxy server. Set up filtering and proxying rules Allocate more memory for the Wallarm Node. Configure logging. Restart NGINX. 1. Log In to Your Google Cloud Platform Account \u00b6 Log in to console.cloud.google.com . 2. Launch a Filter Node Instance \u00b6 Launch your filter node instance using this link , and click LAUNCH ON COMPUTER ENGINE . The instance will launch with a preinstalled filter node. To see detailed information on launching instances in the Google Cloud, proceed to this link . 3. Configure the Filter Node Instance \u00b6 Perform the following actions to configure the launched filter node instance: Navigate to the VM instances page in the Compute Engine section of the menu. Select the launched filter node instance and click the Edit button. Allow the required types of incoming traffic by ticking the corresponding checkboxes in the Firewalls setting. If necessary, you can restrict connecting to the instance with the project SSH keys and use a custom SSH key pair for connecting to this instance. To do this, perform the following actions: Tick the \u201cBlock project-wide\u201d checkbox in the SSH Keys setting. Click the Show and edit button in the SSH Keys setting to expand the field for entering an SSH key. Generate a pair of public and private SSH keys. For example, you can use the ssh-keygen and PuTTYgen utilities. Copy an open key in OpenSSH format from the interface of the used key generator (in the current example, the generated public key should be copied from the Public key for pasting into OpenSSH authorized_keys file area of the PuTTYgen interface) and paste it into the field containing the \u201cEnter entire key data\u201d hint. Save the private key. It will be required for connecting to the configured instance in the future. Click the Save button at the bottom of the page to apply the changes. 4. Connect to the Filter Node Instance via SSH \u00b6 To see detailed information about ways of connecting to instances, proceed to this link . Connecting to the instance via a custom private key If during base instance creation process you have enabled connection to the instance via a custom SSH key pair, make sure you have access to the private key from this key pair. 5. Connect the Filter Node to the Wallarm Cloud \u00b6 The filter node interacts with the Wallarm cloud. There are two ways of connecting the node to the cloud: Using the filter node token Using your cloud account login and password Required access rights Make sure that your Wallarm account has the Administrator role enabled and two-factor authentication disabled, therefore allowing you to connect a filter node to the cloud. You can check the aforementioned parameters by navigating to the user account list in the Wallarm console. * If you are using https://my.wallarm.com/ , proceed to the following link to check your user settings. * If you are using https://us1.my.wallarm.com/ , proceed to the following link to check your user settings. Connecting Using the Filter Node Token \u00b6 To connect the node to the cloud using the token, proceed with the following steps: Create a new node on the Nodes tab of Wallarm web interface. Click the Create new node button. In the form that appears, enter the node name into the corresponding field and select the \u201cCloud\u201d type of installation from the drop-down list. Click the Create button. In the window that appears, click the Copy button next to the field with the token to add the token of the newly created filter node to your clipboard. On the virtual machine run the addcloudnode script: Info:: \u00b6 You have to pick which script to run depending on the Cloud you are using. * If you are using https://my.wallarm.com/ , run the script from the EU Cloud tab below. * If you are using https://us1.my.wallarm.com/ , run the script from the US Cloud tab below. {% termtabs name=\"EU Cloud\" -%} /usr/share/wallarm-common/addcloudnode \u00b6 {%- tab name=\"US Cloud\" -%} /usr/share/wallarm-common/addcloudnode -H us1.api.wallarm.com \u00b6 {%- endtermtabs %} Paste the filter node token from your clipboard. Your filter node will now synchronize with the cloud every 5 seconds according to the default synchronization configuration. Node and cloud synchronization configuration After running the addcloudnode script, the /etc/wallarm/syncnode file containing the node and cloud synchronization settings will be created. To learn more about synchronization configuration file content, proceed to the link . Connecting Using Your Cloud Account Login and Password \u00b6 To connect the node to the cloud using your cloud account requisites, proceed with the following steps: On the virtual machine run the addnode script: Info:: \u00b6 You have to pick which script to run depending on the Cloud you are using. * If you are using https://my.wallarm.com/ , run the script from the \u00ab EU Cloud tab below. * If you are using https://us1.my.wallarm.com/ , run the script from the US Cloud tab below. {% termtabs name=\"EU Cloud\" -%} /usr/share/wallarm-common/addnode \u00b6 {%- tab name=\"US Cloud\" -%} /usr/share/wallarm-common/addnode -H us1.api.wallarm.com \u00b6 {%- endtermtabs %} Provide your Wallarm account\u2019s login and password when prompted. API Access The API choice for your filter node depends on the Cloud you are using. Please, select the API accordingly: * If you are using https://my.wallarm.com/ , your node requires access to https://api.wallarm.com:444 . * If you are using https://us1.my.wallarm.com/ , your node requires access to https://us1.api.wallarm.com:444 . Ensure the access is not blocked by a firewall. 6. Set up the Filter Node for Using a Proxy Server \u00b6 Info This setup step is intended for users who use their own proxy server for the operation of the protected web applications. If you do not use a proxy server, skip this step of the setup. You need to assign new values to the environment variables, which define the proxy server used, to configure Wallarm node for using your proxy server. Add new values of the environment variables to the /etc/environment file: Add https_proxy to define a proxy for the https protocol. Add http_proxy to define a proxy for the http protocol. Add no_proxy to define the list of the resources proxy should not be used for. Assign the <scheme>://<proxy_user>:<proxy_pass>@<host>:<port> string values to the https_proxy and http_proxy variables. <scheme> defines the protocol used. It should match the protocol that the current environment variable sets up proxy for. <proxy_user> defines the username for proxy authorization. <proxy_pass> defines the password for proxy authorization. <host> defines a host of the proxy server. <port> defines a port of the proxy server. Assign a \"<res_1>, <res_2>, <res_3>, <res_4>, ...\" array value, where <res_1> , <res_2> , <res_3> , and <res_4> are the IP addresses and/or domains, to the no_proxy variable to define a list of the resources which proxy should not be used for. This array should consist of IP addresses and/or domains. Resources that need to be addressed without a proxy Add the following IP addresses and domain to the list of the resources that have to be addressed without a proxy for the system to operate correctly: 127.0.0.1 , 127.0.0.8 , 127.0.0.9 , and localhost . The 127.0.0.8 and 127.0.0.9 IP addresses are used for the operation of the Wallarm filter node. The example of the correct /etc/environment file contents below demonstrates the following configuration: HTTPS and HTTP requests are proxied to the 1.2.3.4 host with the 1234 port, using the admin username and the 01234 password for authorization on the proxy server. Proxying is disabled for the requests sent to 127.0.0.1 , 127.0.0.8 , 127.0.0.9 , and localhost . https_proxy=http://admin:01234@1.2.3.4:1234 http_proxy=http://admin:01234@1.2.3.4:1234 no_proxy=\"127.0.0.1, 127.0.0.8, 127.0.0.9, localhost\" 7. Set Up Filtering and Proxying Rules \u00b6 The etc/nginx/conf.d directory contains NGINX and Wallarm filter node configuration files. By default, this directory contains the following configuration files: The default.conf file defines the configuration of NGINX. The wallarm.conf file defines the global configuration of Wallarm filter node. The wallarm-status.conf file defines the Wallarm monitoring configuration. You can create your own configuration files to define the operation of NGINX and Wallarm. It is recommended to create a separate configuration file with the server block for each group of the domains that should be processed in the same way. To see detailed information about working with NGINX configuration files, proceed to the official NGINX documentation . Wallarm directives define the operation logic of the Wallarm filter node. To see the list of Wallarm directives available, proceed to the Wallarm configuration options page. A Configuration File Example \u00b6 Let us suppose that you need to configure the server to work in the following conditions: Only HTTP traffic is processed. There are no HTTPS requests processed. The following domains receive the requests: example.com and www.example.com . All requests must be passed to the server 10.80.0.5 . All incoming requests are considered less than 1MB in size (default setting). The processing of a request takes no more than 60 seconds (default setting). Wallarm must operate in the monitor mode. Clients access the filter node directly, without an intermediate HTTP load balancer. Creating a configuration file You can create a custom NGINX configuration file (e.g. example.com.conf ) or modify the default NGINX configuration file ( default.conf ). When creating a custom configuration file, make sure that NGINX listens to the incoming connections on the free port. To meet the listed conditions, the contents of the configuration file must be the following: server { listen 80; listen [::]:80 ipv6only=on; # the domains for which traffic is processed server_name example.com; server_name www.example.com; # turn on the monitoring mode of traffic processing wallarm_mode monitoring; # wallarm_instance 1; location / { # setting the address for request forwarding proxy_pass http://10.80.0.5; proxy_set_header Host $host; proxy_set_header X-Real-IP $remote_addr; proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for; } } 8. Allocate More Memory for the Wallarm Node \u00b6 The Wallarm Node uses Tarantool, an open-source in-memory database, to calculate traffic metrics required for automated adjusting of security rules. By default, the amount of RAM allocated to Tarantool is 75% of the total instance memory. You can change the amount of RAM allocated for Tarantool To allocate the instance RAM to Tarantool: Open the Tarantool configuration file: # vi /etc/default/wallarm-tarantool Set the amount of allocated RAM in the SLAB_ALLOC_ARENA in GB. For example, to set 24 GB: SLAB_ALLOC_ARENA=24 To apply changes, restart the Tarantool daemon: # systemctl restart wallarm-tarantool 9. Configure Logging \u00b6 Configure the filter node variables logging using NGINX. This will allow to perform a quick filter node diagnostics with the help of the NGINX log file. 10. Restart NGINX \u00b6 Restart NGINX by running the following command: # systemctl restart nginx The Installation Is Complete \u00b6 The installation is now complete. Check that the filter node runs and filters the traffic. See Check the filter node operation . #### Info:: Default Settings A freshly installed filter node operates in blocking mode (see the [`wallarm_mode`](../admin-en/configure-parameters-en.html#wallarmmode) directive description) by default. This may result in the inoperable [Wallarm scanner](../user-guides/cloud-ui/scanner/intro.md). If you plan to use the scanner, then you [need to perform additional actions](#adding-wallarm-scanner-addresses-to-the-whitelist) to render scanner operational. Additional Settings \u00b6 The filter node may require some additional configuration after installation. The document below lists a few of the typical setups that you can apply if needed. To get more information about other available settings, proceed to the \u201cConfiguration\u201d section of the Administrator\u2019s Guide . Configuring the Display of the Client's Real IP \u00b6 If the filter node is deployed behind a proxy server or load balancer without any additional configuration, the request source address may not be equal to the actual IP address of the client. Instead, it may be equal to one of the IP addresses of the proxy server or the load balancer. In this case, if you want the filter node to receive the client's IP address as a request source address, you need to perform an additional configuration of the proxy server or the load balancer. Adding Wallarm Scanner Addresses to the Whitelist \u00b6 The Wallarm scanner checks the resources of your company for vulnerabilities. Scanning is conducted using IP addresses from one of the following lists (depending on the type of Wallarm Cloud you are using): EU scanner addresses for EU Cloud users US scanner addresses for US Cloud users If you are using the Wallarm scanner, you need to configure the whitelists on your network scope security software (such as firewalls, intrusion detection systems, etc.) to contain Wallarm scanner IP addresses. For example, a Wallarm filter node with default settings is placed in the blocking mode, thus rendering the Wallarm scanner unable to scan the resources behind the filter node. To make the scanner operational again, whitelist the scanner's IP addresses on this filter node. Limiting the Single Request Processing Time \u00b6 Use the wallarm_process_time_limit Wallarm directive to specify the limit of the duration for processing a single request by the filter node. If processing the request consumes more time than specified in the directive, then the information on the error is entered into the log file and the request is marked as an overlimit_res attack. Limiting the Server Reply Waiting Time \u00b6 Use the proxy_read_timeout NGINX directive to specify the timeout for reading the proxy server reply. If the server sends nothing during this time, the connection is closed. Limiting the Maximum Request Size \u00b6 Use the client_max_body_size NGINX directive to specify the limit for the maximum size of the body of the client's request. If this limit is exceeded, NGINX replies to the client with the 413 ( Payload Too Large ) code, also known as the Request Entity Too Large message.","title":"Creating and Configuring the Wallarm Filter Node Instance"},{"location":"en/admin-en/installation-gcp-en/#deploying-on-google-cloud-platform-gcp","text":"To deploy a filter node on the Google Cloud Platform, perform the following steps: Log in to your Google Cloud Platform account. Launch a filter node instance. Configure the filter node instance. Connect to the filter node instance via SSH. Connect the filter node to the Wallarm Cloud. Set up the filter node for using a proxy server. Set up filtering and proxying rules Allocate more memory for the Wallarm Node. Configure logging. Restart NGINX.","title":"Deploying on Google Cloud Platform (GCP)"},{"location":"en/admin-en/installation-gcp-en/#1-log-in-to-your-google-cloud-platform-account","text":"Log in to console.cloud.google.com .","title":"1. Log In to Your Google Cloud Platform Account"},{"location":"en/admin-en/installation-gcp-en/#2-launch-a-filter-node-instance","text":"Launch your filter node instance using this link , and click LAUNCH ON COMPUTER ENGINE . The instance will launch with a preinstalled filter node. To see detailed information on launching instances in the Google Cloud, proceed to this link .","title":"2. Launch a Filter Node Instance"},{"location":"en/admin-en/installation-gcp-en/#3-configure-the-filter-node-instance","text":"Perform the following actions to configure the launched filter node instance: Navigate to the VM instances page in the Compute Engine section of the menu. Select the launched filter node instance and click the Edit button. Allow the required types of incoming traffic by ticking the corresponding checkboxes in the Firewalls setting. If necessary, you can restrict connecting to the instance with the project SSH keys and use a custom SSH key pair for connecting to this instance. To do this, perform the following actions: Tick the \u201cBlock project-wide\u201d checkbox in the SSH Keys setting. Click the Show and edit button in the SSH Keys setting to expand the field for entering an SSH key. Generate a pair of public and private SSH keys. For example, you can use the ssh-keygen and PuTTYgen utilities. Copy an open key in OpenSSH format from the interface of the used key generator (in the current example, the generated public key should be copied from the Public key for pasting into OpenSSH authorized_keys file area of the PuTTYgen interface) and paste it into the field containing the \u201cEnter entire key data\u201d hint. Save the private key. It will be required for connecting to the configured instance in the future. Click the Save button at the bottom of the page to apply the changes.","title":"3. Configure the Filter Node Instance"},{"location":"en/admin-en/installation-gcp-en/#4-connect-to-the-filter-node-instance-via-ssh","text":"To see detailed information about ways of connecting to instances, proceed to this link . Connecting to the instance via a custom private key If during base instance creation process you have enabled connection to the instance via a custom SSH key pair, make sure you have access to the private key from this key pair.","title":"4. Connect to the Filter Node Instance via SSH"},{"location":"en/admin-en/installation-gcp-en/#5-connect-the-filter-node-to-the-wallarm-cloud","text":"The filter node interacts with the Wallarm cloud. There are two ways of connecting the node to the cloud: Using the filter node token Using your cloud account login and password Required access rights Make sure that your Wallarm account has the Administrator role enabled and two-factor authentication disabled, therefore allowing you to connect a filter node to the cloud. You can check the aforementioned parameters by navigating to the user account list in the Wallarm console. * If you are using https://my.wallarm.com/ , proceed to the following link to check your user settings. * If you are using https://us1.my.wallarm.com/ , proceed to the following link to check your user settings.","title":"5. Connect the Filter Node to the Wallarm Cloud"},{"location":"en/admin-en/installation-gcp-en/#connecting-using-the-filter-node-token","text":"To connect the node to the cloud using the token, proceed with the following steps: Create a new node on the Nodes tab of Wallarm web interface. Click the Create new node button. In the form that appears, enter the node name into the corresponding field and select the \u201cCloud\u201d type of installation from the drop-down list. Click the Create button. In the window that appears, click the Copy button next to the field with the token to add the token of the newly created filter node to your clipboard. On the virtual machine run the addcloudnode script:","title":"Connecting Using the Filter Node Token"},{"location":"en/admin-en/installation-gcp-en/#info","text":"You have to pick which script to run depending on the Cloud you are using. * If you are using https://my.wallarm.com/ , run the script from the EU Cloud tab below. * If you are using https://us1.my.wallarm.com/ , run the script from the US Cloud tab below. {% termtabs name=\"EU Cloud\" -%}","title":"Info::"},{"location":"en/admin-en/installation-gcp-en/#usrsharewallarm-commonaddcloudnode","text":"{%- tab name=\"US Cloud\" -%}","title":"/usr/share/wallarm-common/addcloudnode"},{"location":"en/admin-en/installation-gcp-en/#usrsharewallarm-commonaddcloudnode-h-us1apiwallarmcom","text":"{%- endtermtabs %} Paste the filter node token from your clipboard. Your filter node will now synchronize with the cloud every 5 seconds according to the default synchronization configuration. Node and cloud synchronization configuration After running the addcloudnode script, the /etc/wallarm/syncnode file containing the node and cloud synchronization settings will be created. To learn more about synchronization configuration file content, proceed to the link .","title":"/usr/share/wallarm-common/addcloudnode -H us1.api.wallarm.com"},{"location":"en/admin-en/installation-gcp-en/#connecting-using-your-cloud-account-login-and-password","text":"To connect the node to the cloud using your cloud account requisites, proceed with the following steps: On the virtual machine run the addnode script:","title":"Connecting Using Your Cloud Account Login and Password"},{"location":"en/admin-en/installation-gcp-en/#info_1","text":"You have to pick which script to run depending on the Cloud you are using. * If you are using https://my.wallarm.com/ , run the script from the \u00ab EU Cloud tab below. * If you are using https://us1.my.wallarm.com/ , run the script from the US Cloud tab below. {% termtabs name=\"EU Cloud\" -%}","title":"Info::"},{"location":"en/admin-en/installation-gcp-en/#usrsharewallarm-commonaddnode","text":"{%- tab name=\"US Cloud\" -%}","title":"/usr/share/wallarm-common/addnode"},{"location":"en/admin-en/installation-gcp-en/#usrsharewallarm-commonaddnode-h-us1apiwallarmcom","text":"{%- endtermtabs %} Provide your Wallarm account\u2019s login and password when prompted. API Access The API choice for your filter node depends on the Cloud you are using. Please, select the API accordingly: * If you are using https://my.wallarm.com/ , your node requires access to https://api.wallarm.com:444 . * If you are using https://us1.my.wallarm.com/ , your node requires access to https://us1.api.wallarm.com:444 . Ensure the access is not blocked by a firewall.","title":"/usr/share/wallarm-common/addnode -H us1.api.wallarm.com"},{"location":"en/admin-en/installation-gcp-en/#6-set-up-the-filter-node-for-using-a-proxy-server","text":"Info This setup step is intended for users who use their own proxy server for the operation of the protected web applications. If you do not use a proxy server, skip this step of the setup. You need to assign new values to the environment variables, which define the proxy server used, to configure Wallarm node for using your proxy server. Add new values of the environment variables to the /etc/environment file: Add https_proxy to define a proxy for the https protocol. Add http_proxy to define a proxy for the http protocol. Add no_proxy to define the list of the resources proxy should not be used for. Assign the <scheme>://<proxy_user>:<proxy_pass>@<host>:<port> string values to the https_proxy and http_proxy variables. <scheme> defines the protocol used. It should match the protocol that the current environment variable sets up proxy for. <proxy_user> defines the username for proxy authorization. <proxy_pass> defines the password for proxy authorization. <host> defines a host of the proxy server. <port> defines a port of the proxy server. Assign a \"<res_1>, <res_2>, <res_3>, <res_4>, ...\" array value, where <res_1> , <res_2> , <res_3> , and <res_4> are the IP addresses and/or domains, to the no_proxy variable to define a list of the resources which proxy should not be used for. This array should consist of IP addresses and/or domains. Resources that need to be addressed without a proxy Add the following IP addresses and domain to the list of the resources that have to be addressed without a proxy for the system to operate correctly: 127.0.0.1 , 127.0.0.8 , 127.0.0.9 , and localhost . The 127.0.0.8 and 127.0.0.9 IP addresses are used for the operation of the Wallarm filter node. The example of the correct /etc/environment file contents below demonstrates the following configuration: HTTPS and HTTP requests are proxied to the 1.2.3.4 host with the 1234 port, using the admin username and the 01234 password for authorization on the proxy server. Proxying is disabled for the requests sent to 127.0.0.1 , 127.0.0.8 , 127.0.0.9 , and localhost . https_proxy=http://admin:01234@1.2.3.4:1234 http_proxy=http://admin:01234@1.2.3.4:1234 no_proxy=\"127.0.0.1, 127.0.0.8, 127.0.0.9, localhost\"","title":"6. Set up the Filter Node for Using a Proxy Server"},{"location":"en/admin-en/installation-gcp-en/#7-set-up-filtering-and-proxying-rules","text":"The etc/nginx/conf.d directory contains NGINX and Wallarm filter node configuration files. By default, this directory contains the following configuration files: The default.conf file defines the configuration of NGINX. The wallarm.conf file defines the global configuration of Wallarm filter node. The wallarm-status.conf file defines the Wallarm monitoring configuration. You can create your own configuration files to define the operation of NGINX and Wallarm. It is recommended to create a separate configuration file with the server block for each group of the domains that should be processed in the same way. To see detailed information about working with NGINX configuration files, proceed to the official NGINX documentation . Wallarm directives define the operation logic of the Wallarm filter node. To see the list of Wallarm directives available, proceed to the Wallarm configuration options page.","title":"7. Set Up Filtering and Proxying Rules"},{"location":"en/admin-en/installation-gcp-en/#a-configuration-file-example","text":"Let us suppose that you need to configure the server to work in the following conditions: Only HTTP traffic is processed. There are no HTTPS requests processed. The following domains receive the requests: example.com and www.example.com . All requests must be passed to the server 10.80.0.5 . All incoming requests are considered less than 1MB in size (default setting). The processing of a request takes no more than 60 seconds (default setting). Wallarm must operate in the monitor mode. Clients access the filter node directly, without an intermediate HTTP load balancer. Creating a configuration file You can create a custom NGINX configuration file (e.g. example.com.conf ) or modify the default NGINX configuration file ( default.conf ). When creating a custom configuration file, make sure that NGINX listens to the incoming connections on the free port. To meet the listed conditions, the contents of the configuration file must be the following: server { listen 80; listen [::]:80 ipv6only=on; # the domains for which traffic is processed server_name example.com; server_name www.example.com; # turn on the monitoring mode of traffic processing wallarm_mode monitoring; # wallarm_instance 1; location / { # setting the address for request forwarding proxy_pass http://10.80.0.5; proxy_set_header Host $host; proxy_set_header X-Real-IP $remote_addr; proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for; } }","title":"A Configuration File Example"},{"location":"en/admin-en/installation-gcp-en/#8-allocate-more-memory-for-the-wallarm-node","text":"The Wallarm Node uses Tarantool, an open-source in-memory database, to calculate traffic metrics required for automated adjusting of security rules. By default, the amount of RAM allocated to Tarantool is 75% of the total instance memory. You can change the amount of RAM allocated for Tarantool To allocate the instance RAM to Tarantool: Open the Tarantool configuration file: # vi /etc/default/wallarm-tarantool Set the amount of allocated RAM in the SLAB_ALLOC_ARENA in GB. For example, to set 24 GB: SLAB_ALLOC_ARENA=24 To apply changes, restart the Tarantool daemon: # systemctl restart wallarm-tarantool","title":"8. Allocate More Memory for the Wallarm Node"},{"location":"en/admin-en/installation-gcp-en/#9-configure-logging","text":"Configure the filter node variables logging using NGINX. This will allow to perform a quick filter node diagnostics with the help of the NGINX log file.","title":"9. Configure Logging"},{"location":"en/admin-en/installation-gcp-en/#10-restart-nginx","text":"Restart NGINX by running the following command: # systemctl restart nginx","title":"10. Restart NGINX"},{"location":"en/admin-en/installation-gcp-en/#the-installation-is-complete","text":"The installation is now complete. Check that the filter node runs and filters the traffic. See Check the filter node operation . #### Info:: Default Settings A freshly installed filter node operates in blocking mode (see the [`wallarm_mode`](../admin-en/configure-parameters-en.html#wallarmmode) directive description) by default. This may result in the inoperable [Wallarm scanner](../user-guides/cloud-ui/scanner/intro.md). If you plan to use the scanner, then you [need to perform additional actions](#adding-wallarm-scanner-addresses-to-the-whitelist) to render scanner operational.","title":"The Installation Is Complete"},{"location":"en/admin-en/installation-gcp-en/#additional-settings","text":"The filter node may require some additional configuration after installation. The document below lists a few of the typical setups that you can apply if needed. To get more information about other available settings, proceed to the \u201cConfiguration\u201d section of the Administrator\u2019s Guide .","title":"Additional Settings"},{"location":"en/admin-en/installation-gcp-en/#configuring-the-display-of-the-clients-real-ip","text":"If the filter node is deployed behind a proxy server or load balancer without any additional configuration, the request source address may not be equal to the actual IP address of the client. Instead, it may be equal to one of the IP addresses of the proxy server or the load balancer. In this case, if you want the filter node to receive the client's IP address as a request source address, you need to perform an additional configuration of the proxy server or the load balancer.","title":"Configuring the Display of the Client's Real IP"},{"location":"en/admin-en/installation-gcp-en/#adding-wallarm-scanner-addresses-to-the-whitelist","text":"The Wallarm scanner checks the resources of your company for vulnerabilities. Scanning is conducted using IP addresses from one of the following lists (depending on the type of Wallarm Cloud you are using): EU scanner addresses for EU Cloud users US scanner addresses for US Cloud users If you are using the Wallarm scanner, you need to configure the whitelists on your network scope security software (such as firewalls, intrusion detection systems, etc.) to contain Wallarm scanner IP addresses. For example, a Wallarm filter node with default settings is placed in the blocking mode, thus rendering the Wallarm scanner unable to scan the resources behind the filter node. To make the scanner operational again, whitelist the scanner's IP addresses on this filter node.","title":"Adding Wallarm Scanner Addresses to the Whitelist"},{"location":"en/admin-en/installation-gcp-en/#limiting-the-single-request-processing-time","text":"Use the wallarm_process_time_limit Wallarm directive to specify the limit of the duration for processing a single request by the filter node. If processing the request consumes more time than specified in the directive, then the information on the error is entered into the log file and the request is marked as an overlimit_res attack.","title":"Limiting the Single Request Processing Time"},{"location":"en/admin-en/installation-gcp-en/#limiting-the-server-reply-waiting-time","text":"Use the proxy_read_timeout NGINX directive to specify the timeout for reading the proxy server reply. If the server sends nothing during this time, the connection is closed.","title":"Limiting the Server Reply Waiting Time"},{"location":"en/admin-en/installation-gcp-en/#limiting-the-maximum-request-size","text":"Use the client_max_body_size NGINX directive to specify the limit for the maximum size of the body of the client's request. If this limit is exceeded, NGINX replies to the client with the 413 ( Payload Too Large ) code, also known as the Request Entity Too Large message.","title":"Limiting the Maximum Request Size"},{"location":"en/admin-en/installation-heroku-en/","text":"Installing as a Heroku App \u00b6 #### Warning:: Installation prerequisites Before installing the filter node please make sure the following requirements are respected: * Your app is using the Heroku-16 or Heroku-18 stack. Detailed information about stacks is available in [Heroku documentation](https://devcenter.heroku.com/articles/stack). * You have a Wallarm account with the Administrator role. Wallarm can protect web-applications and API deployed on the Heroku platform. The Wallarm filter node can be installed by connecting the application to a Buildpack that was built specifically for Heroku apps. You can get the Heroku Buildpack from the Wallarm public repository . The Buildpack contains the following features: L2met friendly NGINX log format. Heroku request IDs embedded in NGINX logs. The app crashes dyno when NGINX or an app server crashes. Safety first. Language/App Server agnostic . Environment variables for filter node configuration Customizable NGINX configuration . Application-coordinated dyno starts . Language and App Server Agnostic \u00b6 The Wallarm Node buildpack provides the wallarm/bin/start-wallarm command. This command takes your app server's startup command as an argument. For example, to get Wallarm Node and Unicorn up and running, run the following command: $ cat Procfile web: wallarm/bin/start-wallarm bundle exec unicorn -c config/unicorn.rb Environment Variables \u00b6 You can use the following environment variables: WALLARM_API_HOST \u2014 The Wallarm API address. WALLARM_USER \u2014 The user on the Wallarm portal in the EU or US cloud that has rights to add new nodes. WALLARM_PASSWORD \u2014 The user password. WALLARM_MODE \u2014 The request handling mode: off , monitoring (default), blocking . WALLARM_TARANTOOL_MEMORY \u2014 The amount of memory in gigabytes allocated to postanalytics; 50% of total memory by default. For example, to set your WALLARM_MODE to the blocking mode, run the following command: $ heroku config:set WALLARM_MODE=block Customizable NGINX Configuration \u00b6 You can provide your own NGINX configuration by creating a file named nginx.conf.erb in the directory wallarm/etc . Start by copying the buildpack's default configuration file . Application and Dyno Coordination \u00b6 The buildpack will not start NGINX with the Wallarm module until a file is written to /tmp/app-initialized . Since NGINX binds to the dyno's $PORT and since $PORT determines if the app can receive traffic, you can delay NGINX traffic reception until your application is ready to handle it. The examples below show how and when you should write the file when working with Unicorn. Filter Node Setup Example \u00b6 Here are the two setup examples. The first example demonstrates the installation of a new app; The second one demonstrates the installation of an existing app. In both cases, we are using Ruby & Unicorn. However, you can use the Buildpack to install Wallarm for applications which are written in other programming languages or use other servers. Existing Application \u00b6 Update the buildpacks using the following command: $ heroku buildpacks:add https://github.com/wallarm/heroku-buildpack-wallarm-node.git Update the Procfile to contain the following: web: wallarm/bin/start-wallarm bundle exec unicorn -c config/unicorn.rb $ git add Procfile $ git commit -m 'Update procfile for Wallarm Node buildpack' Update Unicorn configuration to include the following : require 'fileutils' listen '/tmp/nginx.socket' before_fork do |server,worker| FileUtils.touch('/tmp/app-initialized') end Commit the changes using the following commands: $ git add config/unicorn.rb $ git commit -m 'Update unicorn config to listen on NGINX socket.' Connect to the Wallarm cloud by running the command depending on the EU or US cloud you are using: {% codetabs name=\"EU Cloud\", type=\"sh\" -%} heroku config:set WALLARM_USER= heroku config:set WALLARM_PASSWORD= {%- language name=\"US Cloud\", type=\"sh\" -%} heroku config:set WALLARM_API_HOST=us1.api.wallarm.com heroku config:set WALLARM_USER= heroku config:set WALLARM_PASSWORD= {%- endcodetabs %} Deploy the changes using the following command: $ git push heroku master New Application \u00b6 #### Info:: We are using Ruby & Unicorn. However, you can use the Buildpack to install Wallarm for applications which are written in other programming languages or use other servers. These are the components you need to have installed on your system for the following instructions to work: gcc, heroku cli , bundler . Create a directory for the app using the following command: $ mkdir myapp; cd myapp $ git init Create a Gemfile containing the following code: source 'https://rubygems.org' gem 'unicorn' Create a config.ru file using the following command: $ run Proc.new {[200,{'Content-Type' => 'text/plain'}, [\"hello world\"]]} Create a config/unicorn.rb file containing the following configurations for an application server that receives connections through the local socket: require 'fileutils' preload_app true timeout 5 worker_processes 4 listen '/tmp/nginx.socket', backlog: 1024 before_fork do |server,worker| FileUtils.touch('/tmp/app-initialized') end Install Gems using the following command: $ bundle install Create a Procfile containing the following: web: wallarm/bin/start-wallarm bundle exec unicorn -c config/unicorn.rb Create & push the Heroku app by running the command depending on the EU or US cloud you are using: {% codetabs name=\"EU Cloud\", type=\"sh\" -%} $ heroku create $ heroku buildpacks:add heroku/ruby $ heroku buildpacks:add https://github.com/wallarm/heroku-buildpack-wallarm-node.git $ heroku config:set WALLARM_USER= $ heroku config:set WALLARM_PASSWORD= $ git add . $ git commit -am \"init\" $ git push heroku master $ heroku logs -t {%- language name=\"US Cloud\", type=\"sh\" -%} $ heroku create $ heroku buildpacks:add heroku/ruby $ heroku buildpacks:add https://github.com/wallarm/heroku-buildpack-wallarm-node.git $ heroku config:set WALLARM_API_HOST=us1.api.wallarm.com $ heroku config:set WALLARM_USER= $ heroku config:set WALLARM_PASSWORD= $ git add . $ git commit -am \"init\" $ git push heroku master $ heroku logs -t {%- endcodetabs %} Check the app using the following command: $ heroku open","title":"Installing on Heroku"},{"location":"en/admin-en/installation-heroku-en/#installing-as-a-heroku-app","text":"#### Warning:: Installation prerequisites Before installing the filter node please make sure the following requirements are respected: * Your app is using the Heroku-16 or Heroku-18 stack. Detailed information about stacks is available in [Heroku documentation](https://devcenter.heroku.com/articles/stack). * You have a Wallarm account with the Administrator role. Wallarm can protect web-applications and API deployed on the Heroku platform. The Wallarm filter node can be installed by connecting the application to a Buildpack that was built specifically for Heroku apps. You can get the Heroku Buildpack from the Wallarm public repository . The Buildpack contains the following features: L2met friendly NGINX log format. Heroku request IDs embedded in NGINX logs. The app crashes dyno when NGINX or an app server crashes. Safety first. Language/App Server agnostic . Environment variables for filter node configuration Customizable NGINX configuration . Application-coordinated dyno starts .","title":"Installing as a Heroku App"},{"location":"en/admin-en/installation-heroku-en/#language-and-app-server-agnostic","text":"The Wallarm Node buildpack provides the wallarm/bin/start-wallarm command. This command takes your app server's startup command as an argument. For example, to get Wallarm Node and Unicorn up and running, run the following command: $ cat Procfile web: wallarm/bin/start-wallarm bundle exec unicorn -c config/unicorn.rb","title":"Language and App Server Agnostic"},{"location":"en/admin-en/installation-heroku-en/#environment-variables","text":"You can use the following environment variables: WALLARM_API_HOST \u2014 The Wallarm API address. WALLARM_USER \u2014 The user on the Wallarm portal in the EU or US cloud that has rights to add new nodes. WALLARM_PASSWORD \u2014 The user password. WALLARM_MODE \u2014 The request handling mode: off , monitoring (default), blocking . WALLARM_TARANTOOL_MEMORY \u2014 The amount of memory in gigabytes allocated to postanalytics; 50% of total memory by default. For example, to set your WALLARM_MODE to the blocking mode, run the following command: $ heroku config:set WALLARM_MODE=block","title":"Environment Variables"},{"location":"en/admin-en/installation-heroku-en/#customizable-nginx-configuration","text":"You can provide your own NGINX configuration by creating a file named nginx.conf.erb in the directory wallarm/etc . Start by copying the buildpack's default configuration file .","title":"Customizable NGINX Configuration"},{"location":"en/admin-en/installation-heroku-en/#application-and-dyno-coordination","text":"The buildpack will not start NGINX with the Wallarm module until a file is written to /tmp/app-initialized . Since NGINX binds to the dyno's $PORT and since $PORT determines if the app can receive traffic, you can delay NGINX traffic reception until your application is ready to handle it. The examples below show how and when you should write the file when working with Unicorn.","title":"Application and Dyno Coordination"},{"location":"en/admin-en/installation-heroku-en/#filter-node-setup-example","text":"Here are the two setup examples. The first example demonstrates the installation of a new app; The second one demonstrates the installation of an existing app. In both cases, we are using Ruby & Unicorn. However, you can use the Buildpack to install Wallarm for applications which are written in other programming languages or use other servers.","title":"Filter Node Setup Example"},{"location":"en/admin-en/installation-heroku-en/#existing-application","text":"Update the buildpacks using the following command: $ heroku buildpacks:add https://github.com/wallarm/heroku-buildpack-wallarm-node.git Update the Procfile to contain the following: web: wallarm/bin/start-wallarm bundle exec unicorn -c config/unicorn.rb $ git add Procfile $ git commit -m 'Update procfile for Wallarm Node buildpack' Update Unicorn configuration to include the following : require 'fileutils' listen '/tmp/nginx.socket' before_fork do |server,worker| FileUtils.touch('/tmp/app-initialized') end Commit the changes using the following commands: $ git add config/unicorn.rb $ git commit -m 'Update unicorn config to listen on NGINX socket.' Connect to the Wallarm cloud by running the command depending on the EU or US cloud you are using: {% codetabs name=\"EU Cloud\", type=\"sh\" -%} heroku config:set WALLARM_USER= heroku config:set WALLARM_PASSWORD= {%- language name=\"US Cloud\", type=\"sh\" -%} heroku config:set WALLARM_API_HOST=us1.api.wallarm.com heroku config:set WALLARM_USER= heroku config:set WALLARM_PASSWORD= {%- endcodetabs %} Deploy the changes using the following command: $ git push heroku master","title":"Existing Application"},{"location":"en/admin-en/installation-heroku-en/#new-application","text":"#### Info:: We are using Ruby & Unicorn. However, you can use the Buildpack to install Wallarm for applications which are written in other programming languages or use other servers. These are the components you need to have installed on your system for the following instructions to work: gcc, heroku cli , bundler . Create a directory for the app using the following command: $ mkdir myapp; cd myapp $ git init Create a Gemfile containing the following code: source 'https://rubygems.org' gem 'unicorn' Create a config.ru file using the following command: $ run Proc.new {[200,{'Content-Type' => 'text/plain'}, [\"hello world\"]]} Create a config/unicorn.rb file containing the following configurations for an application server that receives connections through the local socket: require 'fileutils' preload_app true timeout 5 worker_processes 4 listen '/tmp/nginx.socket', backlog: 1024 before_fork do |server,worker| FileUtils.touch('/tmp/app-initialized') end Install Gems using the following command: $ bundle install Create a Procfile containing the following: web: wallarm/bin/start-wallarm bundle exec unicorn -c config/unicorn.rb Create & push the Heroku app by running the command depending on the EU or US cloud you are using: {% codetabs name=\"EU Cloud\", type=\"sh\" -%} $ heroku create $ heroku buildpacks:add heroku/ruby $ heroku buildpacks:add https://github.com/wallarm/heroku-buildpack-wallarm-node.git $ heroku config:set WALLARM_USER= $ heroku config:set WALLARM_PASSWORD= $ git add . $ git commit -am \"init\" $ git push heroku master $ heroku logs -t {%- language name=\"US Cloud\", type=\"sh\" -%} $ heroku create $ heroku buildpacks:add heroku/ruby $ heroku buildpacks:add https://github.com/wallarm/heroku-buildpack-wallarm-node.git $ heroku config:set WALLARM_API_HOST=us1.api.wallarm.com $ heroku config:set WALLARM_USER= $ heroku config:set WALLARM_PASSWORD= $ git add . $ git commit -am \"init\" $ git push heroku master $ heroku logs -t {%- endcodetabs %} Check the app using the following command: $ heroku open","title":"New Application"},{"location":"en/admin-en/installation-kong-en/","text":"Installing with Kong \u00b6 Prerequisites The Kong platform shall meet the following requirements: * Kong version 1.4.3 or lower * Kong installed on the platform supported by Wallarm according to Kong official instructions One of the following points is required for proper Kong operation: * prepared configuration files, * configured database. Please make sure that installed Kong meets the prerequisites before proceeding with Wallarm installation. The official Kong documentation is available by the link . Known Limitations The wallarm_block_page directive is not supported. Wallarm configuration via Kong Admin API is not supported. Installation \u00b6 #### Warning:: Installation of postanalytics on a separate server If you are planning to install postanalytics on a separate server, you must install postanalytics first. See details in [Separate postanalytics installation][doc-postanalytics]. To install the Wallarm module with Kong, you need to: Add Wallarm repositories. Install Wallarm packages. Configure postanalytics. Set up the filter node for using a proxy server. Connect the filter node to the Wallarm cloud. Configure the postanalytics server addresses. Configure the filtration mode. Configure logging. Prerequisites Prior to taking any steps listed below, either disable or configure SELinux if it is installed on the operating system. Make sure that you execute all commands below as superuser (e.g. root ). 1. Add Wallarm Repositories \u00b6 The filter node installs and updates from the Wallarm repositories. Depending on your operating system, run one of the following commands: {% termtabs name=\"Debian 8.x (jessie)\" -%} apt-key adv --keyserver keys.gnupg.net --recv-keys 72B865FD \u00b6 echo 'deb http://repo.wallarm.com/debian/wallarm-node jessie/2.14/' > /etc/apt/sources.list.d/wallarm.list \u00b6 apt-get update \u00b6 {%- tab name=\"Debian 9.x (stretch)\" -%} apt-get install dirmngr \u00b6 apt-key adv --keyserver keys.gnupg.net --recv-keys 72B865FD \u00b6 sh -c \"echo 'deb http://repo.wallarm.com/debian/wallarm-node stretch/2.14/' > /etc/apt/sources.list.d/wallarm.list\" \u00b6 apt-get update \u00b6 {%- tab name=\"Ubuntu 14.04 LTS (trusty)\" -%} apt-key adv --keyserver keys.gnupg.net --recv-keys 72B865FD \u00b6 echo 'deb http://repo.wallarm.com/ubuntu/wallarm-node trusty/2.14/' > /etc/apt/sources.list.d/wallarm.list \u00b6 apt-get update \u00b6 {%- tab name=\"Ubuntu 16.04 LTS (xenial)\" -%} apt-key adv --keyserver keys.gnupg.net --recv-keys 72B865FD \u00b6 echo 'deb http://repo.wallarm.com/ubuntu/wallarm-node xenial/2.14/' > /etc/apt/sources.list.d/wallarm.list \u00b6 apt-get update \u00b6 {%- tab name=\"Ubuntu 18.04 LTS (bionic)\" -%} apt-key adv --keyserver keys.gnupg.net --recv-keys 72B865FD \u00b6 sh -c \"echo 'deb http://repo.wallarm.com/ubuntu/wallarm-node bionic/2.14/' >/etc/apt/sources.list.d/wallarm.list\" \u00b6 apt-get update \u00b6 {%- tab name=\"CentOS 6.x\" -%} yum install --enablerepo=extras -y epel-release centos-release-SCL \u00b6 rpm -i https://repo.wallarm.com/centos/wallarm-node/6/2.14/x86_64/Packages/wallarm-node-repo-1-4.el6.noarch.rpm \u00b6 {%- tab name=\"CentOS 7.x\" -%} yum install -y epel-release \u00b6 rpm -i https://repo.wallarm.com/centos/wallarm-node/7/2.14/x86_64/Packages/wallarm-node-repo-1-4.el7.noarch.rpm \u00b6 {%- endtermtabs %} Repository access Your system must have access to https://repo.wallarm.com to download the packages. Ensure the access is not blocked by a firewall. 2. Install Wallarm Packages \u00b6 To install the filter node and postanalytics on the same server, run the command: {% termtabs name=\"Debian 8.x (jessie)\" -%} apt-get install --no-install-recommends wallarm-node kong-module-wallarm \u00b6 {%- tab name=\"Debian 9.x (stretch)\" -%} apt-get install --no-install-recommends wallarm-node kong-module-wallarm \u00b6 {%- tab name=\"Ubuntu 14.04 LTS (trusty)\" -%} apt-get install --no-install-recommends wallarm-node kong-module-wallarm \u00b6 {%- tab name=\"Ubuntu 16.04 LTS (xenial)\" -%} apt-get install --no-install-recommends wallarm-node kong-module-wallarm \u00b6 {%- tab name=\"Ubuntu 18.04 LTS (bionic)\" -%} apt-get install --no-install-recommends wallarm-node kong-module-wallarm \u00b6 {%- tab name=\"CentOS 6.x\" -%} yum install wallarm-node kong-module-wallarm \u00b6 {%- tab name=\"CentOS 7.x\" -%} yum install wallarm-node kong-module-wallarm \u00b6 {%- endtermtabs %} To install the filter node alone, run the command: {% termtabs name=\"Debian 8.x (jessie)\" -%} apt-get install --no-install-recommends wallarm-node-nginx kong-module-wallarm \u00b6 {%- tab name=\"Debian 9.x (stretch)\" -%} apt-get install --no-install-recommends wallarm-node-nginx kong-module-wallarm \u00b6 {%- tab name=\"Ubuntu 14.04 LTS (trusty)\" -%} apt-get install --no-install-recommends wallarm-node-nginx kong-module-wallarm \u00b6 {%- tab name=\"Ubuntu 16.04 LTS (xenial)\" -%} apt-get install --no-install-recommends wallarm-node-nginx kong-module-wallarm \u00b6 {%- tab name=\"Ubuntu 18.04 LTS (bionic)\" -%} apt-get install --no-install-recommends wallarm-node-nginx kong-module-wallarm \u00b6 {%- tab name=\"CentOS 6.x\" -%} yum install wallarm-node-nginx kong-module-wallarm \u00b6 {%- tab name=\"CentOS 7.x\" -%} yum install wallarm-node-nginx kong-module-wallarm \u00b6 {%- endtermtabs %} 3. Configure Postanalytics \u00b6 #### Info:: Skip this step if you installed postanalytics on a separate server as you already have your postanalytics configured. The amount of memory determines the quality of work of the statistical algorithms. The recommended value is 75% of the total server memory. For example, if the server has 32 GB of memory, the recommended allocation size is 24 GB. Allocate the operating memory size for Tarantool: Open for editing the configuration file of Tarantool: {% termtabs name=\"Debian 8.x (jessie)\" -%} vi /etc/default/wallarm-tarantool \u00b6 {%- tab name=\"Debian 9.x (stretch)\" -%} vi /etc/default/wallarm-tarantool \u00b6 {%- tab name=\"Ubuntu 14.04 LTS (trusty)\" -%} vi /etc/default/wallarm-tarantool \u00b6 {%- tab name=\"Ubuntu 16.04 LTS (xenial)\" -%} vi /etc/default/wallarm-tarantool \u00b6 {%- tab name=\"Ubuntu 18.04 LTS (bionic)\" -%} vi /etc/default/wallarm-tarantool \u00b6 {%- tab name=\"CentOS 6.x\" -%} vi /etc/sysconfig/wallarm-tarantool \u00b6 {%- tab name=\"CentOS 7.x\" -%} vi /etc/sysconfig/wallarm-tarantool \u00b6 {%- endtermtabs %} Set the allocated memory size in the configuration file of Tarantool via the SLAB_ALLOC_ARENA directive. For example: SLAB_ALLOC_ARENA=24 Restart Tarantool: {% termtabs name=\"Debian 8.x (jessie)\" -%} systemctl restart wallarm-tarantool \u00b6 {%- tab name=\"Debian 9.x (stretch)\" -%} systemctl restart wallarm-tarantool \u00b6 {%- tab name=\"Ubuntu 14.04 LTS (trusty)\" -%} service wallarm-tarantool restart \u00b6 {%- tab name=\"Ubuntu 16.04 LTS (xenial)\" -%} service wallarm-tarantool restart \u00b6 {%- tab name=\"Ubuntu 18.04 LTS (bionic)\" -%} service wallarm-tarantool restart \u00b6 {%- tab name=\"CentOS 6.x\" -%} service wallarm-tarantool restart \u00b6 {%- tab name=\"CentOS 7.x\" -%} systemctl restart wallarm-tarantool \u00b6 {%- endtermtabs %} 4. Set up the Filter Node for Using a Proxy Server \u00b6 Info This setup step is intended for users who use their own proxy server for the operation of the protected web applications. If you do not use a proxy server, skip this step of the setup. You need to assign new values to the environment variables, which define the proxy server used, to configure Wallarm node for using your proxy server. Add new values of the environment variables to the /etc/environment file: Add https_proxy to define a proxy for the https protocol. Add http_proxy to define a proxy for the http protocol. Add no_proxy to define the list of the resources proxy should not be used for. Assign the <scheme>://<proxy_user>:<proxy_pass>@<host>:<port> string values to the https_proxy and http_proxy variables. <scheme> defines the protocol used. It should match the protocol that the current environment variable sets up proxy for. <proxy_user> defines the username for proxy authorization. <proxy_pass> defines the password for proxy authorization. <host> defines a host of the proxy server. <port> defines a port of the proxy server. Assign a \"<res_1>, <res_2>, <res_3>, <res_4>, ...\" array value, where <res_1> , <res_2> , <res_3> , and <res_4> are the IP addresses and/or domains, to the no_proxy variable to define a list of the resources which proxy should not be used for. This array should consist of IP addresses and/or domains. Resources that need to be addressed without a proxy Add the following IP addresses and domain to the list of the resources that have to be addressed without a proxy for the system to operate correctly: 127.0.0.1 , 127.0.0.8 , 127.0.0.9 , and localhost . The 127.0.0.8 and 127.0.0.9 IP addresses are used for the operation of the Wallarm filter node. The example of the correct /etc/environment file contents below demonstrates the following configuration: HTTPS and HTTP requests are proxied to the 1.2.3.4 host with the 1234 port, using the admin username and the 01234 password for authorization on the proxy server. Proxying is disabled for the requests sent to 127.0.0.1 , 127.0.0.8 , 127.0.0.9 , and localhost . https_proxy=http://admin:01234@1.2.3.4:1234 http_proxy=http://admin:01234@1.2.3.4:1234 no_proxy=\"127.0.0.1, 127.0.0.8, 127.0.0.9, localhost\" 5. Connect the Filter Node to the Wallarm Cloud \u00b6 API Access The API choice for your filter node depends on the Cloud you are using. Please, select the API accordingly: * If you are using https://my.wallarm.com/ , your node requires access to https://api.wallarm.com:444 . * If you are using https://us1.my.wallarm.com/ , your node requires access to https://us1.api.wallarm.com:444 . Ensure the access is not blocked by a firewall. The filter node interacts with the Wallarm cloud. To connect the node to the cloud using your cloud account requisites, proceed with the following steps: Make sure that your Wallarm account has the Administrator role enabled and two-factor authentication disabled, therefore allowing you to connect a filter node to the cloud. You can check the aforementioned parameters by navigating to the user account list in the Wallarm console. * If you are using <https://my.wallarm.com/>, proceed to the [following link][link-wl-console-users-eu] to check your user settings. * If you are using <https://us1.my.wallarm.com/>, proceed to the [following link][link-wl-console-users-us] to check your user settings. Run the addnode script in a system with the filter node: Info You have to pick the script to run depending on the Cloud you are using. * If you are using https://my.wallarm.com/ , run the script from the \u00abEU Cloud\u00bb tab below. * If you are using https://us1.my.wallarm.com/ , run the script from the \u00abUS Cloud\u00bb tab below. EU Cloud /usr/share/wallarm-common/addnode US Cloud /usr/share/wallarm-common/addnode -H us1.api.wallarm.com To specify the name of the created node, use the -n <node name> option. Provide your Wallarm account\u2019s login and password when prompted. 6. Configure the Postanalytics Server Addresses \u00b6 #### Info:: * Skip this step if you installed postanalytics and the filter node on the same server. * Do this step if you installed postanalytics and the filter node on separate servers. Add the server address of postanalytics to /etc/kong/nginx-wallarm.template : upstream wallarm_tarantool { server <ip1>:3313 max_fails=0 fail_timeout=0 max_conns=1; server <ip2>:3313 max_fails=0 fail_timeout=0 max_conns=1; keepalive 2; } ... wallarm_tarantool_upstream wallarm_tarantool; #### Warning:: Required conditions It is required that the following conditions are satisfied for the `max_conns` and the `keepalive` parameters: * The value of the `keepalive` parameter must not be lower than the number of the tarantool servers. * The value of the `max_conns` parameter must be specified for each of the upstream Tarantool servers to prevent the creation of excessive connections. 7. Set up the Filtration Mode \u00b6 The filtering and proxying rules are configured in the /etc/kong/nginx-wallarm.template file. To see detailed information about working with NGINX configuration files, proceed to the official NGINX documentation . Wallarm directives define the operation logic of the Wallarm filter node. To see the list of Wallarm directives available, proceed to the Wallarm configuration options page. A Configuration File Example \u00b6 Let us suppose that you need to configure the server to work in the following conditions: Only HTTP traffic is processed. There are no HTTPS requests processed. The following domains receive the requests: example.com and www.example.com . All requests must be passed to the server 10.80.0.5 . All incoming requests are considered less than 1MB in size (default setting). The processing of a request takes no more than 60 seconds (default setting). Wallarm must operate in the monitor mode. Clients access the filter node directly, without an intermediate HTTP load balancer. To meet the listed conditions, the contents of the configuration file must be the following: server { listen 80; listen [::]:80 ipv6only=on; # the domains for which traffic is processed server_name example.com; server_name www.example.com; # turn on the monitoring mode of traffic processing wallarm_mode monitoring; # wallarm_instance 1; location / { # setting the address for request forwarding proxy_pass http://10.80.0.5; proxy_set_header Host $host; proxy_set_header X-Real-IP $remote_addr; proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for; } } 8. Configure Logging \u00b6 Configure the filter node variables logging using NGINX. This will allow to perform a quick filter node diagnostics with the help of the NGINX log file. Start Kong \u00b6 To start Kong with the installed Wallarm module, run the command: # kong start --nginx-conf /etc/kong/nginx-wallarm.template The Installation Is Complete \u00b6 Check that the filter node runs and filters the traffic. See Check the filter node operation . #### Info:: Default Settings A freshly installed filter node operates in blocking mode (see the [`wallarm_mode`](../admin-en/configure-parameters-en.html#wallarmmode) directive description) by default. This may result in the inoperable [Wallarm scanner](../user-guides/cloud-ui/scanner/intro.md). If you plan to use the scanner, then you [need to perform additional actions](#adding-wallarm-scanner-addresses-to-the-whitelist) to render scanner operational. Additional Settings \u00b6 The filter node may require some additional configuration after installation. The document below lists a few of the typical setups that you can apply if needed. To get more information about other available settings, proceed to the \u201cConfiguration\u201d section of the Administrator\u2019s Guide . Configuring the Display of the Client's Real IP \u00b6 If the filter node is deployed behind a proxy server or load balancer without any additional configuration, the request source address may not be equal to the actual IP address of the client. Instead, it may be equal to one of the IP addresses of the proxy server or the load balancer. In this case, if you want the filter node to receive the client's IP address as a request source address, you need to perform an additional configuration of the proxy server or the load balancer. Adding Wallarm Scanner Addresses to the Whitelist \u00b6 The Wallarm scanner checks the resources of your company for vulnerabilities. Scanning is conducted using IP addresses from one of the following lists (depending on the type of Wallarm Cloud you are using): EU scanner addresses for EU Cloud users US scanner addresses for US Cloud users If you are using the Wallarm scanner, you need to configure the whitelists on your network scope security software (such as firewalls, intrusion detection systems, etc.) to contain Wallarm scanner IP addresses. For example, a Wallarm filter node with default settings is placed in the blocking mode, thus rendering the Wallarm scanner unable to scan the resources behind the filter node. To make the scanner operational again, whitelist the scanner's IP addresses on this filter node. Limiting the Single Request Processing Time \u00b6 Use the wallarm_process_time_limit Wallarm directive to specify the limit of the duration for processing a single request by the filter node. If processing the request consumes more time than specified in the directive, then the information on the error is entered into the log file and the request is marked as an overlimit_res attack. Limiting the Server Reply Waiting Time \u00b6 Use the proxy_read_timeout NGINX directive to specify the timeout for reading the proxy server reply. If the server sends nothing during this time, the connection is closed. Limiting the Maximum Request Size \u00b6 Use the client_max_body_size NGINX directive to specify the limit for the maximum size of the body of the client's request. If this limit is exceeded, NGINX replies to the client with the 413 ( Payload Too Large ) code, also known as the Request Entity Too Large message.","title":"Installing on the Kong Platform"},{"location":"en/admin-en/installation-kong-en/#installing-with-kong","text":"Prerequisites The Kong platform shall meet the following requirements: * Kong version 1.4.3 or lower * Kong installed on the platform supported by Wallarm according to Kong official instructions One of the following points is required for proper Kong operation: * prepared configuration files, * configured database. Please make sure that installed Kong meets the prerequisites before proceeding with Wallarm installation. The official Kong documentation is available by the link . Known Limitations The wallarm_block_page directive is not supported. Wallarm configuration via Kong Admin API is not supported.","title":"Installing with Kong"},{"location":"en/admin-en/installation-kong-en/#installation","text":"#### Warning:: Installation of postanalytics on a separate server If you are planning to install postanalytics on a separate server, you must install postanalytics first. See details in [Separate postanalytics installation][doc-postanalytics]. To install the Wallarm module with Kong, you need to: Add Wallarm repositories. Install Wallarm packages. Configure postanalytics. Set up the filter node for using a proxy server. Connect the filter node to the Wallarm cloud. Configure the postanalytics server addresses. Configure the filtration mode. Configure logging. Prerequisites Prior to taking any steps listed below, either disable or configure SELinux if it is installed on the operating system. Make sure that you execute all commands below as superuser (e.g. root ).","title":"Installation"},{"location":"en/admin-en/installation-kong-en/#1-add-wallarm-repositories","text":"The filter node installs and updates from the Wallarm repositories. Depending on your operating system, run one of the following commands: {% termtabs name=\"Debian 8.x (jessie)\" -%}","title":"1. Add Wallarm Repositories"},{"location":"en/admin-en/installation-kong-en/#apt-key-adv-keyserver-keysgnupgnet-recv-keys-72b865fd","text":"","title":"apt-key adv --keyserver keys.gnupg.net --recv-keys 72B865FD"},{"location":"en/admin-en/installation-kong-en/#echo-deb-httprepowallarmcomdebianwallarm-node-jessie214-etcaptsourceslistdwallarmlist","text":"","title":"echo 'deb http://repo.wallarm.com/debian/wallarm-node jessie/2.14/' &gt; /etc/apt/sources.list.d/wallarm.list"},{"location":"en/admin-en/installation-kong-en/#apt-get-update","text":"{%- tab name=\"Debian 9.x (stretch)\" -%}","title":"apt-get update"},{"location":"en/admin-en/installation-kong-en/#apt-get-install-dirmngr","text":"","title":"apt-get install dirmngr"},{"location":"en/admin-en/installation-kong-en/#apt-key-adv-keyserver-keysgnupgnet-recv-keys-72b865fd_1","text":"","title":"apt-key adv --keyserver keys.gnupg.net --recv-keys 72B865FD"},{"location":"en/admin-en/installation-kong-en/#sh-c-echo-deb-httprepowallarmcomdebianwallarm-node-stretch214-etcaptsourceslistdwallarmlist","text":"","title":"sh -c \"echo 'deb http://repo.wallarm.com/debian/wallarm-node stretch/2.14/' &gt; /etc/apt/sources.list.d/wallarm.list\""},{"location":"en/admin-en/installation-kong-en/#apt-get-update_1","text":"{%- tab name=\"Ubuntu 14.04 LTS (trusty)\" -%}","title":"apt-get update"},{"location":"en/admin-en/installation-kong-en/#apt-key-adv-keyserver-keysgnupgnet-recv-keys-72b865fd_2","text":"","title":"apt-key adv --keyserver keys.gnupg.net --recv-keys 72B865FD"},{"location":"en/admin-en/installation-kong-en/#echo-deb-httprepowallarmcomubuntuwallarm-node-trusty214-etcaptsourceslistdwallarmlist","text":"","title":"echo 'deb http://repo.wallarm.com/ubuntu/wallarm-node trusty/2.14/' &gt; /etc/apt/sources.list.d/wallarm.list"},{"location":"en/admin-en/installation-kong-en/#apt-get-update_2","text":"{%- tab name=\"Ubuntu 16.04 LTS (xenial)\" -%}","title":"apt-get update"},{"location":"en/admin-en/installation-kong-en/#apt-key-adv-keyserver-keysgnupgnet-recv-keys-72b865fd_3","text":"","title":"apt-key adv --keyserver keys.gnupg.net --recv-keys 72B865FD"},{"location":"en/admin-en/installation-kong-en/#echo-deb-httprepowallarmcomubuntuwallarm-node-xenial214-etcaptsourceslistdwallarmlist","text":"","title":"echo 'deb http://repo.wallarm.com/ubuntu/wallarm-node xenial/2.14/' &gt; /etc/apt/sources.list.d/wallarm.list"},{"location":"en/admin-en/installation-kong-en/#apt-get-update_3","text":"{%- tab name=\"Ubuntu 18.04 LTS (bionic)\" -%}","title":"apt-get update"},{"location":"en/admin-en/installation-kong-en/#apt-key-adv-keyserver-keysgnupgnet-recv-keys-72b865fd_4","text":"","title":"apt-key adv --keyserver keys.gnupg.net --recv-keys 72B865FD"},{"location":"en/admin-en/installation-kong-en/#sh-c-echo-deb-httprepowallarmcomubuntuwallarm-node-bionic214-etcaptsourceslistdwallarmlist","text":"","title":"sh -c \"echo 'deb http://repo.wallarm.com/ubuntu/wallarm-node bionic/2.14/' &gt;/etc/apt/sources.list.d/wallarm.list\""},{"location":"en/admin-en/installation-kong-en/#apt-get-update_4","text":"{%- tab name=\"CentOS 6.x\" -%}","title":"apt-get update"},{"location":"en/admin-en/installation-kong-en/#yum-install-enablerepoextras-y-epel-release-centos-release-scl","text":"","title":"yum install --enablerepo=extras -y epel-release centos-release-SCL"},{"location":"en/admin-en/installation-kong-en/#rpm-i-httpsrepowallarmcomcentoswallarm-node6214x86_64packageswallarm-node-repo-1-4el6noarchrpm","text":"{%- tab name=\"CentOS 7.x\" -%}","title":"rpm -i https://repo.wallarm.com/centos/wallarm-node/6/2.14/x86_64/Packages/wallarm-node-repo-1-4.el6.noarch.rpm"},{"location":"en/admin-en/installation-kong-en/#yum-install-y-epel-release","text":"","title":"yum install -y epel-release"},{"location":"en/admin-en/installation-kong-en/#rpm-i-httpsrepowallarmcomcentoswallarm-node7214x86_64packageswallarm-node-repo-1-4el7noarchrpm","text":"{%- endtermtabs %} Repository access Your system must have access to https://repo.wallarm.com to download the packages. Ensure the access is not blocked by a firewall.","title":"rpm -i https://repo.wallarm.com/centos/wallarm-node/7/2.14/x86_64/Packages/wallarm-node-repo-1-4.el7.noarch.rpm"},{"location":"en/admin-en/installation-kong-en/#2-install-wallarm-packages","text":"To install the filter node and postanalytics on the same server, run the command: {% termtabs name=\"Debian 8.x (jessie)\" -%}","title":"2. Install Wallarm Packages"},{"location":"en/admin-en/installation-kong-en/#apt-get-install-no-install-recommends-wallarm-node-kong-module-wallarm","text":"{%- tab name=\"Debian 9.x (stretch)\" -%}","title":"apt-get install --no-install-recommends wallarm-node kong-module-wallarm"},{"location":"en/admin-en/installation-kong-en/#apt-get-install-no-install-recommends-wallarm-node-kong-module-wallarm_1","text":"{%- tab name=\"Ubuntu 14.04 LTS (trusty)\" -%}","title":"apt-get install --no-install-recommends wallarm-node kong-module-wallarm"},{"location":"en/admin-en/installation-kong-en/#apt-get-install-no-install-recommends-wallarm-node-kong-module-wallarm_2","text":"{%- tab name=\"Ubuntu 16.04 LTS (xenial)\" -%}","title":"apt-get install --no-install-recommends wallarm-node kong-module-wallarm"},{"location":"en/admin-en/installation-kong-en/#apt-get-install-no-install-recommends-wallarm-node-kong-module-wallarm_3","text":"{%- tab name=\"Ubuntu 18.04 LTS (bionic)\" -%}","title":"apt-get install --no-install-recommends wallarm-node kong-module-wallarm"},{"location":"en/admin-en/installation-kong-en/#apt-get-install-no-install-recommends-wallarm-node-kong-module-wallarm_4","text":"{%- tab name=\"CentOS 6.x\" -%}","title":"apt-get install --no-install-recommends wallarm-node kong-module-wallarm"},{"location":"en/admin-en/installation-kong-en/#yum-install-wallarm-node-kong-module-wallarm","text":"{%- tab name=\"CentOS 7.x\" -%}","title":"yum install wallarm-node kong-module-wallarm"},{"location":"en/admin-en/installation-kong-en/#yum-install-wallarm-node-kong-module-wallarm_1","text":"{%- endtermtabs %} To install the filter node alone, run the command: {% termtabs name=\"Debian 8.x (jessie)\" -%}","title":"yum install wallarm-node kong-module-wallarm"},{"location":"en/admin-en/installation-kong-en/#apt-get-install-no-install-recommends-wallarm-node-nginx-kong-module-wallarm","text":"{%- tab name=\"Debian 9.x (stretch)\" -%}","title":"apt-get install --no-install-recommends wallarm-node-nginx kong-module-wallarm"},{"location":"en/admin-en/installation-kong-en/#apt-get-install-no-install-recommends-wallarm-node-nginx-kong-module-wallarm_1","text":"{%- tab name=\"Ubuntu 14.04 LTS (trusty)\" -%}","title":"apt-get install --no-install-recommends wallarm-node-nginx kong-module-wallarm"},{"location":"en/admin-en/installation-kong-en/#apt-get-install-no-install-recommends-wallarm-node-nginx-kong-module-wallarm_2","text":"{%- tab name=\"Ubuntu 16.04 LTS (xenial)\" -%}","title":"apt-get install --no-install-recommends wallarm-node-nginx kong-module-wallarm"},{"location":"en/admin-en/installation-kong-en/#apt-get-install-no-install-recommends-wallarm-node-nginx-kong-module-wallarm_3","text":"{%- tab name=\"Ubuntu 18.04 LTS (bionic)\" -%}","title":"apt-get install --no-install-recommends wallarm-node-nginx kong-module-wallarm"},{"location":"en/admin-en/installation-kong-en/#apt-get-install-no-install-recommends-wallarm-node-nginx-kong-module-wallarm_4","text":"{%- tab name=\"CentOS 6.x\" -%}","title":"apt-get install --no-install-recommends wallarm-node-nginx kong-module-wallarm"},{"location":"en/admin-en/installation-kong-en/#yum-install-wallarm-node-nginx-kong-module-wallarm","text":"{%- tab name=\"CentOS 7.x\" -%}","title":"yum install wallarm-node-nginx kong-module-wallarm"},{"location":"en/admin-en/installation-kong-en/#yum-install-wallarm-node-nginx-kong-module-wallarm_1","text":"{%- endtermtabs %}","title":"yum install wallarm-node-nginx kong-module-wallarm"},{"location":"en/admin-en/installation-kong-en/#3-configure-postanalytics","text":"#### Info:: Skip this step if you installed postanalytics on a separate server as you already have your postanalytics configured. The amount of memory determines the quality of work of the statistical algorithms. The recommended value is 75% of the total server memory. For example, if the server has 32 GB of memory, the recommended allocation size is 24 GB. Allocate the operating memory size for Tarantool: Open for editing the configuration file of Tarantool: {% termtabs name=\"Debian 8.x (jessie)\" -%}","title":"3. Configure Postanalytics"},{"location":"en/admin-en/installation-kong-en/#vi-etcdefaultwallarm-tarantool","text":"{%- tab name=\"Debian 9.x (stretch)\" -%}","title":"vi /etc/default/wallarm-tarantool"},{"location":"en/admin-en/installation-kong-en/#vi-etcdefaultwallarm-tarantool_1","text":"{%- tab name=\"Ubuntu 14.04 LTS (trusty)\" -%}","title":"vi /etc/default/wallarm-tarantool"},{"location":"en/admin-en/installation-kong-en/#vi-etcdefaultwallarm-tarantool_2","text":"{%- tab name=\"Ubuntu 16.04 LTS (xenial)\" -%}","title":"vi /etc/default/wallarm-tarantool"},{"location":"en/admin-en/installation-kong-en/#vi-etcdefaultwallarm-tarantool_3","text":"{%- tab name=\"Ubuntu 18.04 LTS (bionic)\" -%}","title":"vi /etc/default/wallarm-tarantool"},{"location":"en/admin-en/installation-kong-en/#vi-etcdefaultwallarm-tarantool_4","text":"{%- tab name=\"CentOS 6.x\" -%}","title":"vi /etc/default/wallarm-tarantool"},{"location":"en/admin-en/installation-kong-en/#vi-etcsysconfigwallarm-tarantool","text":"{%- tab name=\"CentOS 7.x\" -%}","title":"vi /etc/sysconfig/wallarm-tarantool"},{"location":"en/admin-en/installation-kong-en/#vi-etcsysconfigwallarm-tarantool_1","text":"{%- endtermtabs %} Set the allocated memory size in the configuration file of Tarantool via the SLAB_ALLOC_ARENA directive. For example: SLAB_ALLOC_ARENA=24 Restart Tarantool: {% termtabs name=\"Debian 8.x (jessie)\" -%}","title":"vi /etc/sysconfig/wallarm-tarantool"},{"location":"en/admin-en/installation-kong-en/#systemctl-restart-wallarm-tarantool","text":"{%- tab name=\"Debian 9.x (stretch)\" -%}","title":"systemctl restart wallarm-tarantool"},{"location":"en/admin-en/installation-kong-en/#systemctl-restart-wallarm-tarantool_1","text":"{%- tab name=\"Ubuntu 14.04 LTS (trusty)\" -%}","title":"systemctl restart wallarm-tarantool"},{"location":"en/admin-en/installation-kong-en/#service-wallarm-tarantool-restart","text":"{%- tab name=\"Ubuntu 16.04 LTS (xenial)\" -%}","title":"service wallarm-tarantool restart"},{"location":"en/admin-en/installation-kong-en/#service-wallarm-tarantool-restart_1","text":"{%- tab name=\"Ubuntu 18.04 LTS (bionic)\" -%}","title":"service wallarm-tarantool restart"},{"location":"en/admin-en/installation-kong-en/#service-wallarm-tarantool-restart_2","text":"{%- tab name=\"CentOS 6.x\" -%}","title":"service wallarm-tarantool restart"},{"location":"en/admin-en/installation-kong-en/#service-wallarm-tarantool-restart_3","text":"{%- tab name=\"CentOS 7.x\" -%}","title":"service wallarm-tarantool restart"},{"location":"en/admin-en/installation-kong-en/#systemctl-restart-wallarm-tarantool_2","text":"{%- endtermtabs %}","title":"systemctl restart wallarm-tarantool"},{"location":"en/admin-en/installation-kong-en/#4-set-up-the-filter-node-for-using-a-proxy-server","text":"Info This setup step is intended for users who use their own proxy server for the operation of the protected web applications. If you do not use a proxy server, skip this step of the setup. You need to assign new values to the environment variables, which define the proxy server used, to configure Wallarm node for using your proxy server. Add new values of the environment variables to the /etc/environment file: Add https_proxy to define a proxy for the https protocol. Add http_proxy to define a proxy for the http protocol. Add no_proxy to define the list of the resources proxy should not be used for. Assign the <scheme>://<proxy_user>:<proxy_pass>@<host>:<port> string values to the https_proxy and http_proxy variables. <scheme> defines the protocol used. It should match the protocol that the current environment variable sets up proxy for. <proxy_user> defines the username for proxy authorization. <proxy_pass> defines the password for proxy authorization. <host> defines a host of the proxy server. <port> defines a port of the proxy server. Assign a \"<res_1>, <res_2>, <res_3>, <res_4>, ...\" array value, where <res_1> , <res_2> , <res_3> , and <res_4> are the IP addresses and/or domains, to the no_proxy variable to define a list of the resources which proxy should not be used for. This array should consist of IP addresses and/or domains. Resources that need to be addressed without a proxy Add the following IP addresses and domain to the list of the resources that have to be addressed without a proxy for the system to operate correctly: 127.0.0.1 , 127.0.0.8 , 127.0.0.9 , and localhost . The 127.0.0.8 and 127.0.0.9 IP addresses are used for the operation of the Wallarm filter node. The example of the correct /etc/environment file contents below demonstrates the following configuration: HTTPS and HTTP requests are proxied to the 1.2.3.4 host with the 1234 port, using the admin username and the 01234 password for authorization on the proxy server. Proxying is disabled for the requests sent to 127.0.0.1 , 127.0.0.8 , 127.0.0.9 , and localhost . https_proxy=http://admin:01234@1.2.3.4:1234 http_proxy=http://admin:01234@1.2.3.4:1234 no_proxy=\"127.0.0.1, 127.0.0.8, 127.0.0.9, localhost\"","title":"4. Set up the Filter Node for Using a Proxy Server"},{"location":"en/admin-en/installation-kong-en/#5-connect-the-filter-node-to-the-wallarm-cloud","text":"API Access The API choice for your filter node depends on the Cloud you are using. Please, select the API accordingly: * If you are using https://my.wallarm.com/ , your node requires access to https://api.wallarm.com:444 . * If you are using https://us1.my.wallarm.com/ , your node requires access to https://us1.api.wallarm.com:444 . Ensure the access is not blocked by a firewall. The filter node interacts with the Wallarm cloud. To connect the node to the cloud using your cloud account requisites, proceed with the following steps: Make sure that your Wallarm account has the Administrator role enabled and two-factor authentication disabled, therefore allowing you to connect a filter node to the cloud. You can check the aforementioned parameters by navigating to the user account list in the Wallarm console. * If you are using <https://my.wallarm.com/>, proceed to the [following link][link-wl-console-users-eu] to check your user settings. * If you are using <https://us1.my.wallarm.com/>, proceed to the [following link][link-wl-console-users-us] to check your user settings. Run the addnode script in a system with the filter node: Info You have to pick the script to run depending on the Cloud you are using. * If you are using https://my.wallarm.com/ , run the script from the \u00abEU Cloud\u00bb tab below. * If you are using https://us1.my.wallarm.com/ , run the script from the \u00abUS Cloud\u00bb tab below. EU Cloud /usr/share/wallarm-common/addnode US Cloud /usr/share/wallarm-common/addnode -H us1.api.wallarm.com To specify the name of the created node, use the -n <node name> option. Provide your Wallarm account\u2019s login and password when prompted.","title":"5. Connect the Filter Node to the Wallarm Cloud"},{"location":"en/admin-en/installation-kong-en/#6-configure-the-postanalytics-server-addresses","text":"#### Info:: * Skip this step if you installed postanalytics and the filter node on the same server. * Do this step if you installed postanalytics and the filter node on separate servers. Add the server address of postanalytics to /etc/kong/nginx-wallarm.template : upstream wallarm_tarantool { server <ip1>:3313 max_fails=0 fail_timeout=0 max_conns=1; server <ip2>:3313 max_fails=0 fail_timeout=0 max_conns=1; keepalive 2; } ... wallarm_tarantool_upstream wallarm_tarantool; #### Warning:: Required conditions It is required that the following conditions are satisfied for the `max_conns` and the `keepalive` parameters: * The value of the `keepalive` parameter must not be lower than the number of the tarantool servers. * The value of the `max_conns` parameter must be specified for each of the upstream Tarantool servers to prevent the creation of excessive connections.","title":"6. Configure the Postanalytics Server Addresses"},{"location":"en/admin-en/installation-kong-en/#7-set-up-the-filtration-mode","text":"The filtering and proxying rules are configured in the /etc/kong/nginx-wallarm.template file. To see detailed information about working with NGINX configuration files, proceed to the official NGINX documentation . Wallarm directives define the operation logic of the Wallarm filter node. To see the list of Wallarm directives available, proceed to the Wallarm configuration options page.","title":"7. Set up the Filtration Mode"},{"location":"en/admin-en/installation-kong-en/#a-configuration-file-example","text":"Let us suppose that you need to configure the server to work in the following conditions: Only HTTP traffic is processed. There are no HTTPS requests processed. The following domains receive the requests: example.com and www.example.com . All requests must be passed to the server 10.80.0.5 . All incoming requests are considered less than 1MB in size (default setting). The processing of a request takes no more than 60 seconds (default setting). Wallarm must operate in the monitor mode. Clients access the filter node directly, without an intermediate HTTP load balancer. To meet the listed conditions, the contents of the configuration file must be the following: server { listen 80; listen [::]:80 ipv6only=on; # the domains for which traffic is processed server_name example.com; server_name www.example.com; # turn on the monitoring mode of traffic processing wallarm_mode monitoring; # wallarm_instance 1; location / { # setting the address for request forwarding proxy_pass http://10.80.0.5; proxy_set_header Host $host; proxy_set_header X-Real-IP $remote_addr; proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for; } }","title":"A Configuration File Example"},{"location":"en/admin-en/installation-kong-en/#8-configure-logging","text":"Configure the filter node variables logging using NGINX. This will allow to perform a quick filter node diagnostics with the help of the NGINX log file.","title":"8. Configure Logging"},{"location":"en/admin-en/installation-kong-en/#start-kong","text":"To start Kong with the installed Wallarm module, run the command: # kong start --nginx-conf /etc/kong/nginx-wallarm.template","title":"Start Kong"},{"location":"en/admin-en/installation-kong-en/#the-installation-is-complete","text":"Check that the filter node runs and filters the traffic. See Check the filter node operation . #### Info:: Default Settings A freshly installed filter node operates in blocking mode (see the [`wallarm_mode`](../admin-en/configure-parameters-en.html#wallarmmode) directive description) by default. This may result in the inoperable [Wallarm scanner](../user-guides/cloud-ui/scanner/intro.md). If you plan to use the scanner, then you [need to perform additional actions](#adding-wallarm-scanner-addresses-to-the-whitelist) to render scanner operational.","title":"The Installation Is Complete"},{"location":"en/admin-en/installation-kong-en/#additional-settings","text":"The filter node may require some additional configuration after installation. The document below lists a few of the typical setups that you can apply if needed. To get more information about other available settings, proceed to the \u201cConfiguration\u201d section of the Administrator\u2019s Guide .","title":"Additional Settings"},{"location":"en/admin-en/installation-kong-en/#configuring-the-display-of-the-clients-real-ip","text":"If the filter node is deployed behind a proxy server or load balancer without any additional configuration, the request source address may not be equal to the actual IP address of the client. Instead, it may be equal to one of the IP addresses of the proxy server or the load balancer. In this case, if you want the filter node to receive the client's IP address as a request source address, you need to perform an additional configuration of the proxy server or the load balancer.","title":"Configuring the Display of the Client's Real IP"},{"location":"en/admin-en/installation-kong-en/#adding-wallarm-scanner-addresses-to-the-whitelist","text":"The Wallarm scanner checks the resources of your company for vulnerabilities. Scanning is conducted using IP addresses from one of the following lists (depending on the type of Wallarm Cloud you are using): EU scanner addresses for EU Cloud users US scanner addresses for US Cloud users If you are using the Wallarm scanner, you need to configure the whitelists on your network scope security software (such as firewalls, intrusion detection systems, etc.) to contain Wallarm scanner IP addresses. For example, a Wallarm filter node with default settings is placed in the blocking mode, thus rendering the Wallarm scanner unable to scan the resources behind the filter node. To make the scanner operational again, whitelist the scanner's IP addresses on this filter node.","title":"Adding Wallarm Scanner Addresses to the Whitelist"},{"location":"en/admin-en/installation-kong-en/#limiting-the-single-request-processing-time","text":"Use the wallarm_process_time_limit Wallarm directive to specify the limit of the duration for processing a single request by the filter node. If processing the request consumes more time than specified in the directive, then the information on the error is entered into the log file and the request is marked as an overlimit_res attack.","title":"Limiting the Single Request Processing Time"},{"location":"en/admin-en/installation-kong-en/#limiting-the-server-reply-waiting-time","text":"Use the proxy_read_timeout NGINX directive to specify the timeout for reading the proxy server reply. If the server sends nothing during this time, the connection is closed.","title":"Limiting the Server Reply Waiting Time"},{"location":"en/admin-en/installation-kong-en/#limiting-the-maximum-request-size","text":"Use the client_max_body_size NGINX directive to specify the limit for the maximum size of the body of the client's request. If this limit is exceeded, NGINX replies to the client with the 413 ( Payload Too Large ) code, also known as the Request Entity Too Large message.","title":"Limiting the Maximum Request Size"},{"location":"en/admin-en/installation-kubernetes-en/","text":"Installation in the Kubernetes Cluster \u00b6 System Requirements Installation Configuration Known Restrictions System Requirements \u00b6 Kubernetes platform version 1.15 or lower Helm package manager Compatibility of your services with the official NGINX Ingress Controller See also\": What is Ingress? Installation of Helm Back to the table of contents \u25b2 Installation \u00b6 Install the Wallarm Ingress controller. Enable traffic analysis for your Ingress. Check the Wallarm Ingress controller operation. Step 1: Installing the Wallarm Ingress Controller \u00b6 Select the method of the controller installation: creation of a new controller, replacement of an existing controller. Creating a New Controller \u00b6 Go to your Wallarm account > the Nodes tab by the link below: * https://my.wallarm.com/nodes for the EU cloud, * https://us1.my.wallarm.com/nodes for the US cloud. Create the filter node with the Cloud type and copy the token. Clone the repository of Wallarm NGINX Ingress: term # git clone https://github.com/wallarm/ingress-chart Open the ingress-chart/wallarm-ingress/values.yaml file of the cloned repository and specify the following parameter values: wallarm.enabled: true wallarm.token: \"YOUR_CLOUD_NODE_TOKEN\" Go to the ingress-chart directory and install the Wallarm Ingress controller: term # cd .. # helm install INGRESS_CONTROLLER_NAME ingress-chart/wallarm-ingress -n KUBERNETES_NAMESPACE INGRESS_CONTROLLER_NAME is the name of the Wallarm Ingress controller, KUBERNETES_NAMESPACE is the namespace of your Ingress. Replacing an Existing Controller \u00b6 Go to your Wallarm account > the Nodes tab by the link below: * https://my.wallarm.com/nodes for the EU cloud, * https://us1.my.wallarm.com/nodes for the US cloud. Create the filter node with the Cloud type and copy the token. Clone the repository of Wallarm NGINX Ingress: term # git clone https://github.com/wallarm/ingress-chart Open the ingress-chart/wallarm-ingress/values.yaml file of the cloned repository and specify the following parameter values: wallarm.enabled: true wallarm.token: \"YOUR_CLOUD_NODE_TOKEN\" Replace an existing controller: # helm upgrade INGRESS_CONTROLLER_NAME KUBERNETES_NAMESPACE --reuse-values * INGRESS_CONTROLLER_NAME is the name of the Ingress controller to replace, * KUBERNETES_NAMESPACE is the namespace of your Ingress. Step 2: Enabling Traffic Analysis for Your Ingress \u00b6 # kubectl annotate ingress YOUR_INGRESS_NAME nginx.ingress.kubernetes.io/wallarm-mode=monitoring # kubectl annotate ingress YOUR_INGRESS_NAME nginx.ingress.kubernetes.io/wallarm-instance=INSTANCE YOUR_INGRESS_NAME is the name of your Ingress, INSTANCE is a positive number which is unique to each of your applications or application groups. This will allow you to obtain separate statistics and distinguish between the attacks aimed at corresponding applications. Step 3: Checking the Wallarm Ingress Controller Operation \u00b6 Get the list of pods specifying the name of the Wallarm Ingress controller in INGRESS_CONTROLLER_NAME : term # kubectl get po -l release=INGRESS_CONTROLLER_NAME Each pod should display the following: \"STATUS: Running\" and \"READY: N/N\". For example: NAME READY STATUS RESTARTS AGE ingress-controller-nginx-ingress-controller-675c68d46d-cfck8 3/3 Running 0 5m ingress-controller-nginx-ingress-controller-wallarm-tarantljj8g 8/8 Running 0 5m ingress-controller-nginx-ingress-default-backend-584ffc6c7xj5xx 1/1 Running 0 5m Send a test attack to your Ingress resource as described in this documentation . Go to your Wallarm account > the Events tab by the link below and check that an attack is displayed in the list: * https://my.wallarm.com for the EU cloud, * https://us1.my.wallarm.com for the US cloud. Back to the table of contents \u25b2 Configuration \u00b6 After the Wallarm Ingress controller is successfully installed and checked, you can make advanced configurations to the solution such as: enable blocking requests from particular IP addresses, set up the response code and page that are returned to the client when an invalid request has been blocked, enable WebSockets messages analyzing, etc. To find parameters used for advanced configuration and appropriate instructions, please follow the link . Back to the table of contents \u25b2 Known Restrictions \u00b6 IP blocking is not supported in Wallarm Node version 2.12 or lower. Operation without the postanalytics service is not supported. Scaling down postanalytics service may result in a partial loss of attack data. Back to the table of contents \u25b2","title":"Installing NGINX Ingress Controller with Integrated Wallarm Services"},{"location":"en/admin-en/installation-kubernetes-en/#installation-in-the-kubernetes-cluster","text":"System Requirements Installation Configuration Known Restrictions","title":"Installation in the Kubernetes Cluster"},{"location":"en/admin-en/installation-kubernetes-en/#system-requirements","text":"Kubernetes platform version 1.15 or lower Helm package manager Compatibility of your services with the official NGINX Ingress Controller See also\": What is Ingress? Installation of Helm Back to the table of contents \u25b2","title":"System Requirements"},{"location":"en/admin-en/installation-kubernetes-en/#installation","text":"Install the Wallarm Ingress controller. Enable traffic analysis for your Ingress. Check the Wallarm Ingress controller operation.","title":"Installation"},{"location":"en/admin-en/installation-kubernetes-en/#step-1-installing-the-wallarm-ingress-controller","text":"Select the method of the controller installation: creation of a new controller, replacement of an existing controller.","title":"Step 1: Installing the Wallarm Ingress Controller"},{"location":"en/admin-en/installation-kubernetes-en/#creating-a-new-controller","text":"Go to your Wallarm account > the Nodes tab by the link below: * https://my.wallarm.com/nodes for the EU cloud, * https://us1.my.wallarm.com/nodes for the US cloud. Create the filter node with the Cloud type and copy the token. Clone the repository of Wallarm NGINX Ingress: term # git clone https://github.com/wallarm/ingress-chart Open the ingress-chart/wallarm-ingress/values.yaml file of the cloned repository and specify the following parameter values: wallarm.enabled: true wallarm.token: \"YOUR_CLOUD_NODE_TOKEN\" Go to the ingress-chart directory and install the Wallarm Ingress controller: term # cd .. # helm install INGRESS_CONTROLLER_NAME ingress-chart/wallarm-ingress -n KUBERNETES_NAMESPACE INGRESS_CONTROLLER_NAME is the name of the Wallarm Ingress controller, KUBERNETES_NAMESPACE is the namespace of your Ingress.","title":"Creating a New Controller"},{"location":"en/admin-en/installation-kubernetes-en/#replacing-an-existing-controller","text":"Go to your Wallarm account > the Nodes tab by the link below: * https://my.wallarm.com/nodes for the EU cloud, * https://us1.my.wallarm.com/nodes for the US cloud. Create the filter node with the Cloud type and copy the token. Clone the repository of Wallarm NGINX Ingress: term # git clone https://github.com/wallarm/ingress-chart Open the ingress-chart/wallarm-ingress/values.yaml file of the cloned repository and specify the following parameter values: wallarm.enabled: true wallarm.token: \"YOUR_CLOUD_NODE_TOKEN\" Replace an existing controller: # helm upgrade INGRESS_CONTROLLER_NAME KUBERNETES_NAMESPACE --reuse-values * INGRESS_CONTROLLER_NAME is the name of the Ingress controller to replace, * KUBERNETES_NAMESPACE is the namespace of your Ingress.","title":"Replacing an Existing Controller"},{"location":"en/admin-en/installation-kubernetes-en/#step-2-enabling-traffic-analysis-for-your-ingress","text":"# kubectl annotate ingress YOUR_INGRESS_NAME nginx.ingress.kubernetes.io/wallarm-mode=monitoring # kubectl annotate ingress YOUR_INGRESS_NAME nginx.ingress.kubernetes.io/wallarm-instance=INSTANCE YOUR_INGRESS_NAME is the name of your Ingress, INSTANCE is a positive number which is unique to each of your applications or application groups. This will allow you to obtain separate statistics and distinguish between the attacks aimed at corresponding applications.","title":"Step 2: Enabling Traffic Analysis for Your Ingress"},{"location":"en/admin-en/installation-kubernetes-en/#step-3-checking-the-wallarm-ingress-controller-operation","text":"Get the list of pods specifying the name of the Wallarm Ingress controller in INGRESS_CONTROLLER_NAME : term # kubectl get po -l release=INGRESS_CONTROLLER_NAME Each pod should display the following: \"STATUS: Running\" and \"READY: N/N\". For example: NAME READY STATUS RESTARTS AGE ingress-controller-nginx-ingress-controller-675c68d46d-cfck8 3/3 Running 0 5m ingress-controller-nginx-ingress-controller-wallarm-tarantljj8g 8/8 Running 0 5m ingress-controller-nginx-ingress-default-backend-584ffc6c7xj5xx 1/1 Running 0 5m Send a test attack to your Ingress resource as described in this documentation . Go to your Wallarm account > the Events tab by the link below and check that an attack is displayed in the list: * https://my.wallarm.com for the EU cloud, * https://us1.my.wallarm.com for the US cloud. Back to the table of contents \u25b2","title":"Step 3: Checking the Wallarm Ingress Controller Operation"},{"location":"en/admin-en/installation-kubernetes-en/#configuration","text":"After the Wallarm Ingress controller is successfully installed and checked, you can make advanced configurations to the solution such as: enable blocking requests from particular IP addresses, set up the response code and page that are returned to the client when an invalid request has been blocked, enable WebSockets messages analyzing, etc. To find parameters used for advanced configuration and appropriate instructions, please follow the link . Back to the table of contents \u25b2","title":"Configuration"},{"location":"en/admin-en/installation-kubernetes-en/#known-restrictions","text":"IP blocking is not supported in Wallarm Node version 2.12 or lower. Operation without the postanalytics service is not supported. Scaling down postanalytics service may result in a partial loss of attack data. Back to the table of contents \u25b2","title":"Known Restrictions"},{"location":"en/admin-en/installation-linux-en/","text":"Installing on Linux \u00b6 #### Warning:: INSTRUCTIONS DEPRECATED These instructions are for the installation of legacy and unsupported packages. For the initial product installation, follow the [instruction for installing as a dynamic module for NGINX](installation-nginx-en.md). Installation Options \u00b6 The processing of requests in the filter node is done in two stages: Processing in NGINX-Wallarm. Postanalytics \u2013 statistical analysis of the processed requests. The processing is not memory demanding and can be put on front end servers without changing the server requirements. Postanalytics is memory demanding, which may require changes in the server configuration or installation of postanalytics on a separate server. Wallarm also has the option of installing postanalytics in a separate server pool. To install the filter node, you must: Add the Wallarm repositories, from which you will download packages. Install the Wallarm packages. Configure postanalytics. Set up the filter node for using a proxy server. Connect the filter node to the Wallarm cloud. Configure the server addresses of postanalytics. Configure the filtration mode. Restart the Wallarm service. Prerequisites Prior to taking any steps listed below, either disable or configure SELinux if it is installed on the operating system. Make sure that you execute all commands below as superuser (e.g. root ). 1. Add the Wallarm Repositories \u00b6 The installation and updating of the filter node is done from the Wallarm repositories. Depending on your operating system, run one of the commands: {% termtabs name=\"Debian 8.x (jessie)\" -%} apt-key adv --keyserver keys.gnupg.net --recv-keys 72B865FD \u00b6 echo 'deb http://repo.wallarm.com/debian/wallarm-node jessie/' >/etc/apt/sources.list.d/wallarm.list \u00b6 apt-get update \u00b6 {%- tab name=\"Debian 9.x (stretch)\" -%} apt-get install dirmngr \u00b6 apt-key adv --keyserver keys.gnupg.net --recv-keys 72B865FD \u00b6 sh -c \"echo 'deb http://repo.wallarm.com/debian/wallarm-node stretch/' >/etc/apt/sources.list.d/wallarm.list\" \u00b6 apt-get update \u00b6 {%- tab name=\"Ubuntu 14.04 LTS (trusty)\" -%} apt-key adv --keyserver keys.gnupg.net --recv-keys 72B865FD \u00b6 echo 'deb http://repo.wallarm.com/ubuntu/wallarm-node trusty/' >/etc/apt/sources.list.d/wallarm.list \u00b6 apt-get update \u00b6 {%- tab name=\"Ubuntu 16.04 LTS (xenial)\" -%} apt-key adv --keyserver keys.gnupg.net --recv-keys 72B865FD \u00b6 echo 'deb http://repo.wallarm.com/ubuntu/wallarm-node xenial/' >/etc/apt/sources.list.d/wallarm.list \u00b6 apt-get update \u00b6 {%- tab name=\"Ubuntu 18.04 LTS (bionic)\" -%} apt-key adv --keyserver keys.gnupg.net --recv-keys 72B865FD \u00b6 sh -c \"echo 'deb http://repo.wallarm.com/ubuntu/wallarm-node bionic/' >/etc/apt/sources.list.d/wallarm.list\" \u00b6 apt-get update \u00b6 {%- tab name=\"CentOS 7.x\" -%} yum install -y epel-release \u00b6 rpm -i https://repo.wallarm.com/centos/wallarm-node/7/x86_64/Packages/wallarm-node-repo-1-2.el7.centos.noarch.rpm \u00b6 {%- endtermtabs %} Repository access Your system must have access to https://repo.wallarm.com to download the packages. Ensure the access is not blocked by a firewall. 2. Install the Wallarm Packages \u00b6 Note If these packages are installed, a monolithic version of the filter node will result. The Wallarm filter module will be integrated with and inseparable from NGINX. To install the filter node and postanalytics on the same server, run the command: {% termtabs name=\"Debian 8.x (jessie)\" -%} apt-get install --no-install-recommends wallarm-node=2.10.4 nginx-wallarm wallarm-node-nginx=2.10.4 wallarm-node-tarantool=2.10.4 wallarm-common=2.10.4 wallarm-monitoring=2.10.4 ruby-proton=2.10.13 ruby-wallarm-api=2.10.4 \u00b6 {%- tab name=\"Debian 9.x (stretch)\" -%} apt-get install --no-install-recommends wallarm-node=2.10.4 nginx-wallarm wallarm-node-nginx=2.10.4 wallarm-node-tarantool=2.10.4 wallarm-common=2.10.4 wallarm-monitoring=2.10.4 ruby-proton=2.10.13 ruby-wallarm-api=2.10.4 \u00b6 {%- tab name=\"Ubuntu 14.04 LTS (trusty)\" -%} apt-get install --no-install-recommends wallarm-node=2.10.4 nginx-wallarm wallarm-node-nginx=2.10.4 wallarm-node-tarantool=2.10.4 wallarm-common=2.10.4 wallarm-monitoring=2.10.4 ruby-proton=2.10.13 ruby-wallarm-api=2.10.4 \u00b6 {%- tab name=\"Ubuntu 16.04 LTS (xenial)\" -%} apt-get install --no-install-recommends wallarm-node=2.10.4 nginx-wallarm wallarm-node-nginx=2.10.4 wallarm-node-tarantool=2.10.4 wallarm-common=2.10.4 wallarm-monitoring=2.10.4 ruby-proton=2.10.13 ruby-wallarm-api=2.10.4 \u00b6 {%- tab name=\"Ubuntu 18.04 LTS (bionic)\" -%} apt-get install --no-install-recommends wallarm-node=2.10.4 nginx-wallarm wallarm-node-nginx=2.10.4 wallarm-node-tarantool=2.10.4 wallarm-common=2.10.4 wallarm-monitoring=2.10.4 ruby-proton=2.10.13 ruby-wallarm-api=2.10.4 \u00b6 {%- tab name=\"CentOS 7.x\" -%} yum install libproton210-2.10.4 ruby-proton-2.10.4 nginx-wallarm-2.10.4 wallarm-node-2.10.4 \u00b6 {%- endtermtabs %} 3. Configure Postanalytics \u00b6 #### Info:: Skip this step if you installed postanalytics on a separate server as you already have your postanalytics configured. Postanalytics uses the in-memory storage Tarantool. You must set the amount of server RAM allocated to Tarantool. The amount of memory determines the quality of work of the statistical algorithms. The recommended value is 75% of the total server memory. For example, if the server has 32 GB of memory, the recommended allocation size is 24 GB. Allocate the operating memory size for Tarantool: Open for editing the configuration file of Tarantool: {% termtabs name=\"Debian 8.x (jessie)\" -%} vi /etc/default/wallarm-tarantool \u00b6 {%- tab name=\"Debian 9.x (stretch)\" -%} vi /etc/default/wallarm-tarantool \u00b6 {%- tab name=\"Ubuntu 14.04 LTS (trusty)\" -%} vi /etc/default/wallarm-tarantool \u00b6 {%- tab name=\"Ubuntu 16.04 LTS (xenial)\" -%} vi /etc/default/wallarm-tarantool \u00b6 {%- tab name=\"Ubuntu 18.04 LTS (bionic)\" -%} vi /etc/default/wallarm-tarantool \u00b6 {%- tab name=\"CentOS 7.x\" -%} vi /etc/sysconfig/wallarm-tarantool \u00b6 {%- endtermtabs %} Set the allocated memory size in the configuration file of Tarantool via the SLAB_ALLOC_ARENA directive. For example: SLAB_ALLOC_ARENA=24 Restart Tarantool: {% termtabs name=\"Debian 8.x (jessie)\" -%} systemctl restart wallarm-tarantool \u00b6 {%- tab name=\"Debian 9.x (stretch)\" -%} systemctl restart wallarm-tarantool \u00b6 {%- tab name=\"Ubuntu 14.04 LTS (trusty)\" -%} service wallarm-tarantool restart \u00b6 {%- tab name=\"Ubuntu 16.04 LTS (xenial)\" -%} service wallarm-tarantool restart \u00b6 {%- tab name=\"Ubuntu 18.04 LTS (bionic)\" -%} service wallarm-tarantool restart \u00b6 {%- tab name=\"CentOS 7.x\" -%} systemctl restart wallarm-tarantool \u00b6 {%- endtermtabs %} 4. Set up the Filter Node for Using a Proxy Server \u00b6 Info This setup step is intended for users who use their own proxy server for the operation of the protected web applications. If you do not use a proxy server, skip this step of the setup. You need to assign new values to the environment variables, which define the proxy server used, to configure Wallarm node for using your proxy server. Add new values of the environment variables to the /etc/environment file: Add https_proxy to define a proxy for the https protocol. Add http_proxy to define a proxy for the http protocol. Add no_proxy to define the list of the resources proxy should not be used for. Assign the <scheme>://<proxy_user>:<proxy_pass>@<host>:<port> string values to the https_proxy and http_proxy variables. <scheme> defines the protocol used. It should match the protocol that the current environment variable sets up proxy for. <proxy_user> defines the username for proxy authorization. <proxy_pass> defines the password for proxy authorization. <host> defines a host of the proxy server. <port> defines a port of the proxy server. Assign a \"<res_1>, <res_2>, <res_3>, <res_4>, ...\" array value, where <res_1> , <res_2> , <res_3> , and <res_4> are the IP addresses and/or domains, to the no_proxy variable to define a list of the resources which proxy should not be used for. This array should consist of IP addresses and/or domains. Resources that need to be addressed without a proxy Add the following IP addresses and domain to the list of the resources that have to be addressed without a proxy for the system to operate correctly: 127.0.0.1 , 127.0.0.8 , 127.0.0.9 , and localhost . The 127.0.0.8 and 127.0.0.9 IP addresses are used for the operation of the Wallarm filter node. The example of the correct /etc/environment file contents below demonstrates the following configuration: HTTPS and HTTP requests are proxied to the 1.2.3.4 host with the 1234 port, using the admin username and the 01234 password for authorization on the proxy server. Proxying is disabled for the requests sent to 127.0.0.1 , 127.0.0.8 , 127.0.0.9 , and localhost . https_proxy=http://admin:01234@1.2.3.4:1234 http_proxy=http://admin:01234@1.2.3.4:1234 no_proxy=\"127.0.0.1, 127.0.0.8, 127.0.0.9, localhost\" 5. Connect the Filter Node to the Wallarm Cloud \u00b6 API Access The API choice for your filter node depends on the Cloud you are using. Please, select the API accordingly: * If you are using https://my.wallarm.com/ , your node requires access to https://api.wallarm.com:444 . * If you are using https://us1.my.wallarm.com/ , your node requires access to https://us1.api.wallarm.com:444 . Ensure the access is not blocked by a firewall. The filter node interacts with the Wallarm cloud. To connect the node to the cloud using your cloud account requisites, proceed with the following steps: Make sure that your Wallarm account has the Administrator role enabled and two-factor authentication disabled, therefore allowing you to connect a filter node to the cloud. You can check the aforementioned parameters by navigating to the user account list in the Wallarm console. * If you are using <https://my.wallarm.com/>, proceed to the [following link][link-wl-console-users-eu] to check your user settings. * If you are using <https://us1.my.wallarm.com/>, proceed to the [following link][link-wl-console-users-us] to check your user settings. Run the addnode script in a system with the filter node: Info You have to pick the script to run depending on the Cloud you are using. * If you are using https://my.wallarm.com/ , run the script from the \u00abEU Cloud\u00bb tab below. * If you are using https://us1.my.wallarm.com/ , run the script from the \u00abUS Cloud\u00bb tab below. EU Cloud /usr/share/wallarm-common/addnode US Cloud /usr/share/wallarm-common/addnode -H us1.api.wallarm.com To specify the name of the created node, use the -n <node name> option. Provide your Wallarm account\u2019s login and password when prompted. 6. Configure the Server Addresses of Postanalytics \u00b6 #### Info:: * Skip this step if you installed postanalytics and the filter node on the same server. * Do this step if you installed postanalytics and the filter node on separate servers. Add the server address of postanalytics to /etc/nginx-wallarm/conf.d/wallarm.conf : upstream wallarm_tarantool { server <ip1>:3313 max_fails=0 fail_timeout=0 max_conns=1; server <ip2>:3313 max_fails=0 fail_timeout=0 max_conns=1; keepalive 2; } ... wallarm_tarantool_upstream wallarm_tarantool; #### Warning:: Required conditions It is required that the following conditions are satisfied for the `max_conns` and the `keepalive` parameters: * The value of the `keepalive` parameter must not be lower than the number of the tarantool servers. * The value of the `max_conns` parameter must be specified for each of the upstream Tarantool servers to prevent the creation of excessive connections. 7. Configure the Filtration Mode \u00b6 The filtering and proxying rules are configured in the /etc/nginx-wallarm/conf.d/wallarm.conf file. You can create your own configuration files to define the operation of NGINX-Wallarm. It is recommended to create a separate configuration file with the server block for each group of the domains that should be processed in the same way. To see detailed information about configuring NGINX-Wallarm, proceed to the official NGINX documentation . Wallarm directives define the operation logic of the Wallarm filter node. To see the list of Wallarm directives available, proceed to the Wallarm configuration options page. A Configuration File Example \u00b6 Let us suppose that you need to configure the server to work in the following conditions: Only HTTP traffic is processed. There are no HTTPS requests processed. The following domains receive the requests: example.com and www.example.com . All requests must be passed to the server 10.80.0.5 . All incoming requests are considered less than 1MB in size (default setting). The processing of a request takes no more than 60 seconds (default setting). Wallarm must operate in the monitor mode. Clients access the filter node directly, without an intermediate HTTP load balancer. Creating a configuration file You can create a custom NGINX-Wallarm configuration file (e.g. example.com.conf ) or modify the default NGINX-Wallarm configuration file ( default.conf ). When creating a custom configuration file, make sure that NGINX-Wallarm listens to the incoming connections on the free port. To meet the listed conditions, the contents of the configuration file must be the following: server { listen 80; listen [::]:80 ipv6only=on; # the domains for which traffic is processed server_name example.com; server_name www.example.com; # turn on the monitoring mode of traffic processing wallarm_mode monitoring; # wallarm_instance 1; location / { # setting the address for request forwarding proxy_pass http://10.80.0.5; proxy_set_header Host $host; proxy_set_header X-Real-IP $remote_addr; proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for; } } 8. Restart the Wallarm Service \u00b6 {% termtabs name=\"Debian 8.x (jessie)\" -%} systemctl restart nginx-wallarm \u00b6 {%- tab name=\"Debian 9.x (stretch)\" -%} systemctl restart nginx-wallarm \u00b6 {%- tab name=\"Ubuntu 14.04 LTS (trusty)\" -%} service nginx-wallarm restart \u00b6 {%- tab name=\"Ubuntu 16.04 LTS (xenial)\" -%} service nginx-wallarm restart \u00b6 {%- tab name=\"Ubuntu 18.04 LTS (bionic)\" -%} service nginx-wallarm restart \u00b6 {%- tab name=\"CentOS 7.x\" -%} systemctl restart nginx-wallarm \u00b6 {%- endtermtabs %} The Installation Is Complete \u00b6 Check that the filter node runs and filters the traffic. See Check the filter node operation .","title":"Installing on Linux [DEPRECATED]"},{"location":"en/admin-en/installation-linux-en/#installing-on-linux","text":"#### Warning:: INSTRUCTIONS DEPRECATED These instructions are for the installation of legacy and unsupported packages. For the initial product installation, follow the [instruction for installing as a dynamic module for NGINX](installation-nginx-en.md).","title":"Installing on Linux"},{"location":"en/admin-en/installation-linux-en/#installation-options","text":"The processing of requests in the filter node is done in two stages: Processing in NGINX-Wallarm. Postanalytics \u2013 statistical analysis of the processed requests. The processing is not memory demanding and can be put on front end servers without changing the server requirements. Postanalytics is memory demanding, which may require changes in the server configuration or installation of postanalytics on a separate server. Wallarm also has the option of installing postanalytics in a separate server pool. To install the filter node, you must: Add the Wallarm repositories, from which you will download packages. Install the Wallarm packages. Configure postanalytics. Set up the filter node for using a proxy server. Connect the filter node to the Wallarm cloud. Configure the server addresses of postanalytics. Configure the filtration mode. Restart the Wallarm service. Prerequisites Prior to taking any steps listed below, either disable or configure SELinux if it is installed on the operating system. Make sure that you execute all commands below as superuser (e.g. root ).","title":"Installation Options"},{"location":"en/admin-en/installation-linux-en/#1-add-the-wallarm-repositories","text":"The installation and updating of the filter node is done from the Wallarm repositories. Depending on your operating system, run one of the commands: {% termtabs name=\"Debian 8.x (jessie)\" -%}","title":"1. Add the Wallarm Repositories"},{"location":"en/admin-en/installation-linux-en/#apt-key-adv-keyserver-keysgnupgnet-recv-keys-72b865fd","text":"","title":"apt-key adv --keyserver keys.gnupg.net --recv-keys 72B865FD"},{"location":"en/admin-en/installation-linux-en/#echo-deb-httprepowallarmcomdebianwallarm-node-jessie-etcaptsourceslistdwallarmlist","text":"","title":"echo 'deb http://repo.wallarm.com/debian/wallarm-node jessie/' &gt;/etc/apt/sources.list.d/wallarm.list"},{"location":"en/admin-en/installation-linux-en/#apt-get-update","text":"{%- tab name=\"Debian 9.x (stretch)\" -%}","title":"apt-get update"},{"location":"en/admin-en/installation-linux-en/#apt-get-install-dirmngr","text":"","title":"apt-get install dirmngr"},{"location":"en/admin-en/installation-linux-en/#apt-key-adv-keyserver-keysgnupgnet-recv-keys-72b865fd_1","text":"","title":"apt-key adv --keyserver keys.gnupg.net --recv-keys 72B865FD"},{"location":"en/admin-en/installation-linux-en/#sh-c-echo-deb-httprepowallarmcomdebianwallarm-node-stretch-etcaptsourceslistdwallarmlist","text":"","title":"sh -c \"echo 'deb http://repo.wallarm.com/debian/wallarm-node stretch/' &gt;/etc/apt/sources.list.d/wallarm.list\""},{"location":"en/admin-en/installation-linux-en/#apt-get-update_1","text":"{%- tab name=\"Ubuntu 14.04 LTS (trusty)\" -%}","title":"apt-get update"},{"location":"en/admin-en/installation-linux-en/#apt-key-adv-keyserver-keysgnupgnet-recv-keys-72b865fd_2","text":"","title":"apt-key adv --keyserver keys.gnupg.net --recv-keys 72B865FD"},{"location":"en/admin-en/installation-linux-en/#echo-deb-httprepowallarmcomubuntuwallarm-node-trusty-etcaptsourceslistdwallarmlist","text":"","title":"echo 'deb http://repo.wallarm.com/ubuntu/wallarm-node trusty/' &gt;/etc/apt/sources.list.d/wallarm.list"},{"location":"en/admin-en/installation-linux-en/#apt-get-update_2","text":"{%- tab name=\"Ubuntu 16.04 LTS (xenial)\" -%}","title":"apt-get update"},{"location":"en/admin-en/installation-linux-en/#apt-key-adv-keyserver-keysgnupgnet-recv-keys-72b865fd_3","text":"","title":"apt-key adv --keyserver keys.gnupg.net --recv-keys 72B865FD"},{"location":"en/admin-en/installation-linux-en/#echo-deb-httprepowallarmcomubuntuwallarm-node-xenial-etcaptsourceslistdwallarmlist","text":"","title":"echo 'deb http://repo.wallarm.com/ubuntu/wallarm-node xenial/' &gt;/etc/apt/sources.list.d/wallarm.list"},{"location":"en/admin-en/installation-linux-en/#apt-get-update_3","text":"{%- tab name=\"Ubuntu 18.04 LTS (bionic)\" -%}","title":"apt-get update"},{"location":"en/admin-en/installation-linux-en/#apt-key-adv-keyserver-keysgnupgnet-recv-keys-72b865fd_4","text":"","title":"apt-key adv --keyserver keys.gnupg.net --recv-keys 72B865FD"},{"location":"en/admin-en/installation-linux-en/#sh-c-echo-deb-httprepowallarmcomubuntuwallarm-node-bionic-etcaptsourceslistdwallarmlist","text":"","title":"sh -c \"echo 'deb http://repo.wallarm.com/ubuntu/wallarm-node bionic/' &gt;/etc/apt/sources.list.d/wallarm.list\""},{"location":"en/admin-en/installation-linux-en/#apt-get-update_4","text":"{%- tab name=\"CentOS 7.x\" -%}","title":"apt-get update"},{"location":"en/admin-en/installation-linux-en/#yum-install-y-epel-release","text":"","title":"yum install -y epel-release"},{"location":"en/admin-en/installation-linux-en/#rpm-i-httpsrepowallarmcomcentoswallarm-node7x86_64packageswallarm-node-repo-1-2el7centosnoarchrpm","text":"{%- endtermtabs %} Repository access Your system must have access to https://repo.wallarm.com to download the packages. Ensure the access is not blocked by a firewall.","title":"rpm -i https://repo.wallarm.com/centos/wallarm-node/7/x86_64/Packages/wallarm-node-repo-1-2.el7.centos.noarch.rpm"},{"location":"en/admin-en/installation-linux-en/#2-install-the-wallarm-packages","text":"Note If these packages are installed, a monolithic version of the filter node will result. The Wallarm filter module will be integrated with and inseparable from NGINX. To install the filter node and postanalytics on the same server, run the command: {% termtabs name=\"Debian 8.x (jessie)\" -%}","title":"2. Install the Wallarm Packages"},{"location":"en/admin-en/installation-linux-en/#apt-get-install-no-install-recommends-wallarm-node2104-nginx-wallarm-wallarm-node-nginx2104-wallarm-node-tarantool2104-wallarm-common2104-wallarm-monitoring2104-ruby-proton21013-ruby-wallarm-api2104","text":"{%- tab name=\"Debian 9.x (stretch)\" -%}","title":"apt-get install --no-install-recommends wallarm-node=2.10.4 nginx-wallarm wallarm-node-nginx=2.10.4 wallarm-node-tarantool=2.10.4  wallarm-common=2.10.4 wallarm-monitoring=2.10.4 ruby-proton=2.10.13 ruby-wallarm-api=2.10.4"},{"location":"en/admin-en/installation-linux-en/#apt-get-install-no-install-recommends-wallarm-node2104-nginx-wallarm-wallarm-node-nginx2104-wallarm-node-tarantool2104-wallarm-common2104-wallarm-monitoring2104-ruby-proton21013-ruby-wallarm-api2104_1","text":"{%- tab name=\"Ubuntu 14.04 LTS (trusty)\" -%}","title":"apt-get install --no-install-recommends wallarm-node=2.10.4 nginx-wallarm wallarm-node-nginx=2.10.4 wallarm-node-tarantool=2.10.4  wallarm-common=2.10.4 wallarm-monitoring=2.10.4 ruby-proton=2.10.13 ruby-wallarm-api=2.10.4"},{"location":"en/admin-en/installation-linux-en/#apt-get-install-no-install-recommends-wallarm-node2104-nginx-wallarm-wallarm-node-nginx2104-wallarm-node-tarantool2104-wallarm-common2104-wallarm-monitoring2104-ruby-proton21013-ruby-wallarm-api2104_2","text":"{%- tab name=\"Ubuntu 16.04 LTS (xenial)\" -%}","title":"apt-get install --no-install-recommends wallarm-node=2.10.4 nginx-wallarm wallarm-node-nginx=2.10.4 wallarm-node-tarantool=2.10.4  wallarm-common=2.10.4 wallarm-monitoring=2.10.4 ruby-proton=2.10.13 ruby-wallarm-api=2.10.4"},{"location":"en/admin-en/installation-linux-en/#apt-get-install-no-install-recommends-wallarm-node2104-nginx-wallarm-wallarm-node-nginx2104-wallarm-node-tarantool2104-wallarm-common2104-wallarm-monitoring2104-ruby-proton21013-ruby-wallarm-api2104_3","text":"{%- tab name=\"Ubuntu 18.04 LTS (bionic)\" -%}","title":"apt-get install --no-install-recommends wallarm-node=2.10.4 nginx-wallarm wallarm-node-nginx=2.10.4 wallarm-node-tarantool=2.10.4  wallarm-common=2.10.4 wallarm-monitoring=2.10.4 ruby-proton=2.10.13 ruby-wallarm-api=2.10.4"},{"location":"en/admin-en/installation-linux-en/#apt-get-install-no-install-recommends-wallarm-node2104-nginx-wallarm-wallarm-node-nginx2104-wallarm-node-tarantool2104-wallarm-common2104-wallarm-monitoring2104-ruby-proton21013-ruby-wallarm-api2104_4","text":"{%- tab name=\"CentOS 7.x\" -%}","title":"apt-get install --no-install-recommends wallarm-node=2.10.4 nginx-wallarm wallarm-node-nginx=2.10.4 wallarm-node-tarantool=2.10.4  wallarm-common=2.10.4 wallarm-monitoring=2.10.4 ruby-proton=2.10.13 ruby-wallarm-api=2.10.4"},{"location":"en/admin-en/installation-linux-en/#yum-install-libproton210-2104-ruby-proton-2104-nginx-wallarm-2104-wallarm-node-2104","text":"{%- endtermtabs %}","title":"yum install libproton210-2.10.4 ruby-proton-2.10.4 nginx-wallarm-2.10.4 wallarm-node-2.10.4"},{"location":"en/admin-en/installation-linux-en/#3-configure-postanalytics","text":"#### Info:: Skip this step if you installed postanalytics on a separate server as you already have your postanalytics configured. Postanalytics uses the in-memory storage Tarantool. You must set the amount of server RAM allocated to Tarantool. The amount of memory determines the quality of work of the statistical algorithms. The recommended value is 75% of the total server memory. For example, if the server has 32 GB of memory, the recommended allocation size is 24 GB. Allocate the operating memory size for Tarantool: Open for editing the configuration file of Tarantool: {% termtabs name=\"Debian 8.x (jessie)\" -%}","title":"3. Configure Postanalytics"},{"location":"en/admin-en/installation-linux-en/#vi-etcdefaultwallarm-tarantool","text":"{%- tab name=\"Debian 9.x (stretch)\" -%}","title":"vi /etc/default/wallarm-tarantool"},{"location":"en/admin-en/installation-linux-en/#vi-etcdefaultwallarm-tarantool_1","text":"{%- tab name=\"Ubuntu 14.04 LTS (trusty)\" -%}","title":"vi /etc/default/wallarm-tarantool"},{"location":"en/admin-en/installation-linux-en/#vi-etcdefaultwallarm-tarantool_2","text":"{%- tab name=\"Ubuntu 16.04 LTS (xenial)\" -%}","title":"vi /etc/default/wallarm-tarantool"},{"location":"en/admin-en/installation-linux-en/#vi-etcdefaultwallarm-tarantool_3","text":"{%- tab name=\"Ubuntu 18.04 LTS (bionic)\" -%}","title":"vi /etc/default/wallarm-tarantool"},{"location":"en/admin-en/installation-linux-en/#vi-etcdefaultwallarm-tarantool_4","text":"{%- tab name=\"CentOS 7.x\" -%}","title":"vi /etc/default/wallarm-tarantool"},{"location":"en/admin-en/installation-linux-en/#vi-etcsysconfigwallarm-tarantool","text":"{%- endtermtabs %} Set the allocated memory size in the configuration file of Tarantool via the SLAB_ALLOC_ARENA directive. For example: SLAB_ALLOC_ARENA=24 Restart Tarantool: {% termtabs name=\"Debian 8.x (jessie)\" -%}","title":"vi /etc/sysconfig/wallarm-tarantool"},{"location":"en/admin-en/installation-linux-en/#systemctl-restart-wallarm-tarantool","text":"{%- tab name=\"Debian 9.x (stretch)\" -%}","title":"systemctl restart wallarm-tarantool"},{"location":"en/admin-en/installation-linux-en/#systemctl-restart-wallarm-tarantool_1","text":"{%- tab name=\"Ubuntu 14.04 LTS (trusty)\" -%}","title":"systemctl restart wallarm-tarantool"},{"location":"en/admin-en/installation-linux-en/#service-wallarm-tarantool-restart","text":"{%- tab name=\"Ubuntu 16.04 LTS (xenial)\" -%}","title":"service wallarm-tarantool restart"},{"location":"en/admin-en/installation-linux-en/#service-wallarm-tarantool-restart_1","text":"{%- tab name=\"Ubuntu 18.04 LTS (bionic)\" -%}","title":"service wallarm-tarantool restart"},{"location":"en/admin-en/installation-linux-en/#service-wallarm-tarantool-restart_2","text":"{%- tab name=\"CentOS 7.x\" -%}","title":"service wallarm-tarantool restart"},{"location":"en/admin-en/installation-linux-en/#systemctl-restart-wallarm-tarantool_2","text":"{%- endtermtabs %}","title":"systemctl restart wallarm-tarantool"},{"location":"en/admin-en/installation-linux-en/#4-set-up-the-filter-node-for-using-a-proxy-server","text":"Info This setup step is intended for users who use their own proxy server for the operation of the protected web applications. If you do not use a proxy server, skip this step of the setup. You need to assign new values to the environment variables, which define the proxy server used, to configure Wallarm node for using your proxy server. Add new values of the environment variables to the /etc/environment file: Add https_proxy to define a proxy for the https protocol. Add http_proxy to define a proxy for the http protocol. Add no_proxy to define the list of the resources proxy should not be used for. Assign the <scheme>://<proxy_user>:<proxy_pass>@<host>:<port> string values to the https_proxy and http_proxy variables. <scheme> defines the protocol used. It should match the protocol that the current environment variable sets up proxy for. <proxy_user> defines the username for proxy authorization. <proxy_pass> defines the password for proxy authorization. <host> defines a host of the proxy server. <port> defines a port of the proxy server. Assign a \"<res_1>, <res_2>, <res_3>, <res_4>, ...\" array value, where <res_1> , <res_2> , <res_3> , and <res_4> are the IP addresses and/or domains, to the no_proxy variable to define a list of the resources which proxy should not be used for. This array should consist of IP addresses and/or domains. Resources that need to be addressed without a proxy Add the following IP addresses and domain to the list of the resources that have to be addressed without a proxy for the system to operate correctly: 127.0.0.1 , 127.0.0.8 , 127.0.0.9 , and localhost . The 127.0.0.8 and 127.0.0.9 IP addresses are used for the operation of the Wallarm filter node. The example of the correct /etc/environment file contents below demonstrates the following configuration: HTTPS and HTTP requests are proxied to the 1.2.3.4 host with the 1234 port, using the admin username and the 01234 password for authorization on the proxy server. Proxying is disabled for the requests sent to 127.0.0.1 , 127.0.0.8 , 127.0.0.9 , and localhost . https_proxy=http://admin:01234@1.2.3.4:1234 http_proxy=http://admin:01234@1.2.3.4:1234 no_proxy=\"127.0.0.1, 127.0.0.8, 127.0.0.9, localhost\"","title":"4. Set up the Filter Node for Using a Proxy Server"},{"location":"en/admin-en/installation-linux-en/#5-connect-the-filter-node-to-the-wallarm-cloud","text":"API Access The API choice for your filter node depends on the Cloud you are using. Please, select the API accordingly: * If you are using https://my.wallarm.com/ , your node requires access to https://api.wallarm.com:444 . * If you are using https://us1.my.wallarm.com/ , your node requires access to https://us1.api.wallarm.com:444 . Ensure the access is not blocked by a firewall. The filter node interacts with the Wallarm cloud. To connect the node to the cloud using your cloud account requisites, proceed with the following steps: Make sure that your Wallarm account has the Administrator role enabled and two-factor authentication disabled, therefore allowing you to connect a filter node to the cloud. You can check the aforementioned parameters by navigating to the user account list in the Wallarm console. * If you are using <https://my.wallarm.com/>, proceed to the [following link][link-wl-console-users-eu] to check your user settings. * If you are using <https://us1.my.wallarm.com/>, proceed to the [following link][link-wl-console-users-us] to check your user settings. Run the addnode script in a system with the filter node: Info You have to pick the script to run depending on the Cloud you are using. * If you are using https://my.wallarm.com/ , run the script from the \u00abEU Cloud\u00bb tab below. * If you are using https://us1.my.wallarm.com/ , run the script from the \u00abUS Cloud\u00bb tab below. EU Cloud /usr/share/wallarm-common/addnode US Cloud /usr/share/wallarm-common/addnode -H us1.api.wallarm.com To specify the name of the created node, use the -n <node name> option. Provide your Wallarm account\u2019s login and password when prompted.","title":"5. Connect the Filter Node to the Wallarm Cloud"},{"location":"en/admin-en/installation-linux-en/#6-configure-the-server-addresses-of-postanalytics","text":"#### Info:: * Skip this step if you installed postanalytics and the filter node on the same server. * Do this step if you installed postanalytics and the filter node on separate servers. Add the server address of postanalytics to /etc/nginx-wallarm/conf.d/wallarm.conf : upstream wallarm_tarantool { server <ip1>:3313 max_fails=0 fail_timeout=0 max_conns=1; server <ip2>:3313 max_fails=0 fail_timeout=0 max_conns=1; keepalive 2; } ... wallarm_tarantool_upstream wallarm_tarantool; #### Warning:: Required conditions It is required that the following conditions are satisfied for the `max_conns` and the `keepalive` parameters: * The value of the `keepalive` parameter must not be lower than the number of the tarantool servers. * The value of the `max_conns` parameter must be specified for each of the upstream Tarantool servers to prevent the creation of excessive connections.","title":"6. Configure the Server Addresses of Postanalytics"},{"location":"en/admin-en/installation-linux-en/#7-configure-the-filtration-mode","text":"The filtering and proxying rules are configured in the /etc/nginx-wallarm/conf.d/wallarm.conf file. You can create your own configuration files to define the operation of NGINX-Wallarm. It is recommended to create a separate configuration file with the server block for each group of the domains that should be processed in the same way. To see detailed information about configuring NGINX-Wallarm, proceed to the official NGINX documentation . Wallarm directives define the operation logic of the Wallarm filter node. To see the list of Wallarm directives available, proceed to the Wallarm configuration options page.","title":"7. Configure the Filtration Mode"},{"location":"en/admin-en/installation-linux-en/#a-configuration-file-example","text":"Let us suppose that you need to configure the server to work in the following conditions: Only HTTP traffic is processed. There are no HTTPS requests processed. The following domains receive the requests: example.com and www.example.com . All requests must be passed to the server 10.80.0.5 . All incoming requests are considered less than 1MB in size (default setting). The processing of a request takes no more than 60 seconds (default setting). Wallarm must operate in the monitor mode. Clients access the filter node directly, without an intermediate HTTP load balancer. Creating a configuration file You can create a custom NGINX-Wallarm configuration file (e.g. example.com.conf ) or modify the default NGINX-Wallarm configuration file ( default.conf ). When creating a custom configuration file, make sure that NGINX-Wallarm listens to the incoming connections on the free port. To meet the listed conditions, the contents of the configuration file must be the following: server { listen 80; listen [::]:80 ipv6only=on; # the domains for which traffic is processed server_name example.com; server_name www.example.com; # turn on the monitoring mode of traffic processing wallarm_mode monitoring; # wallarm_instance 1; location / { # setting the address for request forwarding proxy_pass http://10.80.0.5; proxy_set_header Host $host; proxy_set_header X-Real-IP $remote_addr; proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for; } }","title":"A Configuration File Example"},{"location":"en/admin-en/installation-linux-en/#8-restart-the-wallarm-service","text":"{% termtabs name=\"Debian 8.x (jessie)\" -%}","title":"8. Restart the Wallarm Service"},{"location":"en/admin-en/installation-linux-en/#systemctl-restart-nginx-wallarm","text":"{%- tab name=\"Debian 9.x (stretch)\" -%}","title":"systemctl restart nginx-wallarm"},{"location":"en/admin-en/installation-linux-en/#systemctl-restart-nginx-wallarm_1","text":"{%- tab name=\"Ubuntu 14.04 LTS (trusty)\" -%}","title":"systemctl restart nginx-wallarm"},{"location":"en/admin-en/installation-linux-en/#service-nginx-wallarm-restart","text":"{%- tab name=\"Ubuntu 16.04 LTS (xenial)\" -%}","title":"service nginx-wallarm restart"},{"location":"en/admin-en/installation-linux-en/#service-nginx-wallarm-restart_1","text":"{%- tab name=\"Ubuntu 18.04 LTS (bionic)\" -%}","title":"service nginx-wallarm restart"},{"location":"en/admin-en/installation-linux-en/#service-nginx-wallarm-restart_2","text":"{%- tab name=\"CentOS 7.x\" -%}","title":"service nginx-wallarm restart"},{"location":"en/admin-en/installation-linux-en/#systemctl-restart-nginx-wallarm_2","text":"{%- endtermtabs %}","title":"systemctl restart nginx-wallarm"},{"location":"en/admin-en/installation-linux-en/#the-installation-is-complete","text":"Check that the filter node runs and filters the traffic. See Check the filter node operation .","title":"The Installation Is Complete"},{"location":"en/admin-en/installation-nginx-distr-en/","text":"Installing as a Dynamic Module with NGINX from Debian/CentOS Repositories \u00b6 You can install NGINX from the Debian/CentOS repositories. To install NGINX from the repositories, you must: Add the Debian/CentOS repositories. Install NGINX with the Wallarm module. Configure postanalytics. Connect the Wallarm module. Set up the filter node for using a proxy server. Connect the filter node to the Wallarm cloud. Configure the server addresses of postanalytics. Configure the filtration mode. Configure logging Restart NGINX. Prerequisites Prior to taking any steps listed below, either disable or configure SELinux if it is installed on the operating system. Make sure that you execute all commands below as superuser (e.g. root ). 1. Add the Repositories \u00b6 Depending on your operating system, run one of the commands: {% termtabs name=\"Debian 8.x (jessie-backports)\" -%} apt-get install dirmngr \u00b6 apt-key adv --keyserver keys.gnupg.net --recv-keys 72B865FD \u00b6 echo 'Acquire::Check-Valid-Until \"false\";' > /etc/apt/apt.conf.d/ignore-release-date \u00b6 echo 'deb http://archive.debian.org/debian jessie-backports main' > /etc/apt/sources.list.d/jessie-backports.list \u00b6 echo 'deb http://repo.wallarm.com/debian/wallarm-node jessie/2.14/' > /etc/apt/sources.list.d/wallarm.list \u00b6 echo 'deb http://repo.wallarm.com/debian/wallarm-node jessie-backports/2.14/' >> /etc/apt/sources.list.d/wallarm.list \u00b6 apt-get update \u00b6 {%- tab name=\"Debian 9.x (stretch)\" -%} apt-get install dirmngr \u00b6 apt-key adv --keyserver keys.gnupg.net --recv-keys 72B865FD \u00b6 sh -c \"echo 'deb http://repo.wallarm.com/debian/wallarm-node stretch/2.14/' >/etc/apt/sources.list.d/wallarm.list\" \u00b6 apt-get update \u00b6 {%- tab name=\"Debian 9.x (stretch-backports)\" -%} apt-get install dirmngr \u00b6 apt-key adv --keyserver keys.gnupg.net --recv-keys 72B865FD \u00b6 sh -c \"echo 'deb http://repo.wallarm.com/debian/wallarm-node stretch/2.14/' >/etc/apt/sources.list.d/wallarm.list\" \u00b6 sh -c \"echo 'deb http://repo.wallarm.com/debian/wallarm-node stretch-backports/2.14/' >> /etc/apt/sources.list.d/wallarm.list\" \u00b6 [warning][IMPORTANT]uncomment the following line in /etc/apt/sources.list: deb http://deb.debian.org/debian stretch-backports main contrib non-free apt-get update \u00b6 {%- tab name=\"Debian 10.x (buster)\" -%} apt-get install dirmngr \u00b6 apt-key adv --keyserver keys.gnupg.net --recv-keys 72B865FD \u00b6 sh -c \"echo 'deb http://repo.wallarm.com/debian/wallarm-node buster/2.14/' > /etc/apt/sources.list.d/wallarm.list\" \u00b6 apt-get update \u00b6 {%- tab name=\"CentOS 6.x\" -%} yum install --enablerepo=extras -y epel-release centos-release-SCL \u00b6 rpm -i https://repo.wallarm.com/centos/wallarm-node/6/2.14/x86_64/Packages/wallarm-node-repo-1-4.el6.noarch.rpm \u00b6 {%- tab name=\"CentOS 7.x\" -%} yum install -y epel-release \u00b6 rpm -i https://repo.wallarm.com/centos/wallarm-node/7/2.14/x86_64/Packages/wallarm-node-repo-1-4.el7.noarch.rpm \u00b6 {%- endtermtabs %} Repository access Your system must have access to https://repo.wallarm.com to download the packages. Ensure the access is not blocked by a firewall. 2. Install NGINX with the Wallarm Module \u00b6 #### Warning:: Important information for Debian 8 \u201cJessie\u201d users Note that using the NGINX installed from the `jessie` repository will result in non-functioning Wallarm module for NGINX. You need to add the `jessie-backports` backports repository and install NGINX from this repository. If you follow the instructions from the previous step to add the repositories to your system, then the backports repository is already set up. You can execute the command for Debian 8.x (see below) to get all necessary components installed. Install the Requests Processing and Postanalytics on the Same Server \u00b6 To run postanalytics and process the requests on the same server, you need to install the following packages: Wallarm module In-memory storage Tarantool. Postanalytics. Run the following command to install the required packages: {% termtabs name=\"Debian 8.x (jessie-backports)\" -%} apt-get install --no-install-recommends nginx wallarm-node libnginx-mod-http-wallarm -t jessie-backports \u00b6 {%- tab name=\"Debian 9.x (stretch)\" -%} apt-get install --no-install-recommends nginx wallarm-node libnginx-mod-http-wallarm \u00b6 {%- tab name=\"Debian 9.x (stretch-backports)\" -%} apt-get install --no-install-recommends nginx wallarm-node libnginx-mod-http-wallarm -t stretch-backports \u00b6 {%- tab name=\"Debian 10.x (buster)\" -%} apt-get install --no-install-recommends nginx wallarm-node libnginx-mod-http-wallarm \u00b6 {%- tab name=\"CentOS 6.x\" -%} yum install nginx wallarm-node nginx-mod-http-wallarm \u00b6 {%- tab name=\"CentOS 7.x\" -%} yum install nginx wallarm-node nginx-mod-http-wallarm \u00b6 {%- endtermtabs %} Install Only the Requests Processing on the Server \u00b6 To only process the requests on the server, you need to install the following package: Wallarm module Run the following command to install the required package: {% termtabs name=\"Debian 8.x (jessie-backports)\" -%} apt-get install --no-install-recommends nginx wallarm-node-nginx libnginx-mod-http-wallarm -t jessie-backports \u00b6 {%- tab name=\"Debian 9.x (stretch)\" -%} apt-get install --no-install-recommends nginx wallarm-node-nginx libnginx-mod-http-wallarm \u00b6 {%- tab name=\"Debian 9.x (stretch-backports)\" -%} apt-get install --no-install-recommends nginx wallarm-node-nginx libnginx-mod-http-wallarm -t stretch-backports \u00b6 {%- tab name=\"Debian 10.x (buster)\" -%} apt-get install --no-install-recommends nginx wallarm-node-nginx libnginx-mod-http-wallarm \u00b6 {%- tab name=\"CentOS 6.x\" -%} yum install nginx wallarm-node-nginx nginx-mod-http-wallarm \u00b6 {%- tab name=\"CentOS 7.x\" -%} yum install nginx wallarm-node-nginx nginx-mod-http-wallarm \u00b6 {%- endtermtabs %} 3. Configure Postanalytics \u00b6 Postanalytics uses the in-memory storage Tarantool. You must set the amount of server RAM allocated to Tarantool. The amount of memory determines the quality of work of the statistical algorithms. The recommended value is 75% of the total server memory. For example, if the server has 32 GB of memory, the recommended allocation size is 24 GB. Allocate the operating memory size for Tarantool: Open for editing the configuration file of Tarantool: {% termtabs name=\"Debian 8.x (jessie)\" -%} vi /etc/default/wallarm-tarantool \u00b6 {%- tab name=\"Debian 9.x (stretch)\" -%} vi /etc/default/wallarm-tarantool \u00b6 {%- tab name=\"Debian 10.x (buster)\" -%} vi /etc/default/wallarm-tarantool \u00b6 {%- tab name=\"CentOS 6.x\" -%} vi /etc/sysconfig/wallarm-tarantool \u00b6 {%- tab name=\"CentOS 7.x\" -%} vi /etc/sysconfig/wallarm-tarantool \u00b6 {%- endtermtabs %} Set the allocated memory size in the configuration file of Tarantool via the SLAB_ALLOC_ARENA directive. For example: SLAB_ALLOC_ARENA=24 Restart Tarantool: {% termtabs name=\"Debian 8.x (jessie)\" -%} systemctl restart wallarm-tarantool \u00b6 {%- tab name=\"Debian 9.x (stretch)\" -%} systemctl restart wallarm-tarantool \u00b6 {%- tab name=\"Debian 10.x (buster)\" -%} systemctl restart wallarm-tarantool \u00b6 {%- tab name=\"CentOS 6.x\" -%} service wallarm-tarantool restart \u00b6 {%- tab name=\"CentOS 7.x\" -%} systemctl restart wallarm-tarantool \u00b6 {%- endtermtabs %} 4. Connect the Wallarm Module \u00b6 Copy the configuration files for the system setup: {% termtabs name=\"Debian\" -%} $ cp /usr/share/doc/libnginx-mod-http-wallarm/examples/*conf /etc/nginx/conf.d/ {%- tab name=\"CentOS\" -%} $ cp /usr/share/doc/nginx-mod-http-wallarm/examples/*conf /etc/nginx/conf.d/ {%- endtermtabs %} 5. Set up the Filter Node for Using a Proxy Server \u00b6 Info This setup step is intended for users who use their own proxy server for the operation of the protected web applications. If you do not use a proxy server, skip this step of the setup. You need to assign new values to the environment variables, which define the proxy server used, to configure Wallarm node for using your proxy server. Add new values of the environment variables to the /etc/environment file: Add https_proxy to define a proxy for the https protocol. Add http_proxy to define a proxy for the http protocol. Add no_proxy to define the list of the resources proxy should not be used for. Assign the <scheme>://<proxy_user>:<proxy_pass>@<host>:<port> string values to the https_proxy and http_proxy variables. <scheme> defines the protocol used. It should match the protocol that the current environment variable sets up proxy for. <proxy_user> defines the username for proxy authorization. <proxy_pass> defines the password for proxy authorization. <host> defines a host of the proxy server. <port> defines a port of the proxy server. Assign a \"<res_1>, <res_2>, <res_3>, <res_4>, ...\" array value, where <res_1> , <res_2> , <res_3> , and <res_4> are the IP addresses and/or domains, to the no_proxy variable to define a list of the resources which proxy should not be used for. This array should consist of IP addresses and/or domains. Resources that need to be addressed without a proxy Add the following IP addresses and domain to the list of the resources that have to be addressed without a proxy for the system to operate correctly: 127.0.0.1 , 127.0.0.8 , 127.0.0.9 , and localhost . The 127.0.0.8 and 127.0.0.9 IP addresses are used for the operation of the Wallarm filter node. The example of the correct /etc/environment file contents below demonstrates the following configuration: HTTPS and HTTP requests are proxied to the 1.2.3.4 host with the 1234 port, using the admin username and the 01234 password for authorization on the proxy server. Proxying is disabled for the requests sent to 127.0.0.1 , 127.0.0.8 , 127.0.0.9 , and localhost . https_proxy=http://admin:01234@1.2.3.4:1234 http_proxy=http://admin:01234@1.2.3.4:1234 no_proxy=\"127.0.0.1, 127.0.0.8, 127.0.0.9, localhost\" 6. Connect the Filter Node to the Wallarm Cloud \u00b6 API Access The API choice for your filter node depends on the Cloud you are using. Please, select the API accordingly: * If you are using https://my.wallarm.com/ , your node requires access to https://api.wallarm.com:444 . * If you are using https://us1.my.wallarm.com/ , your node requires access to https://us1.api.wallarm.com:444 . Ensure the access is not blocked by a firewall. The filter node interacts with the Wallarm cloud. To connect the node to the cloud using your cloud account requisites, proceed with the following steps: Make sure that your Wallarm account has the Administrator role enabled and two-factor authentication disabled, therefore allowing you to connect a filter node to the cloud. You can check the aforementioned parameters by navigating to the user account list in the Wallarm console. * If you are using <https://my.wallarm.com/>, proceed to the [following link][link-wl-console-users-eu] to check your user settings. * If you are using <https://us1.my.wallarm.com/>, proceed to the [following link][link-wl-console-users-us] to check your user settings. Run the addnode script in a system with the filter node: Info You have to pick the script to run depending on the Cloud you are using. * If you are using https://my.wallarm.com/ , run the script from the \u00abEU Cloud\u00bb tab below. * If you are using https://us1.my.wallarm.com/ , run the script from the \u00abUS Cloud\u00bb tab below. EU Cloud /usr/share/wallarm-common/addnode US Cloud /usr/share/wallarm-common/addnode -H us1.api.wallarm.com To specify the name of the created node, use the -n <node name> option. Provide your Wallarm account\u2019s login and password when prompted. 7. Configure the Server Addresses of Postanalytics \u00b6 #### Info:: * Skip this step if you installed postanalytics and the filter node on the same server. * Do this step if you installed postanalytics and the filter node on separate servers. Add the server address of postanalytics to /etc/nginx/conf.d/wallarm.conf : upstream wallarm_tarantool { server <ip1>:3313 max_fails=0 fail_timeout=0 max_conns=1; server <ip2>:3313 max_fails=0 fail_timeout=0 max_conns=1; keepalive 2; } ... wallarm_tarantool_upstream wallarm_tarantool; #### Warning:: Required conditions It is required that the following conditions are satisfied for the `max_conns` and the `keepalive` parameters: * The value of the `keepalive` parameter must not be lower than the number of the tarantool servers. * The value of the `max_conns` parameter must be specified for each of the upstream Tarantool servers to prevent the creation of excessive connections. 8. Configure the Filtration Mode \u00b6 The etc/nginx/conf.d directory contains NGINX and Wallarm filter node configuration files. By default, this directory contains the following configuration files: The default.conf file defines the configuration of NGINX. The wallarm.conf file defines the global configuration of Wallarm filter node. The wallarm-status.conf file defines the Wallarm monitoring configuration. You can create your own configuration files to define the operation of NGINX and Wallarm. It is recommended to create a separate configuration file with the server block for each group of the domains that should be processed in the same way. To see detailed information about working with NGINX configuration files, proceed to the official NGINX documentation . Wallarm directives define the operation logic of the Wallarm filter node. To see the list of Wallarm directives available, proceed to the Wallarm configuration options page. A Configuration File Example \u00b6 Let us suppose that you need to configure the server to work in the following conditions: Only HTTP traffic is processed. There are no HTTPS requests processed. The following domains receive the requests: example.com and www.example.com . All requests must be passed to the server 10.80.0.5 . All incoming requests are considered less than 1MB in size (default setting). The processing of a request takes no more than 60 seconds (default setting). Wallarm must operate in the monitor mode. Clients access the filter node directly, without an intermediate HTTP load balancer. Creating a configuration file You can create a custom NGINX configuration file (e.g. example.com.conf ) or modify the default NGINX configuration file ( default.conf ). When creating a custom configuration file, make sure that NGINX listens to the incoming connections on the free port. To meet the listed conditions, the contents of the configuration file must be the following: server { listen 80; listen [::]:80 ipv6only=on; # the domains for which traffic is processed server_name example.com; server_name www.example.com; # turn on the monitoring mode of traffic processing wallarm_mode monitoring; # wallarm_instance 1; location / { # setting the address for request forwarding proxy_pass http://10.80.0.5; proxy_set_header Host $host; proxy_set_header X-Real-IP $remote_addr; proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for; } } 9. Configure Logging \u00b6 Configure the filter node variables logging using NGINX. This will allow to perform a quick filter node diagnostics with the help of the NGINX log file. 10. Restart NGINX \u00b6 Providing user with root permission If you are running NGINX as a user that does not have root permission, add this user to the wallarm group using the following command: # usermod -aG wallarm &lt;user_name&gt; where <user_name> is the name of the user without root permission. {% termtabs name=\"Debian 8.x (jessie)\" -%} systemctl restart nginx \u00b6 {%- tab name=\"Debian 9.x (stretch)\" -%} systemctl restart nginx \u00b6 {%- tab name=\"Debian 10.x (buster)\" -%} systemctl restart nginx \u00b6 {%- tab name=\"CentOS 6.x\" -%} service nginx restart \u00b6 {%- tab name=\"CentOS 7.x\" -%} systemctl restart nginx \u00b6 {%- endtermtabs %} The Installation Is Complete \u00b6 Check that the filter node runs and filters the traffic. See Check the filter node operation . #### Info:: Default Settings A freshly installed filter node operates in blocking mode (see the [`wallarm_mode`](../admin-en/configure-parameters-en.html#wallarmmode) directive description) by default. This may result in the inoperable [Wallarm scanner](../user-guides/cloud-ui/scanner/intro.md). If you plan to use the scanner, then you [need to perform additional actions](#adding-wallarm-scanner-addresses-to-the-whitelist) to render scanner operational. Additional Settings \u00b6 The filter node may require some additional configuration after installation. The document below lists a few of the typical setups that you can apply if needed. To get more information about other available settings, proceed to the \u201cConfiguration\u201d section of the Administrator\u2019s Guide . Configuring the Display of the Client's Real IP \u00b6 If the filter node is deployed behind a proxy server or load balancer without any additional configuration, the request source address may not be equal to the actual IP address of the client. Instead, it may be equal to one of the IP addresses of the proxy server or the load balancer. In this case, if you want the filter node to receive the client's IP address as a request source address, you need to perform an additional configuration of the proxy server or the load balancer. Adding Wallarm Scanner Addresses to the Whitelist \u00b6 The Wallarm scanner checks the resources of your company for vulnerabilities. Scanning is conducted using IP addresses from one of the following lists (depending on the type of Wallarm Cloud you are using): EU scanner addresses for EU Cloud users US scanner addresses for US Cloud users If you are using the Wallarm scanner, you need to configure the whitelists on your network scope security software (such as firewalls, intrusion detection systems, etc.) to contain Wallarm scanner IP addresses. For example, a Wallarm filter node with default settings is placed in the blocking mode, thus rendering the Wallarm scanner unable to scan the resources behind the filter node. To make the scanner operational again, whitelist the scanner's IP addresses on this filter node. Limiting the Single Request Processing Time \u00b6 Use the wallarm_process_time_limit Wallarm directive to specify the limit of the duration for processing a single request by the filter node. If processing the request consumes more time than specified in the directive, then the information on the error is entered into the log file and the request is marked as an overlimit_res attack. Limiting the Server Reply Waiting Time \u00b6 Use the proxy_read_timeout NGINX directive to specify the timeout for reading the proxy server reply. If the server sends nothing during this time, the connection is closed. Limiting the Maximum Request Size \u00b6 Use the client_max_body_size NGINX directive to specify the limit for the maximum size of the body of the client's request. If this limit is exceeded, NGINX replies to the client with the 413 ( Payload Too Large ) code, also known as the Request Entity Too Large message.","title":"Installing as a Dynamic Module with NGINX from Debian/CentOS Repositories"},{"location":"en/admin-en/installation-nginx-distr-en/#installing-as-a-dynamic-module-with-nginx-from-debiancentos-repositories","text":"You can install NGINX from the Debian/CentOS repositories. To install NGINX from the repositories, you must: Add the Debian/CentOS repositories. Install NGINX with the Wallarm module. Configure postanalytics. Connect the Wallarm module. Set up the filter node for using a proxy server. Connect the filter node to the Wallarm cloud. Configure the server addresses of postanalytics. Configure the filtration mode. Configure logging Restart NGINX. Prerequisites Prior to taking any steps listed below, either disable or configure SELinux if it is installed on the operating system. Make sure that you execute all commands below as superuser (e.g. root ).","title":"Installing as a Dynamic Module with NGINX from Debian/CentOS Repositories"},{"location":"en/admin-en/installation-nginx-distr-en/#1-add-the-repositories","text":"Depending on your operating system, run one of the commands: {% termtabs name=\"Debian 8.x (jessie-backports)\" -%}","title":"1. Add the Repositories"},{"location":"en/admin-en/installation-nginx-distr-en/#apt-get-install-dirmngr","text":"","title":"apt-get install dirmngr"},{"location":"en/admin-en/installation-nginx-distr-en/#apt-key-adv-keyserver-keysgnupgnet-recv-keys-72b865fd","text":"","title":"apt-key adv --keyserver keys.gnupg.net --recv-keys 72B865FD"},{"location":"en/admin-en/installation-nginx-distr-en/#echo-acquirecheck-valid-until-false-etcaptaptconfdignore-release-date","text":"","title":"echo 'Acquire::Check-Valid-Until \"false\";' &gt; /etc/apt/apt.conf.d/ignore-release-date"},{"location":"en/admin-en/installation-nginx-distr-en/#echo-deb-httparchivedebianorgdebian-jessie-backports-main-etcaptsourceslistdjessie-backportslist","text":"","title":"echo 'deb http://archive.debian.org/debian jessie-backports main' &gt; /etc/apt/sources.list.d/jessie-backports.list"},{"location":"en/admin-en/installation-nginx-distr-en/#echo-deb-httprepowallarmcomdebianwallarm-node-jessie214-etcaptsourceslistdwallarmlist","text":"","title":"echo 'deb http://repo.wallarm.com/debian/wallarm-node jessie/2.14/' &gt; /etc/apt/sources.list.d/wallarm.list"},{"location":"en/admin-en/installation-nginx-distr-en/#echo-deb-httprepowallarmcomdebianwallarm-node-jessie-backports214-etcaptsourceslistdwallarmlist","text":"","title":"echo 'deb http://repo.wallarm.com/debian/wallarm-node jessie-backports/2.14/' &gt;&gt; /etc/apt/sources.list.d/wallarm.list"},{"location":"en/admin-en/installation-nginx-distr-en/#apt-get-update","text":"{%- tab name=\"Debian 9.x (stretch)\" -%}","title":"apt-get update"},{"location":"en/admin-en/installation-nginx-distr-en/#apt-get-install-dirmngr_1","text":"","title":"apt-get install dirmngr"},{"location":"en/admin-en/installation-nginx-distr-en/#apt-key-adv-keyserver-keysgnupgnet-recv-keys-72b865fd_1","text":"","title":"apt-key adv --keyserver keys.gnupg.net --recv-keys 72B865FD"},{"location":"en/admin-en/installation-nginx-distr-en/#sh-c-echo-deb-httprepowallarmcomdebianwallarm-node-stretch214-etcaptsourceslistdwallarmlist","text":"","title":"sh -c \"echo 'deb http://repo.wallarm.com/debian/wallarm-node stretch/2.14/' &gt;/etc/apt/sources.list.d/wallarm.list\""},{"location":"en/admin-en/installation-nginx-distr-en/#apt-get-update_1","text":"{%- tab name=\"Debian 9.x (stretch-backports)\" -%}","title":"apt-get update"},{"location":"en/admin-en/installation-nginx-distr-en/#apt-get-install-dirmngr_2","text":"","title":"apt-get install dirmngr"},{"location":"en/admin-en/installation-nginx-distr-en/#apt-key-adv-keyserver-keysgnupgnet-recv-keys-72b865fd_2","text":"","title":"apt-key adv --keyserver keys.gnupg.net --recv-keys 72B865FD"},{"location":"en/admin-en/installation-nginx-distr-en/#sh-c-echo-deb-httprepowallarmcomdebianwallarm-node-stretch214-etcaptsourceslistdwallarmlist_1","text":"","title":"sh -c \"echo 'deb http://repo.wallarm.com/debian/wallarm-node stretch/2.14/' &gt;/etc/apt/sources.list.d/wallarm.list\""},{"location":"en/admin-en/installation-nginx-distr-en/#sh-c-echo-deb-httprepowallarmcomdebianwallarm-node-stretch-backports214-etcaptsourceslistdwallarmlist","text":"[warning][IMPORTANT]uncomment the following line in /etc/apt/sources.list: deb http://deb.debian.org/debian stretch-backports main contrib non-free","title":"sh -c \"echo 'deb http://repo.wallarm.com/debian/wallarm-node stretch-backports/2.14/' &gt;&gt; /etc/apt/sources.list.d/wallarm.list\""},{"location":"en/admin-en/installation-nginx-distr-en/#apt-get-update_2","text":"{%- tab name=\"Debian 10.x (buster)\" -%}","title":"apt-get update"},{"location":"en/admin-en/installation-nginx-distr-en/#apt-get-install-dirmngr_3","text":"","title":"apt-get install dirmngr"},{"location":"en/admin-en/installation-nginx-distr-en/#apt-key-adv-keyserver-keysgnupgnet-recv-keys-72b865fd_3","text":"","title":"apt-key adv --keyserver keys.gnupg.net --recv-keys 72B865FD"},{"location":"en/admin-en/installation-nginx-distr-en/#sh-c-echo-deb-httprepowallarmcomdebianwallarm-node-buster214-etcaptsourceslistdwallarmlist","text":"","title":"sh -c \"echo 'deb http://repo.wallarm.com/debian/wallarm-node buster/2.14/' &gt; /etc/apt/sources.list.d/wallarm.list\""},{"location":"en/admin-en/installation-nginx-distr-en/#apt-get-update_3","text":"{%- tab name=\"CentOS 6.x\" -%}","title":"apt-get update"},{"location":"en/admin-en/installation-nginx-distr-en/#yum-install-enablerepoextras-y-epel-release-centos-release-scl","text":"","title":"yum install --enablerepo=extras -y epel-release centos-release-SCL"},{"location":"en/admin-en/installation-nginx-distr-en/#rpm-i-httpsrepowallarmcomcentoswallarm-node6214x86_64packageswallarm-node-repo-1-4el6noarchrpm","text":"{%- tab name=\"CentOS 7.x\" -%}","title":"rpm -i https://repo.wallarm.com/centos/wallarm-node/6/2.14/x86_64/Packages/wallarm-node-repo-1-4.el6.noarch.rpm"},{"location":"en/admin-en/installation-nginx-distr-en/#yum-install-y-epel-release","text":"","title":"yum install -y epel-release"},{"location":"en/admin-en/installation-nginx-distr-en/#rpm-i-httpsrepowallarmcomcentoswallarm-node7214x86_64packageswallarm-node-repo-1-4el7noarchrpm","text":"{%- endtermtabs %} Repository access Your system must have access to https://repo.wallarm.com to download the packages. Ensure the access is not blocked by a firewall.","title":"rpm -i https://repo.wallarm.com/centos/wallarm-node/7/2.14/x86_64/Packages/wallarm-node-repo-1-4.el7.noarch.rpm"},{"location":"en/admin-en/installation-nginx-distr-en/#2-install-nginx-with-the-wallarm-module","text":"#### Warning:: Important information for Debian 8 \u201cJessie\u201d users Note that using the NGINX installed from the `jessie` repository will result in non-functioning Wallarm module for NGINX. You need to add the `jessie-backports` backports repository and install NGINX from this repository. If you follow the instructions from the previous step to add the repositories to your system, then the backports repository is already set up. You can execute the command for Debian 8.x (see below) to get all necessary components installed.","title":"2. Install NGINX with the Wallarm Module"},{"location":"en/admin-en/installation-nginx-distr-en/#install-the-requests-processing-and-postanalytics-on-the-same-server","text":"To run postanalytics and process the requests on the same server, you need to install the following packages: Wallarm module In-memory storage Tarantool. Postanalytics. Run the following command to install the required packages: {% termtabs name=\"Debian 8.x (jessie-backports)\" -%}","title":"Install the Requests Processing and Postanalytics on the Same Server"},{"location":"en/admin-en/installation-nginx-distr-en/#apt-get-install-no-install-recommends-nginx-wallarm-node-libnginx-mod-http-wallarm-t-jessie-backports","text":"{%- tab name=\"Debian 9.x (stretch)\" -%}","title":"apt-get install --no-install-recommends nginx wallarm-node libnginx-mod-http-wallarm -t jessie-backports"},{"location":"en/admin-en/installation-nginx-distr-en/#apt-get-install-no-install-recommends-nginx-wallarm-node-libnginx-mod-http-wallarm","text":"{%- tab name=\"Debian 9.x (stretch-backports)\" -%}","title":"apt-get install --no-install-recommends nginx wallarm-node libnginx-mod-http-wallarm"},{"location":"en/admin-en/installation-nginx-distr-en/#apt-get-install-no-install-recommends-nginx-wallarm-node-libnginx-mod-http-wallarm-t-stretch-backports","text":"{%- tab name=\"Debian 10.x (buster)\" -%}","title":"apt-get install --no-install-recommends nginx wallarm-node libnginx-mod-http-wallarm -t stretch-backports"},{"location":"en/admin-en/installation-nginx-distr-en/#apt-get-install-no-install-recommends-nginx-wallarm-node-libnginx-mod-http-wallarm_1","text":"{%- tab name=\"CentOS 6.x\" -%}","title":"apt-get install --no-install-recommends nginx wallarm-node libnginx-mod-http-wallarm"},{"location":"en/admin-en/installation-nginx-distr-en/#yum-install-nginx-wallarm-node-nginx-mod-http-wallarm","text":"{%- tab name=\"CentOS 7.x\" -%}","title":"yum install nginx wallarm-node nginx-mod-http-wallarm"},{"location":"en/admin-en/installation-nginx-distr-en/#yum-install-nginx-wallarm-node-nginx-mod-http-wallarm_1","text":"{%- endtermtabs %}","title":"yum install nginx wallarm-node nginx-mod-http-wallarm"},{"location":"en/admin-en/installation-nginx-distr-en/#install-only-the-requests-processing-on-the-server","text":"To only process the requests on the server, you need to install the following package: Wallarm module Run the following command to install the required package: {% termtabs name=\"Debian 8.x (jessie-backports)\" -%}","title":"Install Only the Requests Processing on the Server"},{"location":"en/admin-en/installation-nginx-distr-en/#apt-get-install-no-install-recommends-nginx-wallarm-node-nginx-libnginx-mod-http-wallarm-t-jessie-backports","text":"{%- tab name=\"Debian 9.x (stretch)\" -%}","title":"apt-get install --no-install-recommends nginx wallarm-node-nginx libnginx-mod-http-wallarm -t jessie-backports"},{"location":"en/admin-en/installation-nginx-distr-en/#apt-get-install-no-install-recommends-nginx-wallarm-node-nginx-libnginx-mod-http-wallarm","text":"{%- tab name=\"Debian 9.x (stretch-backports)\" -%}","title":"apt-get install --no-install-recommends nginx wallarm-node-nginx libnginx-mod-http-wallarm"},{"location":"en/admin-en/installation-nginx-distr-en/#apt-get-install-no-install-recommends-nginx-wallarm-node-nginx-libnginx-mod-http-wallarm-t-stretch-backports","text":"{%- tab name=\"Debian 10.x (buster)\" -%}","title":"apt-get install --no-install-recommends nginx wallarm-node-nginx libnginx-mod-http-wallarm -t stretch-backports"},{"location":"en/admin-en/installation-nginx-distr-en/#apt-get-install-no-install-recommends-nginx-wallarm-node-nginx-libnginx-mod-http-wallarm_1","text":"{%- tab name=\"CentOS 6.x\" -%}","title":"apt-get install --no-install-recommends nginx wallarm-node-nginx libnginx-mod-http-wallarm"},{"location":"en/admin-en/installation-nginx-distr-en/#yum-install-nginx-wallarm-node-nginx-nginx-mod-http-wallarm","text":"{%- tab name=\"CentOS 7.x\" -%}","title":"yum install nginx wallarm-node-nginx nginx-mod-http-wallarm"},{"location":"en/admin-en/installation-nginx-distr-en/#yum-install-nginx-wallarm-node-nginx-nginx-mod-http-wallarm_1","text":"{%- endtermtabs %}","title":"yum install nginx wallarm-node-nginx nginx-mod-http-wallarm"},{"location":"en/admin-en/installation-nginx-distr-en/#3-configure-postanalytics","text":"Postanalytics uses the in-memory storage Tarantool. You must set the amount of server RAM allocated to Tarantool. The amount of memory determines the quality of work of the statistical algorithms. The recommended value is 75% of the total server memory. For example, if the server has 32 GB of memory, the recommended allocation size is 24 GB. Allocate the operating memory size for Tarantool: Open for editing the configuration file of Tarantool: {% termtabs name=\"Debian 8.x (jessie)\" -%}","title":"3. Configure Postanalytics"},{"location":"en/admin-en/installation-nginx-distr-en/#vi-etcdefaultwallarm-tarantool","text":"{%- tab name=\"Debian 9.x (stretch)\" -%}","title":"vi /etc/default/wallarm-tarantool"},{"location":"en/admin-en/installation-nginx-distr-en/#vi-etcdefaultwallarm-tarantool_1","text":"{%- tab name=\"Debian 10.x (buster)\" -%}","title":"vi /etc/default/wallarm-tarantool"},{"location":"en/admin-en/installation-nginx-distr-en/#vi-etcdefaultwallarm-tarantool_2","text":"{%- tab name=\"CentOS 6.x\" -%}","title":"vi /etc/default/wallarm-tarantool"},{"location":"en/admin-en/installation-nginx-distr-en/#vi-etcsysconfigwallarm-tarantool","text":"{%- tab name=\"CentOS 7.x\" -%}","title":"vi /etc/sysconfig/wallarm-tarantool"},{"location":"en/admin-en/installation-nginx-distr-en/#vi-etcsysconfigwallarm-tarantool_1","text":"{%- endtermtabs %} Set the allocated memory size in the configuration file of Tarantool via the SLAB_ALLOC_ARENA directive. For example: SLAB_ALLOC_ARENA=24 Restart Tarantool: {% termtabs name=\"Debian 8.x (jessie)\" -%}","title":"vi /etc/sysconfig/wallarm-tarantool"},{"location":"en/admin-en/installation-nginx-distr-en/#systemctl-restart-wallarm-tarantool","text":"{%- tab name=\"Debian 9.x (stretch)\" -%}","title":"systemctl restart wallarm-tarantool"},{"location":"en/admin-en/installation-nginx-distr-en/#systemctl-restart-wallarm-tarantool_1","text":"{%- tab name=\"Debian 10.x (buster)\" -%}","title":"systemctl restart wallarm-tarantool"},{"location":"en/admin-en/installation-nginx-distr-en/#systemctl-restart-wallarm-tarantool_2","text":"{%- tab name=\"CentOS 6.x\" -%}","title":"systemctl restart wallarm-tarantool"},{"location":"en/admin-en/installation-nginx-distr-en/#service-wallarm-tarantool-restart","text":"{%- tab name=\"CentOS 7.x\" -%}","title":"service wallarm-tarantool restart"},{"location":"en/admin-en/installation-nginx-distr-en/#systemctl-restart-wallarm-tarantool_3","text":"{%- endtermtabs %}","title":"systemctl restart wallarm-tarantool"},{"location":"en/admin-en/installation-nginx-distr-en/#4-connect-the-wallarm-module","text":"Copy the configuration files for the system setup: {% termtabs name=\"Debian\" -%} $ cp /usr/share/doc/libnginx-mod-http-wallarm/examples/*conf /etc/nginx/conf.d/ {%- tab name=\"CentOS\" -%} $ cp /usr/share/doc/nginx-mod-http-wallarm/examples/*conf /etc/nginx/conf.d/ {%- endtermtabs %}","title":"4. Connect the Wallarm Module"},{"location":"en/admin-en/installation-nginx-distr-en/#5-set-up-the-filter-node-for-using-a-proxy-server","text":"Info This setup step is intended for users who use their own proxy server for the operation of the protected web applications. If you do not use a proxy server, skip this step of the setup. You need to assign new values to the environment variables, which define the proxy server used, to configure Wallarm node for using your proxy server. Add new values of the environment variables to the /etc/environment file: Add https_proxy to define a proxy for the https protocol. Add http_proxy to define a proxy for the http protocol. Add no_proxy to define the list of the resources proxy should not be used for. Assign the <scheme>://<proxy_user>:<proxy_pass>@<host>:<port> string values to the https_proxy and http_proxy variables. <scheme> defines the protocol used. It should match the protocol that the current environment variable sets up proxy for. <proxy_user> defines the username for proxy authorization. <proxy_pass> defines the password for proxy authorization. <host> defines a host of the proxy server. <port> defines a port of the proxy server. Assign a \"<res_1>, <res_2>, <res_3>, <res_4>, ...\" array value, where <res_1> , <res_2> , <res_3> , and <res_4> are the IP addresses and/or domains, to the no_proxy variable to define a list of the resources which proxy should not be used for. This array should consist of IP addresses and/or domains. Resources that need to be addressed without a proxy Add the following IP addresses and domain to the list of the resources that have to be addressed without a proxy for the system to operate correctly: 127.0.0.1 , 127.0.0.8 , 127.0.0.9 , and localhost . The 127.0.0.8 and 127.0.0.9 IP addresses are used for the operation of the Wallarm filter node. The example of the correct /etc/environment file contents below demonstrates the following configuration: HTTPS and HTTP requests are proxied to the 1.2.3.4 host with the 1234 port, using the admin username and the 01234 password for authorization on the proxy server. Proxying is disabled for the requests sent to 127.0.0.1 , 127.0.0.8 , 127.0.0.9 , and localhost . https_proxy=http://admin:01234@1.2.3.4:1234 http_proxy=http://admin:01234@1.2.3.4:1234 no_proxy=\"127.0.0.1, 127.0.0.8, 127.0.0.9, localhost\"","title":"5. Set up the Filter Node for Using a Proxy Server"},{"location":"en/admin-en/installation-nginx-distr-en/#6-connect-the-filter-node-to-the-wallarm-cloud","text":"API Access The API choice for your filter node depends on the Cloud you are using. Please, select the API accordingly: * If you are using https://my.wallarm.com/ , your node requires access to https://api.wallarm.com:444 . * If you are using https://us1.my.wallarm.com/ , your node requires access to https://us1.api.wallarm.com:444 . Ensure the access is not blocked by a firewall. The filter node interacts with the Wallarm cloud. To connect the node to the cloud using your cloud account requisites, proceed with the following steps: Make sure that your Wallarm account has the Administrator role enabled and two-factor authentication disabled, therefore allowing you to connect a filter node to the cloud. You can check the aforementioned parameters by navigating to the user account list in the Wallarm console. * If you are using <https://my.wallarm.com/>, proceed to the [following link][link-wl-console-users-eu] to check your user settings. * If you are using <https://us1.my.wallarm.com/>, proceed to the [following link][link-wl-console-users-us] to check your user settings. Run the addnode script in a system with the filter node: Info You have to pick the script to run depending on the Cloud you are using. * If you are using https://my.wallarm.com/ , run the script from the \u00abEU Cloud\u00bb tab below. * If you are using https://us1.my.wallarm.com/ , run the script from the \u00abUS Cloud\u00bb tab below. EU Cloud /usr/share/wallarm-common/addnode US Cloud /usr/share/wallarm-common/addnode -H us1.api.wallarm.com To specify the name of the created node, use the -n <node name> option. Provide your Wallarm account\u2019s login and password when prompted.","title":"6. Connect the Filter Node to the Wallarm Cloud"},{"location":"en/admin-en/installation-nginx-distr-en/#7-configure-the-server-addresses-of-postanalytics","text":"#### Info:: * Skip this step if you installed postanalytics and the filter node on the same server. * Do this step if you installed postanalytics and the filter node on separate servers. Add the server address of postanalytics to /etc/nginx/conf.d/wallarm.conf : upstream wallarm_tarantool { server <ip1>:3313 max_fails=0 fail_timeout=0 max_conns=1; server <ip2>:3313 max_fails=0 fail_timeout=0 max_conns=1; keepalive 2; } ... wallarm_tarantool_upstream wallarm_tarantool; #### Warning:: Required conditions It is required that the following conditions are satisfied for the `max_conns` and the `keepalive` parameters: * The value of the `keepalive` parameter must not be lower than the number of the tarantool servers. * The value of the `max_conns` parameter must be specified for each of the upstream Tarantool servers to prevent the creation of excessive connections.","title":"7. Configure the Server Addresses of Postanalytics"},{"location":"en/admin-en/installation-nginx-distr-en/#8-configure-the-filtration-mode","text":"The etc/nginx/conf.d directory contains NGINX and Wallarm filter node configuration files. By default, this directory contains the following configuration files: The default.conf file defines the configuration of NGINX. The wallarm.conf file defines the global configuration of Wallarm filter node. The wallarm-status.conf file defines the Wallarm monitoring configuration. You can create your own configuration files to define the operation of NGINX and Wallarm. It is recommended to create a separate configuration file with the server block for each group of the domains that should be processed in the same way. To see detailed information about working with NGINX configuration files, proceed to the official NGINX documentation . Wallarm directives define the operation logic of the Wallarm filter node. To see the list of Wallarm directives available, proceed to the Wallarm configuration options page.","title":"8. Configure the Filtration Mode"},{"location":"en/admin-en/installation-nginx-distr-en/#a-configuration-file-example","text":"Let us suppose that you need to configure the server to work in the following conditions: Only HTTP traffic is processed. There are no HTTPS requests processed. The following domains receive the requests: example.com and www.example.com . All requests must be passed to the server 10.80.0.5 . All incoming requests are considered less than 1MB in size (default setting). The processing of a request takes no more than 60 seconds (default setting). Wallarm must operate in the monitor mode. Clients access the filter node directly, without an intermediate HTTP load balancer. Creating a configuration file You can create a custom NGINX configuration file (e.g. example.com.conf ) or modify the default NGINX configuration file ( default.conf ). When creating a custom configuration file, make sure that NGINX listens to the incoming connections on the free port. To meet the listed conditions, the contents of the configuration file must be the following: server { listen 80; listen [::]:80 ipv6only=on; # the domains for which traffic is processed server_name example.com; server_name www.example.com; # turn on the monitoring mode of traffic processing wallarm_mode monitoring; # wallarm_instance 1; location / { # setting the address for request forwarding proxy_pass http://10.80.0.5; proxy_set_header Host $host; proxy_set_header X-Real-IP $remote_addr; proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for; } }","title":"A Configuration File Example"},{"location":"en/admin-en/installation-nginx-distr-en/#9-configure-logging","text":"Configure the filter node variables logging using NGINX. This will allow to perform a quick filter node diagnostics with the help of the NGINX log file.","title":"9. Configure Logging"},{"location":"en/admin-en/installation-nginx-distr-en/#10-restart-nginx","text":"Providing user with root permission If you are running NGINX as a user that does not have root permission, add this user to the wallarm group using the following command: # usermod -aG wallarm &lt;user_name&gt; where <user_name> is the name of the user without root permission. {% termtabs name=\"Debian 8.x (jessie)\" -%}","title":"10. Restart NGINX"},{"location":"en/admin-en/installation-nginx-distr-en/#systemctl-restart-nginx","text":"{%- tab name=\"Debian 9.x (stretch)\" -%}","title":"systemctl restart nginx"},{"location":"en/admin-en/installation-nginx-distr-en/#systemctl-restart-nginx_1","text":"{%- tab name=\"Debian 10.x (buster)\" -%}","title":"systemctl restart nginx"},{"location":"en/admin-en/installation-nginx-distr-en/#systemctl-restart-nginx_2","text":"{%- tab name=\"CentOS 6.x\" -%}","title":"systemctl restart nginx"},{"location":"en/admin-en/installation-nginx-distr-en/#service-nginx-restart","text":"{%- tab name=\"CentOS 7.x\" -%}","title":"service nginx restart"},{"location":"en/admin-en/installation-nginx-distr-en/#systemctl-restart-nginx_3","text":"{%- endtermtabs %}","title":"systemctl restart nginx"},{"location":"en/admin-en/installation-nginx-distr-en/#the-installation-is-complete","text":"Check that the filter node runs and filters the traffic. See Check the filter node operation . #### Info:: Default Settings A freshly installed filter node operates in blocking mode (see the [`wallarm_mode`](../admin-en/configure-parameters-en.html#wallarmmode) directive description) by default. This may result in the inoperable [Wallarm scanner](../user-guides/cloud-ui/scanner/intro.md). If you plan to use the scanner, then you [need to perform additional actions](#adding-wallarm-scanner-addresses-to-the-whitelist) to render scanner operational.","title":"The Installation Is Complete"},{"location":"en/admin-en/installation-nginx-distr-en/#additional-settings","text":"The filter node may require some additional configuration after installation. The document below lists a few of the typical setups that you can apply if needed. To get more information about other available settings, proceed to the \u201cConfiguration\u201d section of the Administrator\u2019s Guide .","title":"Additional Settings"},{"location":"en/admin-en/installation-nginx-distr-en/#configuring-the-display-of-the-clients-real-ip","text":"If the filter node is deployed behind a proxy server or load balancer without any additional configuration, the request source address may not be equal to the actual IP address of the client. Instead, it may be equal to one of the IP addresses of the proxy server or the load balancer. In this case, if you want the filter node to receive the client's IP address as a request source address, you need to perform an additional configuration of the proxy server or the load balancer.","title":"Configuring the Display of the Client's Real IP"},{"location":"en/admin-en/installation-nginx-distr-en/#adding-wallarm-scanner-addresses-to-the-whitelist","text":"The Wallarm scanner checks the resources of your company for vulnerabilities. Scanning is conducted using IP addresses from one of the following lists (depending on the type of Wallarm Cloud you are using): EU scanner addresses for EU Cloud users US scanner addresses for US Cloud users If you are using the Wallarm scanner, you need to configure the whitelists on your network scope security software (such as firewalls, intrusion detection systems, etc.) to contain Wallarm scanner IP addresses. For example, a Wallarm filter node with default settings is placed in the blocking mode, thus rendering the Wallarm scanner unable to scan the resources behind the filter node. To make the scanner operational again, whitelist the scanner's IP addresses on this filter node.","title":"Adding Wallarm Scanner Addresses to the Whitelist"},{"location":"en/admin-en/installation-nginx-distr-en/#limiting-the-single-request-processing-time","text":"Use the wallarm_process_time_limit Wallarm directive to specify the limit of the duration for processing a single request by the filter node. If processing the request consumes more time than specified in the directive, then the information on the error is entered into the log file and the request is marked as an overlimit_res attack.","title":"Limiting the Single Request Processing Time"},{"location":"en/admin-en/installation-nginx-distr-en/#limiting-the-server-reply-waiting-time","text":"Use the proxy_read_timeout NGINX directive to specify the timeout for reading the proxy server reply. If the server sends nothing during this time, the connection is closed.","title":"Limiting the Server Reply Waiting Time"},{"location":"en/admin-en/installation-nginx-distr-en/#limiting-the-maximum-request-size","text":"Use the client_max_body_size NGINX directive to specify the limit for the maximum size of the body of the client's request. If this limit is exceeded, NGINX replies to the client with the 413 ( Payload Too Large ) code, also known as the Request Entity Too Large message.","title":"Limiting the Maximum Request Size"},{"location":"en/admin-en/installation-nginx-en/","text":"Installing as a Dynamic Module for NGINX \u00b6 Commercial NGINX Plus and Open Source NGINX The instructions in this section address the filter node installation as a dynamic module for the free open-source NGINX. If you are running the commercial NGINX Plus, you need a different set of instructions. See Installing with NGINX Plus . If you have a running NGINX installed in your network infrastructure, you can install Wallarm as a dynamic module for NGINX. Use with Official vs. Custom Builds of NGINX \u00b6 Wallarm is compatible with NGINX installed from official NGINX repositories . If you are planning to install a custom build of NGINX, the dynamic module from the Wallarm repository might be incompatible and not load. To rebuild the dynamic module, contact Wallarm Support . With your support request, provide the following information provided by the output of the given commands: Linux kernel version: uname -a Linux distributive: cat /etc/*release NGINX version: NGINX official build : /usr/sbin/nginx -V NGINX custom build: <path to nginx>/nginx -V Compatibility signature: NGINX official build : egrep -ao '.,.,.,[01]{33}' /usr/sbin/nginx NGINX custom build: egrep -ao '.,.,.,[01]{33}' <path to nginx>/nginx The user (and the user's group) who is running the NGINX worker processes: grep -w 'user' <path to the NGINX configuration files/nginx.conf> Installation Options \u00b6 The processing of requests in the filter node is done in two stages: Processing in NGINX-Module-Wallarm. Postanalytics \u2013 statistical analysis of the processed requests. The processing is not memory demanding and can be put on front end servers without changing the server requirements. Postanalytics is memory demanding, which may require changes in the server configuration or installation of postanalytics on a separate server. Wallarm also has the option of installing postanalytics in a separate server pool. Installation of postanalytics on a separate server If you are planning to install postanalytics on a separate server, you must install postanalytics first. See details in Separate postanalytics installation . To install as a dynamic module for NGINX, you must: Install NGINX. Add the Wallarm repositories, from which you will download packages. Install the Wallarm packages. Configure postanalytics. Connect the Wallarm module. Set up the filter node for using a proxy server. Connect the filter node to the Wallarm cloud. Configure the server addresses of postanalytics. Configure the filtration mode. Configure logging. Restart NGINX. Prerequisites Prior to taking any steps listed below, either disable or configure SELinux if it is installed on the operating system. Make sure that you execute all commands below as superuser (e.g. root ). 1. Install NGINX \u00b6 You can: Use the official build . Prepare a custom build with the similar compilation options. See the official NGINX installation instructions . Installing on Amazon Linux 2 To install NGINX on Amazon Linux 2, use the CentOS 7 instruction. 2. Add the Wallarm Repositories \u00b6 The installation and updating of the filter node is done from the Wallarm repositories. Depending on your operating system, run one of the commands: Debian 8.x (jessie) apt-get install dirmngr apt-key adv --keyserver keys.gnupg.net --recv-keys 72B865FD sh -c \"echo 'deb http://repo.wallarm.com/debian/wallarm-node jessie/2.14/' > /etc/apt/sources.list.d/wallarm.list\" apt-get update Debian 9.x (stretch) apt-get install dirmngr apt-key adv --keyserver keys.gnupg.net --recv-keys 72B865FD sh -c \"echo 'deb http://repo.wallarm.com/debian/wallarm-node stretch/2.14/' > /etc/apt/sources.list.d/wallarm.list\" apt-get update Debian 10.x (buster) apt-get install dirmngr apt-key adv --keyserver keys.gnupg.net --recv-keys 72B865FD sh -c \"echo 'deb http://repo.wallarm.com/debian/wallarm-node buster/2.14/' > /etc/apt/sources.list.d/wallarm.list\" apt-get update Ubuntu 14.04 LTS (trusty) apt-key adv --keyserver keys.gnupg.net --recv-keys 72B865FD sh -c \"echo 'deb http://repo.wallarm.com/ubuntu/wallarm-node trusty/2.14/' > /etc/apt/sources.list.d/wallarm.list\" apt-get update Ubuntu 16.04 LTS (xenial) apt-key adv --keyserver keys.gnupg.net --recv-keys 72B865FD sh -c \"echo 'deb http://repo.wallarm.com/ubuntu/wallarm-node xenial/2.14/' > /etc/apt/sources.list.d/wallarm.list\" apt-get update Ubuntu 18.04 LTS (bionic) apt-key adv --keyserver keys.gnupg.net --recv-keys 72B865FD sh -c \"echo 'deb http://repo.wallarm.com/ubuntu/wallarm-node bionic/2.14/' > /etc/apt/sources.list.d/wallarm.list\" apt-get update ``` CentOS 6.x yum install --enablerepo = extras -y epel-release centos-release-SCL rpm -i https://repo.wallarm.com/centos/wallarm-node/6/2.14/x86_64/Packages/wallarm-node-repo-1-4.el6.noarch.rpm CentOS 7.x yum install -y epel-release rpm -i https://repo.wallarm.com/centos/wallarm-node/7/2.14/x86_64/Packages/wallarm-node-repo-1-4.el7.noarch.rpm ``` Amazon Linux 2 yum install -y https://dl.fedoraproject.org/pub/epel/epel-release-latest-7.noarch.rpm rpm -i https://repo.wallarm.com/centos/wallarm-node/7/2.14/x86_64/Packages/wallarm-node-repo-1-4.el7.noarch.rpm Repository access Your system must have access to https://repo.wallarm.com to download the packages. Ensure the access is not blocked by a firewall. 3. Install the Wallarm Packages \u00b6 Install the Requests Processing and Postanalytics on the Same Server \u00b6 To run postanalytics and process the requests on the same server, you need to install the following packages: Wallarm module In-memory storage Tarantool. Postanalytics. Run the following command to install the required packages: Debian 8.x (jessie) apt-get install --no-install-recommends wallarm-node nginx-module-wallarm Debian 9.x (stretch) apt-get install --no-install-recommends wallarm-node nginx-module-wallarm Debian 10.x (buster) apt-get install --no-install-recommends wallarm-node nginx-module-wallarm Ubuntu 14.04 LTS (trusty) apt-get install --no-install-recommends wallarm-node nginx-module-wallarm Ubuntu 16.04 LTS (xenial) apt-get install --no-install-recommends wallarm-node nginx-module-wallarm Ubuntu 18.04 LTS (bionic) apt-get install --no-install-recommends wallarm-node nginx-module-wallarm CentOS 6.x yum install wallarm-node nginx-module-wallarm CentOS 7.x yum install wallarm-node nginx-module-wallarm Amazon Linux 2 yum install wallarm-node nginx-module-wallarm Install Only the Requests Processing on the Server \u00b6 To only process the requests on the server, you need to install the following package: Wallarm module Run the following command to install the required package: Debian 8.x (jessie) apt-get install --no-install-recommends wallarm-node-nginx nginx-module-wallarm Debian 9.x (stretch) apt-get install --no-install-recommends wallarm-node-nginx nginx-module-wallarm Debian 10.x (buster) apt-get install --no-install-recommends wallarm-node-nginx nginx-module-wallarm Ubuntu 14.04 LTS (trusty) apt-get install --no-install-recommends wallarm-node-nginx nginx-module-wallarm Ubuntu 16.04 LTS (xenial) apt-get install --no-install-recommends wallarm-node-nginx nginx-module-wallarm Ubuntu 18.04 LTS (bionic) apt-get install --no-install-recommends wallarm-node-nginx nginx-module-wallarm CentOS 6.x yum install wallarm-node-nginx nginx-module-wallarm CentOS 7.x yum install wallarm-node-nginx nginx-module-wallarm Amazon Linux 2 yum install wallarm-node-nginx nginx-module-wallarm 4. Configure Postanalytics \u00b6 Info Skip this step if you installed postanalytics on a separate server as you already have your postanalytics configured. Postanalytics uses the in-memory storage Tarantool. You must set the amount of server RAM allocated to Tarantool. The amount of memory determines the quality of work of the statistical algorithms. The recommended value is 75% of the total server memory. For example, if the server has 32 GB of memory, the recommended allocation size is 24 GB. Allocate the operating memory size for Tarantool: Open for editing the configuration file of Tarantool: Debian 8.x (jessie) vi /etc/default/wallarm-tarantool Debian 9.x (stretch) vi /etc/default/wallarm-tarantool Debian 10.x (buster) vi /etc/default/wallarm-tarantool Ubuntu 14.04 LTS (trusty) vi /etc/default/wallarm-tarantool Ubuntu 16.04 LTS (xenial) vi /etc/default/wallarm-tarantool Ubuntu 18.04 LTS (bionic) vi /etc/default/wallarm-tarantool CentOS 6.x vi /etc/sysconfig/wallarm-tarantool CentOS 7.x vi /etc/sysconfig/wallarm-tarantool Amazon Linux 2 vi /etc/sysconfig/wallarm-tarantool Set the allocated memory size in the configuration file of Tarantool via the SLAB_ALLOC_ARENA directive. For example: SLAB_ALLOC_ARENA=24 Restart Tarantool: Debian 8.x (jessie) systemctl restart wallarm-tarantool Debian 9.x (stretch) systemctl restart wallarm-tarantool Debian 10.x (buster) systemctl restart wallarm-tarantool Ubuntu 14.04 LTS (trusty) service wallarm-tarantool restart Ubuntu 16.04 LTS (xenial) service wallarm-tarantool restart Ubuntu 18.04 LTS (bionic) service wallarm-tarantool restart CentOS 6.x service wallarm-tarantool restart CentOS 7.x systemctl restart wallarm-tarantool Amazon Linux 2 systemctl restart wallarm-tarantool 5. Connect the Wallarm Module \u00b6 Open the /etc/nginx/nginx.conf file. Ensure that you have the include /etc/nginx/conf.d/* line in the file. If you do not, add it. Add the following directive right after the worker_processes directive: load_module modules/ngx_http_wallarm_module.so; Configuration example with the added directive: user nginx; worker_processes auto; load_module modules/ngx_http_wallarm_module.so; error_log /var/log/nginx/error.log notice; pid /var/run/nginx.pid; Copy the configuration files for the system setup: cp /usr/share/doc/nginx-module-wallarm/examples/*.conf /etc/nginx/conf.d/ 6. Set up the Filter Node for Using a Proxy Server \u00b6 Info This setup step is intended for users who use their own proxy server for the operation of the protected web applications. If you do not use a proxy server, skip this step of the setup. You need to assign new values to the environment variables, which define the proxy server used, to configure Wallarm node for using your proxy server. Add new values of the environment variables to the /etc/environment file: Add https_proxy to define a proxy for the https protocol. Add http_proxy to define a proxy for the http protocol. Add no_proxy to define the list of the resources proxy should not be used for. Assign the <scheme>://<proxy_user>:<proxy_pass>@<host>:<port> string values to the https_proxy and http_proxy variables. <scheme> defines the protocol used. It should match the protocol that the current environment variable sets up proxy for. <proxy_user> defines the username for proxy authorization. <proxy_pass> defines the password for proxy authorization. <host> defines a host of the proxy server. <port> defines a port of the proxy server. Assign a \"<res_1>, <res_2>, <res_3>, <res_4>, ...\" array value, where <res_1> , <res_2> , <res_3> , and <res_4> are the IP addresses and/or domains, to the no_proxy variable to define a list of the resources which proxy should not be used for. This array should consist of IP addresses and/or domains. Resources that need to be addressed without a proxy Add the following IP addresses and domain to the list of the resources that have to be addressed without a proxy for the system to operate correctly: 127.0.0.1 , 127.0.0.8 , 127.0.0.9 , and localhost . The 127.0.0.8 and 127.0.0.9 IP addresses are used for the operation of the Wallarm filter node. The example of the correct /etc/environment file contents below demonstrates the following configuration: HTTPS and HTTP requests are proxied to the 1.2.3.4 host with the 1234 port, using the admin username and the 01234 password for authorization on the proxy server. Proxying is disabled for the requests sent to 127.0.0.1 , 127.0.0.8 , 127.0.0.9 , and localhost . https_proxy=http://admin:01234@1.2.3.4:1234 http_proxy=http://admin:01234@1.2.3.4:1234 no_proxy=\"127.0.0.1, 127.0.0.8, 127.0.0.9, localhost\" 7. Connect the Filter Node to the Wallarm Cloud \u00b6 API Access The API choice for your filter node depends on the Cloud you are using. Please, select the API accordingly: * If you are using https://my.wallarm.com/ , your node requires access to https://api.wallarm.com:444 . * If you are using https://us1.my.wallarm.com/ , your node requires access to https://us1.api.wallarm.com:444 . Ensure the access is not blocked by a firewall. The filter node interacts with the Wallarm cloud. To connect the node to the cloud using your cloud account requisites, proceed with the following steps: Make sure that your Wallarm account has the Administrator role enabled and two-factor authentication disabled, therefore allowing you to connect a filter node to the cloud. You can check the aforementioned parameters by navigating to the user account list in the Wallarm console. * If you are using <https://my.wallarm.com/>, proceed to the [following link][link-wl-console-users-eu] to check your user settings. * If you are using <https://us1.my.wallarm.com/>, proceed to the [following link][link-wl-console-users-us] to check your user settings. Run the addnode script in a system with the filter node: Info You have to pick the script to run depending on the Cloud you are using. * If you are using https://my.wallarm.com/ , run the script from the \u00abEU Cloud\u00bb tab below. * If you are using https://us1.my.wallarm.com/ , run the script from the \u00abUS Cloud\u00bb tab below. EU Cloud /usr/share/wallarm-common/addnode US Cloud /usr/share/wallarm-common/addnode -H us1.api.wallarm.com To specify the name of the created node, use the -n <node name> option. Provide your Wallarm account\u2019s login and password when prompted. 8. Configure the Server Addresses of Postanalytics \u00b6 Info Skip this step if you installed postanalytics and the filter node on the same server. Do this step if you installed postanalytics and the filter node on separate servers. Add the server address of postanalytics to /etc/nginx/conf.d/wallarm.conf : upstream wallarm_tarantool { server <ip1>:3313 max_fails=0 fail_timeout=0 max_conns=1; server <ip2>:3313 max_fails=0 fail_timeout=0 max_conns=1; keepalive 2; } ... wallarm_tarantool_upstream wallarm_tarantool; #### Warning:: Required conditions It is required that the following conditions are satisfied for the `max_conns` and the `keepalive` parameters: * The value of the `keepalive` parameter must not be lower than the number of the tarantool servers. * The value of the `max_conns` parameter must be specified for each of the upstream Tarantool servers to prevent the creation of excessive connections. 9. Configure the Filtration Mode \u00b6 The etc/nginx/conf.d directory contains NGINX and Wallarm filter node configuration files. By default, this directory contains the following configuration files: The default.conf file defines the configuration of NGINX. The wallarm.conf file defines the global configuration of Wallarm filter node. The wallarm-status.conf file defines the Wallarm monitoring configuration. You can create your own configuration files to define the operation of NGINX and Wallarm. It is recommended to create a separate configuration file with the server block for each group of the domains that should be processed in the same way. To see detailed information about working with NGINX configuration files, proceed to the official NGINX documentation . Wallarm directives define the operation logic of the Wallarm filter node. To see the list of Wallarm directives available, proceed to the Wallarm configuration options page. A Configuration File Example \u00b6 Let us suppose that you need to configure the server to work in the following conditions: Only HTTP traffic is processed. There are no HTTPS requests processed. The following domains receive the requests: example.com and www.example.com . All requests must be passed to the server 10.80.0.5 . All incoming requests are considered less than 1MB in size (default setting). The processing of a request takes no more than 60 seconds (default setting). Wallarm must operate in the monitor mode. Clients access the filter node directly, without an intermediate HTTP load balancer. Creating a configuration file You can create a custom NGINX configuration file (e.g. example.com.conf ) or modify the default NGINX configuration file ( default.conf ). When creating a custom configuration file, make sure that NGINX listens to the incoming connections on the free port. To meet the listed conditions, the contents of the configuration file must be the following: server { listen 80; listen [::]:80 ipv6only=on; # the domains for which traffic is processed server_name example.com; server_name www.example.com; # turn on the monitoring mode of traffic processing wallarm_mode monitoring; # wallarm_instance 1; location / { # setting the address for request forwarding proxy_pass http://10.80.0.5; proxy_set_header Host $host; proxy_set_header X-Real-IP $remote_addr; proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for; } } 10. Configure Logging \u00b6 Configure the filter node variables logging using NGINX. This will allow to perform a quick filter node diagnostics with the help of the NGINX log file. 11. Restart NGINX \u00b6 Providing user with root permission If you are running NGINX as a user that does not have root permission, add this user to the wallarm group using the following command: # usermod -aG wallarm &lt;user_name&gt; where <user_name> is the name of the user without root permission. Debian 8.x (jessie) systemctl restart nginx Debian 9.x (stretch) systemctl restart nginx Debian 10.x (buster) systemctl restart nginx Ubuntu 14.04 LTS (trusty) service nginx restart Ubuntu 16.04 LTS (xenial) service nginx restart Ubuntu 18.04 LTS (bionic) service nginx restart CentOS 6.x service nginx restart CentOS 7.x systemctl restart nginx Amazon Linux 2 systemctl restart nginx The Installation Is Complete \u00b6 Check that the filter node runs and filters the traffic. See Check the filter node operation . #### Info:: Default Settings A freshly installed filter node operates in blocking mode (see the [`wallarm_mode`](../admin-en/configure-parameters-en.html#wallarmmode) directive description) by default. This may result in the inoperable [Wallarm scanner](../user-guides/cloud-ui/scanner/intro.md). If you plan to use the scanner, then you [need to perform additional actions](#adding-wallarm-scanner-addresses-to-the-whitelist) to render scanner operational. Additional Settings \u00b6 The filter node may require some additional configuration after installation. The document below lists a few of the typical setups that you can apply if needed. To get more information about other available settings, proceed to the \u201cConfiguration\u201d section of the Administrator\u2019s Guide . Configuring the Display of the Client's Real IP \u00b6 If the filter node is deployed behind a proxy server or load balancer without any additional configuration, the request source address may not be equal to the actual IP address of the client. Instead, it may be equal to one of the IP addresses of the proxy server or the load balancer. In this case, if you want the filter node to receive the client's IP address as a request source address, you need to perform an additional configuration of the proxy server or the load balancer. Adding Wallarm Scanner Addresses to the Whitelist \u00b6 The Wallarm scanner checks the resources of your company for vulnerabilities. Scanning is conducted using IP addresses from one of the following lists (depending on the type of Wallarm Cloud you are using): EU scanner addresses for EU Cloud users US scanner addresses for US Cloud users If you are using the Wallarm scanner, you need to configure the whitelists on your network scope security software (such as firewalls, intrusion detection systems, etc.) to contain Wallarm scanner IP addresses. For example, a Wallarm filter node with default settings is placed in the blocking mode, thus rendering the Wallarm scanner unable to scan the resources behind the filter node. To make the scanner operational again, whitelist the scanner's IP addresses on this filter node. Limiting the Single Request Processing Time \u00b6 Use the wallarm_process_time_limit Wallarm directive to specify the limit of the duration for processing a single request by the filter node. If processing the request consumes more time than specified in the directive, then the information on the error is entered into the log file and the request is marked as an overlimit_res attack. Limiting the Server Reply Waiting Time \u00b6 Use the proxy_read_timeout NGINX directive to specify the timeout for reading the proxy server reply. If the server sends nothing during this time, the connection is closed. Limiting the Maximum Request Size \u00b6 Use the client_max_body_size NGINX directive to specify the limit for the maximum size of the body of the client's request. If this limit is exceeded, NGINX replies to the client with the 413 ( Payload Too Large ) code, also known as the Request Entity Too Large message.","title":"Installing as a Dynamic Module for NGINX"},{"location":"en/admin-en/installation-nginx-en/#installing-as-a-dynamic-module-for-nginx","text":"Commercial NGINX Plus and Open Source NGINX The instructions in this section address the filter node installation as a dynamic module for the free open-source NGINX. If you are running the commercial NGINX Plus, you need a different set of instructions. See Installing with NGINX Plus . If you have a running NGINX installed in your network infrastructure, you can install Wallarm as a dynamic module for NGINX.","title":"Installing as a Dynamic Module for NGINX"},{"location":"en/admin-en/installation-nginx-en/#use-with-official-vs-custom-builds-of-nginx","text":"Wallarm is compatible with NGINX installed from official NGINX repositories . If you are planning to install a custom build of NGINX, the dynamic module from the Wallarm repository might be incompatible and not load. To rebuild the dynamic module, contact Wallarm Support . With your support request, provide the following information provided by the output of the given commands: Linux kernel version: uname -a Linux distributive: cat /etc/*release NGINX version: NGINX official build : /usr/sbin/nginx -V NGINX custom build: <path to nginx>/nginx -V Compatibility signature: NGINX official build : egrep -ao '.,.,.,[01]{33}' /usr/sbin/nginx NGINX custom build: egrep -ao '.,.,.,[01]{33}' <path to nginx>/nginx The user (and the user's group) who is running the NGINX worker processes: grep -w 'user' <path to the NGINX configuration files/nginx.conf>","title":"Use with Official vs. Custom Builds of NGINX"},{"location":"en/admin-en/installation-nginx-en/#installation-options","text":"The processing of requests in the filter node is done in two stages: Processing in NGINX-Module-Wallarm. Postanalytics \u2013 statistical analysis of the processed requests. The processing is not memory demanding and can be put on front end servers without changing the server requirements. Postanalytics is memory demanding, which may require changes in the server configuration or installation of postanalytics on a separate server. Wallarm also has the option of installing postanalytics in a separate server pool. Installation of postanalytics on a separate server If you are planning to install postanalytics on a separate server, you must install postanalytics first. See details in Separate postanalytics installation . To install as a dynamic module for NGINX, you must: Install NGINX. Add the Wallarm repositories, from which you will download packages. Install the Wallarm packages. Configure postanalytics. Connect the Wallarm module. Set up the filter node for using a proxy server. Connect the filter node to the Wallarm cloud. Configure the server addresses of postanalytics. Configure the filtration mode. Configure logging. Restart NGINX. Prerequisites Prior to taking any steps listed below, either disable or configure SELinux if it is installed on the operating system. Make sure that you execute all commands below as superuser (e.g. root ).","title":"Installation Options"},{"location":"en/admin-en/installation-nginx-en/#1-install-nginx","text":"You can: Use the official build . Prepare a custom build with the similar compilation options. See the official NGINX installation instructions . Installing on Amazon Linux 2 To install NGINX on Amazon Linux 2, use the CentOS 7 instruction.","title":"1. Install NGINX"},{"location":"en/admin-en/installation-nginx-en/#2-add-the-wallarm-repositories","text":"The installation and updating of the filter node is done from the Wallarm repositories. Depending on your operating system, run one of the commands: Debian 8.x (jessie) apt-get install dirmngr apt-key adv --keyserver keys.gnupg.net --recv-keys 72B865FD sh -c \"echo 'deb http://repo.wallarm.com/debian/wallarm-node jessie/2.14/' > /etc/apt/sources.list.d/wallarm.list\" apt-get update Debian 9.x (stretch) apt-get install dirmngr apt-key adv --keyserver keys.gnupg.net --recv-keys 72B865FD sh -c \"echo 'deb http://repo.wallarm.com/debian/wallarm-node stretch/2.14/' > /etc/apt/sources.list.d/wallarm.list\" apt-get update Debian 10.x (buster) apt-get install dirmngr apt-key adv --keyserver keys.gnupg.net --recv-keys 72B865FD sh -c \"echo 'deb http://repo.wallarm.com/debian/wallarm-node buster/2.14/' > /etc/apt/sources.list.d/wallarm.list\" apt-get update Ubuntu 14.04 LTS (trusty) apt-key adv --keyserver keys.gnupg.net --recv-keys 72B865FD sh -c \"echo 'deb http://repo.wallarm.com/ubuntu/wallarm-node trusty/2.14/' > /etc/apt/sources.list.d/wallarm.list\" apt-get update Ubuntu 16.04 LTS (xenial) apt-key adv --keyserver keys.gnupg.net --recv-keys 72B865FD sh -c \"echo 'deb http://repo.wallarm.com/ubuntu/wallarm-node xenial/2.14/' > /etc/apt/sources.list.d/wallarm.list\" apt-get update Ubuntu 18.04 LTS (bionic) apt-key adv --keyserver keys.gnupg.net --recv-keys 72B865FD sh -c \"echo 'deb http://repo.wallarm.com/ubuntu/wallarm-node bionic/2.14/' > /etc/apt/sources.list.d/wallarm.list\" apt-get update ``` CentOS 6.x yum install --enablerepo = extras -y epel-release centos-release-SCL rpm -i https://repo.wallarm.com/centos/wallarm-node/6/2.14/x86_64/Packages/wallarm-node-repo-1-4.el6.noarch.rpm CentOS 7.x yum install -y epel-release rpm -i https://repo.wallarm.com/centos/wallarm-node/7/2.14/x86_64/Packages/wallarm-node-repo-1-4.el7.noarch.rpm ``` Amazon Linux 2 yum install -y https://dl.fedoraproject.org/pub/epel/epel-release-latest-7.noarch.rpm rpm -i https://repo.wallarm.com/centos/wallarm-node/7/2.14/x86_64/Packages/wallarm-node-repo-1-4.el7.noarch.rpm Repository access Your system must have access to https://repo.wallarm.com to download the packages. Ensure the access is not blocked by a firewall.","title":"2. Add the Wallarm Repositories"},{"location":"en/admin-en/installation-nginx-en/#3-install-the-wallarm-packages","text":"","title":"3. Install the Wallarm Packages"},{"location":"en/admin-en/installation-nginx-en/#install-the-requests-processing-and-postanalytics-on-the-same-server","text":"To run postanalytics and process the requests on the same server, you need to install the following packages: Wallarm module In-memory storage Tarantool. Postanalytics. Run the following command to install the required packages: Debian 8.x (jessie) apt-get install --no-install-recommends wallarm-node nginx-module-wallarm Debian 9.x (stretch) apt-get install --no-install-recommends wallarm-node nginx-module-wallarm Debian 10.x (buster) apt-get install --no-install-recommends wallarm-node nginx-module-wallarm Ubuntu 14.04 LTS (trusty) apt-get install --no-install-recommends wallarm-node nginx-module-wallarm Ubuntu 16.04 LTS (xenial) apt-get install --no-install-recommends wallarm-node nginx-module-wallarm Ubuntu 18.04 LTS (bionic) apt-get install --no-install-recommends wallarm-node nginx-module-wallarm CentOS 6.x yum install wallarm-node nginx-module-wallarm CentOS 7.x yum install wallarm-node nginx-module-wallarm Amazon Linux 2 yum install wallarm-node nginx-module-wallarm","title":"Install the Requests Processing and Postanalytics on the Same Server"},{"location":"en/admin-en/installation-nginx-en/#install-only-the-requests-processing-on-the-server","text":"To only process the requests on the server, you need to install the following package: Wallarm module Run the following command to install the required package: Debian 8.x (jessie) apt-get install --no-install-recommends wallarm-node-nginx nginx-module-wallarm Debian 9.x (stretch) apt-get install --no-install-recommends wallarm-node-nginx nginx-module-wallarm Debian 10.x (buster) apt-get install --no-install-recommends wallarm-node-nginx nginx-module-wallarm Ubuntu 14.04 LTS (trusty) apt-get install --no-install-recommends wallarm-node-nginx nginx-module-wallarm Ubuntu 16.04 LTS (xenial) apt-get install --no-install-recommends wallarm-node-nginx nginx-module-wallarm Ubuntu 18.04 LTS (bionic) apt-get install --no-install-recommends wallarm-node-nginx nginx-module-wallarm CentOS 6.x yum install wallarm-node-nginx nginx-module-wallarm CentOS 7.x yum install wallarm-node-nginx nginx-module-wallarm Amazon Linux 2 yum install wallarm-node-nginx nginx-module-wallarm","title":"Install Only the Requests Processing on the Server"},{"location":"en/admin-en/installation-nginx-en/#4-configure-postanalytics","text":"Info Skip this step if you installed postanalytics on a separate server as you already have your postanalytics configured. Postanalytics uses the in-memory storage Tarantool. You must set the amount of server RAM allocated to Tarantool. The amount of memory determines the quality of work of the statistical algorithms. The recommended value is 75% of the total server memory. For example, if the server has 32 GB of memory, the recommended allocation size is 24 GB. Allocate the operating memory size for Tarantool: Open for editing the configuration file of Tarantool: Debian 8.x (jessie) vi /etc/default/wallarm-tarantool Debian 9.x (stretch) vi /etc/default/wallarm-tarantool Debian 10.x (buster) vi /etc/default/wallarm-tarantool Ubuntu 14.04 LTS (trusty) vi /etc/default/wallarm-tarantool Ubuntu 16.04 LTS (xenial) vi /etc/default/wallarm-tarantool Ubuntu 18.04 LTS (bionic) vi /etc/default/wallarm-tarantool CentOS 6.x vi /etc/sysconfig/wallarm-tarantool CentOS 7.x vi /etc/sysconfig/wallarm-tarantool Amazon Linux 2 vi /etc/sysconfig/wallarm-tarantool Set the allocated memory size in the configuration file of Tarantool via the SLAB_ALLOC_ARENA directive. For example: SLAB_ALLOC_ARENA=24 Restart Tarantool: Debian 8.x (jessie) systemctl restart wallarm-tarantool Debian 9.x (stretch) systemctl restart wallarm-tarantool Debian 10.x (buster) systemctl restart wallarm-tarantool Ubuntu 14.04 LTS (trusty) service wallarm-tarantool restart Ubuntu 16.04 LTS (xenial) service wallarm-tarantool restart Ubuntu 18.04 LTS (bionic) service wallarm-tarantool restart CentOS 6.x service wallarm-tarantool restart CentOS 7.x systemctl restart wallarm-tarantool Amazon Linux 2 systemctl restart wallarm-tarantool","title":"4. Configure Postanalytics"},{"location":"en/admin-en/installation-nginx-en/#5-connect-the-wallarm-module","text":"Open the /etc/nginx/nginx.conf file. Ensure that you have the include /etc/nginx/conf.d/* line in the file. If you do not, add it. Add the following directive right after the worker_processes directive: load_module modules/ngx_http_wallarm_module.so; Configuration example with the added directive: user nginx; worker_processes auto; load_module modules/ngx_http_wallarm_module.so; error_log /var/log/nginx/error.log notice; pid /var/run/nginx.pid; Copy the configuration files for the system setup: cp /usr/share/doc/nginx-module-wallarm/examples/*.conf /etc/nginx/conf.d/","title":"5. Connect the Wallarm Module"},{"location":"en/admin-en/installation-nginx-en/#6-set-up-the-filter-node-for-using-a-proxy-server","text":"Info This setup step is intended for users who use their own proxy server for the operation of the protected web applications. If you do not use a proxy server, skip this step of the setup. You need to assign new values to the environment variables, which define the proxy server used, to configure Wallarm node for using your proxy server. Add new values of the environment variables to the /etc/environment file: Add https_proxy to define a proxy for the https protocol. Add http_proxy to define a proxy for the http protocol. Add no_proxy to define the list of the resources proxy should not be used for. Assign the <scheme>://<proxy_user>:<proxy_pass>@<host>:<port> string values to the https_proxy and http_proxy variables. <scheme> defines the protocol used. It should match the protocol that the current environment variable sets up proxy for. <proxy_user> defines the username for proxy authorization. <proxy_pass> defines the password for proxy authorization. <host> defines a host of the proxy server. <port> defines a port of the proxy server. Assign a \"<res_1>, <res_2>, <res_3>, <res_4>, ...\" array value, where <res_1> , <res_2> , <res_3> , and <res_4> are the IP addresses and/or domains, to the no_proxy variable to define a list of the resources which proxy should not be used for. This array should consist of IP addresses and/or domains. Resources that need to be addressed without a proxy Add the following IP addresses and domain to the list of the resources that have to be addressed without a proxy for the system to operate correctly: 127.0.0.1 , 127.0.0.8 , 127.0.0.9 , and localhost . The 127.0.0.8 and 127.0.0.9 IP addresses are used for the operation of the Wallarm filter node. The example of the correct /etc/environment file contents below demonstrates the following configuration: HTTPS and HTTP requests are proxied to the 1.2.3.4 host with the 1234 port, using the admin username and the 01234 password for authorization on the proxy server. Proxying is disabled for the requests sent to 127.0.0.1 , 127.0.0.8 , 127.0.0.9 , and localhost . https_proxy=http://admin:01234@1.2.3.4:1234 http_proxy=http://admin:01234@1.2.3.4:1234 no_proxy=\"127.0.0.1, 127.0.0.8, 127.0.0.9, localhost\"","title":"6. Set up the Filter Node for Using a Proxy Server"},{"location":"en/admin-en/installation-nginx-en/#7-connect-the-filter-node-to-the-wallarm-cloud","text":"API Access The API choice for your filter node depends on the Cloud you are using. Please, select the API accordingly: * If you are using https://my.wallarm.com/ , your node requires access to https://api.wallarm.com:444 . * If you are using https://us1.my.wallarm.com/ , your node requires access to https://us1.api.wallarm.com:444 . Ensure the access is not blocked by a firewall. The filter node interacts with the Wallarm cloud. To connect the node to the cloud using your cloud account requisites, proceed with the following steps: Make sure that your Wallarm account has the Administrator role enabled and two-factor authentication disabled, therefore allowing you to connect a filter node to the cloud. You can check the aforementioned parameters by navigating to the user account list in the Wallarm console. * If you are using <https://my.wallarm.com/>, proceed to the [following link][link-wl-console-users-eu] to check your user settings. * If you are using <https://us1.my.wallarm.com/>, proceed to the [following link][link-wl-console-users-us] to check your user settings. Run the addnode script in a system with the filter node: Info You have to pick the script to run depending on the Cloud you are using. * If you are using https://my.wallarm.com/ , run the script from the \u00abEU Cloud\u00bb tab below. * If you are using https://us1.my.wallarm.com/ , run the script from the \u00abUS Cloud\u00bb tab below. EU Cloud /usr/share/wallarm-common/addnode US Cloud /usr/share/wallarm-common/addnode -H us1.api.wallarm.com To specify the name of the created node, use the -n <node name> option. Provide your Wallarm account\u2019s login and password when prompted.","title":"7. Connect the Filter Node to the Wallarm Cloud"},{"location":"en/admin-en/installation-nginx-en/#8-configure-the-server-addresses-of-postanalytics","text":"Info Skip this step if you installed postanalytics and the filter node on the same server. Do this step if you installed postanalytics and the filter node on separate servers. Add the server address of postanalytics to /etc/nginx/conf.d/wallarm.conf : upstream wallarm_tarantool { server <ip1>:3313 max_fails=0 fail_timeout=0 max_conns=1; server <ip2>:3313 max_fails=0 fail_timeout=0 max_conns=1; keepalive 2; } ... wallarm_tarantool_upstream wallarm_tarantool; #### Warning:: Required conditions It is required that the following conditions are satisfied for the `max_conns` and the `keepalive` parameters: * The value of the `keepalive` parameter must not be lower than the number of the tarantool servers. * The value of the `max_conns` parameter must be specified for each of the upstream Tarantool servers to prevent the creation of excessive connections.","title":"8. Configure the Server Addresses of Postanalytics"},{"location":"en/admin-en/installation-nginx-en/#9-configure-the-filtration-mode","text":"The etc/nginx/conf.d directory contains NGINX and Wallarm filter node configuration files. By default, this directory contains the following configuration files: The default.conf file defines the configuration of NGINX. The wallarm.conf file defines the global configuration of Wallarm filter node. The wallarm-status.conf file defines the Wallarm monitoring configuration. You can create your own configuration files to define the operation of NGINX and Wallarm. It is recommended to create a separate configuration file with the server block for each group of the domains that should be processed in the same way. To see detailed information about working with NGINX configuration files, proceed to the official NGINX documentation . Wallarm directives define the operation logic of the Wallarm filter node. To see the list of Wallarm directives available, proceed to the Wallarm configuration options page.","title":"9. Configure the Filtration Mode"},{"location":"en/admin-en/installation-nginx-en/#a-configuration-file-example","text":"Let us suppose that you need to configure the server to work in the following conditions: Only HTTP traffic is processed. There are no HTTPS requests processed. The following domains receive the requests: example.com and www.example.com . All requests must be passed to the server 10.80.0.5 . All incoming requests are considered less than 1MB in size (default setting). The processing of a request takes no more than 60 seconds (default setting). Wallarm must operate in the monitor mode. Clients access the filter node directly, without an intermediate HTTP load balancer. Creating a configuration file You can create a custom NGINX configuration file (e.g. example.com.conf ) or modify the default NGINX configuration file ( default.conf ). When creating a custom configuration file, make sure that NGINX listens to the incoming connections on the free port. To meet the listed conditions, the contents of the configuration file must be the following: server { listen 80; listen [::]:80 ipv6only=on; # the domains for which traffic is processed server_name example.com; server_name www.example.com; # turn on the monitoring mode of traffic processing wallarm_mode monitoring; # wallarm_instance 1; location / { # setting the address for request forwarding proxy_pass http://10.80.0.5; proxy_set_header Host $host; proxy_set_header X-Real-IP $remote_addr; proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for; } }","title":"A Configuration File Example"},{"location":"en/admin-en/installation-nginx-en/#10-configure-logging","text":"Configure the filter node variables logging using NGINX. This will allow to perform a quick filter node diagnostics with the help of the NGINX log file.","title":"10. Configure Logging"},{"location":"en/admin-en/installation-nginx-en/#11-restart-nginx","text":"Providing user with root permission If you are running NGINX as a user that does not have root permission, add this user to the wallarm group using the following command: # usermod -aG wallarm &lt;user_name&gt; where <user_name> is the name of the user without root permission. Debian 8.x (jessie) systemctl restart nginx Debian 9.x (stretch) systemctl restart nginx Debian 10.x (buster) systemctl restart nginx Ubuntu 14.04 LTS (trusty) service nginx restart Ubuntu 16.04 LTS (xenial) service nginx restart Ubuntu 18.04 LTS (bionic) service nginx restart CentOS 6.x service nginx restart CentOS 7.x systemctl restart nginx Amazon Linux 2 systemctl restart nginx","title":"11. Restart NGINX"},{"location":"en/admin-en/installation-nginx-en/#the-installation-is-complete","text":"Check that the filter node runs and filters the traffic. See Check the filter node operation . #### Info:: Default Settings A freshly installed filter node operates in blocking mode (see the [`wallarm_mode`](../admin-en/configure-parameters-en.html#wallarmmode) directive description) by default. This may result in the inoperable [Wallarm scanner](../user-guides/cloud-ui/scanner/intro.md). If you plan to use the scanner, then you [need to perform additional actions](#adding-wallarm-scanner-addresses-to-the-whitelist) to render scanner operational.","title":"The Installation Is Complete"},{"location":"en/admin-en/installation-nginx-en/#additional-settings","text":"The filter node may require some additional configuration after installation. The document below lists a few of the typical setups that you can apply if needed. To get more information about other available settings, proceed to the \u201cConfiguration\u201d section of the Administrator\u2019s Guide .","title":"Additional Settings"},{"location":"en/admin-en/installation-nginx-en/#configuring-the-display-of-the-clients-real-ip","text":"If the filter node is deployed behind a proxy server or load balancer without any additional configuration, the request source address may not be equal to the actual IP address of the client. Instead, it may be equal to one of the IP addresses of the proxy server or the load balancer. In this case, if you want the filter node to receive the client's IP address as a request source address, you need to perform an additional configuration of the proxy server or the load balancer.","title":"Configuring the Display of the Client's Real IP"},{"location":"en/admin-en/installation-nginx-en/#adding-wallarm-scanner-addresses-to-the-whitelist","text":"The Wallarm scanner checks the resources of your company for vulnerabilities. Scanning is conducted using IP addresses from one of the following lists (depending on the type of Wallarm Cloud you are using): EU scanner addresses for EU Cloud users US scanner addresses for US Cloud users If you are using the Wallarm scanner, you need to configure the whitelists on your network scope security software (such as firewalls, intrusion detection systems, etc.) to contain Wallarm scanner IP addresses. For example, a Wallarm filter node with default settings is placed in the blocking mode, thus rendering the Wallarm scanner unable to scan the resources behind the filter node. To make the scanner operational again, whitelist the scanner's IP addresses on this filter node.","title":"Adding Wallarm Scanner Addresses to the Whitelist"},{"location":"en/admin-en/installation-nginx-en/#limiting-the-single-request-processing-time","text":"Use the wallarm_process_time_limit Wallarm directive to specify the limit of the duration for processing a single request by the filter node. If processing the request consumes more time than specified in the directive, then the information on the error is entered into the log file and the request is marked as an overlimit_res attack.","title":"Limiting the Single Request Processing Time"},{"location":"en/admin-en/installation-nginx-en/#limiting-the-server-reply-waiting-time","text":"Use the proxy_read_timeout NGINX directive to specify the timeout for reading the proxy server reply. If the server sends nothing during this time, the connection is closed.","title":"Limiting the Server Reply Waiting Time"},{"location":"en/admin-en/installation-nginx-en/#limiting-the-maximum-request-size","text":"Use the client_max_body_size NGINX directive to specify the limit for the maximum size of the body of the client's request. If this limit is exceeded, NGINX replies to the client with the 413 ( Payload Too Large ) code, also known as the Request Entity Too Large message.","title":"Limiting the Maximum Request Size"},{"location":"en/admin-en/installation-nginx-overview/","text":"Installation Options Overview \u00b6 The filter node that is used with NGINX or NGINX Plus consists of the following modules: The module that connects to NGINX (NGINX Plus) The postanalytics module The modules installation and configuration order depends on the way you install NGINX or NGINX Plus. This document contains the following sections: Modules Overview Links to particular module installation and configuration documents Modules Overview \u00b6 When the filter node is used to process requests, incoming traffic sequentially proceeds through initial processing and then processing by Wallarm modules. The initial traffic processing is performed by the module that connects to NGINX or NGINX Plus that is already installed in the system. Further traffic processing is conducted by the postanalytics module , which requires a significant amount of memory to work properly. Therefore, you can pick one of the following installation options: Installed on the same servers as NGINX/NGINX Plus (if server configurations allow this) Installed on a group of servers separate from NGINX/NGINX Plus Installing and Configuring the Modules \u00b6 Module for NGINX \u00b6 #### Warning:: Selecting the Module to Install The Wallarm module installation and connection procedures depend on the NGINX installation method you are using. The Wallarm module for NGINX can be connected by one of the following installation methods (links to instructions for each of the installation options are listed in the parenthesis): Building NGINX from the source files ( instruction ) Installing NGINX packages from the NGINX repository ( instruction ) Installing NGINX packages from the Debian repository ( instruction ) Installing NGINX packages from the CentOS repository ( instruction ) ####Info:: Deprecated Installation Option If you are using the Wallarm Node version 2.10 or lower , you can install an NGINX build from Wallarm that includes all components necessary for the filter node to work. Such a build only exists for NGINX. If you are using NGINX Plus, you need to [connect the Wallarm module to NGINX Plus][link-ig-nginxplus] even if the Wallarm Node version is 2.10 or lower. Module for NGINX Plus \u00b6 These instructions describe how to connect Wallarm to an NGINX Plus module. Postanalytics Module \u00b6 Instructions on the postanalytics module installation and configuration (either on the same server with NGINX/NGINX Plus or on a separate server) are located in the NGINX module installation and the NGINX Plus module installation sections.","title":"Installation Options Overview"},{"location":"en/admin-en/installation-nginx-overview/#installation-options-overview","text":"The filter node that is used with NGINX or NGINX Plus consists of the following modules: The module that connects to NGINX (NGINX Plus) The postanalytics module The modules installation and configuration order depends on the way you install NGINX or NGINX Plus. This document contains the following sections: Modules Overview Links to particular module installation and configuration documents","title":"Installation Options Overview"},{"location":"en/admin-en/installation-nginx-overview/#modules-overview","text":"When the filter node is used to process requests, incoming traffic sequentially proceeds through initial processing and then processing by Wallarm modules. The initial traffic processing is performed by the module that connects to NGINX or NGINX Plus that is already installed in the system. Further traffic processing is conducted by the postanalytics module , which requires a significant amount of memory to work properly. Therefore, you can pick one of the following installation options: Installed on the same servers as NGINX/NGINX Plus (if server configurations allow this) Installed on a group of servers separate from NGINX/NGINX Plus","title":"Modules Overview"},{"location":"en/admin-en/installation-nginx-overview/#installing-and-configuring-the-modules","text":"","title":"Installing and Configuring the Modules"},{"location":"en/admin-en/installation-nginx-overview/#module-for-nginx","text":"#### Warning:: Selecting the Module to Install The Wallarm module installation and connection procedures depend on the NGINX installation method you are using. The Wallarm module for NGINX can be connected by one of the following installation methods (links to instructions for each of the installation options are listed in the parenthesis): Building NGINX from the source files ( instruction ) Installing NGINX packages from the NGINX repository ( instruction ) Installing NGINX packages from the Debian repository ( instruction ) Installing NGINX packages from the CentOS repository ( instruction ) ####Info:: Deprecated Installation Option If you are using the Wallarm Node version 2.10 or lower , you can install an NGINX build from Wallarm that includes all components necessary for the filter node to work. Such a build only exists for NGINX. If you are using NGINX Plus, you need to [connect the Wallarm module to NGINX Plus][link-ig-nginxplus] even if the Wallarm Node version is 2.10 or lower.","title":"Module for NGINX"},{"location":"en/admin-en/installation-nginx-overview/#module-for-nginx-plus","text":"These instructions describe how to connect Wallarm to an NGINX Plus module.","title":"Module for NGINX Plus"},{"location":"en/admin-en/installation-nginx-overview/#postanalytics-module","text":"Instructions on the postanalytics module installation and configuration (either on the same server with NGINX/NGINX Plus or on a separate server) are located in the NGINX module installation and the NGINX Plus module installation sections.","title":"Postanalytics Module"},{"location":"en/admin-en/installation-nginxplus-en/","text":"Installing with NGINX Plus \u00b6 Installation Options \u00b6 The processing of requests in the filter node is done in two stages: Processing in NGINX-Wallarm. Postanalytics \u2013 statistical analysis of the processed requests. The processing is not memory demanding and can be put on front end servers without changing the server requirements. Postanalytics is memory demanding, which may require changes in the server configuration or installation of postanalytics on a separate server. Wallarm also has the option of installing postanalytics in a separate server pool. #### Warning:: Installation of postanalytics on a separate server If you are planning to install postanalytics on a separate server, you must install postanalytics first. See details in [Separate postanalytics installation](installation-postanalytics-en.md). To install the filter node with NGINX Plus, you must: Install NGINX Plus. Add the Wallarm repositories, from which you will download packages. Install the Wallarm packages. Configure postanalytics. Connect the Wallarm module. Set up the filter node for using a proxy server. Connect the filter node to the Wallarm cloud. Configure the server addresses of postanalytics. Configure the filtration mode. Configure logging. Restart NGINX Plus. Prerequisites Prior to taking any steps listed below, either disable or configure SELinux if it is installed on the operating system. Make sure that you execute all commands below as superuser (e.g. root ). 1. Install NGINX Plus \u00b6 See the official NGINX installation instructions . Installing on Amazon Linux 2 To install NGINX on Amazon Linux 2, use the CentOS 7 instruction. 2. Add the Wallarm Repositories \u00b6 The installation and updating of NGINX Plus with the Wallarm module is done from the Wallarm repositories. Depending on your operating system, run one of the commands: Debian 8.x (jessie) apt-get install dirmngr apt-key adv --keyserver keys.gnupg.net --recv-keys 72B865FD sh -c \"echo 'deb http://repo.wallarm.com/debian/wallarm-node jessie/2.14/' > /etc/apt/sources.list.d/wallarm.list\" apt-get update Debian 9.x (stretch) apt-get install dirmngr apt-key adv --keyserver keys.gnupg.net --recv-keys 72B865FD sh -c \"echo 'deb http://repo.wallarm.com/debian/wallarm-node stretch/2.14/' > /etc/apt/sources.list.d/wallarm.list\" apt-get update Debian 10.x (buster) apt-get install dirmngr apt-key adv --keyserver keys.gnupg.net --recv-keys 72B865FD sh -c \"echo 'deb http://repo.wallarm.com/debian/wallarm-node buster/2.14/' > /etc/apt/sources.list.d/wallarm.list\" apt-get update Ubuntu 14.04 LTS (trusty) apt-key adv --keyserver keys.gnupg.net --recv-keys 72B865FD sh -c \"echo 'deb http://repo.wallarm.com/ubuntu/wallarm-node trusty/2.14/' > /etc/apt/sources.list.d/wallarm.list\" apt-get update Ubuntu 16.04 LTS (xenial) apt-key adv --keyserver keys.gnupg.net --recv-keys 72B865FD sh -c \"echo 'deb http://repo.wallarm.com/ubuntu/wallarm-node xenial/2.14/' > /etc/apt/sources.list.d/wallarm.list\" apt-get update Ubuntu 18.04 LTS (bionic) apt-key adv --keyserver keys.gnupg.net --recv-keys 72B865FD sh -c \"echo 'deb http://repo.wallarm.com/ubuntu/wallarm-node bionic/2.14/' > /etc/apt/sources.list.d/wallarm.list\" apt-get update ``` CentOS 6.x yum install --enablerepo = extras -y epel-release centos-release-SCL rpm -i https://repo.wallarm.com/centos/wallarm-node/6/2.14/x86_64/Packages/wallarm-node-repo-1-4.el6.noarch.rpm CentOS 7.x yum install -y epel-release rpm -i https://repo.wallarm.com/centos/wallarm-node/7/2.14/x86_64/Packages/wallarm-node-repo-1-4.el7.noarch.rpm ``` Amazon Linux 2 yum install -y https://dl.fedoraproject.org/pub/epel/epel-release-latest-7.noarch.rpm rpm -i https://repo.wallarm.com/centos/wallarm-node/7/2.14/x86_64/Packages/wallarm-node-repo-1-4.el7.noarch.rpm Repository access Your system must have access to https://repo.wallarm.com to download the packages. Ensure the access is not blocked by a firewall. 3. Install the Wallarm Packages \u00b6 To run postanalytics and process the requests on the same server, you must install the following packages: NGINX Plus with the Wallarm module. Postanalytics. To only process the requests on the server, you must install the following package: nginx-plus-module-wallarm. Install the Requests Processing and Postanalytics on the Same Server \u00b6 {% termtabs name=\"Debian 8.x (jessie)\" -%} apt-get install --no-install-recommends wallarm-node nginx-plus-module-wallarm \u00b6 {%- tab name=\"Debian 9.x (stretch)\" -%} apt-get install --no-install-recommends wallarm-node nginx-plus-module-wallarm \u00b6 {%- tab name=\"Debian 10.x (buster)\" -%} apt-get install --no-install-recommends wallarm-node nginx-plus-module-wallarm \u00b6 {%- tab name=\"Ubuntu 14.04 LTS (trusty)\" -%} apt-get install --no-install-recommends wallarm-node nginx-plus-module-wallarm \u00b6 {%- tab name=\"Ubuntu 16.04 LTS (xenial)\" -%} apt-get install --no-install-recommends wallarm-node nginx-plus-module-wallarm \u00b6 {%- tab name=\"Ubuntu 18.04 LTS (bionic)\" -%} apt-get install --no-install-recommends wallarm-node nginx-plus-module-wallarm \u00b6 {%- tab name=\"CentOS 6.x\" -%} yum install wallarm-node nginx-plus-module-wallarm \u00b6 {%- tab name=\"CentOS 7.x\" -%} yum install wallarm-node nginx-plus-module-wallarm \u00b6 {%- tab name=\"Amazon Linux 2\" -%} yum install wallarm-node nginx-plus-module-wallarm \u00b6 {%- endtermtabs %} Install Only the Requests Processing \u00b6 {% termtabs name=\"Debian 8.x (jessie)\" -%} apt-get install --no-install-recommends wallarm-node-nginx nginx-plus-module-wallarm \u00b6 {%- tab name=\"Debian 9.x (stretch)\" -%} apt-get install --no-install-recommends wallarm-node-nginx nginx-plus-module-wallarm \u00b6 {%- tab name=\"Debian 10.x (buster)\" -%} apt-get install --no-install-recommends wallarm-node-nginx nginx-plus-module-wallarm \u00b6 {%- tab name=\"Ubuntu 14.04 LTS (trusty)\" -%} apt-get install --no-install-recommends wallarm-node-nginx nginx-plus-module-wallarm \u00b6 {%- tab name=\"Ubuntu 16.04 LTS (xenial)\" -%} apt-get install --no-install-recommends wallarm-node-nginx nginx-plus-module-wallarm \u00b6 {%- tab name=\"Ubuntu 18.04 LTS (bionic)\" -%} apt-get install --no-install-recommends wallarm-node-nginx nginx-plus-module-wallarm \u00b6 {%- tab name=\"CentOS 6.x\" -%} yum install wallarm-node-nginx nginx-plus-module-wallarm \u00b6 {%- tab name=\"CentOS 7.x\" -%} yum install wallarm-node-nginx nginx-plus-module-wallarm \u00b6 {%- tab name=\"Amazon Linux 2\" -%} yum install wallarm-node-nginx nginx-plus-module-wallarm \u00b6 {%- endtermtabs %} 4. Configure Postanalytics \u00b6 #### Info:: Skip this step if you installed postanalytics on a separate server as you already have your postanalytics configured. Postanalytics uses the in-memory storage Tarantool. You must set the amount of server RAM allocated to Tarantool. The amount of memory determines the quality of work of the statistical algorithms. The recommended value is 75% of the total server memory. For example, if the server has 32 GB of memory, the recommended allocation size is 24 GB. Allocate the operating memory size for Tarantool: Open for editing the configuration file of Tarantool: Debian 8.x (jessie) vi /etc/default/wallarm-tarantool Debian 9.x (stretch) vi /etc/default/wallarm-tarantool Debian 10.x (buster) vi /etc/default/wallarm-tarantool Ubuntu 14.04 LTS (trusty) vi /etc/default/wallarm-tarantool Ubuntu 16.04 LTS (xenial) vi /etc/default/wallarm-tarantool Ubuntu 18.04 LTS (bionic) vi /etc/default/wallarm-tarantool CentOS 6.x vi /etc/sysconfig/wallarm-tarantool CentOS 7.x vi /etc/sysconfig/wallarm-tarantool Amazon Linux 2 vi /etc/sysconfig/wallarm-tarantool Set the allocated memory size in the configuration file of Tarantool via the SLAB_ALLOC_ARENA directive. For example: SLAB_ALLOC_ARENA=24 Restart Tarantool: Debian 8.x (jessie) systemctl restart wallarm-tarantool Debian 9.x (stretch) systemctl restart wallarm-tarantool Debian 10.x (buster) systemctl restart wallarm-tarantool Ubuntu 14.04 LTS (trusty) service wallarm-tarantool restart Ubuntu 16.04 LTS (xenial) service wallarm-tarantool restart Ubuntu 18.04 LTS (bionic) service wallarm-tarantool restart CentOS 6.x service wallarm-tarantool restart CentOS 7.x systemctl restart wallarm-tarantool Amazon Linux 2 systemctl restart wallarm-tarantool 5. Connect the Wallarm Module \u00b6 In the file /etc/nginx/nginx.conf , add the following directive right after the worker_processes directive: load_module modules/ngx_http_wallarm_module.so; Confguration example with the added directive: user nginx; worker_processes auto; load_module modules/ngx_http_wallarm_module.so; error_log /var/log/nginx/error.log notice; pid /var/run/nginx.pid; Copy the configuration files for the system setup: $ cp /usr/share/doc/nginx-plus-module-wallarm/examples/*.conf /etc/nginx/conf.d/ 6. Set up the Filter Node for Using a Proxy Server \u00b6 Info This setup step is intended for users who use their own proxy server for the operation of the protected web applications. If you do not use a proxy server, skip this step of the setup. You need to assign new values to the environment variables, which define the proxy server used, to configure Wallarm node for using your proxy server. Add new values of the environment variables to the /etc/environment file: Add https_proxy to define a proxy for the https protocol. Add http_proxy to define a proxy for the http protocol. Add no_proxy to define the list of the resources proxy should not be used for. Assign the <scheme>://<proxy_user>:<proxy_pass>@<host>:<port> string values to the https_proxy and http_proxy variables. <scheme> defines the protocol used. It should match the protocol that the current environment variable sets up proxy for. <proxy_user> defines the username for proxy authorization. <proxy_pass> defines the password for proxy authorization. <host> defines a host of the proxy server. <port> defines a port of the proxy server. Assign a \"<res_1>, <res_2>, <res_3>, <res_4>, ...\" array value, where <res_1> , <res_2> , <res_3> , and <res_4> are the IP addresses and/or domains, to the no_proxy variable to define a list of the resources which proxy should not be used for. This array should consist of IP addresses and/or domains. Resources that need to be addressed without a proxy Add the following IP addresses and domain to the list of the resources that have to be addressed without a proxy for the system to operate correctly: 127.0.0.1 , 127.0.0.8 , 127.0.0.9 , and localhost . The 127.0.0.8 and 127.0.0.9 IP addresses are used for the operation of the Wallarm filter node. The example of the correct /etc/environment file contents below demonstrates the following configuration: HTTPS and HTTP requests are proxied to the 1.2.3.4 host with the 1234 port, using the admin username and the 01234 password for authorization on the proxy server. Proxying is disabled for the requests sent to 127.0.0.1 , 127.0.0.8 , 127.0.0.9 , and localhost . https_proxy=http://admin:01234@1.2.3.4:1234 http_proxy=http://admin:01234@1.2.3.4:1234 no_proxy=\"127.0.0.1, 127.0.0.8, 127.0.0.9, localhost\" 7. Connect the Filter Node to the Wallarm Cloud \u00b6 API Access The API choice for your filter node depends on the Cloud you are using. Please, select the API accordingly: * If you are using https://my.wallarm.com/ , your node requires access to https://api.wallarm.com:444 . * If you are using https://us1.my.wallarm.com/ , your node requires access to https://us1.api.wallarm.com:444 . Ensure the access is not blocked by a firewall. The filter node interacts with the Wallarm cloud. To connect the node to the cloud using your cloud account requisites, proceed with the following steps: Make sure that your Wallarm account has the Administrator role enabled and two-factor authentication disabled, therefore allowing you to connect a filter node to the cloud. You can check the aforementioned parameters by navigating to the user account list in the Wallarm console. * If you are using <https://my.wallarm.com/>, proceed to the [following link][link-wl-console-users-eu] to check your user settings. * If you are using <https://us1.my.wallarm.com/>, proceed to the [following link][link-wl-console-users-us] to check your user settings. Run the addnode script in a system with the filter node: Info You have to pick the script to run depending on the Cloud you are using. * If you are using https://my.wallarm.com/ , run the script from the \u00abEU Cloud\u00bb tab below. * If you are using https://us1.my.wallarm.com/ , run the script from the \u00abUS Cloud\u00bb tab below. EU Cloud /usr/share/wallarm-common/addnode US Cloud /usr/share/wallarm-common/addnode -H us1.api.wallarm.com To specify the name of the created node, use the -n <node name> option. Provide your Wallarm account\u2019s login and password when prompted. 8. Configure the Server Addresses of Postanalytics \u00b6 #### Info:: * Skip this step if you installed postanalytics and the filter node on the same server. * Do this step if you installed postanalytics and the filter node on separate servers. Add the server address of postanalytics to /etc/nginx/conf.d/wallarm.conf : upstream wallarm_tarantool { server <ip1>:3313 max_fails=0 fail_timeout=0 max_conns=1; server <ip2>:3313 max_fails=0 fail_timeout=0 max_conns=1; keepalive 2; } ... wallarm_tarantool_upstream wallarm_tarantool; #### Warning:: Required conditions It is required that the following conditions are satisfied for the `max_conns` and the `keepalive` parameters: * The value of the `keepalive` parameter must not be lower than the number of the tarantool servers. * The value of the `max_conns` parameter must be specified for each of the upstream Tarantool servers to prevent the creation of excessive connections. 9. Configure the Filtration Mode \u00b6 The etc/nginx/conf.d directory contains NGINX and Wallarm filter node configuration files. By default, this directory contains the following configuration files: The default.conf file defines the configuration of NGINX. The wallarm.conf file defines the global configuration of Wallarm filter node. The wallarm-status.conf file defines the Wallarm monitoring configuration. You can create your own configuration files to define the operation of NGINX and Wallarm. It is recommended to create a separate configuration file with the server block for each group of the domains that should be processed in the same way. To see detailed information about working with NGINX configuration files, proceed to the official NGINX documentation . Wallarm directives define the operation logic of the Wallarm filter node. To see the list of Wallarm directives available, proceed to the Wallarm configuration options page. A Configuration File Example \u00b6 Let us suppose that you need to configure the server to work in the following conditions: Only HTTP traffic is processed. There are no HTTPS requests processed. The following domains receive the requests: example.com and www.example.com . All requests must be passed to the server 10.80.0.5 . All incoming requests are considered less than 1MB in size (default setting). The processing of a request takes no more than 60 seconds (default setting). Wallarm must operate in the monitor mode. Clients access the filter node directly, without an intermediate HTTP load balancer. Creating a configuration file You can create a custom NGINX configuration file (e.g. example.com.conf ) or modify the default NGINX configuration file ( default.conf ). When creating a custom configuration file, make sure that NGINX listens to the incoming connections on the free port. To meet the listed conditions, the contents of the configuration file must be the following: server { listen 80; listen [::]:80 ipv6only=on; # the domains for which traffic is processed server_name example.com; server_name www.example.com; # turn on the monitoring mode of traffic processing wallarm_mode monitoring; # wallarm_instance 1; location / { # setting the address for request forwarding proxy_pass http://10.80.0.5; proxy_set_header Host $host; proxy_set_header X-Real-IP $remote_addr; proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for; } } 10. Configure Logging \u00b6 Configure the filter node variables logging using NGINX. This will allow to perform a quick filter node diagnostics with the help of the NGINX log file. 11. Restart NGINX \u00b6 Providing user with root permission If you are running NGINX as a user that does not have root permission, add this user to the wallarm group using the following command: # usermod -aG wallarm &lt;user_name&gt; where <user_name> is the name of the user without root permission. Debian 8.x (jessie) systemctl restart nginx Debian 9.x (stretch) systemctl restart nginx Debian 10.x (buster) systemctl restart nginx Ubuntu 14.04 LTS (trusty) service nginx restart Ubuntu 16.04 LTS (xenial) service nginx restart Ubuntu 18.04 LTS (bionic) service nginx restart CentOS 6.x service nginx restart CentOS 7.x systemctl restart nginx Amazon Linux 2 systemctl restart nginx The Installation Is Complete \u00b6 Check that the filter node runs and filters the traffic. See Check the filter node operation . #### Info:: Default Settings A freshly installed filter node operates in blocking mode (see the [`wallarm_mode`](../admin-en/configure-parameters-en.html#wallarmmode) directive description) by default. This may result in the inoperable [Wallarm scanner](../user-guides/cloud-ui/scanner/intro.md). If you plan to use the scanner, then you [need to perform additional actions](#adding-wallarm-scanner-addresses-to-the-whitelist) to render scanner operational. Additional Settings \u00b6 The filter node may require some additional configuration after installation. The document below lists a few of the typical setups that you can apply if needed. To get more information about other available settings, proceed to the \u201cConfiguration\u201d section of the Administrator\u2019s Guide . Configuring the Display of the Client's Real IP \u00b6 If the filter node is deployed behind a proxy server or load balancer without any additional configuration, the request source address may not be equal to the actual IP address of the client. Instead, it may be equal to one of the IP addresses of the proxy server or the load balancer. In this case, if you want the filter node to receive the client's IP address as a request source address, you need to perform an additional configuration of the proxy server or the load balancer. Adding Wallarm Scanner Addresses to the Whitelist \u00b6 The Wallarm scanner checks the resources of your company for vulnerabilities. Scanning is conducted using IP addresses from one of the following lists (depending on the type of Wallarm Cloud you are using): EU scanner addresses for EU Cloud users US scanner addresses for US Cloud users If you are using the Wallarm scanner, you need to configure the whitelists on your network scope security software (such as firewalls, intrusion detection systems, etc.) to contain Wallarm scanner IP addresses. For example, a Wallarm filter node with default settings is placed in the blocking mode, thus rendering the Wallarm scanner unable to scan the resources behind the filter node. To make the scanner operational again, whitelist the scanner's IP addresses on this filter node. Limiting the Single Request Processing Time \u00b6 Use the wallarm_process_time_limit Wallarm directive to specify the limit of the duration for processing a single request by the filter node. If processing the request consumes more time than specified in the directive, then the information on the error is entered into the log file and the request is marked as an overlimit_res attack. Limiting the Server Reply Waiting Time \u00b6 Use the proxy_read_timeout NGINX directive to specify the timeout for reading the proxy server reply. If the server sends nothing during this time, the connection is closed. Limiting the Maximum Request Size \u00b6 Use the client_max_body_size NGINX directive to specify the limit for the maximum size of the body of the client's request. If this limit is exceeded, NGINX replies to the client with the 413 ( Payload Too Large ) code, also known as the Request Entity Too Large message.","title":"Installing with NGINX Plus"},{"location":"en/admin-en/installation-nginxplus-en/#installing-with-nginx-plus","text":"","title":"Installing with NGINX Plus"},{"location":"en/admin-en/installation-nginxplus-en/#installation-options","text":"The processing of requests in the filter node is done in two stages: Processing in NGINX-Wallarm. Postanalytics \u2013 statistical analysis of the processed requests. The processing is not memory demanding and can be put on front end servers without changing the server requirements. Postanalytics is memory demanding, which may require changes in the server configuration or installation of postanalytics on a separate server. Wallarm also has the option of installing postanalytics in a separate server pool. #### Warning:: Installation of postanalytics on a separate server If you are planning to install postanalytics on a separate server, you must install postanalytics first. See details in [Separate postanalytics installation](installation-postanalytics-en.md). To install the filter node with NGINX Plus, you must: Install NGINX Plus. Add the Wallarm repositories, from which you will download packages. Install the Wallarm packages. Configure postanalytics. Connect the Wallarm module. Set up the filter node for using a proxy server. Connect the filter node to the Wallarm cloud. Configure the server addresses of postanalytics. Configure the filtration mode. Configure logging. Restart NGINX Plus. Prerequisites Prior to taking any steps listed below, either disable or configure SELinux if it is installed on the operating system. Make sure that you execute all commands below as superuser (e.g. root ).","title":"Installation Options"},{"location":"en/admin-en/installation-nginxplus-en/#1-install-nginx-plus","text":"See the official NGINX installation instructions . Installing on Amazon Linux 2 To install NGINX on Amazon Linux 2, use the CentOS 7 instruction.","title":"1. Install NGINX Plus"},{"location":"en/admin-en/installation-nginxplus-en/#2-add-the-wallarm-repositories","text":"The installation and updating of NGINX Plus with the Wallarm module is done from the Wallarm repositories. Depending on your operating system, run one of the commands: Debian 8.x (jessie) apt-get install dirmngr apt-key adv --keyserver keys.gnupg.net --recv-keys 72B865FD sh -c \"echo 'deb http://repo.wallarm.com/debian/wallarm-node jessie/2.14/' > /etc/apt/sources.list.d/wallarm.list\" apt-get update Debian 9.x (stretch) apt-get install dirmngr apt-key adv --keyserver keys.gnupg.net --recv-keys 72B865FD sh -c \"echo 'deb http://repo.wallarm.com/debian/wallarm-node stretch/2.14/' > /etc/apt/sources.list.d/wallarm.list\" apt-get update Debian 10.x (buster) apt-get install dirmngr apt-key adv --keyserver keys.gnupg.net --recv-keys 72B865FD sh -c \"echo 'deb http://repo.wallarm.com/debian/wallarm-node buster/2.14/' > /etc/apt/sources.list.d/wallarm.list\" apt-get update Ubuntu 14.04 LTS (trusty) apt-key adv --keyserver keys.gnupg.net --recv-keys 72B865FD sh -c \"echo 'deb http://repo.wallarm.com/ubuntu/wallarm-node trusty/2.14/' > /etc/apt/sources.list.d/wallarm.list\" apt-get update Ubuntu 16.04 LTS (xenial) apt-key adv --keyserver keys.gnupg.net --recv-keys 72B865FD sh -c \"echo 'deb http://repo.wallarm.com/ubuntu/wallarm-node xenial/2.14/' > /etc/apt/sources.list.d/wallarm.list\" apt-get update Ubuntu 18.04 LTS (bionic) apt-key adv --keyserver keys.gnupg.net --recv-keys 72B865FD sh -c \"echo 'deb http://repo.wallarm.com/ubuntu/wallarm-node bionic/2.14/' > /etc/apt/sources.list.d/wallarm.list\" apt-get update ``` CentOS 6.x yum install --enablerepo = extras -y epel-release centos-release-SCL rpm -i https://repo.wallarm.com/centos/wallarm-node/6/2.14/x86_64/Packages/wallarm-node-repo-1-4.el6.noarch.rpm CentOS 7.x yum install -y epel-release rpm -i https://repo.wallarm.com/centos/wallarm-node/7/2.14/x86_64/Packages/wallarm-node-repo-1-4.el7.noarch.rpm ``` Amazon Linux 2 yum install -y https://dl.fedoraproject.org/pub/epel/epel-release-latest-7.noarch.rpm rpm -i https://repo.wallarm.com/centos/wallarm-node/7/2.14/x86_64/Packages/wallarm-node-repo-1-4.el7.noarch.rpm Repository access Your system must have access to https://repo.wallarm.com to download the packages. Ensure the access is not blocked by a firewall.","title":"2. Add the Wallarm Repositories"},{"location":"en/admin-en/installation-nginxplus-en/#3-install-the-wallarm-packages","text":"To run postanalytics and process the requests on the same server, you must install the following packages: NGINX Plus with the Wallarm module. Postanalytics. To only process the requests on the server, you must install the following package: nginx-plus-module-wallarm.","title":"3. Install the Wallarm Packages"},{"location":"en/admin-en/installation-nginxplus-en/#install-the-requests-processing-and-postanalytics-on-the-same-server","text":"{% termtabs name=\"Debian 8.x (jessie)\" -%}","title":"Install the Requests Processing and Postanalytics on the Same Server"},{"location":"en/admin-en/installation-nginxplus-en/#apt-get-install-no-install-recommends-wallarm-node-nginx-plus-module-wallarm","text":"{%- tab name=\"Debian 9.x (stretch)\" -%}","title":"apt-get install --no-install-recommends wallarm-node nginx-plus-module-wallarm"},{"location":"en/admin-en/installation-nginxplus-en/#apt-get-install-no-install-recommends-wallarm-node-nginx-plus-module-wallarm_1","text":"{%- tab name=\"Debian 10.x (buster)\" -%}","title":"apt-get install --no-install-recommends wallarm-node nginx-plus-module-wallarm"},{"location":"en/admin-en/installation-nginxplus-en/#apt-get-install-no-install-recommends-wallarm-node-nginx-plus-module-wallarm_2","text":"{%- tab name=\"Ubuntu 14.04 LTS (trusty)\" -%}","title":"apt-get install --no-install-recommends wallarm-node nginx-plus-module-wallarm"},{"location":"en/admin-en/installation-nginxplus-en/#apt-get-install-no-install-recommends-wallarm-node-nginx-plus-module-wallarm_3","text":"{%- tab name=\"Ubuntu 16.04 LTS (xenial)\" -%}","title":"apt-get install --no-install-recommends wallarm-node nginx-plus-module-wallarm"},{"location":"en/admin-en/installation-nginxplus-en/#apt-get-install-no-install-recommends-wallarm-node-nginx-plus-module-wallarm_4","text":"{%- tab name=\"Ubuntu 18.04 LTS (bionic)\" -%}","title":"apt-get install --no-install-recommends wallarm-node nginx-plus-module-wallarm"},{"location":"en/admin-en/installation-nginxplus-en/#apt-get-install-no-install-recommends-wallarm-node-nginx-plus-module-wallarm_5","text":"{%- tab name=\"CentOS 6.x\" -%}","title":"apt-get install --no-install-recommends wallarm-node nginx-plus-module-wallarm"},{"location":"en/admin-en/installation-nginxplus-en/#yum-install-wallarm-node-nginx-plus-module-wallarm","text":"{%- tab name=\"CentOS 7.x\" -%}","title":"yum install wallarm-node nginx-plus-module-wallarm"},{"location":"en/admin-en/installation-nginxplus-en/#yum-install-wallarm-node-nginx-plus-module-wallarm_1","text":"{%- tab name=\"Amazon Linux 2\" -%}","title":"yum install wallarm-node nginx-plus-module-wallarm"},{"location":"en/admin-en/installation-nginxplus-en/#yum-install-wallarm-node-nginx-plus-module-wallarm_2","text":"{%- endtermtabs %}","title":"yum install wallarm-node nginx-plus-module-wallarm"},{"location":"en/admin-en/installation-nginxplus-en/#install-only-the-requests-processing","text":"{% termtabs name=\"Debian 8.x (jessie)\" -%}","title":"Install Only the Requests Processing"},{"location":"en/admin-en/installation-nginxplus-en/#apt-get-install-no-install-recommends-wallarm-node-nginx-nginx-plus-module-wallarm","text":"{%- tab name=\"Debian 9.x (stretch)\" -%}","title":"apt-get install --no-install-recommends wallarm-node-nginx nginx-plus-module-wallarm"},{"location":"en/admin-en/installation-nginxplus-en/#apt-get-install-no-install-recommends-wallarm-node-nginx-nginx-plus-module-wallarm_1","text":"{%- tab name=\"Debian 10.x (buster)\" -%}","title":"apt-get install --no-install-recommends wallarm-node-nginx nginx-plus-module-wallarm"},{"location":"en/admin-en/installation-nginxplus-en/#apt-get-install-no-install-recommends-wallarm-node-nginx-nginx-plus-module-wallarm_2","text":"{%- tab name=\"Ubuntu 14.04 LTS (trusty)\" -%}","title":"apt-get install --no-install-recommends wallarm-node-nginx nginx-plus-module-wallarm"},{"location":"en/admin-en/installation-nginxplus-en/#apt-get-install-no-install-recommends-wallarm-node-nginx-nginx-plus-module-wallarm_3","text":"{%- tab name=\"Ubuntu 16.04 LTS (xenial)\" -%}","title":"apt-get install --no-install-recommends wallarm-node-nginx nginx-plus-module-wallarm"},{"location":"en/admin-en/installation-nginxplus-en/#apt-get-install-no-install-recommends-wallarm-node-nginx-nginx-plus-module-wallarm_4","text":"{%- tab name=\"Ubuntu 18.04 LTS (bionic)\" -%}","title":"apt-get install --no-install-recommends wallarm-node-nginx nginx-plus-module-wallarm"},{"location":"en/admin-en/installation-nginxplus-en/#apt-get-install-no-install-recommends-wallarm-node-nginx-nginx-plus-module-wallarm_5","text":"{%- tab name=\"CentOS 6.x\" -%}","title":"apt-get install --no-install-recommends wallarm-node-nginx nginx-plus-module-wallarm"},{"location":"en/admin-en/installation-nginxplus-en/#yum-install-wallarm-node-nginx-nginx-plus-module-wallarm","text":"{%- tab name=\"CentOS 7.x\" -%}","title":"yum install wallarm-node-nginx nginx-plus-module-wallarm"},{"location":"en/admin-en/installation-nginxplus-en/#yum-install-wallarm-node-nginx-nginx-plus-module-wallarm_1","text":"{%- tab name=\"Amazon Linux 2\" -%}","title":"yum install wallarm-node-nginx nginx-plus-module-wallarm"},{"location":"en/admin-en/installation-nginxplus-en/#yum-install-wallarm-node-nginx-nginx-plus-module-wallarm_2","text":"{%- endtermtabs %}","title":"yum install wallarm-node-nginx nginx-plus-module-wallarm"},{"location":"en/admin-en/installation-nginxplus-en/#4-configure-postanalytics","text":"#### Info:: Skip this step if you installed postanalytics on a separate server as you already have your postanalytics configured. Postanalytics uses the in-memory storage Tarantool. You must set the amount of server RAM allocated to Tarantool. The amount of memory determines the quality of work of the statistical algorithms. The recommended value is 75% of the total server memory. For example, if the server has 32 GB of memory, the recommended allocation size is 24 GB. Allocate the operating memory size for Tarantool: Open for editing the configuration file of Tarantool: Debian 8.x (jessie) vi /etc/default/wallarm-tarantool Debian 9.x (stretch) vi /etc/default/wallarm-tarantool Debian 10.x (buster) vi /etc/default/wallarm-tarantool Ubuntu 14.04 LTS (trusty) vi /etc/default/wallarm-tarantool Ubuntu 16.04 LTS (xenial) vi /etc/default/wallarm-tarantool Ubuntu 18.04 LTS (bionic) vi /etc/default/wallarm-tarantool CentOS 6.x vi /etc/sysconfig/wallarm-tarantool CentOS 7.x vi /etc/sysconfig/wallarm-tarantool Amazon Linux 2 vi /etc/sysconfig/wallarm-tarantool Set the allocated memory size in the configuration file of Tarantool via the SLAB_ALLOC_ARENA directive. For example: SLAB_ALLOC_ARENA=24 Restart Tarantool: Debian 8.x (jessie) systemctl restart wallarm-tarantool Debian 9.x (stretch) systemctl restart wallarm-tarantool Debian 10.x (buster) systemctl restart wallarm-tarantool Ubuntu 14.04 LTS (trusty) service wallarm-tarantool restart Ubuntu 16.04 LTS (xenial) service wallarm-tarantool restart Ubuntu 18.04 LTS (bionic) service wallarm-tarantool restart CentOS 6.x service wallarm-tarantool restart CentOS 7.x systemctl restart wallarm-tarantool Amazon Linux 2 systemctl restart wallarm-tarantool","title":"4. Configure Postanalytics"},{"location":"en/admin-en/installation-nginxplus-en/#5-connect-the-wallarm-module","text":"In the file /etc/nginx/nginx.conf , add the following directive right after the worker_processes directive: load_module modules/ngx_http_wallarm_module.so; Confguration example with the added directive: user nginx; worker_processes auto; load_module modules/ngx_http_wallarm_module.so; error_log /var/log/nginx/error.log notice; pid /var/run/nginx.pid; Copy the configuration files for the system setup: $ cp /usr/share/doc/nginx-plus-module-wallarm/examples/*.conf /etc/nginx/conf.d/","title":"5. Connect the Wallarm Module"},{"location":"en/admin-en/installation-nginxplus-en/#6-set-up-the-filter-node-for-using-a-proxy-server","text":"Info This setup step is intended for users who use their own proxy server for the operation of the protected web applications. If you do not use a proxy server, skip this step of the setup. You need to assign new values to the environment variables, which define the proxy server used, to configure Wallarm node for using your proxy server. Add new values of the environment variables to the /etc/environment file: Add https_proxy to define a proxy for the https protocol. Add http_proxy to define a proxy for the http protocol. Add no_proxy to define the list of the resources proxy should not be used for. Assign the <scheme>://<proxy_user>:<proxy_pass>@<host>:<port> string values to the https_proxy and http_proxy variables. <scheme> defines the protocol used. It should match the protocol that the current environment variable sets up proxy for. <proxy_user> defines the username for proxy authorization. <proxy_pass> defines the password for proxy authorization. <host> defines a host of the proxy server. <port> defines a port of the proxy server. Assign a \"<res_1>, <res_2>, <res_3>, <res_4>, ...\" array value, where <res_1> , <res_2> , <res_3> , and <res_4> are the IP addresses and/or domains, to the no_proxy variable to define a list of the resources which proxy should not be used for. This array should consist of IP addresses and/or domains. Resources that need to be addressed without a proxy Add the following IP addresses and domain to the list of the resources that have to be addressed without a proxy for the system to operate correctly: 127.0.0.1 , 127.0.0.8 , 127.0.0.9 , and localhost . The 127.0.0.8 and 127.0.0.9 IP addresses are used for the operation of the Wallarm filter node. The example of the correct /etc/environment file contents below demonstrates the following configuration: HTTPS and HTTP requests are proxied to the 1.2.3.4 host with the 1234 port, using the admin username and the 01234 password for authorization on the proxy server. Proxying is disabled for the requests sent to 127.0.0.1 , 127.0.0.8 , 127.0.0.9 , and localhost . https_proxy=http://admin:01234@1.2.3.4:1234 http_proxy=http://admin:01234@1.2.3.4:1234 no_proxy=\"127.0.0.1, 127.0.0.8, 127.0.0.9, localhost\"","title":"6. Set up the Filter Node for Using a Proxy Server"},{"location":"en/admin-en/installation-nginxplus-en/#7-connect-the-filter-node-to-the-wallarm-cloud","text":"API Access The API choice for your filter node depends on the Cloud you are using. Please, select the API accordingly: * If you are using https://my.wallarm.com/ , your node requires access to https://api.wallarm.com:444 . * If you are using https://us1.my.wallarm.com/ , your node requires access to https://us1.api.wallarm.com:444 . Ensure the access is not blocked by a firewall. The filter node interacts with the Wallarm cloud. To connect the node to the cloud using your cloud account requisites, proceed with the following steps: Make sure that your Wallarm account has the Administrator role enabled and two-factor authentication disabled, therefore allowing you to connect a filter node to the cloud. You can check the aforementioned parameters by navigating to the user account list in the Wallarm console. * If you are using <https://my.wallarm.com/>, proceed to the [following link][link-wl-console-users-eu] to check your user settings. * If you are using <https://us1.my.wallarm.com/>, proceed to the [following link][link-wl-console-users-us] to check your user settings. Run the addnode script in a system with the filter node: Info You have to pick the script to run depending on the Cloud you are using. * If you are using https://my.wallarm.com/ , run the script from the \u00abEU Cloud\u00bb tab below. * If you are using https://us1.my.wallarm.com/ , run the script from the \u00abUS Cloud\u00bb tab below. EU Cloud /usr/share/wallarm-common/addnode US Cloud /usr/share/wallarm-common/addnode -H us1.api.wallarm.com To specify the name of the created node, use the -n <node name> option. Provide your Wallarm account\u2019s login and password when prompted.","title":"7. Connect the Filter Node to the Wallarm Cloud"},{"location":"en/admin-en/installation-nginxplus-en/#8-configure-the-server-addresses-of-postanalytics","text":"#### Info:: * Skip this step if you installed postanalytics and the filter node on the same server. * Do this step if you installed postanalytics and the filter node on separate servers. Add the server address of postanalytics to /etc/nginx/conf.d/wallarm.conf : upstream wallarm_tarantool { server <ip1>:3313 max_fails=0 fail_timeout=0 max_conns=1; server <ip2>:3313 max_fails=0 fail_timeout=0 max_conns=1; keepalive 2; } ... wallarm_tarantool_upstream wallarm_tarantool; #### Warning:: Required conditions It is required that the following conditions are satisfied for the `max_conns` and the `keepalive` parameters: * The value of the `keepalive` parameter must not be lower than the number of the tarantool servers. * The value of the `max_conns` parameter must be specified for each of the upstream Tarantool servers to prevent the creation of excessive connections.","title":"8. Configure the Server Addresses of Postanalytics"},{"location":"en/admin-en/installation-nginxplus-en/#9-configure-the-filtration-mode","text":"The etc/nginx/conf.d directory contains NGINX and Wallarm filter node configuration files. By default, this directory contains the following configuration files: The default.conf file defines the configuration of NGINX. The wallarm.conf file defines the global configuration of Wallarm filter node. The wallarm-status.conf file defines the Wallarm monitoring configuration. You can create your own configuration files to define the operation of NGINX and Wallarm. It is recommended to create a separate configuration file with the server block for each group of the domains that should be processed in the same way. To see detailed information about working with NGINX configuration files, proceed to the official NGINX documentation . Wallarm directives define the operation logic of the Wallarm filter node. To see the list of Wallarm directives available, proceed to the Wallarm configuration options page.","title":"9. Configure the Filtration Mode"},{"location":"en/admin-en/installation-nginxplus-en/#a-configuration-file-example","text":"Let us suppose that you need to configure the server to work in the following conditions: Only HTTP traffic is processed. There are no HTTPS requests processed. The following domains receive the requests: example.com and www.example.com . All requests must be passed to the server 10.80.0.5 . All incoming requests are considered less than 1MB in size (default setting). The processing of a request takes no more than 60 seconds (default setting). Wallarm must operate in the monitor mode. Clients access the filter node directly, without an intermediate HTTP load balancer. Creating a configuration file You can create a custom NGINX configuration file (e.g. example.com.conf ) or modify the default NGINX configuration file ( default.conf ). When creating a custom configuration file, make sure that NGINX listens to the incoming connections on the free port. To meet the listed conditions, the contents of the configuration file must be the following: server { listen 80; listen [::]:80 ipv6only=on; # the domains for which traffic is processed server_name example.com; server_name www.example.com; # turn on the monitoring mode of traffic processing wallarm_mode monitoring; # wallarm_instance 1; location / { # setting the address for request forwarding proxy_pass http://10.80.0.5; proxy_set_header Host $host; proxy_set_header X-Real-IP $remote_addr; proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for; } }","title":"A Configuration File Example"},{"location":"en/admin-en/installation-nginxplus-en/#10-configure-logging","text":"Configure the filter node variables logging using NGINX. This will allow to perform a quick filter node diagnostics with the help of the NGINX log file.","title":"10. Configure Logging"},{"location":"en/admin-en/installation-nginxplus-en/#11-restart-nginx","text":"Providing user with root permission If you are running NGINX as a user that does not have root permission, add this user to the wallarm group using the following command: # usermod -aG wallarm &lt;user_name&gt; where <user_name> is the name of the user without root permission. Debian 8.x (jessie) systemctl restart nginx Debian 9.x (stretch) systemctl restart nginx Debian 10.x (buster) systemctl restart nginx Ubuntu 14.04 LTS (trusty) service nginx restart Ubuntu 16.04 LTS (xenial) service nginx restart Ubuntu 18.04 LTS (bionic) service nginx restart CentOS 6.x service nginx restart CentOS 7.x systemctl restart nginx Amazon Linux 2 systemctl restart nginx","title":"11. Restart NGINX"},{"location":"en/admin-en/installation-nginxplus-en/#the-installation-is-complete","text":"Check that the filter node runs and filters the traffic. See Check the filter node operation . #### Info:: Default Settings A freshly installed filter node operates in blocking mode (see the [`wallarm_mode`](../admin-en/configure-parameters-en.html#wallarmmode) directive description) by default. This may result in the inoperable [Wallarm scanner](../user-guides/cloud-ui/scanner/intro.md). If you plan to use the scanner, then you [need to perform additional actions](#adding-wallarm-scanner-addresses-to-the-whitelist) to render scanner operational.","title":"The Installation Is Complete"},{"location":"en/admin-en/installation-nginxplus-en/#additional-settings","text":"The filter node may require some additional configuration after installation. The document below lists a few of the typical setups that you can apply if needed. To get more information about other available settings, proceed to the \u201cConfiguration\u201d section of the Administrator\u2019s Guide .","title":"Additional Settings"},{"location":"en/admin-en/installation-nginxplus-en/#configuring-the-display-of-the-clients-real-ip","text":"If the filter node is deployed behind a proxy server or load balancer without any additional configuration, the request source address may not be equal to the actual IP address of the client. Instead, it may be equal to one of the IP addresses of the proxy server or the load balancer. In this case, if you want the filter node to receive the client's IP address as a request source address, you need to perform an additional configuration of the proxy server or the load balancer.","title":"Configuring the Display of the Client's Real IP"},{"location":"en/admin-en/installation-nginxplus-en/#adding-wallarm-scanner-addresses-to-the-whitelist","text":"The Wallarm scanner checks the resources of your company for vulnerabilities. Scanning is conducted using IP addresses from one of the following lists (depending on the type of Wallarm Cloud you are using): EU scanner addresses for EU Cloud users US scanner addresses for US Cloud users If you are using the Wallarm scanner, you need to configure the whitelists on your network scope security software (such as firewalls, intrusion detection systems, etc.) to contain Wallarm scanner IP addresses. For example, a Wallarm filter node with default settings is placed in the blocking mode, thus rendering the Wallarm scanner unable to scan the resources behind the filter node. To make the scanner operational again, whitelist the scanner's IP addresses on this filter node.","title":"Adding Wallarm Scanner Addresses to the Whitelist"},{"location":"en/admin-en/installation-nginxplus-en/#limiting-the-single-request-processing-time","text":"Use the wallarm_process_time_limit Wallarm directive to specify the limit of the duration for processing a single request by the filter node. If processing the request consumes more time than specified in the directive, then the information on the error is entered into the log file and the request is marked as an overlimit_res attack.","title":"Limiting the Single Request Processing Time"},{"location":"en/admin-en/installation-nginxplus-en/#limiting-the-server-reply-waiting-time","text":"Use the proxy_read_timeout NGINX directive to specify the timeout for reading the proxy server reply. If the server sends nothing during this time, the connection is closed.","title":"Limiting the Server Reply Waiting Time"},{"location":"en/admin-en/installation-nginxplus-en/#limiting-the-maximum-request-size","text":"Use the client_max_body_size NGINX directive to specify the limit for the maximum size of the body of the client's request. If this limit is exceeded, NGINX replies to the client with the 413 ( Payload Too Large ) code, also known as the Request Entity Too Large message.","title":"Limiting the Maximum Request Size"},{"location":"en/admin-en/installation-postanalytics-en/","text":"Separate Postanalytics Installation \u00b6 The processing of requests in the filter node is done in two stages: Processing in NGINX-Wallarm. Postanalytics \u2013 statistical analysis of the processed requests. The processing is not memory demanding and can be put on front end servers without changing the server requirements. Postanalytics is memory demanding, which may require changes in the server configuration or installation of postanalytics on a separate server. Wallarm also has the option of installing postanalytics in a separate server pool. To install postanalytics, you must: Add the Wallarm repositories, from which you will download packages. Install the Wallarm packages. Configure postanalytics. Connect postanalytics to the Wallarm cloud. Change the Tarantool addresses for postanalytics. Prerequisites Prior to taking any steps listed below, either disable or configure SELinux if it is installed on the operating system. Make sure that you execute all commands below as superuser (e.g. root ). 1. Add the Wallarm Repositories \u00b6 The installation and updating of the filter node is done from the Wallarm repositories. Depending on your operating system, run one of the commands: Debian 8.x (jessie) apt-get install dirmngr apt-key adv --keyserver keys.gnupg.net --recv-keys 72B865FD sh -c \"echo 'deb http://repo.wallarm.com/debian/wallarm-node jessie/2.14/' > /etc/apt/sources.list.d/wallarm.list\" apt-get update Debian 9.x (stretch) apt-get install dirmngr apt-key adv --keyserver keys.gnupg.net --recv-keys 72B865FD sh -c \"echo 'deb http://repo.wallarm.com/debian/wallarm-node stretch/2.14/' > /etc/apt/sources.list.d/wallarm.list\" apt-get update Debian 10.x (buster) apt-get install dirmngr apt-key adv --keyserver keys.gnupg.net --recv-keys 72B865FD sh -c \"echo 'deb http://repo.wallarm.com/debian/wallarm-node buster/2.14/' > /etc/apt/sources.list.d/wallarm.list\" apt-get update Ubuntu 14.04 LTS (trusty) apt-key adv --keyserver keys.gnupg.net --recv-keys 72B865FD sh -c \"echo 'deb http://repo.wallarm.com/ubuntu/wallarm-node trusty/2.14/' > /etc/apt/sources.list.d/wallarm.list\" apt-get update Ubuntu 16.04 LTS (xenial) apt-key adv --keyserver keys.gnupg.net --recv-keys 72B865FD sh -c \"echo 'deb http://repo.wallarm.com/ubuntu/wallarm-node xenial/2.14/' > /etc/apt/sources.list.d/wallarm.list\" apt-get update Ubuntu 18.04 LTS (bionic) apt-key adv --keyserver keys.gnupg.net --recv-keys 72B865FD sh -c \"echo 'deb http://repo.wallarm.com/ubuntu/wallarm-node bionic/2.14/' > /etc/apt/sources.list.d/wallarm.list\" apt-get update ``` CentOS 6.x yum install --enablerepo = extras -y epel-release centos-release-SCL rpm -i https://repo.wallarm.com/centos/wallarm-node/6/2.14/x86_64/Packages/wallarm-node-repo-1-4.el6.noarch.rpm CentOS 7.x yum install -y epel-release rpm -i https://repo.wallarm.com/centos/wallarm-node/7/2.14/x86_64/Packages/wallarm-node-repo-1-4.el7.noarch.rpm ``` Amazon Linux 2 yum install -y https://dl.fedoraproject.org/pub/epel/epel-release-latest-7.noarch.rpm rpm -i https://repo.wallarm.com/centos/wallarm-node/7/2.14/x86_64/Packages/wallarm-node-repo-1-4.el7.noarch.rpm Repository access Your system must have access to https://repo.wallarm.com to download the packages. Ensure the access is not blocked by a firewall. 2. Install the Wallarm Packages \u00b6 #### Warning:: Update OpenSSL Update the OpenSSL package to the latest version available from the repositories of your operating system. Make sure to do this prior to installing the Wallarm packages. Install NGINX-Wallarm and the required scripts to interact with the Wallarm cloud. {% termtabs name=\"Debian 8.x (jessie)\" -%} apt-get install --no-install-recommends wallarm-node-tarantool \u00b6 {%- tab name=\"Debian 9.x (stretch)\" -%} apt-get install --no-install-recommends wallarm-node-tarantool \u00b6 {%- tab name=\"Debian 10.x (buster)\" -%} apt-get install --no-install-recommends wallarm-node-tarantool \u00b6 {%- tab name=\"Ubuntu 14.04 LTS (trusty)\" -%} apt-get install --no-install-recommends wallarm-node-tarantool \u00b6 {%- tab name=\"Ubuntu 16.04 LTS (xenial)\" -%} apt-get install --no-install-recommends wallarm-node-tarantool \u00b6 {%- tab name=\"Ubuntu 18.04 LTS (bionic)\" -%} apt-get install --no-install-recommends wallarm-node-tarantool \u00b6 {%- tab name=\"CentOS 6.x\" -%} yum install wallarm-node-tarantool \u00b6 {%- tab name=\"CentOS 7.x\" -%} yum install wallarm-node-tarantool \u00b6 {%- tab name=\"Amazon Linux 2\" -%} yum install wallarm-node-tarantool \u00b6 {%- endtermtabs %} 3. Configure Postanalytics \u00b6 Allocate the operating memory size for Tarantool The amount of memory determines the quality of work of the statistical algorithms. The recommended value is 75% of the total server memory. For example, if the server has 32 GB of memory, the recommended allocation size is 24 GB. Open for editing the configuration file of Tarantool: {% termtabs name=\"Debian 8.x (jessie)\" -%} vi /etc/default/wallarm-tarantool \u00b6 {%- tab name=\"Debian 9.x (stretch)\" -%} vi /etc/default/wallarm-tarantool \u00b6 {%- tab name=\"Debian 10.x (buster)\" -%} vi /etc/default/wallarm-tarantool \u00b6 {%- tab name=\"Ubuntu 14.04 LTS (trusty)\" -%} vi /etc/default/wallarm-tarantool \u00b6 {%- tab name=\"Ubuntu 16.04 LTS (xenial)\" -%} vi /etc/default/wallarm-tarantool \u00b6 {%- tab name=\"Ubuntu 18.04 LTS (bionic)\" -%} vi /etc/default/wallarm-tarantool \u00b6 {%- tab name=\"CentOS 6.x\" -%} vi /etc/sysconfig/wallarm-tarantool \u00b6 {%- tab name=\"CentOS 7.x\" -%} vi /etc/sysconfig/wallarm-tarantool \u00b6 {%- tab name=\"Amazon Linux 2\" -%} vi /etc/sysconfig/wallarm-tarantool \u00b6 {%- endtermtabs %} Set the allocated memory size in the configuration file of Tarantool via the SLAB_ALLOC_ARENA directive. For example: SLAB_ALLOC_ARENA=24 Configure the server addresses of postanalytics Uncomment HOST and PORT variables and set them the following values: # address and port for bind HOST='0.0.0.0' PORT=3313 Restart Tarantool {% termtabs name=\"Debian 8.x (jessie)\" -%} service wallarm-tarantool restart \u00b6 {%- tab name=\"Debian 9.x (stretch)\" -%} systemctl restart wallarm-tarantool \u00b6 {%- tab name=\"Debian 10.x (buster)\" -%} systemctl restart wallarm-tarantool \u00b6 {%- tab name=\"Ubuntu 14.04 LTS (trusty)\" -%} service wallarm-tarantool restart \u00b6 {%- tab name=\"Ubuntu 16.04 LTS (xenial)\" -%} systemctl restart wallarm-tarantool \u00b6 {%- tab name=\"Ubuntu 18.04 LTS (bionic)\" -%} systemctl restart wallarm-tarantool \u00b6 {%- tab name=\"CentOS 6.x\" -%} service wallarm-tarantool restart \u00b6 {%- tab name=\"CentOS 7.x\" -%} systemctl restart wallarm-tarantool \u00b6 {%- tab name=\"Amazon Linux 2\" -%} systemctl restart wallarm-tarantool \u00b6 {%- endtermtabs %} Check Tarantool status To make sure that the postanalytics module has been installed correctly and started successfully, enter the following command: {% termtabs name=\"Debian 8.x (jessie)\" -%} systemctl status wallarm-tarantool \u00b6 {%- tab name=\"Debian 9.x (stretch)\" -%} systemctl status wallarm-tarantool \u00b6 {%- tab name=\"Debian 10.x (buster)\" -%} systemctl status wallarm-tarantool \u00b6 {%- tab name=\"Ubuntu 14.04 LTS (trusty)\" -%} service wallarm-tarantool status \u00b6 {%- tab name=\"Ubuntu 16.04 LTS (xenial)\" -%} systemctl status wallarm-tarantool \u00b6 {%- tab name=\"Ubuntu 18.04 LTS (bionic)\" -%} systemctl status wallarm-tarantool \u00b6 {%- tab name=\"CentOS 6.x\" -%} service wallarm-tarantool status \u00b6 {%- tab name=\"CentOS 7.x\" -%} systemctl status wallarm-tarantool \u00b6 {%- tab name=\"Amazon Linux 2\" -%} systemctl status wallarm-tarantool \u00b6 {%- endtermtabs %} The module status should be active : 4. Connect Postanalytics to the Wallarm Cloud \u00b6 Provide access to the Wallarm cloud so that postanalytics can always update the rules, upload metrics and the attack data. Run one of the following scripts depending on the EU or US cloud in use: {% codetabs name=\"EU Cloud\", type=\"sh\" -%} /usr/share/wallarm-common/addnode --no-sync \u00b6 {%- language name=\"US Cloud\", type=\"sh\" -%} /usr/share/wallarm-common/addnode -H us1.api.wallarm.com --no-sync \u00b6 {%- endcodetabs %} When started, the script will prompt for the login and password. Provide the login and password that you use to access the Wallarm portal in the EU or US cloud . Your Wallarm account must have the Administrator role. If you have the Analyst role, the script will error out. Accounts with 2FA enabled are not supported. Script will error out in a such case. API Access The API choice for your filter node depends on the cloud you are using. Please, select the API accordingly: * If you are using EU cloud, your node requires access to https://api.wallarm.com:444 . * If you are using US cloud, your node requires access to https://us1.api.wallarm.com:444 . Ensure the access is not blocked by a firewall. 5. Change the Tarantool Addresses for Postanalytics \u00b6 If the configuration file of Tarantool is set up to accept connections on the IP addresses different from 0.0.0.0 or 127.0.0.1 , then you must provide the addresses in /etc/wallarm/node.yaml : hostname: <node hostname> uuid: <node uuid> secret: <node secret> tarantool: host: <IP address of Tarantool host> port: 3313 The Installation Is Complete \u00b6 This completes the installation of postanalytics.","title":"Separate Postanalytics Installation"},{"location":"en/admin-en/installation-postanalytics-en/#separate-postanalytics-installation","text":"The processing of requests in the filter node is done in two stages: Processing in NGINX-Wallarm. Postanalytics \u2013 statistical analysis of the processed requests. The processing is not memory demanding and can be put on front end servers without changing the server requirements. Postanalytics is memory demanding, which may require changes in the server configuration or installation of postanalytics on a separate server. Wallarm also has the option of installing postanalytics in a separate server pool. To install postanalytics, you must: Add the Wallarm repositories, from which you will download packages. Install the Wallarm packages. Configure postanalytics. Connect postanalytics to the Wallarm cloud. Change the Tarantool addresses for postanalytics. Prerequisites Prior to taking any steps listed below, either disable or configure SELinux if it is installed on the operating system. Make sure that you execute all commands below as superuser (e.g. root ).","title":"Separate Postanalytics Installation"},{"location":"en/admin-en/installation-postanalytics-en/#1-add-the-wallarm-repositories","text":"The installation and updating of the filter node is done from the Wallarm repositories. Depending on your operating system, run one of the commands: Debian 8.x (jessie) apt-get install dirmngr apt-key adv --keyserver keys.gnupg.net --recv-keys 72B865FD sh -c \"echo 'deb http://repo.wallarm.com/debian/wallarm-node jessie/2.14/' > /etc/apt/sources.list.d/wallarm.list\" apt-get update Debian 9.x (stretch) apt-get install dirmngr apt-key adv --keyserver keys.gnupg.net --recv-keys 72B865FD sh -c \"echo 'deb http://repo.wallarm.com/debian/wallarm-node stretch/2.14/' > /etc/apt/sources.list.d/wallarm.list\" apt-get update Debian 10.x (buster) apt-get install dirmngr apt-key adv --keyserver keys.gnupg.net --recv-keys 72B865FD sh -c \"echo 'deb http://repo.wallarm.com/debian/wallarm-node buster/2.14/' > /etc/apt/sources.list.d/wallarm.list\" apt-get update Ubuntu 14.04 LTS (trusty) apt-key adv --keyserver keys.gnupg.net --recv-keys 72B865FD sh -c \"echo 'deb http://repo.wallarm.com/ubuntu/wallarm-node trusty/2.14/' > /etc/apt/sources.list.d/wallarm.list\" apt-get update Ubuntu 16.04 LTS (xenial) apt-key adv --keyserver keys.gnupg.net --recv-keys 72B865FD sh -c \"echo 'deb http://repo.wallarm.com/ubuntu/wallarm-node xenial/2.14/' > /etc/apt/sources.list.d/wallarm.list\" apt-get update Ubuntu 18.04 LTS (bionic) apt-key adv --keyserver keys.gnupg.net --recv-keys 72B865FD sh -c \"echo 'deb http://repo.wallarm.com/ubuntu/wallarm-node bionic/2.14/' > /etc/apt/sources.list.d/wallarm.list\" apt-get update ``` CentOS 6.x yum install --enablerepo = extras -y epel-release centos-release-SCL rpm -i https://repo.wallarm.com/centos/wallarm-node/6/2.14/x86_64/Packages/wallarm-node-repo-1-4.el6.noarch.rpm CentOS 7.x yum install -y epel-release rpm -i https://repo.wallarm.com/centos/wallarm-node/7/2.14/x86_64/Packages/wallarm-node-repo-1-4.el7.noarch.rpm ``` Amazon Linux 2 yum install -y https://dl.fedoraproject.org/pub/epel/epel-release-latest-7.noarch.rpm rpm -i https://repo.wallarm.com/centos/wallarm-node/7/2.14/x86_64/Packages/wallarm-node-repo-1-4.el7.noarch.rpm Repository access Your system must have access to https://repo.wallarm.com to download the packages. Ensure the access is not blocked by a firewall.","title":"1. Add the Wallarm Repositories"},{"location":"en/admin-en/installation-postanalytics-en/#2-install-the-wallarm-packages","text":"#### Warning:: Update OpenSSL Update the OpenSSL package to the latest version available from the repositories of your operating system. Make sure to do this prior to installing the Wallarm packages. Install NGINX-Wallarm and the required scripts to interact with the Wallarm cloud. {% termtabs name=\"Debian 8.x (jessie)\" -%}","title":"2. Install the Wallarm Packages"},{"location":"en/admin-en/installation-postanalytics-en/#apt-get-install-no-install-recommends-wallarm-node-tarantool","text":"{%- tab name=\"Debian 9.x (stretch)\" -%}","title":"apt-get install --no-install-recommends wallarm-node-tarantool"},{"location":"en/admin-en/installation-postanalytics-en/#apt-get-install-no-install-recommends-wallarm-node-tarantool_1","text":"{%- tab name=\"Debian 10.x (buster)\" -%}","title":"apt-get install --no-install-recommends wallarm-node-tarantool"},{"location":"en/admin-en/installation-postanalytics-en/#apt-get-install-no-install-recommends-wallarm-node-tarantool_2","text":"{%- tab name=\"Ubuntu 14.04 LTS (trusty)\" -%}","title":"apt-get install --no-install-recommends wallarm-node-tarantool"},{"location":"en/admin-en/installation-postanalytics-en/#apt-get-install-no-install-recommends-wallarm-node-tarantool_3","text":"{%- tab name=\"Ubuntu 16.04 LTS (xenial)\" -%}","title":"apt-get install --no-install-recommends wallarm-node-tarantool"},{"location":"en/admin-en/installation-postanalytics-en/#apt-get-install-no-install-recommends-wallarm-node-tarantool_4","text":"{%- tab name=\"Ubuntu 18.04 LTS (bionic)\" -%}","title":"apt-get install --no-install-recommends wallarm-node-tarantool"},{"location":"en/admin-en/installation-postanalytics-en/#apt-get-install-no-install-recommends-wallarm-node-tarantool_5","text":"{%- tab name=\"CentOS 6.x\" -%}","title":"apt-get install --no-install-recommends wallarm-node-tarantool"},{"location":"en/admin-en/installation-postanalytics-en/#yum-install-wallarm-node-tarantool","text":"{%- tab name=\"CentOS 7.x\" -%}","title":"yum install wallarm-node-tarantool"},{"location":"en/admin-en/installation-postanalytics-en/#yum-install-wallarm-node-tarantool_1","text":"{%- tab name=\"Amazon Linux 2\" -%}","title":"yum install wallarm-node-tarantool"},{"location":"en/admin-en/installation-postanalytics-en/#yum-install-wallarm-node-tarantool_2","text":"{%- endtermtabs %}","title":"yum install wallarm-node-tarantool"},{"location":"en/admin-en/installation-postanalytics-en/#3-configure-postanalytics","text":"Allocate the operating memory size for Tarantool The amount of memory determines the quality of work of the statistical algorithms. The recommended value is 75% of the total server memory. For example, if the server has 32 GB of memory, the recommended allocation size is 24 GB. Open for editing the configuration file of Tarantool: {% termtabs name=\"Debian 8.x (jessie)\" -%}","title":"3. Configure Postanalytics"},{"location":"en/admin-en/installation-postanalytics-en/#vi-etcdefaultwallarm-tarantool","text":"{%- tab name=\"Debian 9.x (stretch)\" -%}","title":"vi /etc/default/wallarm-tarantool"},{"location":"en/admin-en/installation-postanalytics-en/#vi-etcdefaultwallarm-tarantool_1","text":"{%- tab name=\"Debian 10.x (buster)\" -%}","title":"vi /etc/default/wallarm-tarantool"},{"location":"en/admin-en/installation-postanalytics-en/#vi-etcdefaultwallarm-tarantool_2","text":"{%- tab name=\"Ubuntu 14.04 LTS (trusty)\" -%}","title":"vi /etc/default/wallarm-tarantool"},{"location":"en/admin-en/installation-postanalytics-en/#vi-etcdefaultwallarm-tarantool_3","text":"{%- tab name=\"Ubuntu 16.04 LTS (xenial)\" -%}","title":"vi /etc/default/wallarm-tarantool"},{"location":"en/admin-en/installation-postanalytics-en/#vi-etcdefaultwallarm-tarantool_4","text":"{%- tab name=\"Ubuntu 18.04 LTS (bionic)\" -%}","title":"vi /etc/default/wallarm-tarantool"},{"location":"en/admin-en/installation-postanalytics-en/#vi-etcdefaultwallarm-tarantool_5","text":"{%- tab name=\"CentOS 6.x\" -%}","title":"vi /etc/default/wallarm-tarantool"},{"location":"en/admin-en/installation-postanalytics-en/#vi-etcsysconfigwallarm-tarantool","text":"{%- tab name=\"CentOS 7.x\" -%}","title":"vi /etc/sysconfig/wallarm-tarantool"},{"location":"en/admin-en/installation-postanalytics-en/#vi-etcsysconfigwallarm-tarantool_1","text":"{%- tab name=\"Amazon Linux 2\" -%}","title":"vi /etc/sysconfig/wallarm-tarantool"},{"location":"en/admin-en/installation-postanalytics-en/#vi-etcsysconfigwallarm-tarantool_2","text":"{%- endtermtabs %} Set the allocated memory size in the configuration file of Tarantool via the SLAB_ALLOC_ARENA directive. For example: SLAB_ALLOC_ARENA=24 Configure the server addresses of postanalytics Uncomment HOST and PORT variables and set them the following values: # address and port for bind HOST='0.0.0.0' PORT=3313 Restart Tarantool {% termtabs name=\"Debian 8.x (jessie)\" -%}","title":"vi /etc/sysconfig/wallarm-tarantool"},{"location":"en/admin-en/installation-postanalytics-en/#service-wallarm-tarantool-restart","text":"{%- tab name=\"Debian 9.x (stretch)\" -%}","title":"service wallarm-tarantool restart"},{"location":"en/admin-en/installation-postanalytics-en/#systemctl-restart-wallarm-tarantool","text":"{%- tab name=\"Debian 10.x (buster)\" -%}","title":"systemctl restart wallarm-tarantool"},{"location":"en/admin-en/installation-postanalytics-en/#systemctl-restart-wallarm-tarantool_1","text":"{%- tab name=\"Ubuntu 14.04 LTS (trusty)\" -%}","title":"systemctl restart wallarm-tarantool"},{"location":"en/admin-en/installation-postanalytics-en/#service-wallarm-tarantool-restart_1","text":"{%- tab name=\"Ubuntu 16.04 LTS (xenial)\" -%}","title":"service wallarm-tarantool restart"},{"location":"en/admin-en/installation-postanalytics-en/#systemctl-restart-wallarm-tarantool_2","text":"{%- tab name=\"Ubuntu 18.04 LTS (bionic)\" -%}","title":"systemctl restart wallarm-tarantool"},{"location":"en/admin-en/installation-postanalytics-en/#systemctl-restart-wallarm-tarantool_3","text":"{%- tab name=\"CentOS 6.x\" -%}","title":"systemctl restart wallarm-tarantool"},{"location":"en/admin-en/installation-postanalytics-en/#service-wallarm-tarantool-restart_2","text":"{%- tab name=\"CentOS 7.x\" -%}","title":"service wallarm-tarantool restart"},{"location":"en/admin-en/installation-postanalytics-en/#systemctl-restart-wallarm-tarantool_4","text":"{%- tab name=\"Amazon Linux 2\" -%}","title":"systemctl restart wallarm-tarantool"},{"location":"en/admin-en/installation-postanalytics-en/#systemctl-restart-wallarm-tarantool_5","text":"{%- endtermtabs %} Check Tarantool status To make sure that the postanalytics module has been installed correctly and started successfully, enter the following command: {% termtabs name=\"Debian 8.x (jessie)\" -%}","title":"systemctl restart wallarm-tarantool"},{"location":"en/admin-en/installation-postanalytics-en/#systemctl-status-wallarm-tarantool","text":"{%- tab name=\"Debian 9.x (stretch)\" -%}","title":"systemctl status wallarm-tarantool"},{"location":"en/admin-en/installation-postanalytics-en/#systemctl-status-wallarm-tarantool_1","text":"{%- tab name=\"Debian 10.x (buster)\" -%}","title":"systemctl status wallarm-tarantool"},{"location":"en/admin-en/installation-postanalytics-en/#systemctl-status-wallarm-tarantool_2","text":"{%- tab name=\"Ubuntu 14.04 LTS (trusty)\" -%}","title":"systemctl status wallarm-tarantool"},{"location":"en/admin-en/installation-postanalytics-en/#service-wallarm-tarantool-status","text":"{%- tab name=\"Ubuntu 16.04 LTS (xenial)\" -%}","title":"service wallarm-tarantool status"},{"location":"en/admin-en/installation-postanalytics-en/#systemctl-status-wallarm-tarantool_3","text":"{%- tab name=\"Ubuntu 18.04 LTS (bionic)\" -%}","title":"systemctl status wallarm-tarantool"},{"location":"en/admin-en/installation-postanalytics-en/#systemctl-status-wallarm-tarantool_4","text":"{%- tab name=\"CentOS 6.x\" -%}","title":"systemctl status wallarm-tarantool"},{"location":"en/admin-en/installation-postanalytics-en/#service-wallarm-tarantool-status_1","text":"{%- tab name=\"CentOS 7.x\" -%}","title":"service wallarm-tarantool status"},{"location":"en/admin-en/installation-postanalytics-en/#systemctl-status-wallarm-tarantool_5","text":"{%- tab name=\"Amazon Linux 2\" -%}","title":"systemctl status wallarm-tarantool"},{"location":"en/admin-en/installation-postanalytics-en/#systemctl-status-wallarm-tarantool_6","text":"{%- endtermtabs %} The module status should be active :","title":"systemctl status wallarm-tarantool"},{"location":"en/admin-en/installation-postanalytics-en/#4-connect-postanalytics-to-the-wallarm-cloud","text":"Provide access to the Wallarm cloud so that postanalytics can always update the rules, upload metrics and the attack data. Run one of the following scripts depending on the EU or US cloud in use: {% codetabs name=\"EU Cloud\", type=\"sh\" -%}","title":"4. Connect Postanalytics to the Wallarm Cloud"},{"location":"en/admin-en/installation-postanalytics-en/#usrsharewallarm-commonaddnode-no-sync","text":"{%- language name=\"US Cloud\", type=\"sh\" -%}","title":"/usr/share/wallarm-common/addnode --no-sync"},{"location":"en/admin-en/installation-postanalytics-en/#usrsharewallarm-commonaddnode-h-us1apiwallarmcom-no-sync","text":"{%- endcodetabs %} When started, the script will prompt for the login and password. Provide the login and password that you use to access the Wallarm portal in the EU or US cloud . Your Wallarm account must have the Administrator role. If you have the Analyst role, the script will error out. Accounts with 2FA enabled are not supported. Script will error out in a such case. API Access The API choice for your filter node depends on the cloud you are using. Please, select the API accordingly: * If you are using EU cloud, your node requires access to https://api.wallarm.com:444 . * If you are using US cloud, your node requires access to https://us1.api.wallarm.com:444 . Ensure the access is not blocked by a firewall.","title":"/usr/share/wallarm-common/addnode -H us1.api.wallarm.com --no-sync"},{"location":"en/admin-en/installation-postanalytics-en/#5-change-the-tarantool-addresses-for-postanalytics","text":"If the configuration file of Tarantool is set up to accept connections on the IP addresses different from 0.0.0.0 or 127.0.0.1 , then you must provide the addresses in /etc/wallarm/node.yaml : hostname: <node hostname> uuid: <node uuid> secret: <node secret> tarantool: host: <IP address of Tarantool host> port: 3313","title":"5. Change the Tarantool Addresses for Postanalytics"},{"location":"en/admin-en/installation-postanalytics-en/#the-installation-is-complete","text":"This completes the installation of postanalytics.","title":"The Installation Is Complete"},{"location":"en/admin-en/installation-prereq-en/","text":"Prerequisites \u00b6 Wallarm installation prerequisites: Supported operating system. Root access. Wallarm account on the Wallarm portal in the EU or US cloud. Supported Operating Systems \u00b6 The filter node supports installation from packages on the following operating systems: #### Warning:: Supported OS types Only x64 operating systems are supported. Debian 8.x (jessie) Debian 9.x (stretch) Debian 10.x (buster) Ubuntu 14.04 LTS (trusty) Ubuntu 16.04 LTS (xenial) Ubuntu 18.04 LTS (bionic) CentOS 6.x CentOS 7.x Amazon Linux 2","title":"Prerequisites"},{"location":"en/admin-en/installation-prereq-en/#prerequisites","text":"Wallarm installation prerequisites: Supported operating system. Root access. Wallarm account on the Wallarm portal in the EU or US cloud.","title":"Prerequisites"},{"location":"en/admin-en/installation-prereq-en/#supported-operating-systems","text":"The filter node supports installation from packages on the following operating systems: #### Warning:: Supported OS types Only x64 operating systems are supported. Debian 8.x (jessie) Debian 9.x (stretch) Debian 10.x (buster) Ubuntu 14.04 LTS (trusty) Ubuntu 16.04 LTS (xenial) Ubuntu 18.04 LTS (bionic) CentOS 6.x CentOS 7.x Amazon Linux 2","title":"Supported Operating Systems"},{"location":"en/admin-en/installation-vmware-en/","text":"Installing as a VMware vApp \u00b6 The filter node can be installed as a VMware vApp. The functionality of the filter node installed as a VMware vApp is completely identical to the functionality of the other deployment options. Prerequisites \u00b6 The virtualization system must meet the following requirements: vApp support vCenter version 5.5 or higher. ESXi version 5.5 or higher. Privileges: User has access to the vCenter console with the permission to deploy OVF-templates. Access to the Wallarm cloud with the permission to create a node. Get the Link to the OVF Template \u00b6 Proceed to the link that corresponds to the cloud you are using: If you are using the EU cloud, proceed to the https://my.wallarm.com/ link. If you are using the US cloud, proceed to the https://us1.my.wallarm.com link. Click Nodes . Click OVF-template for VMware . The path to the OVF template will be copied to the clipboard. The link will be valid for 24 hours. #### Info:: The node's access credentials are replaced automatically. If the filter node is still in operation, it will lose the ability to interact with the Wallarm API. Deploy the OVF Template VMware \u00b6 Go to the vCenter through the vSphere Client or the vSphere Web Service. Click File . Click Deploy OVF template . Paste the link to the OVF template from the clipboard. On the Name and Location step, specify the name for the virtual machine to be displayed in the vSphere Client interface. On the Deployment configuration step, choose configuration: up to 10mbps is designed for test installations. It uses one virtual processor and 512 MB of memory. 10-50mbps is designed for up to 50 Mbit of traffic. It uses 4 virtual processors and 16 GB of memory. 50-100mbps is designed for up to 100 Mbit of traffic. It uses 8 virtual processors and 32 GB of memory. Disk space Make sure that the allocated disk space is at least 4x the amount of RAM. For example, if you have 16 GB of RAM, you will need 64 GB of disk space. On the Properties step, configure the filter node parameters. These parameters are used only for the configuration on the first start. Hostname is server name. HTTP hosts : a list of domains to be processed. The requests whose Host header value is not included in the list will not be transferred to the backend and will be blocked. HTTP backends : a list of IP addresses, to which the requests will be forwarded. On the first virtual host boot, the server console will prompt to set the root password. !!! info \"Username\" When prompted to provide a username, enter installer . After the first boot, you need to do one of the following: * Wait for 15 minutes until the filter node-specific files are downloaded. * Manually run `/usr/share/wallarm-common/syncnode`. Configure logging. Configure the filter node variables logging using NGINX. This will allow to perform a quick filter node diagnostics with the help of the NGINX log file. #### Info:: Default Settings A freshly installed filter node operates in blocking mode (see the wallarm_mode directive description) by default. This may result in the inoperable Wallarm scanner . If you plan to use the scanner, then you need to perform additional actions to render scanner operational. Additional Settings \u00b6 The filter node may require some additional configuration after installation. The document below lists a few of the typical setups that you can apply if needed. To get more information about other available settings, proceed to the \u201cConfiguration\u201d section of the Administrator\u2019s Guide . Configuring the Display of the Client's Real IP \u00b6 If the filter node is deployed behind a proxy server or load balancer without any additional configuration, the request source address may not be equal to the actual IP address of the client. Instead, it may be equal to one of the IP addresses of the proxy server or the load balancer. In this case, if you want the filter node to receive the client's IP address as a request source address, you need to perform an additional configuration of the proxy server or the load balancer. Adding Wallarm Scanner Addresses to the Whitelist \u00b6 The Wallarm scanner checks the resources of your company for vulnerabilities. Scanning is conducted using IP addresses from one of the following lists (depending on the type of Wallarm Cloud you are using): EU scanner addresses for EU Cloud users US scanner addresses for US Cloud users If you are using the Wallarm scanner, you need to configure the whitelists on your network scope security software (such as firewalls, intrusion detection systems, etc.) to contain Wallarm scanner IP addresses. For example, a Wallarm filter node with default settings is placed in the blocking mode, thus rendering the Wallarm scanner unable to scan the resources behind the filter node. To make the scanner operational again, whitelist the scanner's IP addresses on this filter node. Limiting the Single Request Processing Time \u00b6 Use the wallarm_process_time_limit Wallarm directive to specify the limit of the duration for processing a single request by the filter node. If processing the request consumes more time than specified in the directive, then the information on the error is entered into the log file and the request is marked as an overlimit_res attack. Limiting the Server Reply Waiting Time \u00b6 Use the proxy_read_timeout NGINX directive to specify the timeout for reading the proxy server reply. If the server sends nothing during this time, the connection is closed. Limiting the Maximum Request Size \u00b6 Use the client_max_body_size NGINX directive to specify the limit for the maximum size of the body of the client's request. If this limit is exceeded, NGINX replies to the client with the 413 ( Payload Too Large ) code, also known as the Request Entity Too Large message.","title":"Installing as a VMware vApp"},{"location":"en/admin-en/installation-vmware-en/#installing-as-a-vmware-vapp","text":"The filter node can be installed as a VMware vApp. The functionality of the filter node installed as a VMware vApp is completely identical to the functionality of the other deployment options.","title":"Installing as a VMware vApp"},{"location":"en/admin-en/installation-vmware-en/#prerequisites","text":"The virtualization system must meet the following requirements: vApp support vCenter version 5.5 or higher. ESXi version 5.5 or higher. Privileges: User has access to the vCenter console with the permission to deploy OVF-templates. Access to the Wallarm cloud with the permission to create a node.","title":"Prerequisites"},{"location":"en/admin-en/installation-vmware-en/#get-the-link-to-the-ovf-template","text":"Proceed to the link that corresponds to the cloud you are using: If you are using the EU cloud, proceed to the https://my.wallarm.com/ link. If you are using the US cloud, proceed to the https://us1.my.wallarm.com link. Click Nodes . Click OVF-template for VMware . The path to the OVF template will be copied to the clipboard. The link will be valid for 24 hours. #### Info:: The node's access credentials are replaced automatically. If the filter node is still in operation, it will lose the ability to interact with the Wallarm API.","title":"Get the Link to the OVF Template"},{"location":"en/admin-en/installation-vmware-en/#deploy-the-ovf-template-vmware","text":"Go to the vCenter through the vSphere Client or the vSphere Web Service. Click File . Click Deploy OVF template . Paste the link to the OVF template from the clipboard. On the Name and Location step, specify the name for the virtual machine to be displayed in the vSphere Client interface. On the Deployment configuration step, choose configuration: up to 10mbps is designed for test installations. It uses one virtual processor and 512 MB of memory. 10-50mbps is designed for up to 50 Mbit of traffic. It uses 4 virtual processors and 16 GB of memory. 50-100mbps is designed for up to 100 Mbit of traffic. It uses 8 virtual processors and 32 GB of memory. Disk space Make sure that the allocated disk space is at least 4x the amount of RAM. For example, if you have 16 GB of RAM, you will need 64 GB of disk space. On the Properties step, configure the filter node parameters. These parameters are used only for the configuration on the first start. Hostname is server name. HTTP hosts : a list of domains to be processed. The requests whose Host header value is not included in the list will not be transferred to the backend and will be blocked. HTTP backends : a list of IP addresses, to which the requests will be forwarded. On the first virtual host boot, the server console will prompt to set the root password. !!! info \"Username\" When prompted to provide a username, enter installer . After the first boot, you need to do one of the following: * Wait for 15 minutes until the filter node-specific files are downloaded. * Manually run `/usr/share/wallarm-common/syncnode`. Configure logging. Configure the filter node variables logging using NGINX. This will allow to perform a quick filter node diagnostics with the help of the NGINX log file. #### Info:: Default Settings A freshly installed filter node operates in blocking mode (see the wallarm_mode directive description) by default. This may result in the inoperable Wallarm scanner . If you plan to use the scanner, then you need to perform additional actions to render scanner operational.","title":"Deploy the OVF Template VMware"},{"location":"en/admin-en/installation-vmware-en/#additional-settings","text":"The filter node may require some additional configuration after installation. The document below lists a few of the typical setups that you can apply if needed. To get more information about other available settings, proceed to the \u201cConfiguration\u201d section of the Administrator\u2019s Guide .","title":"Additional Settings"},{"location":"en/admin-en/installation-vmware-en/#configuring-the-display-of-the-clients-real-ip","text":"If the filter node is deployed behind a proxy server or load balancer without any additional configuration, the request source address may not be equal to the actual IP address of the client. Instead, it may be equal to one of the IP addresses of the proxy server or the load balancer. In this case, if you want the filter node to receive the client's IP address as a request source address, you need to perform an additional configuration of the proxy server or the load balancer.","title":"Configuring the Display of the Client's Real IP"},{"location":"en/admin-en/installation-vmware-en/#adding-wallarm-scanner-addresses-to-the-whitelist","text":"The Wallarm scanner checks the resources of your company for vulnerabilities. Scanning is conducted using IP addresses from one of the following lists (depending on the type of Wallarm Cloud you are using): EU scanner addresses for EU Cloud users US scanner addresses for US Cloud users If you are using the Wallarm scanner, you need to configure the whitelists on your network scope security software (such as firewalls, intrusion detection systems, etc.) to contain Wallarm scanner IP addresses. For example, a Wallarm filter node with default settings is placed in the blocking mode, thus rendering the Wallarm scanner unable to scan the resources behind the filter node. To make the scanner operational again, whitelist the scanner's IP addresses on this filter node.","title":"Adding Wallarm Scanner Addresses to the Whitelist"},{"location":"en/admin-en/installation-vmware-en/#limiting-the-single-request-processing-time","text":"Use the wallarm_process_time_limit Wallarm directive to specify the limit of the duration for processing a single request by the filter node. If processing the request consumes more time than specified in the directive, then the information on the error is entered into the log file and the request is marked as an overlimit_res attack.","title":"Limiting the Single Request Processing Time"},{"location":"en/admin-en/installation-vmware-en/#limiting-the-server-reply-waiting-time","text":"Use the proxy_read_timeout NGINX directive to specify the timeout for reading the proxy server reply. If the server sends nothing during this time, the connection is closed.","title":"Limiting the Server Reply Waiting Time"},{"location":"en/admin-en/installation-vmware-en/#limiting-the-maximum-request-size","text":"Use the client_max_body_size NGINX directive to specify the limit for the maximum size of the body of the client's request. If this limit is exceeded, NGINX replies to the client with the 413 ( Payload Too Large ) code, also known as the Request Entity Too Large message.","title":"Limiting the Maximum Request Size"},{"location":"en/admin-en/integration/","text":"","title":"Integration"},{"location":"en/admin-en/libproton-error-en/","text":"The Filter Node Errors out with \u00ablibproton error: did not allocate memory\u00bb \u00b6 #### Warning:: INSTRUCTION DEPRECATED This issue is irrelevant for the latest filter node version users. See the full error message in the log file: nginx: the configuration file /etc/nginx-wallarm/nginx.conf syntax is ok nginx: libproton error: did not allocate memory nginx: wallarm enabled but wallarm training set file /etc/wallarm/lom is invalid, please check wallarm_local_trainingset_path nginx: configuration file /etc/nginx-wallarm/nginx.conf test failed The error cause is in that the shared memory is smaller than the LOM file. Increase the shared memory value to make it bigger than the LOM file: Open for editing the configuration file in /etc/nginx-wallarm . Set the wallarm_shm_size value bigger than the size of the file /etc/wallarm/lom .","title":"Filter Node Errors out with \u00ablibproton error did not allocate memory\u00bb [DEPRECATED]"},{"location":"en/admin-en/libproton-error-en/#the-filter-node-errors-out-with-libproton-error-did-not-allocate-memory","text":"#### Warning:: INSTRUCTION DEPRECATED This issue is irrelevant for the latest filter node version users. See the full error message in the log file: nginx: the configuration file /etc/nginx-wallarm/nginx.conf syntax is ok nginx: libproton error: did not allocate memory nginx: wallarm enabled but wallarm training set file /etc/wallarm/lom is invalid, please check wallarm_local_trainingset_path nginx: configuration file /etc/nginx-wallarm/nginx.conf test failed The error cause is in that the shared memory is smaller than the LOM file. Increase the shared memory value to make it bigger than the LOM file: Open for editing the configuration file in /etc/nginx-wallarm . Set the wallarm_shm_size value bigger than the size of the file /etc/wallarm/lom .","title":"The Filter Node Errors out with \u00ablibproton error: did not allocate memory\u00bb"},{"location":"en/admin-en/migrating-212-214/","text":"Migrating the Filter Node 2.12 to 2.14 on Linux \u00b6 To migrate an existing filter node version 2.12 to version 2.14, do the following: Add the Wallarm repository for the new filter node version. Update the Wallarm packages. Restart the services. Adding the Wallarm Repository for a New Filter Node Version \u00b6 If your current filter node is installed on Debian (including installations from the backports repositories ) or Ubuntu, then comment the existing repository URLs and add the new ones in the /etc/apt/sources.list.d/wallarm.list file: {% codetabs name=\"Debian 8.x (jessie)\", type=\"sh\" %} deb http://repo.wallarm.com/debian/wallarm-node jessie/ \u00b6 deb http://repo.wallarm.com/debian/wallarm-node jessie/2.14/ {% language name=\"Debian 8.x (jessie-backports)\", type=\"sh\" %} deb http://repo.wallarm.com/debian/wallarm-node jessie/ \u00b6 deb http://repo.wallarm.com/debian/wallarm-node jessie-backports/ \u00b6 deb http://repo.wallarm.com/debian/wallarm-node jessie/2.14/ deb http://repo.wallarm.com/debian/wallarm-node jessie-backports/2.14/ {% language name=\"Debian 9.x (stretch)\", type=\"sh\" %} deb http://repo.wallarm.com/debian/wallarm-node stretch/ \u00b6 deb http://repo.wallarm.com/debian/wallarm-node stretch/2.14/ {% language name=\"Debian 9.x (stretch-backports)\", type=\"sh\" %} deb http://repo.wallarm.com/debian/wallarm-node stretch/ \u00b6 deb http://repo.wallarm.com/debian/wallarm-node stretch-backports/ \u00b6 deb http://repo.wallarm.com/debian/wallarm-node stretch/2.14/ deb http://repo.wallarm.com/debian/wallarm-node stretch-backports/2.14/ {% language name=\"Debian 10.x (buster)\", type=\"sh\" %} deb http://repo.wallarm.com/debian/wallarm-node buster/ \u00b6 deb http://repo.wallarm.com/debian/wallarm-node buster/2.14/ {% language name=\"Ubuntu 14.04 LTS (trusty)\", type=\"sh\" %} deb http://repo.wallarm.com/ubuntu/wallarm-node trusty/ \u00b6 deb http://repo.wallarm.com/ubuntu/wallarm-node trusty/2.14/ {% language name=\"Ubuntu 16.04 LTS (xenial)\", type=\"sh\" %} deb http://repo.wallarm.com/ubuntu/wallarm-node xenial/ \u00b6 deb http://repo.wallarm.com/ubuntu/wallarm-node xenial/2.14/ {% language name=\"Ubuntu 18.04 LTS (bionic)\", type=\"sh\" %} deb http://repo.wallarm.com/ubuntu/wallarm-node bionic/ \u00b6 deb http://repo.wallarm.com/ubuntu/wallarm-node bionic/2.14/ {% endcodetabs %} If your current filter node is installed on CentOS or Amazon Linux 2, then comment the existing baseurl parameter and add the new one in the /etc/yum.repos.d/wallarm-node.repo file: {% codetabs name=\"CentOS 6.x\", type=\"sh\" %} [wallarm-node] baseurl= http://repo.wallarm.com/centos/wallarm-node/6/$basearch \u00b6 baseurl= http://repo.wallarm.com/centos/wallarm-node/6/2.14/$basearch {% language name=\"CentOS 7.x or Amazon Linux 2\", type=\"sh\" %} [wallarm-node] baseurl= http://repo.wallarm.com/centos/wallarm-node/7/$basearch \u00b6 baseurl= http://repo.wallarm.com/centos/wallarm-node/7/2.14/$basearch {% endcodetabs %} Updating the Wallarm Packages \u00b6 #### Warning:: Update Sequence If the Wallarm modules are installed separately, first update the postanalytics module. Update the Wallarm postanalytics module and the Wallarm NGINX/NGINX Plus/Kong module. If these modules are installed on the same host, then execute the following command: {% termtabs name=\"Debian or Ubuntu\" %} apt-get install wallarm-node --no-install-recommends \u00b6 {% tab name=\"CentOS or Amazon Linux 2\" %} yum upgrade wallarm-node \u00b6 {% endtermtabs %} If these modules are installed on the different hosts, then execute the following command on the appropriate host to update the postanalytics module: {% termtabs name=\"Debian or Ubuntu\" %} apt-get install wallarm-node-tarantool --no-install-recommends \u00b6 {% tab name=\"CentOS or Amazon Linux 2\" %} yum upgrade wallarm-node-tarantool \u00b6 {% endtermtabs %} execute the following command on the appropriate host to update the Wallarm NGINX/NGINX Plus/Kong module: {% termtabs name=\"Debian or Ubuntu\" %} apt-get install wallarm-node-nginx --no-install-recommends \u00b6 {% tab name=\"CentOS or Amazon Linux 2\" %} yum upgrade wallarm-node-nginx \u00b6 {% endtermtabs %} Restarting the Services \u00b6 After successful update of the Wallarm packages, restart the updated services by issuing the following command: {% termtabs name=\"CentOS 6.x or Ubuntu 14.04\" %} service nginx restart \u00b6 {% tab name=\"Other supported OS distributive\" %} systemctl restart nginx \u00b6 {% endtermtabs %} The Migration is Complete \u00b6 Now you should have successfully migrated your filter node to version 2.14. #### Info:: See also: [Checking the Filter Node Operation][check-operation]","title":"Migrating the Filter Node 2.12 to 2.14 on Linux"},{"location":"en/admin-en/migrating-212-214/#migrating-the-filter-node-212-to-214-on-linux","text":"To migrate an existing filter node version 2.12 to version 2.14, do the following: Add the Wallarm repository for the new filter node version. Update the Wallarm packages. Restart the services.","title":"Migrating the Filter Node 2.12 to 2.14 on Linux"},{"location":"en/admin-en/migrating-212-214/#adding-the-wallarm-repository-for-a-new-filter-node-version","text":"If your current filter node is installed on Debian (including installations from the backports repositories ) or Ubuntu, then comment the existing repository URLs and add the new ones in the /etc/apt/sources.list.d/wallarm.list file: {% codetabs name=\"Debian 8.x (jessie)\", type=\"sh\" %}","title":"Adding the Wallarm Repository for a New Filter Node Version"},{"location":"en/admin-en/migrating-212-214/#deb-httprepowallarmcomdebianwallarm-node-jessie","text":"deb http://repo.wallarm.com/debian/wallarm-node jessie/2.14/ {% language name=\"Debian 8.x (jessie-backports)\", type=\"sh\" %}","title":"deb http://repo.wallarm.com/debian/wallarm-node jessie/"},{"location":"en/admin-en/migrating-212-214/#deb-httprepowallarmcomdebianwallarm-node-jessie_1","text":"","title":"deb http://repo.wallarm.com/debian/wallarm-node jessie/"},{"location":"en/admin-en/migrating-212-214/#deb-httprepowallarmcomdebianwallarm-node-jessie-backports","text":"deb http://repo.wallarm.com/debian/wallarm-node jessie/2.14/ deb http://repo.wallarm.com/debian/wallarm-node jessie-backports/2.14/ {% language name=\"Debian 9.x (stretch)\", type=\"sh\" %}","title":"deb http://repo.wallarm.com/debian/wallarm-node jessie-backports/"},{"location":"en/admin-en/migrating-212-214/#deb-httprepowallarmcomdebianwallarm-node-stretch","text":"deb http://repo.wallarm.com/debian/wallarm-node stretch/2.14/ {% language name=\"Debian 9.x (stretch-backports)\", type=\"sh\" %}","title":"deb http://repo.wallarm.com/debian/wallarm-node stretch/"},{"location":"en/admin-en/migrating-212-214/#deb-httprepowallarmcomdebianwallarm-node-stretch_1","text":"","title":"deb http://repo.wallarm.com/debian/wallarm-node stretch/"},{"location":"en/admin-en/migrating-212-214/#deb-httprepowallarmcomdebianwallarm-node-stretch-backports","text":"deb http://repo.wallarm.com/debian/wallarm-node stretch/2.14/ deb http://repo.wallarm.com/debian/wallarm-node stretch-backports/2.14/ {% language name=\"Debian 10.x (buster)\", type=\"sh\" %}","title":"deb http://repo.wallarm.com/debian/wallarm-node stretch-backports/"},{"location":"en/admin-en/migrating-212-214/#deb-httprepowallarmcomdebianwallarm-node-buster","text":"deb http://repo.wallarm.com/debian/wallarm-node buster/2.14/ {% language name=\"Ubuntu 14.04 LTS (trusty)\", type=\"sh\" %}","title":"deb http://repo.wallarm.com/debian/wallarm-node buster/"},{"location":"en/admin-en/migrating-212-214/#deb-httprepowallarmcomubuntuwallarm-node-trusty","text":"deb http://repo.wallarm.com/ubuntu/wallarm-node trusty/2.14/ {% language name=\"Ubuntu 16.04 LTS (xenial)\", type=\"sh\" %}","title":"deb http://repo.wallarm.com/ubuntu/wallarm-node trusty/"},{"location":"en/admin-en/migrating-212-214/#deb-httprepowallarmcomubuntuwallarm-node-xenial","text":"deb http://repo.wallarm.com/ubuntu/wallarm-node xenial/2.14/ {% language name=\"Ubuntu 18.04 LTS (bionic)\", type=\"sh\" %}","title":"deb http://repo.wallarm.com/ubuntu/wallarm-node xenial/"},{"location":"en/admin-en/migrating-212-214/#deb-httprepowallarmcomubuntuwallarm-node-bionic","text":"deb http://repo.wallarm.com/ubuntu/wallarm-node bionic/2.14/ {% endcodetabs %} If your current filter node is installed on CentOS or Amazon Linux 2, then comment the existing baseurl parameter and add the new one in the /etc/yum.repos.d/wallarm-node.repo file: {% codetabs name=\"CentOS 6.x\", type=\"sh\" %} [wallarm-node]","title":"deb http://repo.wallarm.com/ubuntu/wallarm-node bionic/"},{"location":"en/admin-en/migrating-212-214/#baseurlhttprepowallarmcomcentoswallarm-node6basearch","text":"baseurl= http://repo.wallarm.com/centos/wallarm-node/6/2.14/$basearch {% language name=\"CentOS 7.x or Amazon Linux 2\", type=\"sh\" %} [wallarm-node]","title":"baseurl=http://repo.wallarm.com/centos/wallarm-node/6/$basearch"},{"location":"en/admin-en/migrating-212-214/#baseurlhttprepowallarmcomcentoswallarm-node7basearch","text":"baseurl= http://repo.wallarm.com/centos/wallarm-node/7/2.14/$basearch {% endcodetabs %}","title":"baseurl=http://repo.wallarm.com/centos/wallarm-node/7/$basearch"},{"location":"en/admin-en/migrating-212-214/#updating-the-wallarm-packages","text":"#### Warning:: Update Sequence If the Wallarm modules are installed separately, first update the postanalytics module. Update the Wallarm postanalytics module and the Wallarm NGINX/NGINX Plus/Kong module. If these modules are installed on the same host, then execute the following command: {% termtabs name=\"Debian or Ubuntu\" %}","title":"Updating the Wallarm Packages"},{"location":"en/admin-en/migrating-212-214/#apt-get-install-wallarm-node-no-install-recommends","text":"{% tab name=\"CentOS or Amazon Linux 2\" %}","title":"apt-get install wallarm-node --no-install-recommends"},{"location":"en/admin-en/migrating-212-214/#yum-upgrade-wallarm-node","text":"{% endtermtabs %} If these modules are installed on the different hosts, then execute the following command on the appropriate host to update the postanalytics module: {% termtabs name=\"Debian or Ubuntu\" %}","title":"yum upgrade wallarm-node"},{"location":"en/admin-en/migrating-212-214/#apt-get-install-wallarm-node-tarantool-no-install-recommends","text":"{% tab name=\"CentOS or Amazon Linux 2\" %}","title":"apt-get install wallarm-node-tarantool --no-install-recommends"},{"location":"en/admin-en/migrating-212-214/#yum-upgrade-wallarm-node-tarantool","text":"{% endtermtabs %} execute the following command on the appropriate host to update the Wallarm NGINX/NGINX Plus/Kong module: {% termtabs name=\"Debian or Ubuntu\" %}","title":"yum upgrade wallarm-node-tarantool"},{"location":"en/admin-en/migrating-212-214/#apt-get-install-wallarm-node-nginx-no-install-recommends","text":"{% tab name=\"CentOS or Amazon Linux 2\" %}","title":"apt-get install wallarm-node-nginx --no-install-recommends"},{"location":"en/admin-en/migrating-212-214/#yum-upgrade-wallarm-node-nginx","text":"{% endtermtabs %}","title":"yum upgrade wallarm-node-nginx"},{"location":"en/admin-en/migrating-212-214/#restarting-the-services","text":"After successful update of the Wallarm packages, restart the updated services by issuing the following command: {% termtabs name=\"CentOS 6.x or Ubuntu 14.04\" %}","title":"Restarting the Services"},{"location":"en/admin-en/migrating-212-214/#service-nginx-restart","text":"{% tab name=\"Other supported OS distributive\" %}","title":"service nginx restart"},{"location":"en/admin-en/migrating-212-214/#systemctl-restart-nginx","text":"{% endtermtabs %}","title":"systemctl restart nginx"},{"location":"en/admin-en/migrating-212-214/#the-migration-is-complete","text":"Now you should have successfully migrated your filter node to version 2.14. #### Info:: See also: [Checking the Filter Node Operation][check-operation]","title":"The Migration is Complete"},{"location":"en/admin-en/mirror-traffic-en/","text":"Analyzing Mirrored Traffic with NGINX \u00b6 Starting with NGINX 1.13 you can mirror the traffic to an additional backend. Installing a Wallarm node as the addtional backend lets you run an analysis of the traffic copy without considerable changes to the production system. This setup is useful to: Quickly pilot a project. Be sure that the protection service will not affect application's performance. Train the system on the traffic copy before running the module on the production system. Limitations: Only requests are analyzed; responses are not analyzed. The attacks are not blocked in real time on the request level. Configuration \u00b6 General Diagram \u00b6 Configure NGINX: install the module and configure the request mirroring. Install and configure the Wallarm node. See Installing as a dynamic module for NGINX . On step 1, install the mirroring module ngx_http_mirror_module and configure the request mirroring to an additional backend. On step 2, as an additional backend, install the Wallarm node. Configure NGINX \u00b6 Configure mirroring with the mirror directive that you can set inside the location or server block. Example of mirrored requests to location / on location /mirror-test : location / { mirror /mirror-test; mirror_request_body on; root /usr/share/nginx/html; index index.html index.htm; } location /mirror-test { internal; #proxy_pass http://111.11.111.1$request_uri; proxy_pass http://222.222.222.222$request_uri; proxy_set_header X-SERVER-PORT $server_port; proxy_set_header X-SERVER-ADDR $server_addr; proxy_set_header HOST $http_host; proxy_set_header X-REAL-IP $remote_addr; proxy_set_header X-Request-ID $request_id; } In location , to send the mirrored traffic, you must list the headers that will be sent. As an IP address, set the machine with the Wallarm node that receives the traffic copy. Configure the Wallarm Node to Receive the Mirrored Traffic \u00b6 To have the Wallarm interface display the IP addresses of the attackers, configure real_ip_header and disable the request processing \u2013 the requests will not be analyzed with the wallarm_force_response_* directives as only copies of the requests are sent. Example of the configured real_ip_header with the disabled requests handling: wallarm_force server_addr $http_x_server_addr; wallarm_force server_port $http_x_server_port; #Change 222.222.222.22 to the mirror server address set_real_ip_from 222.222.222.22; real_ip_header X-REAL-IP; #real_ip_recursive on; wallarm_force response_status 0; wallarm_force response_time 0; wallarm_force response_size 0;","title":"Analyzing Mirrored Traffic with NGINX"},{"location":"en/admin-en/mirror-traffic-en/#analyzing-mirrored-traffic-with-nginx","text":"Starting with NGINX 1.13 you can mirror the traffic to an additional backend. Installing a Wallarm node as the addtional backend lets you run an analysis of the traffic copy without considerable changes to the production system. This setup is useful to: Quickly pilot a project. Be sure that the protection service will not affect application's performance. Train the system on the traffic copy before running the module on the production system. Limitations: Only requests are analyzed; responses are not analyzed. The attacks are not blocked in real time on the request level.","title":"Analyzing Mirrored Traffic with NGINX"},{"location":"en/admin-en/mirror-traffic-en/#configuration","text":"","title":"Configuration"},{"location":"en/admin-en/mirror-traffic-en/#general-diagram","text":"Configure NGINX: install the module and configure the request mirroring. Install and configure the Wallarm node. See Installing as a dynamic module for NGINX . On step 1, install the mirroring module ngx_http_mirror_module and configure the request mirroring to an additional backend. On step 2, as an additional backend, install the Wallarm node.","title":"General Diagram"},{"location":"en/admin-en/mirror-traffic-en/#configure-nginx","text":"Configure mirroring with the mirror directive that you can set inside the location or server block. Example of mirrored requests to location / on location /mirror-test : location / { mirror /mirror-test; mirror_request_body on; root /usr/share/nginx/html; index index.html index.htm; } location /mirror-test { internal; #proxy_pass http://111.11.111.1$request_uri; proxy_pass http://222.222.222.222$request_uri; proxy_set_header X-SERVER-PORT $server_port; proxy_set_header X-SERVER-ADDR $server_addr; proxy_set_header HOST $http_host; proxy_set_header X-REAL-IP $remote_addr; proxy_set_header X-Request-ID $request_id; } In location , to send the mirrored traffic, you must list the headers that will be sent. As an IP address, set the machine with the Wallarm node that receives the traffic copy.","title":"Configure NGINX"},{"location":"en/admin-en/mirror-traffic-en/#configure-the-wallarm-node-to-receive-the-mirrored-traffic","text":"To have the Wallarm interface display the IP addresses of the attackers, configure real_ip_header and disable the request processing \u2013 the requests will not be analyzed with the wallarm_force_response_* directives as only copies of the requests are sent. Example of the configured real_ip_header with the disabled requests handling: wallarm_force server_addr $http_x_server_addr; wallarm_force server_port $http_x_server_port; #Change 222.222.222.22 to the mirror server address set_real_ip_from 222.222.222.22; real_ip_header X-REAL-IP; #real_ip_recursive on; wallarm_force response_status 0; wallarm_force response_time 0; wallarm_force response_size 0;","title":"Configure the Wallarm Node to Receive the Mirrored Traffic"},{"location":"en/admin-en/scanner-address-en/","text":"Scanner Addresses for EU Cloud \u00b6 Info This list only works for users who use the EU Cloud https://my.wallarm.com . If you are using the US Cloud https://us1.my.wallarm.com , proceed to the list of scanner addresses for US Cloud . The list of ip addresses for EU Cloud from which the Wallarm Scanner scans for vulnerabilities . 139.162.130.66 139.162.144.202 139.162.151.10 139.162.151.155 139.162.156.102 139.162.157.131 139.162.158.79 139.162.159.137 139.162.159.244 139.162.163.61 139.162.164.41 139.162.166.202 139.162.167.19 139.162.167.51 139.162.168.17 139.162.170.84 139.162.171.141 139.162.172.35 139.162.174.220 139.162.174.26 139.162.175.71 139.162.176.169 139.162.178.148 139.162.179.214 139.162.180.37 139.162.182.156 139.162.182.20 139.162.184.225 139.162.185.243 139.162.186.136 139.162.187.138 139.162.188.246 139.162.190.22 139.162.190.86 139.162.191.89 85.90.246.120 104.200.29.36 104.237.151.23 173.230.130.253 173.230.138.206 173.230.156.200 173.230.158.207 173.255.192.83 173.255.193.92 173.255.200.80 173.255.214.180 192.155.82.205 23.239.11.21 23.92.18.13 23.92.30.204 45.33.105.35 45.33.33.19 45.33.41.31 45.33.64.71 45.33.65.37 45.33.72.81 45.33.73.43 45.33.80.65 45.33.81.109 45.33.88.42 45.33.97.86 45.33.98.89 45.56.102.9 45.56.104.7 45.56.113.41 45.56.114.24 45.56.119.39 50.116.35.43 50.116.42.181 50.116.43.110 66.175.222.237 66.228.58.101 69.164.202.55 72.14.181.105 72.14.184.100 72.14.191.76 172.104.150.243 139.162.190.165 139.162.130.123 139.162.132.87 139.162.145.238 139.162.146.245 139.162.162.71 139.162.171.208 139.162.184.33 139.162.186.129 172.104.128.103 172.104.128.67 172.104.139.37 172.104.146.90 172.104.151.59 172.104.152.244 172.104.152.96 172.104.154.128 172.104.229.59 172.104.250.27 172.104.252.112 45.33.115.7 45.56.69.211 45.79.16.240 50.116.23.110 85.90.246.49 172.104.139.18 172.104.152.28 139.162.177.83 172.104.240.115 172.105.64.135 139.162.153.16 172.104.241.162 139.162.167.48 172.104.233.100 172.104.157.26 172.105.65.182 Active Threat Verification scanner: 178.32.42.221 46.105.75.84 51.254.85.145 188.165.30.182 188.165.136.41 188.165.137.10 54.36.135.252 54.36.135.253 54.36.135.254 54.36.135.255 54.36.131.128 54.36.131.129 #### Info:: Get the list of IP addresses [Download the plain text file containing list of scanners' IP addresses.][file-ips-list]","title":"Scanner Addresses for EU Cloud"},{"location":"en/admin-en/scanner-address-en/#scanner-addresses-for-eu-cloud","text":"Info This list only works for users who use the EU Cloud https://my.wallarm.com . If you are using the US Cloud https://us1.my.wallarm.com , proceed to the list of scanner addresses for US Cloud . The list of ip addresses for EU Cloud from which the Wallarm Scanner scans for vulnerabilities . 139.162.130.66 139.162.144.202 139.162.151.10 139.162.151.155 139.162.156.102 139.162.157.131 139.162.158.79 139.162.159.137 139.162.159.244 139.162.163.61 139.162.164.41 139.162.166.202 139.162.167.19 139.162.167.51 139.162.168.17 139.162.170.84 139.162.171.141 139.162.172.35 139.162.174.220 139.162.174.26 139.162.175.71 139.162.176.169 139.162.178.148 139.162.179.214 139.162.180.37 139.162.182.156 139.162.182.20 139.162.184.225 139.162.185.243 139.162.186.136 139.162.187.138 139.162.188.246 139.162.190.22 139.162.190.86 139.162.191.89 85.90.246.120 104.200.29.36 104.237.151.23 173.230.130.253 173.230.138.206 173.230.156.200 173.230.158.207 173.255.192.83 173.255.193.92 173.255.200.80 173.255.214.180 192.155.82.205 23.239.11.21 23.92.18.13 23.92.30.204 45.33.105.35 45.33.33.19 45.33.41.31 45.33.64.71 45.33.65.37 45.33.72.81 45.33.73.43 45.33.80.65 45.33.81.109 45.33.88.42 45.33.97.86 45.33.98.89 45.56.102.9 45.56.104.7 45.56.113.41 45.56.114.24 45.56.119.39 50.116.35.43 50.116.42.181 50.116.43.110 66.175.222.237 66.228.58.101 69.164.202.55 72.14.181.105 72.14.184.100 72.14.191.76 172.104.150.243 139.162.190.165 139.162.130.123 139.162.132.87 139.162.145.238 139.162.146.245 139.162.162.71 139.162.171.208 139.162.184.33 139.162.186.129 172.104.128.103 172.104.128.67 172.104.139.37 172.104.146.90 172.104.151.59 172.104.152.244 172.104.152.96 172.104.154.128 172.104.229.59 172.104.250.27 172.104.252.112 45.33.115.7 45.56.69.211 45.79.16.240 50.116.23.110 85.90.246.49 172.104.139.18 172.104.152.28 139.162.177.83 172.104.240.115 172.105.64.135 139.162.153.16 172.104.241.162 139.162.167.48 172.104.233.100 172.104.157.26 172.105.65.182 Active Threat Verification scanner: 178.32.42.221 46.105.75.84 51.254.85.145 188.165.30.182 188.165.136.41 188.165.137.10 54.36.135.252 54.36.135.253 54.36.135.254 54.36.135.255 54.36.131.128 54.36.131.129 #### Info:: Get the list of IP addresses [Download the plain text file containing list of scanners' IP addresses.][file-ips-list]","title":"Scanner Addresses for EU Cloud"},{"location":"en/admin-en/scanner-address-us-en/","text":"Scanner Addresses for US Cloud \u00b6 Info This list only works for users who use the US Cloud https://us1.my.wallarm.com . If you are using the EU Cloud https://my.wallarm.com , proceed to the list of scanner addresses for EU Cloud . The list of ip addresses for US Cloud from which the Wallarm Scanner scans for vulnerabilities . 23.239.18.250 104.237.155.105 45.56.71.221 45.79.194.128 104.237.151.202 45.33.15.249 45.33.43.225 45.79.10.15 45.33.79.18 45.79.75.59 23.239.30.236 50.116.11.251 45.56.123.144 45.79.143.18 172.104.21.210 74.207.237.202 45.79.186.159 45.79.216.187 45.33.16.32 96.126.127.23 172.104.208.113 192.81.135.28 Rechecker IP addresses: 35.236.51.79 35.236.75.97 35.236.111.124 35.236.108.88 35.236.16.246 35.236.61.185 35.236.110.91 35.236.14.198 35.235.124.137 35.236.48.47 35.236.100.176 35.236.18.117 35.235.112.188 35.236.55.214 35.236.126.84 35.236.3.158 35.236.127.211 35.236.118.146 35.236.20.89 35.236.1.4 #### Info:: Get the list of IP addresses [Download the plain text file containing list of scanners' IP addresses.][file-ips-list]","title":"Scanner Addresses for US Cloud"},{"location":"en/admin-en/scanner-address-us-en/#scanner-addresses-for-us-cloud","text":"Info This list only works for users who use the US Cloud https://us1.my.wallarm.com . If you are using the EU Cloud https://my.wallarm.com , proceed to the list of scanner addresses for EU Cloud . The list of ip addresses for US Cloud from which the Wallarm Scanner scans for vulnerabilities . 23.239.18.250 104.237.155.105 45.56.71.221 45.79.194.128 104.237.151.202 45.33.15.249 45.33.43.225 45.79.10.15 45.33.79.18 45.79.75.59 23.239.30.236 50.116.11.251 45.56.123.144 45.79.143.18 172.104.21.210 74.207.237.202 45.79.186.159 45.79.216.187 45.33.16.32 96.126.127.23 172.104.208.113 192.81.135.28 Rechecker IP addresses: 35.236.51.79 35.236.75.97 35.236.111.124 35.236.108.88 35.236.16.246 35.236.61.185 35.236.110.91 35.236.14.198 35.235.124.137 35.236.48.47 35.236.100.176 35.236.18.117 35.235.112.188 35.236.55.214 35.236.126.84 35.236.3.158 35.236.127.211 35.236.118.146 35.236.20.89 35.236.1.4 #### Info:: Get the list of IP addresses [Download the plain text file containing list of scanners' IP addresses.][file-ips-list]","title":"Scanner Addresses for US Cloud"},{"location":"en/admin-en/scanner-complaint-en/","text":"Contacting Wallarm Support to Stop the Scanner \u00b6 If the Wallarm scanner scans your company's resources that you never set for discovery, contact Wallarm Support to exclude the resource from scanning. See also Scanner addresses","title":"Contacting Wallarm Support to Stop the Scanner"},{"location":"en/admin-en/scanner-complaint-en/#contacting-wallarm-support-to-stop-the-scanner","text":"If the Wallarm scanner scans your company's resources that you never set for discovery, contact Wallarm Support to exclude the resource from scanning. See also Scanner addresses","title":"Contacting Wallarm Support to Stop the Scanner"},{"location":"en/admin-en/scanner-ips-whitelisting/","text":"Disabling IP Address Blocking for the Wallarm Scanner \u00b6 Note that if you use the blocking mode of the filter node (the wallarm_mode directive) by default when detecting malicious requests, you must explicitly specify for the Wallarm scanner a list of IP addresses from which requests should not be blocked. Suppose the following blocking settings are set in the NGINX configuration file: map $remote_addr $wallarm_mode_real { default block; # Default blocking mode enabled 1.1.1.1/24 monitoring; # Monitoring mode (cancels blocking) 2.2.2.2 off; # Blocking mode for the address disabled ... } ... wallarm_mode $wallarm_mode_real; ... The off directive is used keep each IP address reserved for the Wallarm scanner from being blocked. #### Info:: The Wallarm Scanner IP Addresses Lists of the IP addresses for the scanner: * [for the EU cloud](scanner-address-en.md) * [for the US cloud](scanner-address-us-en.md). To avoid overloading the NGINX configuration file, you can make a list of the IP addresses for the scanner in a separate file and then add its contents to the configuration file using the include directive. For example, create the /etc/nginx/scanner-ip-list file: # The list of the Wallarm scanner IP addresses 3.3.3.3 off; 4.4.4.4 off; 5.5.5.5 off; ... # Add all the required IP addresses here Now use the include directive to include this list in the required block of the configuration file: map $remote_addr $wallarm_mode_real { default block; 1.1.1.1/24 monitoring; 2.2.2.2 off; include /etc/nginx/scanner-ip-list; } ... wallarm_mode $wallarm_mode_real; #### Warning:: Using Additional Traffic Filtering Facilities Note that if you use additional facilities (software or hardware) to automatically filter and block traffic, it is also recommended that you configure a whitelist with the IP addresses for the Wallarm scanner.","title":"Disabling the IP Address Blocking of the Wallarm Scanner"},{"location":"en/admin-en/scanner-ips-whitelisting/#disabling-ip-address-blocking-for-the-wallarm-scanner","text":"Note that if you use the blocking mode of the filter node (the wallarm_mode directive) by default when detecting malicious requests, you must explicitly specify for the Wallarm scanner a list of IP addresses from which requests should not be blocked. Suppose the following blocking settings are set in the NGINX configuration file: map $remote_addr $wallarm_mode_real { default block; # Default blocking mode enabled 1.1.1.1/24 monitoring; # Monitoring mode (cancels blocking) 2.2.2.2 off; # Blocking mode for the address disabled ... } ... wallarm_mode $wallarm_mode_real; ... The off directive is used keep each IP address reserved for the Wallarm scanner from being blocked. #### Info:: The Wallarm Scanner IP Addresses Lists of the IP addresses for the scanner: * [for the EU cloud](scanner-address-en.md) * [for the US cloud](scanner-address-us-en.md). To avoid overloading the NGINX configuration file, you can make a list of the IP addresses for the scanner in a separate file and then add its contents to the configuration file using the include directive. For example, create the /etc/nginx/scanner-ip-list file: # The list of the Wallarm scanner IP addresses 3.3.3.3 off; 4.4.4.4 off; 5.5.5.5 off; ... # Add all the required IP addresses here Now use the include directive to include this list in the required block of the configuration file: map $remote_addr $wallarm_mode_real { default block; 1.1.1.1/24 monitoring; 2.2.2.2 off; include /etc/nginx/scanner-ip-list; } ... wallarm_mode $wallarm_mode_real; #### Warning:: Using Additional Traffic Filtering Facilities Note that if you use additional facilities (software or hardware) to automatically filter and block traffic, it is also recommended that you configure a whitelist with the IP addresses for the Wallarm scanner.","title":"Disabling IP Address Blocking for the Wallarm Scanner"},{"location":"en/admin-en/sensitive-data-en/","text":"Masking Sensitive Data \u00b6 The Wallarm node sends the following data to the Wallarm Cloud: Serialized requests with attacks. Wallarm system counters. System statistics: CPU load, RAM usage, etc. Wallarm system statistics: number of processed NGINX requests, Tarantool statistics, etc. Information on the nature of the traffic that Wallarm needs to correctly detect application structure. You can mask the data that the filter node sends to the Wallarm cloud. The pattern can be set up to mask the sensitive data even in malicious requests: user_session , password , token , etc. To turn on and set up the data masking, contact Wallarm support .","title":"Masking Sensitive Data"},{"location":"en/admin-en/sensitive-data-en/#masking-sensitive-data","text":"The Wallarm node sends the following data to the Wallarm Cloud: Serialized requests with attacks. Wallarm system counters. System statistics: CPU load, RAM usage, etc. Wallarm system statistics: number of processed NGINX requests, Tarantool statistics, etc. Information on the nature of the traffic that Wallarm needs to correctly detect application structure. You can mask the data that the filter node sends to the Wallarm cloud. The pattern can be set up to mask the sensitive data even in malicious requests: user_session , password , token , etc. To turn on and set up the data masking, contact Wallarm support .","title":"Masking Sensitive Data"},{"location":"en/admin-en/supported-platforms/","text":"Supported Platforms \u00b6 Installation Prerequisites Make sure that you acquire the following before installing the filter node: The supported platform The permissions to execute commands with root rights A Wallarm account in one of the following clouds: The Wallarm EU cloud The Wallarm US cloud The Wallarm filter node can be installed on the following platforms: NGINX and NGINX Plus The integration of the filter node with NGINX or NGINX Plus is performed using several modules. There are several options for module installation . The option you select will depend on the way you install NGINX or NGINX Plus. Additionally, you can deploy a filter node as a Docker container. The resulting filter node installation will contain all necessary modules (see installation instructions ). Supported Operating Systems The Wallarm modules can be installed on the following operating systems: Debian 8.x (jessie) Debian 9.x (stretch) Debian 10.x (buster) Ubuntu 14.04 LTS (trusty) Ubuntu 16.04 LTS (xenial) Ubuntu 18.04 LTS (bionic) CentOS 6.x CentOS 7.x Amazon Linux 2 Operating System Requirements The modules can only be installed on 64-bit operating systems. The Kubernetes Cluster #### Warning:: Supported Kubernetes Platform Please note, that the Wallarm NGINX or NGINX Plus Ingress controllers run only on the Kubernetes platform version 1.15 and lower. Installing the filter node on the Kubernetes Cluster provides the following options: * The NGINX Ingress Controller with Integrated Wallarm Services ( installation instructions ) > #### Info:: Konvoy Support > > Note that you can deploy this Ingress controller on the Konvoy by D2IQ (formerly Mesosphere). > > [The Wallarm's installation instructions][link-ig-ingress-nginx] are suitable if you are deploying the Ingress Controller with integrated Wallarm services on the Konvoy. However, you may want to look at [the D2IQ's installation instructions][link-ig-ingress-nginx-d2iq]. The NGINX Plus Ingress Controller with Integrated Wallarm Services ( installation instructions ) The cloud platforms: Amazon AWS ( installation instructions ) Google Cloud ( installation instructions ) Heroku with the Heroku-16 or Heroku-18 stack ( installation instructions ) Kong ( installation instructions ) > #### Info:: Supported Operating Systems > > The Kong platform must have version 1.4.3 or lower and must be installed on one of the following operating systems: > > * Debian 8.x (jessie) > * Debian 9.x (stretch) > * Ubuntu 14.04 LTS (trusty) > * Ubuntu 16.04 LTS (xenial) > * Ubuntu 18.04 LTS (bionic) > * CentOS 6.x > * CentOS 7.x","title":"Supported Platforms"},{"location":"en/admin-en/supported-platforms/#supported-platforms","text":"Installation Prerequisites Make sure that you acquire the following before installing the filter node: The supported platform The permissions to execute commands with root rights A Wallarm account in one of the following clouds: The Wallarm EU cloud The Wallarm US cloud The Wallarm filter node can be installed on the following platforms: NGINX and NGINX Plus The integration of the filter node with NGINX or NGINX Plus is performed using several modules. There are several options for module installation . The option you select will depend on the way you install NGINX or NGINX Plus. Additionally, you can deploy a filter node as a Docker container. The resulting filter node installation will contain all necessary modules (see installation instructions ). Supported Operating Systems The Wallarm modules can be installed on the following operating systems: Debian 8.x (jessie) Debian 9.x (stretch) Debian 10.x (buster) Ubuntu 14.04 LTS (trusty) Ubuntu 16.04 LTS (xenial) Ubuntu 18.04 LTS (bionic) CentOS 6.x CentOS 7.x Amazon Linux 2 Operating System Requirements The modules can only be installed on 64-bit operating systems. The Kubernetes Cluster #### Warning:: Supported Kubernetes Platform Please note, that the Wallarm NGINX or NGINX Plus Ingress controllers run only on the Kubernetes platform version 1.15 and lower. Installing the filter node on the Kubernetes Cluster provides the following options: * The NGINX Ingress Controller with Integrated Wallarm Services ( installation instructions ) > #### Info:: Konvoy Support > > Note that you can deploy this Ingress controller on the Konvoy by D2IQ (formerly Mesosphere). > > [The Wallarm's installation instructions][link-ig-ingress-nginx] are suitable if you are deploying the Ingress Controller with integrated Wallarm services on the Konvoy. However, you may want to look at [the D2IQ's installation instructions][link-ig-ingress-nginx-d2iq]. The NGINX Plus Ingress Controller with Integrated Wallarm Services ( installation instructions ) The cloud platforms: Amazon AWS ( installation instructions ) Google Cloud ( installation instructions ) Heroku with the Heroku-16 or Heroku-18 stack ( installation instructions ) Kong ( installation instructions ) > #### Info:: Supported Operating Systems > > The Kong platform must have version 1.4.3 or lower and must be installed on one of the following operating systems: > > * Debian 8.x (jessie) > * Debian 9.x (stretch) > * Ubuntu 14.04 LTS (trusty) > * Ubuntu 16.04 LTS (xenial) > * Ubuntu 18.04 LTS (bionic) > * CentOS 6.x > * CentOS 7.x","title":"Supported Platforms"},{"location":"en/admin-en/testrun-en/","text":"Testing your Applications \u00b6 You can use the Test run feature to test your application against vulnerabilities before putting it in production. To run a test, you must have: The Wallarm FAST Proxy Docker container. The container provides access to the application for your requests only. Any web application testing tool. For example, Burp Suite. The Test run feature in the Wallarm cloud at https://my.wallarm.com/ How It Works \u00b6 The request passes from browser to the testing tool. The testing tool adds X-Wallarm-Marker to the header of the request and a unique token. The request with X-Wallarm-Marker and a unique token is passed to Wallarm FAST Proxy. Wallarm FAST Proxy sends the request to the application. The application returns the request to Wallarm FAST Proxy. Wallarm FAST Proxy sends the request to Wallarm Fuzzer, which is part of the Wallarm scanner. Wallarm Fuzzer generates requests and sends them to Wallarm FAST Proxy. Wallarm FAST Proxy sends fuzzing requests to the tested application. The requests are processed by the filter node and are sent to the Wallarm cloud. The test results are displayed in the cloud at https://my.wallarm.com/ Configuring and Starting Wallarm FAST Proxy \u00b6 Wallarm FAST Proxy is delivered as a Docker image in Docker Hub. Wallarm FAST Proxy provides access to the tested application for your requests only. Wallarm Fuzzer is part of the Wallarm scanner and resides on the Wallarm servers. See [Scanner addresses]((../user-en/configure-scanner-en.md). The Wallarm scanner must have access to Wallarm FAST Proxy. Start Wallarm FAST Proxy: # docker run -e VARIABLE wallarm/fast-proxy Where VARIABLE: ALLOWED_HOSTS \u2013 The hosts to which requests can be sent. The variable supports regular expressions. ALLOW_FROM \u2013 The IP addresses and subnets that are allowed to send the requests. This includes the IP addresses of the Wallarm scanner. You can list multiple IP addresses by separating them with a comma, a full stop, a semicolon or a space. BACKEND \u2013 The IP address to which the requests are forced. If no IP address specified, the requests are sent to the host. NODE_UUID \u2013 The UUID of your filter node. NODE_SECRET \u2013 The secret of your filter node. PUBLIC_IP \u2013 The IP address of Wallarm FAST Proxy accessible by the Wallarm scanner. Configuring and Starting the Test Run in the Wallarm Cloud \u00b6 In the cloud at https://my.wallarm.com , on the Test run tab click Create test run . Fill out the following: Name \u2013 This can be any name. Description \u2013 An optional description of the test. Source IP for test requests \u2013 An IP address or a subnet, from which the test requests will be sent. Tags \u2013 Optional tags to filter the results in the web interface. Stop on first fail \u2013 Stop the test run on detecting the first vulnerability. Copy the unique token. You must put the token to the X-Wallarm-Marker header of your test requests. Configuring and Starting the Testing Tool \u00b6 Configure the testing tool so that: The requests pass to the IP address of Wallarm FAST Proxy. The requests must have X-Wallarm-Marker with a unique token in the header. You can use any testing tool to send the requests. Configuration example with Firefox and Burp Suite: Configure Firefox proxy on 127.0.0.1. See Configuring Firefox to work with Burp . Import the Burp certificate. See Installing CA Certificate . Add X-Wallarm-Marker: token to the request in Burp Suite and the Repeater tool. See Using Repeater .","title":"Testing your Applications"},{"location":"en/admin-en/testrun-en/#testing-your-applications","text":"You can use the Test run feature to test your application against vulnerabilities before putting it in production. To run a test, you must have: The Wallarm FAST Proxy Docker container. The container provides access to the application for your requests only. Any web application testing tool. For example, Burp Suite. The Test run feature in the Wallarm cloud at https://my.wallarm.com/","title":"Testing your Applications"},{"location":"en/admin-en/testrun-en/#how-it-works","text":"The request passes from browser to the testing tool. The testing tool adds X-Wallarm-Marker to the header of the request and a unique token. The request with X-Wallarm-Marker and a unique token is passed to Wallarm FAST Proxy. Wallarm FAST Proxy sends the request to the application. The application returns the request to Wallarm FAST Proxy. Wallarm FAST Proxy sends the request to Wallarm Fuzzer, which is part of the Wallarm scanner. Wallarm Fuzzer generates requests and sends them to Wallarm FAST Proxy. Wallarm FAST Proxy sends fuzzing requests to the tested application. The requests are processed by the filter node and are sent to the Wallarm cloud. The test results are displayed in the cloud at https://my.wallarm.com/","title":"How It Works"},{"location":"en/admin-en/testrun-en/#configuring-and-starting-wallarm-fast-proxy","text":"Wallarm FAST Proxy is delivered as a Docker image in Docker Hub. Wallarm FAST Proxy provides access to the tested application for your requests only. Wallarm Fuzzer is part of the Wallarm scanner and resides on the Wallarm servers. See [Scanner addresses]((../user-en/configure-scanner-en.md). The Wallarm scanner must have access to Wallarm FAST Proxy. Start Wallarm FAST Proxy: # docker run -e VARIABLE wallarm/fast-proxy Where VARIABLE: ALLOWED_HOSTS \u2013 The hosts to which requests can be sent. The variable supports regular expressions. ALLOW_FROM \u2013 The IP addresses and subnets that are allowed to send the requests. This includes the IP addresses of the Wallarm scanner. You can list multiple IP addresses by separating them with a comma, a full stop, a semicolon or a space. BACKEND \u2013 The IP address to which the requests are forced. If no IP address specified, the requests are sent to the host. NODE_UUID \u2013 The UUID of your filter node. NODE_SECRET \u2013 The secret of your filter node. PUBLIC_IP \u2013 The IP address of Wallarm FAST Proxy accessible by the Wallarm scanner.","title":"Configuring and Starting Wallarm FAST Proxy"},{"location":"en/admin-en/testrun-en/#configuring-and-starting-the-test-run-in-the-wallarm-cloud","text":"In the cloud at https://my.wallarm.com , on the Test run tab click Create test run . Fill out the following: Name \u2013 This can be any name. Description \u2013 An optional description of the test. Source IP for test requests \u2013 An IP address or a subnet, from which the test requests will be sent. Tags \u2013 Optional tags to filter the results in the web interface. Stop on first fail \u2013 Stop the test run on detecting the first vulnerability. Copy the unique token. You must put the token to the X-Wallarm-Marker header of your test requests.","title":"Configuring and Starting the Test Run in the Wallarm Cloud"},{"location":"en/admin-en/testrun-en/#configuring-and-starting-the-testing-tool","text":"Configure the testing tool so that: The requests pass to the IP address of Wallarm FAST Proxy. The requests must have X-Wallarm-Marker with a unique token in the header. You can use any testing tool to send the requests. Configuration example with Firefox and Burp Suite: Configure Firefox proxy on 127.0.0.1. See Configuring Firefox to work with Burp . Import the Burp certificate. See Installing CA Certificate . Add X-Wallarm-Marker: token to the request in Burp Suite and the Repeater tool. See Using Repeater .","title":"Configuring and Starting the Testing Tool"},{"location":"en/admin-en/troubleshooting/","text":"","title":"Troubleshooting"},{"location":"en/admin-en/uat-checklist-en/","text":"Wallarm User Acceptance Testing Checklist \u00b6 This section provides you with a checklist to ensure your Wallarm instance operates correctly. Operation Expected behavior Check Wallarm node detects attacks Attacks are detected You can log into the Wallarm interface You can log in Wallarm interface shows requests per second You see the requests stats Wallarm marks requests as false and stops blocking them Wallarm does not block the requests Wallarm detects vulnerabilities and creates security incidents Security incidents are created Attack verification works Attacks are verified Wallarm detects perimeter Scope is discovered Blacklisting works IP addresses are blocked Users can be configured and have proper access rights Users can be created and updated User activity log has records The log has records Reporting works You receive reports Wallarm Node Detects Attacks \u00b6 Send a malicious request to your resource: http://<resource_URL>/?id='or+1=1--a-<script>prompt(1)</script> Run the following command to check if the attack count increased: $ curl http://127.0.0.8/wallarm-status See also Checking the filter node operation You Can Log into the Wallarm Interface \u00b6 Proceed to the link that corresponds to the cloud you are using: If you are using the EU cloud, proceed to the https://my.wallarm.com/ link. If you are using the US cloud, proceed to the https://us1.my.wallarm.com link. See if you can log in successfully. See also Dashboard overview . Wallarm Interface Shows Requests per Second \u00b6 Send a request to your resource: $ curl http://<resource_URL> Or send several requests with a bash script: for (( i=0 ; $i<10 ; i++ )) ; do curl http://<resource_URL> ; done This example is for 10 requests. Check if the Wallarm interface shows detected requests per second. See also Application firewall . Wallarm Marks Requests as False and Stops Blocking them \u00b6 Expand an attack on the Attacks tab. Select a hit and click False . Wait for around 3 minutes. Resend the request and check if Wallarm detects it as an attack and blocks it. See also Working with false attacks . Wallarm Detects Vulnerabilities and Creates Security Incidents \u00b6 Ensure you have an open vulnerability on your resource. Send a malicious request to exploit the vulnerability. Check if there is an incident detected in the Wallarm interface. See also Checking attacks and incidents . Attack Verification Works \u00b6 On the Attacks tab, check the detected malicious request from the previous step. Check the status in the Verification column. See also Verifying attacks . Wallarm Detects Perimeter \u00b6 On the Scanner tab, add your resource's domain. Check if Wallarm discovers all resources associated with the added domain. See also Working with the scanner . Blacklisting Works \u00b6 Set up IP address blocking as described in Blocking by IP address . On the Settings -> Blacklist tab, add the blocked IP address. Check if the IP address is blocked and the Wallarm interface displays the IP address as blocked. See also IP Blacklist . Users Can Be Configured and Have Proper Access Rights \u00b6 Ensure you have the Administrator role in the Wallarm system. Create, change role, disable, and delete a user as described in Configuring users . See also Configuring users . User Activity Log Has Records \u00b6 Go to Settings \u2013> Users . Check that User Activity Log has records. See also User activity log . Reporting Works \u00b6 On the Attacks tab, put in a search query. Click the report button on the right. Put in your email and click the report button again. Check if you receive the report. See also Creating a custom report .","title":"Wallarm User Acceptance Testing Checklist"},{"location":"en/admin-en/uat-checklist-en/#wallarm-user-acceptance-testing-checklist","text":"This section provides you with a checklist to ensure your Wallarm instance operates correctly. Operation Expected behavior Check Wallarm node detects attacks Attacks are detected You can log into the Wallarm interface You can log in Wallarm interface shows requests per second You see the requests stats Wallarm marks requests as false and stops blocking them Wallarm does not block the requests Wallarm detects vulnerabilities and creates security incidents Security incidents are created Attack verification works Attacks are verified Wallarm detects perimeter Scope is discovered Blacklisting works IP addresses are blocked Users can be configured and have proper access rights Users can be created and updated User activity log has records The log has records Reporting works You receive reports","title":"Wallarm User Acceptance Testing Checklist"},{"location":"en/admin-en/uat-checklist-en/#wallarm-node-detects-attacks","text":"Send a malicious request to your resource: http://<resource_URL>/?id='or+1=1--a-<script>prompt(1)</script> Run the following command to check if the attack count increased: $ curl http://127.0.0.8/wallarm-status See also Checking the filter node operation","title":"Wallarm Node Detects Attacks"},{"location":"en/admin-en/uat-checklist-en/#you-can-log-into-the-wallarm-interface","text":"Proceed to the link that corresponds to the cloud you are using: If you are using the EU cloud, proceed to the https://my.wallarm.com/ link. If you are using the US cloud, proceed to the https://us1.my.wallarm.com link. See if you can log in successfully. See also Dashboard overview .","title":"You Can Log into the Wallarm Interface"},{"location":"en/admin-en/uat-checklist-en/#wallarm-interface-shows-requests-per-second","text":"Send a request to your resource: $ curl http://<resource_URL> Or send several requests with a bash script: for (( i=0 ; $i<10 ; i++ )) ; do curl http://<resource_URL> ; done This example is for 10 requests. Check if the Wallarm interface shows detected requests per second. See also Application firewall .","title":"Wallarm Interface Shows Requests per Second"},{"location":"en/admin-en/uat-checklist-en/#wallarm-marks-requests-as-false-and-stops-blocking-them","text":"Expand an attack on the Attacks tab. Select a hit and click False . Wait for around 3 minutes. Resend the request and check if Wallarm detects it as an attack and blocks it. See also Working with false attacks .","title":"Wallarm Marks Requests as False and Stops Blocking them"},{"location":"en/admin-en/uat-checklist-en/#wallarm-detects-vulnerabilities-and-creates-security-incidents","text":"Ensure you have an open vulnerability on your resource. Send a malicious request to exploit the vulnerability. Check if there is an incident detected in the Wallarm interface. See also Checking attacks and incidents .","title":"Wallarm Detects Vulnerabilities and Creates Security Incidents"},{"location":"en/admin-en/uat-checklist-en/#attack-verification-works","text":"On the Attacks tab, check the detected malicious request from the previous step. Check the status in the Verification column. See also Verifying attacks .","title":"Attack Verification Works"},{"location":"en/admin-en/uat-checklist-en/#wallarm-detects-perimeter","text":"On the Scanner tab, add your resource's domain. Check if Wallarm discovers all resources associated with the added domain. See also Working with the scanner .","title":"Wallarm Detects Perimeter"},{"location":"en/admin-en/uat-checklist-en/#blacklisting-works","text":"Set up IP address blocking as described in Blocking by IP address . On the Settings -> Blacklist tab, add the blocked IP address. Check if the IP address is blocked and the Wallarm interface displays the IP address as blocked. See also IP Blacklist .","title":"Blacklisting Works"},{"location":"en/admin-en/uat-checklist-en/#users-can-be-configured-and-have-proper-access-rights","text":"Ensure you have the Administrator role in the Wallarm system. Create, change role, disable, and delete a user as described in Configuring users . See also Configuring users .","title":"Users Can Be Configured and Have Proper Access Rights"},{"location":"en/admin-en/uat-checklist-en/#user-activity-log-has-records","text":"Go to Settings \u2013> Users . Check that User Activity Log has records. See also User activity log .","title":"User Activity Log Has Records"},{"location":"en/admin-en/uat-checklist-en/#reporting-works","text":"On the Attacks tab, put in a search query. Click the report button on the right. Put in your email and click the report button again. Check if you receive the report. See also Creating a custom report .","title":"Reporting Works"},{"location":"en/admin-en/update-docker-en/","text":"Updating the Docker Container \u00b6 To update the Wallarm modules installed inside the Docker container, you must: Download the updated image. Stop the running container. Start the container on the new image. 1. Download the Updated Image \u00b6 Run the command: # docker pull wallarm/node 2. Stop the Running Container \u00b6 Run the command: # docker stop <container name> 3. Start the Container on the New Image. \u00b6 Run the command: # docker run -d -v /path/to/license.key:/etc/wallarm/license.key -v /path/to/node.yaml:/etc/wallarm/node.yaml -e NGINX_BACKEND=93.184.216.34 wallarm/node See also Deploying with Docker","title":"Updating Docker"},{"location":"en/admin-en/update-docker-en/#updating-the-docker-container","text":"To update the Wallarm modules installed inside the Docker container, you must: Download the updated image. Stop the running container. Start the container on the new image.","title":"Updating the Docker Container"},{"location":"en/admin-en/update-docker-en/#1-download-the-updated-image","text":"Run the command: # docker pull wallarm/node","title":"1. Download the Updated Image"},{"location":"en/admin-en/update-docker-en/#2-stop-the-running-container","text":"Run the command: # docker stop <container name>","title":"2. Stop the Running Container"},{"location":"en/admin-en/update-docker-en/#3-start-the-container-on-the-new-image","text":"Run the command: # docker run -d -v /path/to/license.key:/etc/wallarm/license.key -v /path/to/node.yaml:/etc/wallarm/node.yaml -e NGINX_BACKEND=93.184.216.34 wallarm/node See also Deploying with Docker","title":"3. Start the Container on the New Image."},{"location":"en/admin-en/update-linux-en/","text":"Updating the Wallarm Packages on Linux \u00b6 To update the Wallarm packages on Linux, you must: Update the Wallarm packages. Check the NGINX configuration file. Restart NGINX. #### Warning:: Updating the Postanalytics Module The postanalytics module should be updated prior to updating any other packages if it is installed on the separate server. If the postanalytics module and Wallarm NGINX module shares the same server, then no additional actions are required. Take steps described in this document to update all packages at once. 1. Update the Wallarm Packages \u00b6 Run the command if postanalytics module and Wallarm NGINX modules are installed on the same server: {% termtabs name=\"Debian 8.x (jessie)\" -%} apt-get update \u00b6 apt-get install wallarm-node \u00b6 {%- tab name=\"Debian 9.x (stretch)\" -%} apt-get update \u00b6 apt-get install wallarm-node \u00b6 {%- tab name=\"Debian 10.x (buster)\" -%} apt-get update \u00b6 apt-get install wallarm-node \u00b6 {%- tab name=\"Ubuntu 14.04 LTS (trusty)\" -%} apt-get update \u00b6 apt-get install wallarm-node \u00b6 {%- tab name=\"Ubuntu 16.04 LTS (xenial)\" -%} apt-get update \u00b6 apt-get install wallarm-node \u00b6 {%- tab name=\"Ubuntu 18.04 LTS (bionic)\" -%} apt-get update \u00b6 apt-get install wallarm-node \u00b6 {%- tab name=\"CentOS 6.x\" -%} yum update wallarm-node \u00b6 {%- tab name=\"CentOS 7.x\" -%} yum update wallarm-node \u00b6 {%- tab name=\"Amazon Linux 2\" -%} yum update wallarm-node \u00b6 {%- endtermtabs %} Run the command if only Wallarm NGINX module is installed on the server: {% termtabs name=\"Debian 8.x (jessie)\" -%} apt-get update \u00b6 apt-get install wallarm-node-nginx \u00b6 {%- tab name=\"Debian 9.x (stretch)\" -%} apt-get update \u00b6 apt-get install wallarm-node-nginx \u00b6 {%- tab name=\"Debian 10.x (buster)\" -%} apt-get update \u00b6 apt-get install wallarm-node-nginx \u00b6 {%- tab name=\"Ubuntu 14.04 LTS (trusty)\" -%} apt-get update \u00b6 apt-get install wallarm-node-nginx \u00b6 {%- tab name=\"Ubuntu 16.04 LTS (xenial)\" -%} apt-get update \u00b6 apt-get install wallarm-node-nginx \u00b6 {%- tab name=\"Ubuntu 18.04 LTS (bionic)\" -%} apt-get update \u00b6 apt-get install wallarm-node-nginx \u00b6 {%- tab name=\"CentOS 6.x\" -%} yum update wallarm-node-nginx \u00b6 {%- tab name=\"CentOS 7.x\" -%} yum update wallarm-node-nginx \u00b6 {%- tab name=\"Amazon Linux 2\" -%} yum update wallarm-node-nginx \u00b6 {%- endtermtabs %} Repository access Your system must have access to https://repo.wallarm.com to download the packages. Ensure the access is not blocked by a firewall. 2. Check the NGINX Configuration File \u00b6 Parameters wallarm_tarantool_host and wallarm_tarantool_port The wallarm_tarantool_host and wallarm_tarantool_port have been deprecated starting with version 2.6. If you used these parameters to set up Tarantool, you must replace them with wallarm_tarantool_upstream . See wallarm_tarantool_upstream . Check that the configuration file is correct after updating the packages. Run the command: # nginx-wallarm -t 3. Restart NGINX \u00b6 If you installed Wallarm with NGINX Plus or as a dynamic module for NGINX, restart the nginx service. Restart the nginx service: Debian 8.x (jessie) systemctl restart nginx Debian 9.x (stretch) systemctl restart nginx Debian 10.x (buster) systemctl restart nginx Ubuntu 14.04 LTS (trusty) service nginx restart Ubuntu 16.04 LTS (xenial) service nginx restart Ubuntu 18.04 LTS (bionic) service nginx restart CentOS 6.x service nginx restart CentOS 7.x systemctl restart nginx Amazon Linux 2 systemctl restart nginx If you installed Wallarm without NGINX Plus or not as a dynamic module for NGINX, restart the nginx-wallarm service. Restart the nginx-wallarm service: {% termtabs name=\"Debian 8.x (jessie)\" -%} systemctl restart nginx-wallarm \u00b6 {%- tab name=\"Debian 9.x (stretch)\" -%} systemctl restart nginx-wallarm \u00b6 {%- tab name=\"Ubuntu 14.04 LTS (trusty)\" -%} service nginx-wallarm restart \u00b6 {%- tab name=\"Ubuntu 16.04 LTS (xenial)\" -%} service nginx-wallarm restart \u00b6 {%- tab name=\"Ubuntu 18.04 LTS (bionic)\" -%} service nginx-wallarm restart \u00b6 {%- tab name=\"CentOS 6.x\" -%} service nginx-wallarm restart \u00b6 {%- tab name=\"CentOS 7.x\" -%} systemctl restart nginx-wallarm \u00b6 {%- tab name=\"Amazon Linux 2\" -%} systemctl restart nginx-wallarm \u00b6 {%- endtermtabs %}","title":"Updating on Linux"},{"location":"en/admin-en/update-linux-en/#updating-the-wallarm-packages-on-linux","text":"To update the Wallarm packages on Linux, you must: Update the Wallarm packages. Check the NGINX configuration file. Restart NGINX. #### Warning:: Updating the Postanalytics Module The postanalytics module should be updated prior to updating any other packages if it is installed on the separate server. If the postanalytics module and Wallarm NGINX module shares the same server, then no additional actions are required. Take steps described in this document to update all packages at once.","title":"Updating the Wallarm Packages on Linux"},{"location":"en/admin-en/update-linux-en/#1-update-the-wallarm-packages","text":"Run the command if postanalytics module and Wallarm NGINX modules are installed on the same server: {% termtabs name=\"Debian 8.x (jessie)\" -%}","title":"1. Update the Wallarm Packages"},{"location":"en/admin-en/update-linux-en/#apt-get-update","text":"","title":"apt-get update"},{"location":"en/admin-en/update-linux-en/#apt-get-install-wallarm-node","text":"{%- tab name=\"Debian 9.x (stretch)\" -%}","title":"apt-get install wallarm-node"},{"location":"en/admin-en/update-linux-en/#apt-get-update_1","text":"","title":"apt-get update"},{"location":"en/admin-en/update-linux-en/#apt-get-install-wallarm-node_1","text":"{%- tab name=\"Debian 10.x (buster)\" -%}","title":"apt-get install wallarm-node"},{"location":"en/admin-en/update-linux-en/#apt-get-update_2","text":"","title":"apt-get update"},{"location":"en/admin-en/update-linux-en/#apt-get-install-wallarm-node_2","text":"{%- tab name=\"Ubuntu 14.04 LTS (trusty)\" -%}","title":"apt-get install wallarm-node"},{"location":"en/admin-en/update-linux-en/#apt-get-update_3","text":"","title":"apt-get update"},{"location":"en/admin-en/update-linux-en/#apt-get-install-wallarm-node_3","text":"{%- tab name=\"Ubuntu 16.04 LTS (xenial)\" -%}","title":"apt-get install wallarm-node"},{"location":"en/admin-en/update-linux-en/#apt-get-update_4","text":"","title":"apt-get update"},{"location":"en/admin-en/update-linux-en/#apt-get-install-wallarm-node_4","text":"{%- tab name=\"Ubuntu 18.04 LTS (bionic)\" -%}","title":"apt-get install wallarm-node"},{"location":"en/admin-en/update-linux-en/#apt-get-update_5","text":"","title":"apt-get update"},{"location":"en/admin-en/update-linux-en/#apt-get-install-wallarm-node_5","text":"{%- tab name=\"CentOS 6.x\" -%}","title":"apt-get install wallarm-node"},{"location":"en/admin-en/update-linux-en/#yum-update-wallarm-node","text":"{%- tab name=\"CentOS 7.x\" -%}","title":"yum update wallarm-node"},{"location":"en/admin-en/update-linux-en/#yum-update-wallarm-node_1","text":"{%- tab name=\"Amazon Linux 2\" -%}","title":"yum update wallarm-node"},{"location":"en/admin-en/update-linux-en/#yum-update-wallarm-node_2","text":"{%- endtermtabs %} Run the command if only Wallarm NGINX module is installed on the server: {% termtabs name=\"Debian 8.x (jessie)\" -%}","title":"yum update wallarm-node"},{"location":"en/admin-en/update-linux-en/#apt-get-update_6","text":"","title":"apt-get update"},{"location":"en/admin-en/update-linux-en/#apt-get-install-wallarm-node-nginx","text":"{%- tab name=\"Debian 9.x (stretch)\" -%}","title":"apt-get install wallarm-node-nginx"},{"location":"en/admin-en/update-linux-en/#apt-get-update_7","text":"","title":"apt-get update"},{"location":"en/admin-en/update-linux-en/#apt-get-install-wallarm-node-nginx_1","text":"{%- tab name=\"Debian 10.x (buster)\" -%}","title":"apt-get install wallarm-node-nginx"},{"location":"en/admin-en/update-linux-en/#apt-get-update_8","text":"","title":"apt-get update"},{"location":"en/admin-en/update-linux-en/#apt-get-install-wallarm-node-nginx_2","text":"{%- tab name=\"Ubuntu 14.04 LTS (trusty)\" -%}","title":"apt-get install wallarm-node-nginx"},{"location":"en/admin-en/update-linux-en/#apt-get-update_9","text":"","title":"apt-get update"},{"location":"en/admin-en/update-linux-en/#apt-get-install-wallarm-node-nginx_3","text":"{%- tab name=\"Ubuntu 16.04 LTS (xenial)\" -%}","title":"apt-get install wallarm-node-nginx"},{"location":"en/admin-en/update-linux-en/#apt-get-update_10","text":"","title":"apt-get update"},{"location":"en/admin-en/update-linux-en/#apt-get-install-wallarm-node-nginx_4","text":"{%- tab name=\"Ubuntu 18.04 LTS (bionic)\" -%}","title":"apt-get install wallarm-node-nginx"},{"location":"en/admin-en/update-linux-en/#apt-get-update_11","text":"","title":"apt-get update"},{"location":"en/admin-en/update-linux-en/#apt-get-install-wallarm-node-nginx_5","text":"{%- tab name=\"CentOS 6.x\" -%}","title":"apt-get install wallarm-node-nginx"},{"location":"en/admin-en/update-linux-en/#yum-update-wallarm-node-nginx","text":"{%- tab name=\"CentOS 7.x\" -%}","title":"yum update wallarm-node-nginx"},{"location":"en/admin-en/update-linux-en/#yum-update-wallarm-node-nginx_1","text":"{%- tab name=\"Amazon Linux 2\" -%}","title":"yum update wallarm-node-nginx"},{"location":"en/admin-en/update-linux-en/#yum-update-wallarm-node-nginx_2","text":"{%- endtermtabs %} Repository access Your system must have access to https://repo.wallarm.com to download the packages. Ensure the access is not blocked by a firewall.","title":"yum update wallarm-node-nginx"},{"location":"en/admin-en/update-linux-en/#2-check-the-nginx-configuration-file","text":"Parameters wallarm_tarantool_host and wallarm_tarantool_port The wallarm_tarantool_host and wallarm_tarantool_port have been deprecated starting with version 2.6. If you used these parameters to set up Tarantool, you must replace them with wallarm_tarantool_upstream . See wallarm_tarantool_upstream . Check that the configuration file is correct after updating the packages. Run the command: # nginx-wallarm -t","title":"2. Check the NGINX Configuration File"},{"location":"en/admin-en/update-linux-en/#3-restart-nginx","text":"If you installed Wallarm with NGINX Plus or as a dynamic module for NGINX, restart the nginx service. Restart the nginx service: Debian 8.x (jessie) systemctl restart nginx Debian 9.x (stretch) systemctl restart nginx Debian 10.x (buster) systemctl restart nginx Ubuntu 14.04 LTS (trusty) service nginx restart Ubuntu 16.04 LTS (xenial) service nginx restart Ubuntu 18.04 LTS (bionic) service nginx restart CentOS 6.x service nginx restart CentOS 7.x systemctl restart nginx Amazon Linux 2 systemctl restart nginx If you installed Wallarm without NGINX Plus or not as a dynamic module for NGINX, restart the nginx-wallarm service. Restart the nginx-wallarm service: {% termtabs name=\"Debian 8.x (jessie)\" -%}","title":"3. Restart NGINX"},{"location":"en/admin-en/update-linux-en/#systemctl-restart-nginx-wallarm","text":"{%- tab name=\"Debian 9.x (stretch)\" -%}","title":"systemctl restart nginx-wallarm"},{"location":"en/admin-en/update-linux-en/#systemctl-restart-nginx-wallarm_1","text":"{%- tab name=\"Ubuntu 14.04 LTS (trusty)\" -%}","title":"systemctl restart nginx-wallarm"},{"location":"en/admin-en/update-linux-en/#service-nginx-wallarm-restart","text":"{%- tab name=\"Ubuntu 16.04 LTS (xenial)\" -%}","title":"service nginx-wallarm restart"},{"location":"en/admin-en/update-linux-en/#service-nginx-wallarm-restart_1","text":"{%- tab name=\"Ubuntu 18.04 LTS (bionic)\" -%}","title":"service nginx-wallarm restart"},{"location":"en/admin-en/update-linux-en/#service-nginx-wallarm-restart_2","text":"{%- tab name=\"CentOS 6.x\" -%}","title":"service nginx-wallarm restart"},{"location":"en/admin-en/update-linux-en/#service-nginx-wallarm-restart_3","text":"{%- tab name=\"CentOS 7.x\" -%}","title":"service nginx-wallarm restart"},{"location":"en/admin-en/update-linux-en/#systemctl-restart-nginx-wallarm_2","text":"{%- tab name=\"Amazon Linux 2\" -%}","title":"systemctl restart nginx-wallarm"},{"location":"en/admin-en/update-linux-en/#systemctl-restart-nginx-wallarm_3","text":"{%- endtermtabs %}","title":"systemctl restart nginx-wallarm"},{"location":"en/admin-en/update-postanalytics/","text":"Updating the Separately Installed Postanalytics Module \u00b6 If the postanalytics module is installed on the separate server, then you need to update it prior to updating the Wallarm NGINX module . To update the postanalytics module, do the following: Execute the commands below in order to perform the update. The choice of the commands depends on the operation system in use: {% termtabs name=\"Debian 8.x (jessie)\" -%} apt-get update \u00b6 apt-get install wallarm-node-tarantool \u00b6 {%- tab name=\"Debian 9.x (stretch)\" -%} apt-get update \u00b6 apt-get install wallarm-node-tarantool \u00b6 {%- tab name=\"Debian 10.x (buster)\" -%} apt-get update \u00b6 apt-get install wallarm-node-tarantool \u00b6 {%- tab name=\"Ubuntu 14.04 LTS (trusty)\" -%} apt-get update \u00b6 apt-get install wallarm-node-tarantool \u00b6 {%- tab name=\"Ubuntu 16.04 LTS (xenial)\" -%} apt-get update \u00b6 apt-get install wallarm-node-tarantool \u00b6 {%- tab name=\"Ubuntu 18.04 LTS (bionic)\" -%} apt-get update \u00b6 apt-get install wallarm-node-tarantool \u00b6 {%- tab name=\"CentOS 6.x\" -%} yum update wallarm-node-tarantool \u00b6 {%- tab name=\"CentOS 7.x\" -%} yum update wallarm-node-tarantool \u00b6 {%- endtermtabs %} Restart the wallarm-tarantool service by executing one of the commands below. The choice of the command depends on the operation system in use: {% termtabs name=\"Debian 8.x (jessie)\" -%} systemctl restart wallarm-tarantool \u00b6 {%- tab name=\"Debian 9.x (stretch)\" -%} systemctl restart wallarm-tarantool \u00b6 {%- tab name=\"Debian 10.x (buster)\" -%} systemctl restart wallarm-tarantool \u00b6 {%- tab name=\"Ubuntu 14.04 LTS (trusty)\" -%} service wallarm-tarantool restart \u00b6 {%- tab name=\"Ubuntu 16.04 LTS (xenial)\" -%} systemctl restart wallarm-tarantool \u00b6 {%- tab name=\"Ubuntu 18.04 LTS (bionic)\" -%} systemctl restart wallarm-tarantool \u00b6 {%- tab name=\"CentOS 6.x\" -%} service wallarm-tarantool restart \u00b6 {%- tab name=\"CentOS 7.x\" -%} systemctl restart wallarm-tarantool \u00b6 {%- endtermtabs %}","title":"Updating the Separately Installed Postanalytics Module"},{"location":"en/admin-en/update-postanalytics/#updating-the-separately-installed-postanalytics-module","text":"If the postanalytics module is installed on the separate server, then you need to update it prior to updating the Wallarm NGINX module . To update the postanalytics module, do the following: Execute the commands below in order to perform the update. The choice of the commands depends on the operation system in use: {% termtabs name=\"Debian 8.x (jessie)\" -%}","title":"Updating the Separately Installed Postanalytics Module"},{"location":"en/admin-en/update-postanalytics/#apt-get-update","text":"","title":"apt-get update"},{"location":"en/admin-en/update-postanalytics/#apt-get-install-wallarm-node-tarantool","text":"{%- tab name=\"Debian 9.x (stretch)\" -%}","title":"apt-get install wallarm-node-tarantool"},{"location":"en/admin-en/update-postanalytics/#apt-get-update_1","text":"","title":"apt-get update"},{"location":"en/admin-en/update-postanalytics/#apt-get-install-wallarm-node-tarantool_1","text":"{%- tab name=\"Debian 10.x (buster)\" -%}","title":"apt-get install wallarm-node-tarantool"},{"location":"en/admin-en/update-postanalytics/#apt-get-update_2","text":"","title":"apt-get update"},{"location":"en/admin-en/update-postanalytics/#apt-get-install-wallarm-node-tarantool_2","text":"{%- tab name=\"Ubuntu 14.04 LTS (trusty)\" -%}","title":"apt-get install wallarm-node-tarantool"},{"location":"en/admin-en/update-postanalytics/#apt-get-update_3","text":"","title":"apt-get update"},{"location":"en/admin-en/update-postanalytics/#apt-get-install-wallarm-node-tarantool_3","text":"{%- tab name=\"Ubuntu 16.04 LTS (xenial)\" -%}","title":"apt-get install wallarm-node-tarantool"},{"location":"en/admin-en/update-postanalytics/#apt-get-update_4","text":"","title":"apt-get update"},{"location":"en/admin-en/update-postanalytics/#apt-get-install-wallarm-node-tarantool_4","text":"{%- tab name=\"Ubuntu 18.04 LTS (bionic)\" -%}","title":"apt-get install wallarm-node-tarantool"},{"location":"en/admin-en/update-postanalytics/#apt-get-update_5","text":"","title":"apt-get update"},{"location":"en/admin-en/update-postanalytics/#apt-get-install-wallarm-node-tarantool_5","text":"{%- tab name=\"CentOS 6.x\" -%}","title":"apt-get install wallarm-node-tarantool"},{"location":"en/admin-en/update-postanalytics/#yum-update-wallarm-node-tarantool","text":"{%- tab name=\"CentOS 7.x\" -%}","title":"yum update wallarm-node-tarantool"},{"location":"en/admin-en/update-postanalytics/#yum-update-wallarm-node-tarantool_1","text":"{%- endtermtabs %} Restart the wallarm-tarantool service by executing one of the commands below. The choice of the command depends on the operation system in use: {% termtabs name=\"Debian 8.x (jessie)\" -%}","title":"yum update wallarm-node-tarantool"},{"location":"en/admin-en/update-postanalytics/#systemctl-restart-wallarm-tarantool","text":"{%- tab name=\"Debian 9.x (stretch)\" -%}","title":"systemctl restart wallarm-tarantool"},{"location":"en/admin-en/update-postanalytics/#systemctl-restart-wallarm-tarantool_1","text":"{%- tab name=\"Debian 10.x (buster)\" -%}","title":"systemctl restart wallarm-tarantool"},{"location":"en/admin-en/update-postanalytics/#systemctl-restart-wallarm-tarantool_2","text":"{%- tab name=\"Ubuntu 14.04 LTS (trusty)\" -%}","title":"systemctl restart wallarm-tarantool"},{"location":"en/admin-en/update-postanalytics/#service-wallarm-tarantool-restart","text":"{%- tab name=\"Ubuntu 16.04 LTS (xenial)\" -%}","title":"service wallarm-tarantool restart"},{"location":"en/admin-en/update-postanalytics/#systemctl-restart-wallarm-tarantool_3","text":"{%- tab name=\"Ubuntu 18.04 LTS (bionic)\" -%}","title":"systemctl restart wallarm-tarantool"},{"location":"en/admin-en/update-postanalytics/#systemctl-restart-wallarm-tarantool_4","text":"{%- tab name=\"CentOS 6.x\" -%}","title":"systemctl restart wallarm-tarantool"},{"location":"en/admin-en/update-postanalytics/#service-wallarm-tarantool-restart_1","text":"{%- tab name=\"CentOS 7.x\" -%}","title":"service wallarm-tarantool restart"},{"location":"en/admin-en/update-postanalytics/#systemctl-restart-wallarm-tarantool_5","text":"{%- endtermtabs %}","title":"systemctl restart wallarm-tarantool"},{"location":"en/admin-en/update-vmware-en/","text":"Updating Wallarm Deployed as a VMware vApp \u00b6 Update Wallarm by means of the operating system. See Updating the Wallarm packages on Linux .","title":"Updating Wallarm Deployed as a VMware vApp"},{"location":"en/admin-en/update-vmware-en/#updating-wallarm-deployed-as-a-vmware-vapp","text":"Update Wallarm by means of the operating system. See Updating the Wallarm packages on Linux .","title":"Updating Wallarm Deployed as a VMware vApp"},{"location":"en/admin-en/updating/","text":"","title":"Updating"},{"location":"en/admin-en/using-proxy-or-balancer-en/","text":"Settings for Using a Balancer or Proxy in Front of the Filter Node \u00b6 !!! info \"Who's this document for? This document contains information for users who have a proxy server or balancer installed that receives requests and proxies them to the Wallarm filter nodes. If your system does not have such a balancer, you can skip this configuration step. By default, the Wallarm filter node considers the IP address from which the request originated to be the IP address of the request source. If the request passed through a proxy server or load balancer before being sent to the node, the IP address of the balancer will be displayed in the web interface as the IP address of the request source. To correctly display the IP address of the request source in the Wallarm web interface, configure the balancer and the filter node to transmit the IP address of the source in the request header. The figure below shows an example using the X-Client-IP header by the HAProxy server to send the client IP address. To configure sending a client IP address in the request header by a proxy server or a balancer, follow the steps described in the following sections: Configuring a proxy server or load balancer Configuring the filter node Configuring a Proxy Server or Load Balancer \u00b6 Configure a proxy server or load balancer to write the IP address from which the request was received to the header of this request and send the request with the header to the filter node. To learn how to configure your proxy server or balancer, refer to its official documentation. The example below demonstrates how to configure the X-Client-IP header for the HAProxy balancer. HAProxy Balancer Setup Example \u00b6 The option forwardfor directive tells the HAProxy balancer that a header must be added to the request with the IP address of the client. You can use the X-Client-IP header for this purpose. In the /etc/haproxy/haproxy.cfg configuration file, insert the option forwardfor header X-Client-IP line into the backend directive block, which is responsible for connecting HAProxy to the Wallarm filter node. !!! info \"Details of the directive You can find detailed information about the option forwardfor directive in the official HAProxy documentation . An example fragment of the /etc/haproxy/haproxy.cfg configuration file is given below: # Public IP address for receiving requests frontend my_frontend bind <haproxy-ip> mode http default_backend my_backend # Backend with the Wallarm filter node backend my_backend mode http option forwardfor header X-Client-IP server wallarm-node <node-ip> In the example above <haproxy-ip> is the IP address of the HAProxy server to receive client requests; <node-ip> is the IP address of the Wallarm filter node to receive requests from the HAProxy server. Configuring the Filter Node \u00b6 For the Wallarm filter node to recognize the value of the X-Client-IP header as the request source address, add the set_real_ip_from and real_ip_header directives to the NGINX configuration file. The real_ip_header directive reports that the real IP address of the client that sent the request is transmitted in the X-Client-IP header. The set_real_ip_from directive specifies the IP address of your proxy server or a balancer from which requests with the X-Client-IP header are sent. If your system has several proxies or balancers, specify several set_real_ip_from directives with their IP addresses. You can also specify IP address ranges (for example, 1.2.3.0/24 ). !!! info \"Details of the directives You can find detailed information about the set_real_ip_from and real_ip_header directives in the NGINX official documentation . An example fragment of the /etc/nginx/conf.d/default.conf configuration file is given below: location / { # Setting of proxy and filtration mode of the node wallarm_mode block; # Settings of proxying requests to the protected application proxy_pass http://<app-ip>; proxy_set_header Host $host; proxy_set_header X-Real-IP $remote_addr; proxy_set_header X-Forwarded-For $proxy_add_forwarded_for; # Settings of determining the true source IP address of requests set_real_ip_from <proxy-ip1>; set_real_ip_from <proxy-ip2>; real_ip_header X-Client-IP; } In the example above <app-ip> is the IP address of the protected application for requests from the filter node; <proxy-ip1> , <proxy-ip2> is the IP addresses of proxies that pass requests to the Wallarm filter node. After you save the modified NGINX configuration file, restart NGINX: # service nginx restart Checking results \u00b6 Perform a test attack and verify that the IP address of the request source is correctly displayed in the Wallarm web interface:","title":"Settings for Using a Balancer or Proxy"},{"location":"en/admin-en/using-proxy-or-balancer-en/#settings-for-using-a-balancer-or-proxy-in-front-of-the-filter-node","text":"!!! info \"Who's this document for? This document contains information for users who have a proxy server or balancer installed that receives requests and proxies them to the Wallarm filter nodes. If your system does not have such a balancer, you can skip this configuration step. By default, the Wallarm filter node considers the IP address from which the request originated to be the IP address of the request source. If the request passed through a proxy server or load balancer before being sent to the node, the IP address of the balancer will be displayed in the web interface as the IP address of the request source. To correctly display the IP address of the request source in the Wallarm web interface, configure the balancer and the filter node to transmit the IP address of the source in the request header. The figure below shows an example using the X-Client-IP header by the HAProxy server to send the client IP address. To configure sending a client IP address in the request header by a proxy server or a balancer, follow the steps described in the following sections: Configuring a proxy server or load balancer Configuring the filter node","title":"Settings for Using a Balancer or Proxy in Front of the Filter Node"},{"location":"en/admin-en/using-proxy-or-balancer-en/#configuring-a-proxy-server-or-load-balancer","text":"Configure a proxy server or load balancer to write the IP address from which the request was received to the header of this request and send the request with the header to the filter node. To learn how to configure your proxy server or balancer, refer to its official documentation. The example below demonstrates how to configure the X-Client-IP header for the HAProxy balancer.","title":"Configuring a Proxy Server or Load Balancer"},{"location":"en/admin-en/using-proxy-or-balancer-en/#haproxy-balancer-setup-example","text":"The option forwardfor directive tells the HAProxy balancer that a header must be added to the request with the IP address of the client. You can use the X-Client-IP header for this purpose. In the /etc/haproxy/haproxy.cfg configuration file, insert the option forwardfor header X-Client-IP line into the backend directive block, which is responsible for connecting HAProxy to the Wallarm filter node. !!! info \"Details of the directive You can find detailed information about the option forwardfor directive in the official HAProxy documentation . An example fragment of the /etc/haproxy/haproxy.cfg configuration file is given below: # Public IP address for receiving requests frontend my_frontend bind <haproxy-ip> mode http default_backend my_backend # Backend with the Wallarm filter node backend my_backend mode http option forwardfor header X-Client-IP server wallarm-node <node-ip> In the example above <haproxy-ip> is the IP address of the HAProxy server to receive client requests; <node-ip> is the IP address of the Wallarm filter node to receive requests from the HAProxy server.","title":"HAProxy Balancer Setup Example"},{"location":"en/admin-en/using-proxy-or-balancer-en/#configuring-the-filter-node","text":"For the Wallarm filter node to recognize the value of the X-Client-IP header as the request source address, add the set_real_ip_from and real_ip_header directives to the NGINX configuration file. The real_ip_header directive reports that the real IP address of the client that sent the request is transmitted in the X-Client-IP header. The set_real_ip_from directive specifies the IP address of your proxy server or a balancer from which requests with the X-Client-IP header are sent. If your system has several proxies or balancers, specify several set_real_ip_from directives with their IP addresses. You can also specify IP address ranges (for example, 1.2.3.0/24 ). !!! info \"Details of the directives You can find detailed information about the set_real_ip_from and real_ip_header directives in the NGINX official documentation . An example fragment of the /etc/nginx/conf.d/default.conf configuration file is given below: location / { # Setting of proxy and filtration mode of the node wallarm_mode block; # Settings of proxying requests to the protected application proxy_pass http://<app-ip>; proxy_set_header Host $host; proxy_set_header X-Real-IP $remote_addr; proxy_set_header X-Forwarded-For $proxy_add_forwarded_for; # Settings of determining the true source IP address of requests set_real_ip_from <proxy-ip1>; set_real_ip_from <proxy-ip2>; real_ip_header X-Client-IP; } In the example above <app-ip> is the IP address of the protected application for requests from the filter node; <proxy-ip1> , <proxy-ip2> is the IP addresses of proxies that pass requests to the Wallarm filter node. After you save the modified NGINX configuration file, restart NGINX: # service nginx restart","title":"Configuring the Filter Node"},{"location":"en/admin-en/using-proxy-or-balancer-en/#checking-results","text":"Perform a test attack and verify that the IP address of the request source is correctly displayed in the Wallarm web interface:","title":"Checking results"},{"location":"en/admin-en/configuration-guides/envoy/fine-tuning/","text":"Configuration Options for the Envoy-Based Filter Node \u00b6 Envoy uses pluggable filters defined in the Envoy configuration file to process incoming requests. These filters describe the actions to be performed on the request. For example, an envoy.http_connection_manager filter is used to proxy HTTP requests. This filter has its own set of HTTP filters that can be applied to the request. The Wallarm module is designed as an Envoy HTTP filter. The module's general settings are placed in a section dedicated to the wallarm HTTP filter (that filter will be referred to as \u201cthe Wallarm filter\u201d throughout this document): listeners: - address: filter_chains: - filters: - name: envoy.http_connection_manager typed_config: http_filters: - name: wallarm typed_config: \"@type\": type.googleapis.com/wallarm.Wallarm <the Wallarm module configuration> ... #### Warning:: Enable Request Body Processing In order to enable the Wallarm module to process an HTTP request body, the buffer filter must be placed before the Wallarm filter in the Envoy HTTP filter chain. For example: ``` http_filters: - name: envoy.buffer typed_config: \"@type\": type.googleapis.com/envoy.config.filter.http.buffer.v2.Buffer max_request_bytes: <maximum request size (in bytes)> - name: wallarm typed_config: \"@type\": type.googleapis.com/wallarm.Wallarm <the Wallarm module configuration> ... ``` If the incoming request size exceeds the value of the `max_request_bytes` parameter, then this request will be dropped and Envoy will return the `413` response code (\u201cPayload Too Large\u201d). Filtering Mode Settings \u00b6 The tsets section of the Wallarm filter contains the parameters related to the filtering mode settings: tsets: ts0: pdb: /etc/wallarm/proton.db lom: /etc/wallarm/lom key: /etc/wallarm/license.key ... tsN: ... The ts0 ... tsN entries are one or more parameter groups. The groups can have any names (so that they could be referred to later via the ts parameter in the conf section). At least one group should be present in the Wallarm filter configuration (e.g., with the name ts0 ). This section has no default values; you need to explicitly specify values in the config file. #### Info:: This section can be defined on the Wallarm filter level only. pdb \u00b6 A path to the proton.db file. This file contains the global settings for requests filtering, which do not depend on the application structure. #### Info:: **Default value:** `/etc/wallarm/proton.db` lom \u00b6 A path to the LOM file that contains information about the protected application and the filter node settings. #### Info:: **Default value:** `/etc/wallarm/lom` key \u00b6 A path to the Wallarm license key. #### Info:: **Default value:** `/etc/wallarm/license.key` Postanalytics Module Settings \u00b6 The tarantool section of the Wallarm filter contains the parameters related to the postanalytics module: tarantool: server: - uri: localhost:3313 max_packets: 512 max_packets_mem: 0 reconnect_interval: 1 The server entry is a parameter group that describes the settings for the Tarantool server. #### Info:: This section can be defined on the Wallarm filter level only. uri \u00b6 A string with the credentials to be used in order to connect to the Tarantool server. The string format is IP address or domain name:port . #### Info:: **Default value:** `localhost:3313` max_packets \u00b6 This parameter limits the number of serialized requests to be sent to Tarantool. #### Info:: **Default value:** `512` To remove the limit, set 0 as the parameter value. max_packets_mem \u00b6 Limits the total volume (in bytes) of serialized requests to be sent to Tarantool. #### Info:: **Default value:** `0` (the volume is not limited). reconnect_interval \u00b6 This parameter defines the interval (in seconds) between attempts to reconnect to the Tarantool. #### Info:: **Default value:** `1` A value of `0` means that the filter node will try to reconnect to the server as quickly as possible if the server renders unavailable (not recommended). Basic Settings \u00b6 The conf section of the Wallarm filter contains the parameters that influence filter node's basic operations: conf: ts: ts0 mode: \"off\" mode_allow_override: \"off\" process_time_limit: 1000 process_time_limit_block: \"attack\" instance: 42 This section can be overridden on the route or virtual host level, which distinguishes this section from those described above. Therefore, the protection level is flexible. The conf section override follows: on the route level: routes: - match: typed_per_filter_config: wallarm: \"@type\": type.googleapis.com/wallarm.WallarmConf <the section parameters> on the virtual host level: virtual_hosts: - name: <the name of the virtual host> typed_per_filter_config: wallarm: \"@type\": type.googleapis.com/wallarm.WallarmConf <the section parameters> An overridden conf section can contain any of the parameters described below. The parameters in the conf section overridden on the route level have priority over the parameters in the section defined on the virtual host level which in turn have higher priority than the parameters listed in the section on the Wallarm filter level. ts \u00b6 This is the name of the one of the parameter groups that are defined in the tsets section. This parameter group sets the request filtering rules to be used. If this parameter is omitted from the conf section of the Wallarm filter, then it should be present in the conf section overridden on the route or virtual host level. #### Info:: **Default value:** none. mode \u00b6 This sets the traffic filtration mode: off : requests are not processed. monitoring : all requests are processed, but none of them are blocked even if an attack is detected. block : all requests where an attack is detected are blocked. aggressive : all non-standard requests are blocked, for example, mapping a string in the field usually used for passing a number. Use this mode with extreme caution. The modes are listed from the most lenient to the strictest one. #### Info:: **Default value:** `off` mode_allow_override \u00b6 This parameter allows overriding the filtering mode that is set via the mode parameter with the LOM rules downloaded from the Wallarm cloud: off : the LOM rule set is ignored. strict : LOM can only strengthen the operation mode. on : it is possible to both strengthen and soften the operation mode. For example, if the mode parameter is set to the monitoring value and the mode_allow_override parameter is set to the strict value, then it will be possible to block some requests ( block ) but not to fully disable the filter node ( off ). #### Info:: **Default value:** `off` process_time_limit \u00b6 This sets the limit on the processing time of a single request (in milliseconds). If the request cannot be processed in the defined amount of time, then an error message is recorded to the log file and the request is marked as an overlimit_res attack. #### Info:: **Default value:** `1000` process_time_limit_block \u00b6 This parameter specifies the action to take when the request processing time exceeds the limit set via the process_time_limit parameter: on : the requests are always blocked off : the requests are always ignored attack : depends on the attack blocking mode set via the mode parameter: monitoring : the requests are ignored block and aggressive : the requests are blocked #### Info:: Default value: attack instance \u00b6 This is an application identifier. It is used to visually separate the data of different applications on the dashboard . Only numeric values are allowed. The application identifiers are used solely for the convenience of data presentation. To correctly separate the data of different applications, the same application identifiers must be set in the Wallarm interface. Any filter node will filter traffic for any number of applications without additional configuration. #### Info:: **Default value:** none.","title":"Fine tuning"},{"location":"en/admin-en/configuration-guides/envoy/fine-tuning/#configuration-options-for-the-envoy-based-filter-node","text":"Envoy uses pluggable filters defined in the Envoy configuration file to process incoming requests. These filters describe the actions to be performed on the request. For example, an envoy.http_connection_manager filter is used to proxy HTTP requests. This filter has its own set of HTTP filters that can be applied to the request. The Wallarm module is designed as an Envoy HTTP filter. The module's general settings are placed in a section dedicated to the wallarm HTTP filter (that filter will be referred to as \u201cthe Wallarm filter\u201d throughout this document): listeners: - address: filter_chains: - filters: - name: envoy.http_connection_manager typed_config: http_filters: - name: wallarm typed_config: \"@type\": type.googleapis.com/wallarm.Wallarm <the Wallarm module configuration> ... #### Warning:: Enable Request Body Processing In order to enable the Wallarm module to process an HTTP request body, the buffer filter must be placed before the Wallarm filter in the Envoy HTTP filter chain. For example: ``` http_filters: - name: envoy.buffer typed_config: \"@type\": type.googleapis.com/envoy.config.filter.http.buffer.v2.Buffer max_request_bytes: <maximum request size (in bytes)> - name: wallarm typed_config: \"@type\": type.googleapis.com/wallarm.Wallarm <the Wallarm module configuration> ... ``` If the incoming request size exceeds the value of the `max_request_bytes` parameter, then this request will be dropped and Envoy will return the `413` response code (\u201cPayload Too Large\u201d).","title":"Configuration Options for the Envoy-Based Filter Node"},{"location":"en/admin-en/configuration-guides/envoy/fine-tuning/#filtering-mode-settings","text":"The tsets section of the Wallarm filter contains the parameters related to the filtering mode settings: tsets: ts0: pdb: /etc/wallarm/proton.db lom: /etc/wallarm/lom key: /etc/wallarm/license.key ... tsN: ... The ts0 ... tsN entries are one or more parameter groups. The groups can have any names (so that they could be referred to later via the ts parameter in the conf section). At least one group should be present in the Wallarm filter configuration (e.g., with the name ts0 ). This section has no default values; you need to explicitly specify values in the config file. #### Info:: This section can be defined on the Wallarm filter level only.","title":"Filtering Mode Settings"},{"location":"en/admin-en/configuration-guides/envoy/fine-tuning/#pdb","text":"A path to the proton.db file. This file contains the global settings for requests filtering, which do not depend on the application structure. #### Info:: **Default value:** `/etc/wallarm/proton.db`","title":"pdb"},{"location":"en/admin-en/configuration-guides/envoy/fine-tuning/#lom","text":"A path to the LOM file that contains information about the protected application and the filter node settings. #### Info:: **Default value:** `/etc/wallarm/lom`","title":"lom"},{"location":"en/admin-en/configuration-guides/envoy/fine-tuning/#key","text":"A path to the Wallarm license key. #### Info:: **Default value:** `/etc/wallarm/license.key`","title":"key"},{"location":"en/admin-en/configuration-guides/envoy/fine-tuning/#postanalytics-module-settings","text":"The tarantool section of the Wallarm filter contains the parameters related to the postanalytics module: tarantool: server: - uri: localhost:3313 max_packets: 512 max_packets_mem: 0 reconnect_interval: 1 The server entry is a parameter group that describes the settings for the Tarantool server. #### Info:: This section can be defined on the Wallarm filter level only.","title":"Postanalytics Module Settings"},{"location":"en/admin-en/configuration-guides/envoy/fine-tuning/#uri","text":"A string with the credentials to be used in order to connect to the Tarantool server. The string format is IP address or domain name:port . #### Info:: **Default value:** `localhost:3313`","title":"uri"},{"location":"en/admin-en/configuration-guides/envoy/fine-tuning/#max_packets","text":"This parameter limits the number of serialized requests to be sent to Tarantool. #### Info:: **Default value:** `512` To remove the limit, set 0 as the parameter value.","title":"max_packets"},{"location":"en/admin-en/configuration-guides/envoy/fine-tuning/#max_packets_mem","text":"Limits the total volume (in bytes) of serialized requests to be sent to Tarantool. #### Info:: **Default value:** `0` (the volume is not limited).","title":"max_packets_mem"},{"location":"en/admin-en/configuration-guides/envoy/fine-tuning/#reconnect_interval","text":"This parameter defines the interval (in seconds) between attempts to reconnect to the Tarantool. #### Info:: **Default value:** `1` A value of `0` means that the filter node will try to reconnect to the server as quickly as possible if the server renders unavailable (not recommended).","title":"reconnect_interval"},{"location":"en/admin-en/configuration-guides/envoy/fine-tuning/#basic-settings","text":"The conf section of the Wallarm filter contains the parameters that influence filter node's basic operations: conf: ts: ts0 mode: \"off\" mode_allow_override: \"off\" process_time_limit: 1000 process_time_limit_block: \"attack\" instance: 42 This section can be overridden on the route or virtual host level, which distinguishes this section from those described above. Therefore, the protection level is flexible. The conf section override follows: on the route level: routes: - match: typed_per_filter_config: wallarm: \"@type\": type.googleapis.com/wallarm.WallarmConf <the section parameters> on the virtual host level: virtual_hosts: - name: <the name of the virtual host> typed_per_filter_config: wallarm: \"@type\": type.googleapis.com/wallarm.WallarmConf <the section parameters> An overridden conf section can contain any of the parameters described below. The parameters in the conf section overridden on the route level have priority over the parameters in the section defined on the virtual host level which in turn have higher priority than the parameters listed in the section on the Wallarm filter level.","title":"Basic Settings"},{"location":"en/admin-en/configuration-guides/envoy/fine-tuning/#ts","text":"This is the name of the one of the parameter groups that are defined in the tsets section. This parameter group sets the request filtering rules to be used. If this parameter is omitted from the conf section of the Wallarm filter, then it should be present in the conf section overridden on the route or virtual host level. #### Info:: **Default value:** none.","title":"ts"},{"location":"en/admin-en/configuration-guides/envoy/fine-tuning/#mode","text":"This sets the traffic filtration mode: off : requests are not processed. monitoring : all requests are processed, but none of them are blocked even if an attack is detected. block : all requests where an attack is detected are blocked. aggressive : all non-standard requests are blocked, for example, mapping a string in the field usually used for passing a number. Use this mode with extreme caution. The modes are listed from the most lenient to the strictest one. #### Info:: **Default value:** `off`","title":"mode"},{"location":"en/admin-en/configuration-guides/envoy/fine-tuning/#mode_allow_override","text":"This parameter allows overriding the filtering mode that is set via the mode parameter with the LOM rules downloaded from the Wallarm cloud: off : the LOM rule set is ignored. strict : LOM can only strengthen the operation mode. on : it is possible to both strengthen and soften the operation mode. For example, if the mode parameter is set to the monitoring value and the mode_allow_override parameter is set to the strict value, then it will be possible to block some requests ( block ) but not to fully disable the filter node ( off ). #### Info:: **Default value:** `off`","title":"mode_allow_override"},{"location":"en/admin-en/configuration-guides/envoy/fine-tuning/#process_time_limit","text":"This sets the limit on the processing time of a single request (in milliseconds). If the request cannot be processed in the defined amount of time, then an error message is recorded to the log file and the request is marked as an overlimit_res attack. #### Info:: **Default value:** `1000`","title":"process_time_limit"},{"location":"en/admin-en/configuration-guides/envoy/fine-tuning/#process_time_limit_block","text":"This parameter specifies the action to take when the request processing time exceeds the limit set via the process_time_limit parameter: on : the requests are always blocked off : the requests are always ignored attack : depends on the attack blocking mode set via the mode parameter: monitoring : the requests are ignored block and aggressive : the requests are blocked #### Info:: Default value: attack","title":"process_time_limit_block"},{"location":"en/admin-en/configuration-guides/envoy/fine-tuning/#instance","text":"This is an application identifier. It is used to visually separate the data of different applications on the dashboard . Only numeric values are allowed. The application identifiers are used solely for the convenience of data presentation. To correctly separate the data of different applications, the same application identifiers must be set in the Wallarm interface. Any filter node will filter traffic for any number of applications without additional configuration. #### Info:: **Default value:** none.","title":"instance"},{"location":"en/admin-en/configuration-guides/sso/disable-sso-provider/","text":"Disabling and Removing the Configured SSO Provider \u00b6 You can disable or remove configured SSO provider. #### Warning:: Attention: SSO will be disabled for all users Note that when you disable or remove SSO authentication, it will be disabled for all users. Users will be notified that SSO authentication is disabled and the password needs to be restored. Disabling \u00b6 To disable SSO, go to Settings \u2192 Integration . Click on the block of the corresponding SSO provider and then on the Disable button. In the pop-up window, it is required to confirm the disabling of the SSO provider, as well as the disabling of the SSO authentication of all users. Click Yes, disable . After confirmation, the SSO provider will be disconnected, but its settings will be saved and you can enable this provider again in the future. In addition, after disabling, you will be able to connect another SSO provider (another service as an identity provider). Removing \u00b6 #### Warning:: Attention: About removing the SSO provider Compared to disabling, removing the SSO provider will cause the loss of all its settings without the possibility of recovery. If you need to reconnect your provider, you will need to reconfigure it. Removing the SSO provider is similar to disabling it. Go to Settings \u2192 Integration . Click on the block of the corresponding SSO provider and then on the Remove button. In the pop-up window, it is required to confirm the removing of the provider, as well as to disable SSO authentication of all users. Click Yes, remove . After confirmation, the selected SSO provider will be removed and will no longer be available. Also, you will be able to connect to another SSO provider. #### Info:: See also: * [Configuring the G Suite SSO provider][doc-setup-sso-gsuite] * [Configuring the Okta SSO provider][doc-setup-sso-okta]","title":"Disabling and Removing the Configured SSO Provider"},{"location":"en/admin-en/configuration-guides/sso/disable-sso-provider/#disabling-and-removing-the-configured-sso-provider","text":"You can disable or remove configured SSO provider. #### Warning:: Attention: SSO will be disabled for all users Note that when you disable or remove SSO authentication, it will be disabled for all users. Users will be notified that SSO authentication is disabled and the password needs to be restored.","title":"Disabling and Removing the Configured SSO Provider"},{"location":"en/admin-en/configuration-guides/sso/disable-sso-provider/#disabling","text":"To disable SSO, go to Settings \u2192 Integration . Click on the block of the corresponding SSO provider and then on the Disable button. In the pop-up window, it is required to confirm the disabling of the SSO provider, as well as the disabling of the SSO authentication of all users. Click Yes, disable . After confirmation, the SSO provider will be disconnected, but its settings will be saved and you can enable this provider again in the future. In addition, after disabling, you will be able to connect another SSO provider (another service as an identity provider).","title":"Disabling"},{"location":"en/admin-en/configuration-guides/sso/disable-sso-provider/#removing","text":"#### Warning:: Attention: About removing the SSO provider Compared to disabling, removing the SSO provider will cause the loss of all its settings without the possibility of recovery. If you need to reconnect your provider, you will need to reconfigure it. Removing the SSO provider is similar to disabling it. Go to Settings \u2192 Integration . Click on the block of the corresponding SSO provider and then on the Remove button. In the pop-up window, it is required to confirm the removing of the provider, as well as to disable SSO authentication of all users. Click Yes, remove . After confirmation, the selected SSO provider will be removed and will no longer be available. Also, you will be able to connect to another SSO provider. #### Info:: See also: * [Configuring the G Suite SSO provider][doc-setup-sso-gsuite] * [Configuring the Okta SSO provider][doc-setup-sso-okta]","title":"Removing"},{"location":"en/admin-en/configuration-guides/sso/employ-user-auth/","text":"Configuring SSO Authentication for Users \u00b6 You can enable or disable SSO authentication to Wallarm portal users. Enabling SSO Authentication for Users \u00b6 #### Warning:: Attention: * When enabling SSO authentication for users with any non-administrator roles (*Admin* or *Super Admin*), a login/password log in mechanism and the two-factor authentication will not be available. When SSO authentication is enabled, the user's password is erased and two-factor authentication is disabled. The *Admin* and *Super Admin* roles can use login/password pair, two-factor authentication, and SSO authentication simultaneously. <br><br> * It is assumed that you have already given the required group of users access to the configured Wallarm application on the [Okta][doc-allow-access-okta] or [G Suite][doc-allow-access-gsuite] side. To enable SSO authentication for Wallarm users go to Settings \u2192 Users . Find the desired user and open the user action menu by clicking the button on the right of the user's record. Click Enable SSO login . In the pop-up window, you will be prompted to send a notification to the user that SSO authentication is enabled. Click the Send notification button. If the notification is not required, click Cancel . After that, the user can authenticate through the identity provider. Disabling SSO Authentication for Users \u00b6 To disable SSO authentication for Wallarm users, go to Settings \u2192 Users . Find the desired user and open the user action menu by clicking the button on the right of the user's record. Click Disable SSO . After that, the user will be notified by an email that the login using SSO is disabled with a suggestion (link) to restore the password to log in with the login/password pair. In addition, two-factor authentication becomes available to the user. #### Info:: See also: [Disabling and removing the configured SSO provider.][doc-disable-sso]","title":"Configuring SSO Authentication for Users"},{"location":"en/admin-en/configuration-guides/sso/employ-user-auth/#configuring-sso-authentication-for-users","text":"You can enable or disable SSO authentication to Wallarm portal users.","title":"Configuring SSO Authentication for Users"},{"location":"en/admin-en/configuration-guides/sso/employ-user-auth/#enabling-sso-authentication-for-users","text":"#### Warning:: Attention: * When enabling SSO authentication for users with any non-administrator roles (*Admin* or *Super Admin*), a login/password log in mechanism and the two-factor authentication will not be available. When SSO authentication is enabled, the user's password is erased and two-factor authentication is disabled. The *Admin* and *Super Admin* roles can use login/password pair, two-factor authentication, and SSO authentication simultaneously. <br><br> * It is assumed that you have already given the required group of users access to the configured Wallarm application on the [Okta][doc-allow-access-okta] or [G Suite][doc-allow-access-gsuite] side. To enable SSO authentication for Wallarm users go to Settings \u2192 Users . Find the desired user and open the user action menu by clicking the button on the right of the user's record. Click Enable SSO login . In the pop-up window, you will be prompted to send a notification to the user that SSO authentication is enabled. Click the Send notification button. If the notification is not required, click Cancel . After that, the user can authenticate through the identity provider.","title":"Enabling SSO Authentication for Users"},{"location":"en/admin-en/configuration-guides/sso/employ-user-auth/#disabling-sso-authentication-for-users","text":"To disable SSO authentication for Wallarm users, go to Settings \u2192 Users . Find the desired user and open the user action menu by clicking the button on the right of the user's record. Click Disable SSO . After that, the user will be notified by an email that the login using SSO is disabled with a suggestion (link) to restore the password to log in with the login/password pair. In addition, two-factor authentication becomes available to the user. #### Info:: See also: [Disabling and removing the configured SSO provider.][doc-disable-sso]","title":"Disabling SSO Authentication for Users"},{"location":"en/admin-en/configuration-guides/sso/intro/","text":"Introduction \u00b6 You can use Single Sign-On (SSO) technology to authenticate your company's users to the Wallarm portal if your company already uses a SAML SSO solution. Wallarm can be integrated with any solution that supports the SAML standard. The SSO guides describe integration using Okta or Google Suite (G Suite) as an example. The documents related to the configuration and operation of Wallarm with SSO assume the following: Wallarm acts as a service provider (SP). Google or Okta acts as an identity provider (IdP). More information about roles in SAML SSO can be found here ( PDF ). #### Warning:: Enabling the SSO service By default, SSO connection on Wallarm is not available without activating the appropriate service. To activate the SSO service, please contact your account manager. If no SSO service is activated, then SSO-related blocks will not be visible in the *Integrations* tab of the *Settings* section on the Wallarm portal.","title":"Introduction"},{"location":"en/admin-en/configuration-guides/sso/intro/#introduction","text":"You can use Single Sign-On (SSO) technology to authenticate your company's users to the Wallarm portal if your company already uses a SAML SSO solution. Wallarm can be integrated with any solution that supports the SAML standard. The SSO guides describe integration using Okta or Google Suite (G Suite) as an example. The documents related to the configuration and operation of Wallarm with SSO assume the following: Wallarm acts as a service provider (SP). Google or Okta acts as an identity provider (IdP). More information about roles in SAML SSO can be found here ( PDF ). #### Warning:: Enabling the SSO service By default, SSO connection on Wallarm is not available without activating the appropriate service. To activate the SSO service, please contact your account manager. If no SSO service is activated, then SSO-related blocks will not be visible in the *Integrations* tab of the *Settings* section on the Wallarm portal.","title":"Introduction"},{"location":"en/admin-en/configuration-guides/sso/gsuite/allow-access-to-wl/","text":"Step 4: Allowing Access to the Wallarm Application on the G Suite Side \u00b6 To authenticate through G Suite, an account must be created on the G Suite side, and the user must have access rights to the Wallarm application. The required sequence of actions for granting access rights is described below. Go to the G Suite\u2019s user management section by clicking on the Users block. Make sure that the user you are going to give access to the application via SSO authentication is in your organization's user list. Go to the SAML applications section by clicking on the SAML apps menu item as shown below. Enter the settings of the desired application and make sure that the status of the application is \u201cON for everyone.\u201d If the status of the application is \u201cOFF for everyone,\u201d click the Edit service button. Select the \u201cON for everyone\u201d status and click Save . After that you will receive a message that the status of the service has been updated. The Wallarm application is now available for SSO authentication to all users of your organization in G Suite. Setup Complete \u00b6 This completes the configuration of the G Suite-based SSO, and now you can start configuring the user specific SSO authentication on the Wallarm side.","title":"Step 4. Allowing Access to the Wallarm Application on the G Suite Side"},{"location":"en/admin-en/configuration-guides/sso/gsuite/allow-access-to-wl/#step-4-allowing-access-to-the-wallarm-application-on-the-g-suite-side","text":"To authenticate through G Suite, an account must be created on the G Suite side, and the user must have access rights to the Wallarm application. The required sequence of actions for granting access rights is described below. Go to the G Suite\u2019s user management section by clicking on the Users block. Make sure that the user you are going to give access to the application via SSO authentication is in your organization's user list. Go to the SAML applications section by clicking on the SAML apps menu item as shown below. Enter the settings of the desired application and make sure that the status of the application is \u201cON for everyone.\u201d If the status of the application is \u201cOFF for everyone,\u201d click the Edit service button. Select the \u201cON for everyone\u201d status and click Save . After that you will receive a message that the status of the service has been updated. The Wallarm application is now available for SSO authentication to all users of your organization in G Suite.","title":"Step 4: Allowing Access to the Wallarm Application on the G Suite Side"},{"location":"en/admin-en/configuration-guides/sso/gsuite/allow-access-to-wl/#setup-complete","text":"This completes the configuration of the G Suite-based SSO, and now you can start configuring the user specific SSO authentication on the Wallarm side.","title":"Setup Complete"},{"location":"en/admin-en/configuration-guides/sso/gsuite/metadata-transfer/","text":"Step 3: Transferring G Suite Metadata to the Wallarm Setup Wizard \u00b6 Return to the SSO Wallarm setup wizard and click Next to proceed to the next setup step. At this stage, you need to provide the metadata generated by the G Suite service to the Wallarm SSO setup wizard. There are two ways to transfer metadata: Upload an XML file with metadata in the Wallarm setup wizard. Copy and paste the required parameters into the Wallarm setup wizard manually. Uploading Metadata Using an XML File \u00b6 If you saved the metadata of G Suite as an XML file when configuring the application in G Suite earlier (in Step 2 ), click the Upload button and select the desired file. You can also do this by dragging the file from your file manager to the \u201cXML\u201d icon. After uploading the file, click Next to go to the next step. Copying Parameters Manually \u00b6 If you have copied the provided identity provider parameters when configuring the application in G Suite, click the Enter manually link to enter the copied parameters manually and fill out the form. Insert the parameters generated by G Suite into the fields of the Wallarm setup wizard as follows: * SSO URL \u2192 Identity provider SSO URL * Entity ID \u2192 Identity provider issuer * Certificate \u2192 X.509 Certificate Click Next to go to the next step. If you want to return to the previous step, click Back . Completing SSO Wizard \u00b6 On the final step of the Wallarm setup wizard, a test connection to the G Suite service will be performed automatically and the SSO provider will be checked. After successful completion of the test (if all the necessary parameters are filled in correctly), the setup wizard will inform you that the G Suite service is connected as an identity provider and you can start connecting the SSO mechanism to authenticate your users. Finish configuring SSO by clicking the Finish button or go to the user page to configure SSO by clicking the corresponding button. After completing the SSO configuration wizard, on the Integration tab you will see that the G Suite service is connected as an identity provider and that no other SSO providers are available. Now, navigate to the next step of the SSO configuration process.","title":"Step 3. Transferring G Suite Metadata to the Wallarm Setup Wizard"},{"location":"en/admin-en/configuration-guides/sso/gsuite/metadata-transfer/#step-3-transferring-g-suite-metadata-to-the-wallarm-setup-wizard","text":"Return to the SSO Wallarm setup wizard and click Next to proceed to the next setup step. At this stage, you need to provide the metadata generated by the G Suite service to the Wallarm SSO setup wizard. There are two ways to transfer metadata: Upload an XML file with metadata in the Wallarm setup wizard. Copy and paste the required parameters into the Wallarm setup wizard manually.","title":"Step 3: Transferring G Suite Metadata to the Wallarm Setup Wizard"},{"location":"en/admin-en/configuration-guides/sso/gsuite/metadata-transfer/#uploading-metadata-using-an-xml-file","text":"If you saved the metadata of G Suite as an XML file when configuring the application in G Suite earlier (in Step 2 ), click the Upload button and select the desired file. You can also do this by dragging the file from your file manager to the \u201cXML\u201d icon. After uploading the file, click Next to go to the next step.","title":"Uploading Metadata Using an XML File"},{"location":"en/admin-en/configuration-guides/sso/gsuite/metadata-transfer/#copying-parameters-manually","text":"If you have copied the provided identity provider parameters when configuring the application in G Suite, click the Enter manually link to enter the copied parameters manually and fill out the form. Insert the parameters generated by G Suite into the fields of the Wallarm setup wizard as follows: * SSO URL \u2192 Identity provider SSO URL * Entity ID \u2192 Identity provider issuer * Certificate \u2192 X.509 Certificate Click Next to go to the next step. If you want to return to the previous step, click Back .","title":"Copying Parameters Manually"},{"location":"en/admin-en/configuration-guides/sso/gsuite/metadata-transfer/#completing-sso-wizard","text":"On the final step of the Wallarm setup wizard, a test connection to the G Suite service will be performed automatically and the SSO provider will be checked. After successful completion of the test (if all the necessary parameters are filled in correctly), the setup wizard will inform you that the G Suite service is connected as an identity provider and you can start connecting the SSO mechanism to authenticate your users. Finish configuring SSO by clicking the Finish button or go to the user page to configure SSO by clicking the corresponding button. After completing the SSO configuration wizard, on the Integration tab you will see that the G Suite service is connected as an identity provider and that no other SSO providers are available. Now, navigate to the next step of the SSO configuration process.","title":"Completing SSO Wizard"},{"location":"en/admin-en/configuration-guides/sso/gsuite/overview/","text":"Connecting SSO with G Suite \u00b6 This guide will cover the process of connecting the G Suite (Google) service as an identity provider to Wallarm, which acts as the service provider. #### Warning:: Note By default, SSO connection on Wallarm is not available without activating the appropriate service. To activate the SSO service, please contact your account manager. After activating the service * you will be able to perform the following SSO connection procedure, and * the SSO-related blocks will be visible in the \u201cIntegrations\u201d tab. <!-- --> In addition, you need accounts with administration rights both for Wallarm and G Suite. The process of connecting SSO with G Suite comprises the following steps: Generating Parameters on the Wallarm Side. Creating and Configuring an Application in G Suite. Transferring G Suite Metadata to the Wallarm Setup Wizard. Allowing Access to the Wallarm Application on the G Suite Side After that, configure SSO authentication for Wallarm users. #### Info:: See also: * [User guide][doc-user-sso-guide] to using SSO authentication to log in to Wallarm. * [Disabling and removing the configured SSO provider.][doc-disable-sso]","title":"Overview"},{"location":"en/admin-en/configuration-guides/sso/gsuite/overview/#connecting-sso-with-g-suite","text":"This guide will cover the process of connecting the G Suite (Google) service as an identity provider to Wallarm, which acts as the service provider. #### Warning:: Note By default, SSO connection on Wallarm is not available without activating the appropriate service. To activate the SSO service, please contact your account manager. After activating the service * you will be able to perform the following SSO connection procedure, and * the SSO-related blocks will be visible in the \u201cIntegrations\u201d tab. <!-- --> In addition, you need accounts with administration rights both for Wallarm and G Suite. The process of connecting SSO with G Suite comprises the following steps: Generating Parameters on the Wallarm Side. Creating and Configuring an Application in G Suite. Transferring G Suite Metadata to the Wallarm Setup Wizard. Allowing Access to the Wallarm Application on the G Suite Side After that, configure SSO authentication for Wallarm users. #### Info:: See also: * [User guide][doc-user-sso-guide] to using SSO authentication to log in to Wallarm. * [Disabling and removing the configured SSO provider.][doc-disable-sso]","title":"Connecting SSO with G Suite"},{"location":"en/admin-en/configuration-guides/sso/gsuite/setup-idp/","text":"Step 2: Creating and Configuring an Application in G Suite \u00b6 #### Info:: Prerequisites. The following values are used as demonstration values in this guide: * `WallarmApp` as a value for the **Application Name** parameter (in G Suite). * `https://sso.online.wallarm.com/acs` as a value for the **ACS URL** parameter (in G Suite). * `https://sso.online.wallarm.com/entity-id` as a value for the **Entity ID** parameter (in G Suite). #### Warning:: Warning Ensure that you replace the sample values for the **ACS URL** and **Entity ID** parameters with the real ones obtained in the [previous step][doc-setup-sp]. Log in to the Google admin console . Click on the Apps block. Click on the SAML apps block. Add a new application by clicking the Add a service/App to your domain link or the \u201c+\u201d button at the bottom right. Click on the Setup my own custom app button. You will be provided with information (metadata) by G Suite as your identity provider: * SSO URL * Entity ID Certificate (X.509) Metadata is a set of parameters describing the identity provider's properties (similar to those generated for the service provider in Step 1 ) that are required to configure SSO. You can transfer them to the SSO Wallarm setup wizard in two ways: Copy each parameter and download the certificate, and then paste (upload) it into the corresponding fields of the Wallarm setup wizard. Download an XML file with metadata and upload it on the Wallarm side. Save the metadata in any way you like and go to the next step of configuring the application by clicking Next . Entering the identity provider metadata on the Wallarm side will be described in Step 3 . The next stage of configuring the application is to provide the service provider's (Wallarm) metadata. Required fields: ACS URL corresponds to the Assertion Consumer Service URL parameter generated on the Wallarm side. Entity ID corresponds to the Wallarm Entity ID parameter generated on the Wallarm side. Fill in the remaining parameters if required. Click Next . At the final stage of configuring the application, you will be prompted to provide mappings between service provider's attributes to the available user profile fields. Wallarm (as a service provider) requires you to create an attribute mapping. Press Add new mapping and then map the email attribute to the \u201cPrimary Email\u201d user profile field (in the \u201cBasic Information\u201d group). Click Finish . After that, you will be informed in the pop-up window that the provided information is saved and, in order to complete the SAML SSO configuration, you will need to upload the data about the identity provider (Google) in the admin panel of the service provider (Wallarm). Press Ok . After that, you will be redirected to the page of the created application. Once the application is created, it is disabled for all your organizations in G Suite. To activate the SSO for this application, click the Edit Service button. Select ON for everyone for the Service status parameter and click Save . Now you can continue configuring the SSO on the Wallarm side.","title":"Step 2. Creating and Configuring an Application in G Suite"},{"location":"en/admin-en/configuration-guides/sso/gsuite/setup-idp/#step-2-creating-and-configuring-an-application-in-g-suite","text":"#### Info:: Prerequisites. The following values are used as demonstration values in this guide: * `WallarmApp` as a value for the **Application Name** parameter (in G Suite). * `https://sso.online.wallarm.com/acs` as a value for the **ACS URL** parameter (in G Suite). * `https://sso.online.wallarm.com/entity-id` as a value for the **Entity ID** parameter (in G Suite). #### Warning:: Warning Ensure that you replace the sample values for the **ACS URL** and **Entity ID** parameters with the real ones obtained in the [previous step][doc-setup-sp]. Log in to the Google admin console . Click on the Apps block. Click on the SAML apps block. Add a new application by clicking the Add a service/App to your domain link or the \u201c+\u201d button at the bottom right. Click on the Setup my own custom app button. You will be provided with information (metadata) by G Suite as your identity provider: * SSO URL * Entity ID Certificate (X.509) Metadata is a set of parameters describing the identity provider's properties (similar to those generated for the service provider in Step 1 ) that are required to configure SSO. You can transfer them to the SSO Wallarm setup wizard in two ways: Copy each parameter and download the certificate, and then paste (upload) it into the corresponding fields of the Wallarm setup wizard. Download an XML file with metadata and upload it on the Wallarm side. Save the metadata in any way you like and go to the next step of configuring the application by clicking Next . Entering the identity provider metadata on the Wallarm side will be described in Step 3 . The next stage of configuring the application is to provide the service provider's (Wallarm) metadata. Required fields: ACS URL corresponds to the Assertion Consumer Service URL parameter generated on the Wallarm side. Entity ID corresponds to the Wallarm Entity ID parameter generated on the Wallarm side. Fill in the remaining parameters if required. Click Next . At the final stage of configuring the application, you will be prompted to provide mappings between service provider's attributes to the available user profile fields. Wallarm (as a service provider) requires you to create an attribute mapping. Press Add new mapping and then map the email attribute to the \u201cPrimary Email\u201d user profile field (in the \u201cBasic Information\u201d group). Click Finish . After that, you will be informed in the pop-up window that the provided information is saved and, in order to complete the SAML SSO configuration, you will need to upload the data about the identity provider (Google) in the admin panel of the service provider (Wallarm). Press Ok . After that, you will be redirected to the page of the created application. Once the application is created, it is disabled for all your organizations in G Suite. To activate the SSO for this application, click the Edit Service button. Select ON for everyone for the Service status parameter and click Save . Now you can continue configuring the SSO on the Wallarm side.","title":"Step 2: Creating and Configuring an Application in G Suite"},{"location":"en/admin-en/configuration-guides/sso/gsuite/setup-sp/","text":"Step 1: Generating Parameters on the Wallarm Side (G Suite) \u00b6 Log in to the Wallarm portal using your Admin account and go to the Settings \u2192 Integration tab. In the SSO/SAML Authentication section, click on the Google SSO block. This will bring up the SSO configuration wizard. At the first step of the wizard you will be presented with a form with the parameters (service provider's metadata) that should be passed to the G Suite service: Wallarm Entity ID is a unique application identifier generated by the Wallarm application for the identity provider. Assertion Consumer Service URL (ACS URL) is the address on the Wallarm side of the application on which identity provider sends requests with the SamlResponse parameter. The generated parameters will need to be entered into the corresponding fields on the G Suite service side (see Step 2 ).","title":"Step 1. Generating Parameters on the Wallarm Side"},{"location":"en/admin-en/configuration-guides/sso/gsuite/setup-sp/#step-1-generating-parameters-on-the-wallarm-side-g-suite","text":"Log in to the Wallarm portal using your Admin account and go to the Settings \u2192 Integration tab. In the SSO/SAML Authentication section, click on the Google SSO block. This will bring up the SSO configuration wizard. At the first step of the wizard you will be presented with a form with the parameters (service provider's metadata) that should be passed to the G Suite service: Wallarm Entity ID is a unique application identifier generated by the Wallarm application for the identity provider. Assertion Consumer Service URL (ACS URL) is the address on the Wallarm side of the application on which identity provider sends requests with the SamlResponse parameter. The generated parameters will need to be entered into the corresponding fields on the G Suite service side (see Step 2 ).","title":"Step 1: Generating Parameters on the Wallarm Side (G Suite)"},{"location":"en/admin-en/configuration-guides/sso/okta/allow-access-to-wl/","text":"Step 4: Allowing Access to the Wallarm Application on the Okta Side \u00b6 To authenticate through Okta, an account must be created on the Okta side and the user must have access rights to the Wallarm application. The required sequence of actions for granting access rights is described below. Click the Admin button at the top right of the Okta portal. In the Dashboard section, click the Assign Applications link. You will be prompted to assign the applications to the right users in order to give these users access to the selected applications. To do this, tick the checkboxes beside the required applications and users and click Next . Next, you will be prompted to check and confirm the application assignments. If all is correct, confirm the assignments by clicking the Confirm Assignments button. After that, you can go to the application settings page on the Assignments tab. Here you will be able to see a list of users who have access to the application for which SSO is configured. The access rights to the Wallarm application are now set up. Now, users assigned to the application can access the application using SSO authentication through the Okta service. Setup Complete \u00b6 This completes the configuration of the Okta-based SSO, and now you can start configuring the user specific SSO authentication on the Wallarm side.","title":"Step 4. Allowing Access to the Wallarm Application on the Okta Side"},{"location":"en/admin-en/configuration-guides/sso/okta/allow-access-to-wl/#step-4-allowing-access-to-the-wallarm-application-on-the-okta-side","text":"To authenticate through Okta, an account must be created on the Okta side and the user must have access rights to the Wallarm application. The required sequence of actions for granting access rights is described below. Click the Admin button at the top right of the Okta portal. In the Dashboard section, click the Assign Applications link. You will be prompted to assign the applications to the right users in order to give these users access to the selected applications. To do this, tick the checkboxes beside the required applications and users and click Next . Next, you will be prompted to check and confirm the application assignments. If all is correct, confirm the assignments by clicking the Confirm Assignments button. After that, you can go to the application settings page on the Assignments tab. Here you will be able to see a list of users who have access to the application for which SSO is configured. The access rights to the Wallarm application are now set up. Now, users assigned to the application can access the application using SSO authentication through the Okta service.","title":"Step 4: Allowing Access to the Wallarm Application on the Okta Side"},{"location":"en/admin-en/configuration-guides/sso/okta/allow-access-to-wl/#setup-complete","text":"This completes the configuration of the Okta-based SSO, and now you can start configuring the user specific SSO authentication on the Wallarm side.","title":"Setup Complete"},{"location":"en/admin-en/configuration-guides/sso/okta/metadata-transfer/","text":"Step 3: Transferring Okta Metadata to the Wallarm Setup Wizard \u00b6 Return to the SSO Wallarm setup wizard and click Next to proceed to the next setup step. At this step, you need to provide the metadata generated by the Okta service. There are two ways to pass the identity provider metadata (in this case Okta) to the Wallarm setup wizard: By uploading an XML file with metadata. Upload the XML file by clicking the Upload button and selecting the appropriate file. You can also do this by dragging the file from your file manager to the \u201cXML\u201d icon field. By entering the metadata manually. Click the Enter manually link and copy the Okta service parameters to the fields of the setup wizard as follows: * Identity Provider Single Sign-On URL to the Identity provider SSO URL field. * Identity Provider Issuer to the Identity provider issuer field. * X.509 Certificate to the X.509 Certificate field. Click Next to go to the next step. If you want to return to the previous step, click Back . Completing SSO Wizard \u00b6 On the final step of the Wallarm setup wizard, a test connection to the Okta service will be performed automatically and the SSO provider will be checked. After successful completion of the test (if all the necessary parameters are filled in correctly), the setup wizard will inform you that the Okta service is connected as an identity provider, and you can start connecting the SSO mechanism to authenticate your users. Finish configuring SSO by clicking the Finish button or going to the user page to configure SSO by clicking the corresponding button. After completing the SSO configuration wizard, on the Integration tab you will see that the Okta service is connected as an identity provider and that no other SSO providers are available. Now, navigate to the next step of the SSO configuration process.","title":"Step 3. Transferring Okta Metadata to the Wallarm Setup Wizard"},{"location":"en/admin-en/configuration-guides/sso/okta/metadata-transfer/#step-3-transferring-okta-metadata-to-the-wallarm-setup-wizard","text":"Return to the SSO Wallarm setup wizard and click Next to proceed to the next setup step. At this step, you need to provide the metadata generated by the Okta service. There are two ways to pass the identity provider metadata (in this case Okta) to the Wallarm setup wizard: By uploading an XML file with metadata. Upload the XML file by clicking the Upload button and selecting the appropriate file. You can also do this by dragging the file from your file manager to the \u201cXML\u201d icon field. By entering the metadata manually. Click the Enter manually link and copy the Okta service parameters to the fields of the setup wizard as follows: * Identity Provider Single Sign-On URL to the Identity provider SSO URL field. * Identity Provider Issuer to the Identity provider issuer field. * X.509 Certificate to the X.509 Certificate field. Click Next to go to the next step. If you want to return to the previous step, click Back .","title":"Step 3: Transferring Okta Metadata to the Wallarm Setup Wizard"},{"location":"en/admin-en/configuration-guides/sso/okta/metadata-transfer/#completing-sso-wizard","text":"On the final step of the Wallarm setup wizard, a test connection to the Okta service will be performed automatically and the SSO provider will be checked. After successful completion of the test (if all the necessary parameters are filled in correctly), the setup wizard will inform you that the Okta service is connected as an identity provider, and you can start connecting the SSO mechanism to authenticate your users. Finish configuring SSO by clicking the Finish button or going to the user page to configure SSO by clicking the corresponding button. After completing the SSO configuration wizard, on the Integration tab you will see that the Okta service is connected as an identity provider and that no other SSO providers are available. Now, navigate to the next step of the SSO configuration process.","title":"Completing SSO Wizard"},{"location":"en/admin-en/configuration-guides/sso/okta/overview/","text":"Connecting SSO with Okta \u00b6 This guide will cover the process of connecting the Okta service as an identity provider to Wallarm, which acts as the service provider. #### Warning:: Note By default, SSO connection on Wallarm is not available without activating the appropriate service. To activate the SSO service, please contact your account manager. After activating the service * you will be able to perform the following SSO connection procedure, and * the SSO-related blocks will be visible in the \u201cIntegrations\u201d tab. <!-- --> In addition, you need accounts with administration rights both for Wallarm and Okta. The process of connecting SSO with Okta comprises the following steps: Generating Parameters on the Wallarm Side. Creating and Configuring an Application in Okta. Transferring Okta Metadata to the Wallarm Setup Wizard. Allowing Access to the Wallarm Application on the Okta Side After that, configure SSO authentication for Wallarm users. #### Info:: See also: * [User guide][doc-user-sso-guide] to using SSO authentication to log in to Wallarm. * [Disabling and removing the configured SSO provider.][doc-disable-sso]","title":"Overview"},{"location":"en/admin-en/configuration-guides/sso/okta/overview/#connecting-sso-with-okta","text":"This guide will cover the process of connecting the Okta service as an identity provider to Wallarm, which acts as the service provider. #### Warning:: Note By default, SSO connection on Wallarm is not available without activating the appropriate service. To activate the SSO service, please contact your account manager. After activating the service * you will be able to perform the following SSO connection procedure, and * the SSO-related blocks will be visible in the \u201cIntegrations\u201d tab. <!-- --> In addition, you need accounts with administration rights both for Wallarm and Okta. The process of connecting SSO with Okta comprises the following steps: Generating Parameters on the Wallarm Side. Creating and Configuring an Application in Okta. Transferring Okta Metadata to the Wallarm Setup Wizard. Allowing Access to the Wallarm Application on the Okta Side After that, configure SSO authentication for Wallarm users. #### Info:: See also: * [User guide][doc-user-sso-guide] to using SSO authentication to log in to Wallarm. * [Disabling and removing the configured SSO provider.][doc-disable-sso]","title":"Connecting SSO with Okta"},{"location":"en/admin-en/configuration-guides/sso/okta/setup-idp/","text":"Step 2: Creating and Configuring an Application in Okta \u00b6 #### Info:: Prerequisites. The following values are used as demonstration values in this guide: * `WallarmApp` as a value for the **App name** parameter (in Okta). * `https://sso.online.wallarm.com/acs` as a value for the **Single sign-on URL** parameter (in Okta). * `https://sso.online.wallarm.com/entity-id` as a value for the **Audience URI** parameter (in Okta). #### Warning:: Warning Ensure that you replace the sample values for the **Single sign-on URL** and **Audience URI** parameters with the real ones obtained in the [previous step][doc-setup-sp]. Log in to the Okta service (the account must have administrator rights) and click on the Administrator button in the upper right. In the Dashboard section, click the Add Applications button on the right. In the new application section, click the Create New App button on the right. In the pop-up window, set the following options: Platform \u2192 \u201cWeb\u201d. Sign-on method \u2192 \u201cSAML 2.0\u201d. Click the Create button. After that you will be taken to the SAML integration wizard ( Create SAML Integration ). To create and configure SAML integration you will be prompted to complete three stages: General Settings. Configure SAML. Feedback. After that, the metadata needs to be downloaded for the newly created integration. 1. General Settings \u00b6 Enter the name of the application you are creating in the App Name field. Optionally, you can download the logo of the application ( App logo ) and configure application visibility for your users on the Okta homepage and in the Okta mobile application. Click the Next button. 2. Configure SAML \u00b6 At this stage you will need the parameters generated earlier on the Wallarm side: * Wallarm Entity ID * Assertion Consumer Service URL (ACS URL) #### Info:: Okta parameters This manual describes only the mandatory parameters to be filled in when configuring SSO with Okta. To learn more about the rest of the parameters (including those related to the digital signature and SAML message encryption settings), please refer to the [Okta documentation][link-okta-docs]. Fill in the following basic parameters: Single sign-on URL \u2014enter the Assertion Consumer Service URL (ACS URL) value previously obtained on the Wallarm side. Audience URI (SP Entity ID) \u2014enter the value of the Wallarm Entity ID received earlier on the Wallarm side. The remaining parameters for the initial setup can be left as default. Click Next to continue the setup. If you want to return to the previous step, click Previous . 3. Feedback \u00b6 At this stage, you are asked to provide Okta with additional information about the type of your application, whether you are an Okta customer or partner, and other data. It is enough to choose \u201cI'm an Okta customer adding an internal app\u201d for the parameter Are you a customer or partner ? If required, fill in other available parameters. After that, you can finish the SAML integration wizard by clicking the Finish button. To go to the previous step, click the Previous button. After this stage, you will be taken to the settings page of the created application. Now you need to download the metadata for the created integration to continue configuring the SSO provider on the Wallarm side. The metadata is a set of parameters describing the identity provider's properties (such as those generated for the service provider in Step 1 ) required to configure SSO. Downloading Metadata \u00b6 You can download the metadata either as an XML file or \u201cas is\u201d in text form (you will need to enter the metadata manually when configuring it further). To download as an XML file: Click the Identity Provider metadata link on the settings page of the created application: As a result, you will be taken to a new tab on your browser with similar content: Save the content to an XML file (with your browser or other suitable method). To download the metadata \u201cas is\u201d: On the settings page of the created application, click the View Setup instructions button. Copy all the given data. Now you can continue configuring the SSO on the Wallarm side.","title":"Step 2. Creating and Configuring an Application in Okta"},{"location":"en/admin-en/configuration-guides/sso/okta/setup-idp/#step-2-creating-and-configuring-an-application-in-okta","text":"#### Info:: Prerequisites. The following values are used as demonstration values in this guide: * `WallarmApp` as a value for the **App name** parameter (in Okta). * `https://sso.online.wallarm.com/acs` as a value for the **Single sign-on URL** parameter (in Okta). * `https://sso.online.wallarm.com/entity-id` as a value for the **Audience URI** parameter (in Okta). #### Warning:: Warning Ensure that you replace the sample values for the **Single sign-on URL** and **Audience URI** parameters with the real ones obtained in the [previous step][doc-setup-sp]. Log in to the Okta service (the account must have administrator rights) and click on the Administrator button in the upper right. In the Dashboard section, click the Add Applications button on the right. In the new application section, click the Create New App button on the right. In the pop-up window, set the following options: Platform \u2192 \u201cWeb\u201d. Sign-on method \u2192 \u201cSAML 2.0\u201d. Click the Create button. After that you will be taken to the SAML integration wizard ( Create SAML Integration ). To create and configure SAML integration you will be prompted to complete three stages: General Settings. Configure SAML. Feedback. After that, the metadata needs to be downloaded for the newly created integration.","title":"Step 2: Creating and Configuring an Application in Okta"},{"location":"en/admin-en/configuration-guides/sso/okta/setup-idp/#1-general-settings","text":"Enter the name of the application you are creating in the App Name field. Optionally, you can download the logo of the application ( App logo ) and configure application visibility for your users on the Okta homepage and in the Okta mobile application. Click the Next button.","title":"1.  General Settings"},{"location":"en/admin-en/configuration-guides/sso/okta/setup-idp/#2-configure-saml","text":"At this stage you will need the parameters generated earlier on the Wallarm side: * Wallarm Entity ID * Assertion Consumer Service URL (ACS URL) #### Info:: Okta parameters This manual describes only the mandatory parameters to be filled in when configuring SSO with Okta. To learn more about the rest of the parameters (including those related to the digital signature and SAML message encryption settings), please refer to the [Okta documentation][link-okta-docs]. Fill in the following basic parameters: Single sign-on URL \u2014enter the Assertion Consumer Service URL (ACS URL) value previously obtained on the Wallarm side. Audience URI (SP Entity ID) \u2014enter the value of the Wallarm Entity ID received earlier on the Wallarm side. The remaining parameters for the initial setup can be left as default. Click Next to continue the setup. If you want to return to the previous step, click Previous .","title":"2.  Configure SAML"},{"location":"en/admin-en/configuration-guides/sso/okta/setup-idp/#3-feedback","text":"At this stage, you are asked to provide Okta with additional information about the type of your application, whether you are an Okta customer or partner, and other data. It is enough to choose \u201cI'm an Okta customer adding an internal app\u201d for the parameter Are you a customer or partner ? If required, fill in other available parameters. After that, you can finish the SAML integration wizard by clicking the Finish button. To go to the previous step, click the Previous button. After this stage, you will be taken to the settings page of the created application. Now you need to download the metadata for the created integration to continue configuring the SSO provider on the Wallarm side. The metadata is a set of parameters describing the identity provider's properties (such as those generated for the service provider in Step 1 ) required to configure SSO.","title":"3.  Feedback"},{"location":"en/admin-en/configuration-guides/sso/okta/setup-idp/#downloading-metadata","text":"You can download the metadata either as an XML file or \u201cas is\u201d in text form (you will need to enter the metadata manually when configuring it further). To download as an XML file: Click the Identity Provider metadata link on the settings page of the created application: As a result, you will be taken to a new tab on your browser with similar content: Save the content to an XML file (with your browser or other suitable method). To download the metadata \u201cas is\u201d: On the settings page of the created application, click the View Setup instructions button. Copy all the given data. Now you can continue configuring the SSO on the Wallarm side.","title":"Downloading Metadata"},{"location":"en/admin-en/configuration-guides/sso/okta/setup-sp/","text":"Step 1: Generating Parameters on the Wallarm Side (Okta) \u00b6 Log in to the Wallarm portal using your Admin account and go to the Settings \u2192 Integration tab. In the SSO/SAML Authentication section, click on the Okta SSO block. This will bring up the SSO configuration wizard. At the first step of the wizard you will be presented with a form with the parameters (service provider's metadata) that should be passed to the Okta service: Wallarm Entity ID is a unique application identifier generated by the Wallarm application for the identity provider. Assertion Consumer Service URL (ACS URL) is the address on the Wallarm side of the application on which identity provider sends requests with the SamlResponse parameter. The generated parameters will need to be entered into the corresponding fields on the Okta service side (see Step 2 ).","title":"Step 1. Generating Parameters on the Wallarm Side"},{"location":"en/admin-en/configuration-guides/sso/okta/setup-sp/#step-1-generating-parameters-on-the-wallarm-side-okta","text":"Log in to the Wallarm portal using your Admin account and go to the Settings \u2192 Integration tab. In the SSO/SAML Authentication section, click on the Okta SSO block. This will bring up the SSO configuration wizard. At the first step of the wizard you will be presented with a form with the parameters (service provider's metadata) that should be passed to the Okta service: Wallarm Entity ID is a unique application identifier generated by the Wallarm application for the identity provider. Assertion Consumer Service URL (ACS URL) is the address on the Wallarm side of the application on which identity provider sends requests with the SamlResponse parameter. The generated parameters will need to be entered into the corresponding fields on the Okta service side (see Step 2 ).","title":"Step 1: Generating Parameters on the Wallarm Side (Okta)"},{"location":"en/admin-en/installation-guides/clouds-intro/","text":"Deploying in Clouds: Overview \u00b6 Wallarm filter node can be deployed on certain cloud platforms. You can: Install a single filter node in the cloud: Amazon AWS Google Cloud Platform Create an image of a deployed filter node to configure auto-scaling of nodes: Amazon AWS Google Cloud Platform Set up auto-scaling of filter nodes in the cloud using the created image: Amazon AWS Google Cloud Platform","title":"Installation Options Overview"},{"location":"en/admin-en/installation-guides/clouds-intro/#deploying-in-clouds-overview","text":"Wallarm filter node can be deployed on certain cloud platforms. You can: Install a single filter node in the cloud: Amazon AWS Google Cloud Platform Create an image of a deployed filter node to configure auto-scaling of nodes: Amazon AWS Google Cloud Platform Set up auto-scaling of filter nodes in the cloud using the created image: Amazon AWS Google Cloud Platform","title":"Deploying in Clouds: Overview"},{"location":"en/admin-en/installation-guides/amazon-cloud/autoscaling-group-guide/","text":"Setting Up Filter Node Auto-Scaling \u00b6 #### Info:: Required rights Before setting up auto-scaling, make sure that your Amazon AWS account is granted with one of the following rights: * `AutoScalingFullAccess` * `AutoScalingConsoleFullAccess` To set up filter node auto-scaling, proceed with the following steps: Creating a Launch Template Creating an Auto Scaling Group 1. Creating a Launch Template \u00b6 A Launch Template defines the instance type to be used during the deployment of an Amazon Machine Image (AMI) and sets up some of the general virtual machine parameters. Create a Launch Template by doing the following steps: Navigate to the Launch Templates tab on the Amazon EC2 dashboard and click the Create launch template button. Enter the template name into the Launch template name field. Select the previously created Amazon Machine Image. To do this, click the Search for AMI link and select the required image from the My AMIs catalog. Select the instance type to launch a filter node\u2019s virtual machine on from the Instance type list. #### Warning:: Select the proper instance type Select the same instance type that you used when you initially configured the filter node or a more powerful one. Using a less powerful instance type may lead to issues in filter node operation. Select the name of the previously created pair of SSH keys to access the filter node from the Key pair name list. Select the previously created Security Group from the Security Groups list. Click the Create launch template button. Wait until the template creation process is finished. After creating the Launch Template, you can proceed with the creation of an Auto-Scaling Group. 2. Creating an Auto Scaling Group \u00b6 #### Info:: Selecting an auto-scaling method This section describes the process of creating an Auto Scaling Group using the EC2 Auto Scaling method. You can also use the AWS Auto Scaling method. To see a detailed FAQ about auto-scaling methods from Amazon, proceed to this [link][link-doc-as-faq]. To create an Auto Scaling Group, do the following steps: Navigate to the Auto Scaling Groups tab on the Amazon EC2 dashboard and click the Create Auto Scaling Group button. Select the Launch Template option, then select the previously created Launch Template from the list and click the Next Step button. Enter the desired Auto Scaling Group name into the Group name field. Select the \u201cLatest\u201d version of the Launch Template from the Launch Template Version list. Select the instance type required for the Auto Scaling Group by picking one of the Fleet Composition options. If you followed this guide when creating a Launch Template and an instance type to launch virtual machines on was specified, then you can use the Adhere to the launch template option. #### Info:: Select the proper instance type You can also select the Combine purchase options and instances option if no instance type is specified in your Launch Template or if you want to select multiple different instance types for auto-scaling. Select the same instance type that you used when you initially configured the filter node or a more powerful one. Using a less powerful instance type may lead to issues in filter node operation. Enter the initial Auto Scaling Group size into the Group size field (e.g., two instances). Select the correct VPC from the Network drop-down list. Select the correct subnets from the Subnets drop-down list. Warning:: Provide the filter node with an internet connection \u00b6 The filter node requires access to the Wallarm API server for proper operation. The choice of the Wallarm API server depends on the Wallarm Cloud you are using: * If you are using the EU cloud, your node needs to be granted access to https://api.wallarm.com:444 . * If you are using the US cloud, your node needs to be granted access to https://us1.api.wallarm.com:444 . Make sure that you choose the correct VPC and subnets and configure a security group in a way that does not prevent the filter node\u2019s access to Wallarm API servers. Navigate to the Configure scaling policies page by clicking the Next: Configure scaling policies button. Select the \u201cUse scaling policies to adjust the capacity of this group\u201d option to enable auto-scaling. Enter the minimum and the maximum Auto Scaling Group size. #### Info:: Auto Scaling Group size Note that the minimum Auto Scaling Group size can be less than the initial group size specified in the sixth step. Enable the step-by-step policies configuration mode by selecting the \u201cScale the Auto Scaling group using step or simple scaling policies\u201d option. Configure the group size increase policy using the Increase Group Size parameter group. If necessary, specify the group size increase policy name using the Name parameter. Select the event from the Execute policy when to specify the event that will trigger the increase of the group size. If you did not create any events earlier, click the Add Alarm button to create an event. You can set up an event name, a metric to monitor, and notifications about event occurrences. #### Info:: Roles required for configuring notifications Your Amazon AWS account needs the \u201cAutoScalingNotificationAccessRole\u201d for notifications configuration. #### Info:: Example You can set up triggering of an event with the name \u201cHigh CPU utilization\u201d upon reaching a 60% average processor load within five minutes: #### Info:: Available standard metrics of Amazon cloud * CPU Utilization (in percentages) * Disk Reads (in bytes) * Disk Writes (in bytes) * Disk Read Operations count * Disk Write Operations count * Network In (in bytes) * Network Out (in bytes) Click the Create Alarm button to create an event. Select the action to be taken in the case the \u201cHigh CPU Utilization\u201d event triggers. For example, you may configure an auto-scaling policy to add (using the Add action) one instance when the event is triggered. The event may trigger early if resource consumption leaps occur after adding a new instance. To avoid this, you can set up a warm-up period in seconds using the Instances need X seconds to warm up parameter. No events will be triggered during this period of time. Similarly, use the Decrease Group Size parameter group to configure the group size decrease policy. If necessary, configure notifications and tags for the Auto Scaling Group or proceed to the review of the changes by clicking the Review button. Make sure all of the parameters are correctly specified and then launch the Auto Scaling Group creation process by clicking the Create Auto Scaling group button. The specified number of instances will be launched automatically upon the successful Auto Scaling Group creation. You can check that the Auto Scaling Group has been created correctly by viewing the number of launched instances in the group and comparing this data with the number of filter nodes connected to the Wallarm cloud. You can do this using the Wallarm website. For example, if two instances with filter nodes are concurrently operating, the Wallarm website will display the \u201c2/2 nodes are active\u201d label for the corresponding cloud node on the Nodes tab. You can now proceed with the creation and configuration of a load balancer.","title":"Setting Up Filter Node Auto-Scaling"},{"location":"en/admin-en/installation-guides/amazon-cloud/autoscaling-group-guide/#setting-up-filter-node-auto-scaling","text":"#### Info:: Required rights Before setting up auto-scaling, make sure that your Amazon AWS account is granted with one of the following rights: * `AutoScalingFullAccess` * `AutoScalingConsoleFullAccess` To set up filter node auto-scaling, proceed with the following steps: Creating a Launch Template Creating an Auto Scaling Group","title":"Setting Up Filter Node Auto-Scaling"},{"location":"en/admin-en/installation-guides/amazon-cloud/autoscaling-group-guide/#1-creating-a-launch-template","text":"A Launch Template defines the instance type to be used during the deployment of an Amazon Machine Image (AMI) and sets up some of the general virtual machine parameters. Create a Launch Template by doing the following steps: Navigate to the Launch Templates tab on the Amazon EC2 dashboard and click the Create launch template button. Enter the template name into the Launch template name field. Select the previously created Amazon Machine Image. To do this, click the Search for AMI link and select the required image from the My AMIs catalog. Select the instance type to launch a filter node\u2019s virtual machine on from the Instance type list. #### Warning:: Select the proper instance type Select the same instance type that you used when you initially configured the filter node or a more powerful one. Using a less powerful instance type may lead to issues in filter node operation. Select the name of the previously created pair of SSH keys to access the filter node from the Key pair name list. Select the previously created Security Group from the Security Groups list. Click the Create launch template button. Wait until the template creation process is finished. After creating the Launch Template, you can proceed with the creation of an Auto-Scaling Group.","title":"1.  Creating a Launch Template"},{"location":"en/admin-en/installation-guides/amazon-cloud/autoscaling-group-guide/#2-creating-an-auto-scaling-group","text":"#### Info:: Selecting an auto-scaling method This section describes the process of creating an Auto Scaling Group using the EC2 Auto Scaling method. You can also use the AWS Auto Scaling method. To see a detailed FAQ about auto-scaling methods from Amazon, proceed to this [link][link-doc-as-faq]. To create an Auto Scaling Group, do the following steps: Navigate to the Auto Scaling Groups tab on the Amazon EC2 dashboard and click the Create Auto Scaling Group button. Select the Launch Template option, then select the previously created Launch Template from the list and click the Next Step button. Enter the desired Auto Scaling Group name into the Group name field. Select the \u201cLatest\u201d version of the Launch Template from the Launch Template Version list. Select the instance type required for the Auto Scaling Group by picking one of the Fleet Composition options. If you followed this guide when creating a Launch Template and an instance type to launch virtual machines on was specified, then you can use the Adhere to the launch template option. #### Info:: Select the proper instance type You can also select the Combine purchase options and instances option if no instance type is specified in your Launch Template or if you want to select multiple different instance types for auto-scaling. Select the same instance type that you used when you initially configured the filter node or a more powerful one. Using a less powerful instance type may lead to issues in filter node operation. Enter the initial Auto Scaling Group size into the Group size field (e.g., two instances). Select the correct VPC from the Network drop-down list. Select the correct subnets from the Subnets drop-down list.","title":"2.  Creating an Auto Scaling Group"},{"location":"en/admin-en/installation-guides/amazon-cloud/autoscaling-group-guide/#warning-provide-the-filter-node-with-an-internet-connection","text":"The filter node requires access to the Wallarm API server for proper operation. The choice of the Wallarm API server depends on the Wallarm Cloud you are using: * If you are using the EU cloud, your node needs to be granted access to https://api.wallarm.com:444 . * If you are using the US cloud, your node needs to be granted access to https://us1.api.wallarm.com:444 . Make sure that you choose the correct VPC and subnets and configure a security group in a way that does not prevent the filter node\u2019s access to Wallarm API servers. Navigate to the Configure scaling policies page by clicking the Next: Configure scaling policies button. Select the \u201cUse scaling policies to adjust the capacity of this group\u201d option to enable auto-scaling. Enter the minimum and the maximum Auto Scaling Group size. #### Info:: Auto Scaling Group size Note that the minimum Auto Scaling Group size can be less than the initial group size specified in the sixth step. Enable the step-by-step policies configuration mode by selecting the \u201cScale the Auto Scaling group using step or simple scaling policies\u201d option. Configure the group size increase policy using the Increase Group Size parameter group. If necessary, specify the group size increase policy name using the Name parameter. Select the event from the Execute policy when to specify the event that will trigger the increase of the group size. If you did not create any events earlier, click the Add Alarm button to create an event. You can set up an event name, a metric to monitor, and notifications about event occurrences. #### Info:: Roles required for configuring notifications Your Amazon AWS account needs the \u201cAutoScalingNotificationAccessRole\u201d for notifications configuration. #### Info:: Example You can set up triggering of an event with the name \u201cHigh CPU utilization\u201d upon reaching a 60% average processor load within five minutes: #### Info:: Available standard metrics of Amazon cloud * CPU Utilization (in percentages) * Disk Reads (in bytes) * Disk Writes (in bytes) * Disk Read Operations count * Disk Write Operations count * Network In (in bytes) * Network Out (in bytes) Click the Create Alarm button to create an event. Select the action to be taken in the case the \u201cHigh CPU Utilization\u201d event triggers. For example, you may configure an auto-scaling policy to add (using the Add action) one instance when the event is triggered. The event may trigger early if resource consumption leaps occur after adding a new instance. To avoid this, you can set up a warm-up period in seconds using the Instances need X seconds to warm up parameter. No events will be triggered during this period of time. Similarly, use the Decrease Group Size parameter group to configure the group size decrease policy. If necessary, configure notifications and tags for the Auto Scaling Group or proceed to the review of the changes by clicking the Review button. Make sure all of the parameters are correctly specified and then launch the Auto Scaling Group creation process by clicking the Create Auto Scaling group button. The specified number of instances will be launched automatically upon the successful Auto Scaling Group creation. You can check that the Auto Scaling Group has been created correctly by viewing the number of launched instances in the group and comparing this data with the number of filter nodes connected to the Wallarm cloud. You can do this using the Wallarm website. For example, if two instances with filter nodes are concurrently operating, the Wallarm website will display the \u201c2/2 nodes are active\u201d label for the corresponding cloud node on the Nodes tab. You can now proceed with the creation and configuration of a load balancer.","title":"Warning:: Provide the filter node with an internet connection"},{"location":"en/admin-en/installation-guides/amazon-cloud/autoscaling-overview/","text":"Filter Node Auto-Scaling: Overview \u00b6 You can set up Wallarm filter node auto-scaling to make sure that filter nodes are capable of handling traffic fluctuations, if there are any. Enabling auto-scaling allows processing the incoming requests to the application using the filter nodes even when traffic soars significantly. The Amazon cloud supports the following auto-scaling methods: AWS Autoscaling: The new auto-scaling technology on the basis of the metrics that are collected by AWS. To see detailed information about AWS Auto Scaling, proceed to this link . EC2 Autoscaling: The legacy auto-scaling technology that allows creating custom variables for defining the scaling rules. To see detailed information about EC2 Auto Scaling, proceed to this link . #### Info:: Information about auto-scaling methods To see a detailed FAQ about auto-scaling methods provided by Amazon, proceed to this link . This guide explains how to configure auto-scaling of the filter nodes using EC2 Auto Scaling, but you can also use AWS Auto Scaling if needed. #### Warning:: Prerequisites A virtual machine image (Amazon Machine Image, AMI) with the Wallarm filter node is required for setting up auto-scaling. To see detailed information about creating an AMI with the filter node, proceed with this [link][link-doc-ami-creation]. #### Info:: Private SSH key Make sure you have access to the private SSH key (stored in PEM format) that you created earlier to connect to the filter node. To enable filter node auto-scaling in the Amazon cloud, do the following steps: Set up filter node auto-scaling Create a Launch Template Create an Auto Scaling Group Set up incoming requests balancing Create a load balancer Set up an Auto Scaling Group for using the created balancer","title":"Overview"},{"location":"en/admin-en/installation-guides/amazon-cloud/autoscaling-overview/#filter-node-auto-scaling-overview","text":"You can set up Wallarm filter node auto-scaling to make sure that filter nodes are capable of handling traffic fluctuations, if there are any. Enabling auto-scaling allows processing the incoming requests to the application using the filter nodes even when traffic soars significantly. The Amazon cloud supports the following auto-scaling methods: AWS Autoscaling: The new auto-scaling technology on the basis of the metrics that are collected by AWS. To see detailed information about AWS Auto Scaling, proceed to this link . EC2 Autoscaling: The legacy auto-scaling technology that allows creating custom variables for defining the scaling rules. To see detailed information about EC2 Auto Scaling, proceed to this link . #### Info:: Information about auto-scaling methods To see a detailed FAQ about auto-scaling methods provided by Amazon, proceed to this link . This guide explains how to configure auto-scaling of the filter nodes using EC2 Auto Scaling, but you can also use AWS Auto Scaling if needed. #### Warning:: Prerequisites A virtual machine image (Amazon Machine Image, AMI) with the Wallarm filter node is required for setting up auto-scaling. To see detailed information about creating an AMI with the filter node, proceed with this [link][link-doc-ami-creation]. #### Info:: Private SSH key Make sure you have access to the private SSH key (stored in PEM format) that you created earlier to connect to the filter node. To enable filter node auto-scaling in the Amazon cloud, do the following steps: Set up filter node auto-scaling Create a Launch Template Create an Auto Scaling Group Set up incoming requests balancing Create a load balancer Set up an Auto Scaling Group for using the created balancer","title":"Filter Node Auto-Scaling: Overview"},{"location":"en/admin-en/installation-guides/amazon-cloud/create-image/","text":"Creating an AMI with the Wallarm Filter Node \u00b6 You can set up auto-scaling for the Wallarm filter nodes deployed on the Amazon cloud. This function requires preliminarily prepared virtual machine images. This document describes the procedure of preparing an Amazon Machine Image (AMI) with the Wallarm filter node installed. AMI is required for the filter node auto-scaling setup. To see detailed information about setting up auto-scaling, proceed to this link . To create an AMI with the Wallarm filter node, perform the following procedures: Creating and configuring the filter node instance in the Amazon cloud ; Creating an AMI on the basis of the configured filter node instance . 1. Creating and Configuring the Wallarm Filter Node Instance in the Amazon Cloud \u00b6 Before creating an AMI you need to perform an initial configuration of a single Wallarm filter node. To configure a filter node, do the following: Create a filter node instance in the Amazon cloud. #### Warning:: Private SSH key Make sure you have access to the private SSH key (stored in PEM format) that you created earlier to connect to the filter node. #### Warning:: Provide the filter node with an internet connection The filter node requires access to the Wallarm API server for proper operation. The choice of the Wallarm API server depends on the Wallarm Cloud you are using: * If you are using the EU cloud, your node needs to be granted access to https://api.wallarm.com:444 . * If you are using the US cloud, your node needs to be granted access to https://us1.api.wallarm.com:444 . Make sure that you choose the correct VPC and subnets and configure a security group in a way that does not prevent the filter node from accessing Wallarm API servers. Connect the filter node to the Wallarm cloud. #### Warning:: Use a token to connect to the Wallarm cloud Please note that you need to connect the filter node to the Wallarm cloud using a token. Multiple filter nodes are allowed to connect to the Wallarm cloud using the same token. Thus, upon filter nodes\u2019 auto-scaling, you will not need to manually connect each of the filter nodes to the Wallarm cloud. Configure the filter node to act as a reverse proxy for your web application. Make sure that the filter node is configured correctly and protects your web application against malicious requests. After you have finished configuring the filter node, turn the virtual machine off by completing the following actions: Navigate to the Instances tab on the Amazon EC2 dashboard. Select your configured filter node instance. Select \u201cInstance State\u201d and then \u201cStop\u201d in the Actions drop-down menu. #### Info:: Turning off with the poweroff command You may also turn the virtual machine off by connecting to it via the SSH protocol and running the following command: # poweroff 2. Creating an Amazon Machine Image \u00b6 You can now create a virtual machine image based on the configured filter node instance. To create an image, perform the following steps: Proceed to the Instances tab on the Amazon EC2 dashboard. Select your configured filter node instance. Launch the image creation wizard by selecting \u201cImage\u201d and then \u201cCreate Image\u201d in the Actions drop-down menu. The Create Image form will appear. Enter the image name into the Image name field. You can leave the remaining fields unaltered. Click the Create Image button to launch the virtual machine image creation process. When the image creation process is finished, the corresponding message is displayed. Navigate to the \u201cAMIs\u201d tab on the Amazon EC2 dashboard to make sure that the image was successfully created and has the \u201cAvailable\u201d status. #### Info:: Image visibility Because the prepared image contains settings that are specific to your application and the Wallarm token, it is not recommended to change the image visibility setting and make it public (by default, AMIs are created with the \u201cPrivate\u201d visibility setting). Now you can set up the auto-scaling of Wallarm filter nodes in the Amazon cloud using the prepared image.","title":"Creating an Amazon Machine Image"},{"location":"en/admin-en/installation-guides/amazon-cloud/create-image/#creating-an-ami-with-the-wallarm-filter-node","text":"You can set up auto-scaling for the Wallarm filter nodes deployed on the Amazon cloud. This function requires preliminarily prepared virtual machine images. This document describes the procedure of preparing an Amazon Machine Image (AMI) with the Wallarm filter node installed. AMI is required for the filter node auto-scaling setup. To see detailed information about setting up auto-scaling, proceed to this link . To create an AMI with the Wallarm filter node, perform the following procedures: Creating and configuring the filter node instance in the Amazon cloud ; Creating an AMI on the basis of the configured filter node instance .","title":"Creating an AMI with the Wallarm Filter Node"},{"location":"en/admin-en/installation-guides/amazon-cloud/create-image/#1-creating-and-configuring-the-wallarm-filter-node-instance-in-the-amazon-cloud","text":"Before creating an AMI you need to perform an initial configuration of a single Wallarm filter node. To configure a filter node, do the following: Create a filter node instance in the Amazon cloud. #### Warning:: Private SSH key Make sure you have access to the private SSH key (stored in PEM format) that you created earlier to connect to the filter node. #### Warning:: Provide the filter node with an internet connection The filter node requires access to the Wallarm API server for proper operation. The choice of the Wallarm API server depends on the Wallarm Cloud you are using: * If you are using the EU cloud, your node needs to be granted access to https://api.wallarm.com:444 . * If you are using the US cloud, your node needs to be granted access to https://us1.api.wallarm.com:444 . Make sure that you choose the correct VPC and subnets and configure a security group in a way that does not prevent the filter node from accessing Wallarm API servers. Connect the filter node to the Wallarm cloud. #### Warning:: Use a token to connect to the Wallarm cloud Please note that you need to connect the filter node to the Wallarm cloud using a token. Multiple filter nodes are allowed to connect to the Wallarm cloud using the same token. Thus, upon filter nodes\u2019 auto-scaling, you will not need to manually connect each of the filter nodes to the Wallarm cloud. Configure the filter node to act as a reverse proxy for your web application. Make sure that the filter node is configured correctly and protects your web application against malicious requests. After you have finished configuring the filter node, turn the virtual machine off by completing the following actions: Navigate to the Instances tab on the Amazon EC2 dashboard. Select your configured filter node instance. Select \u201cInstance State\u201d and then \u201cStop\u201d in the Actions drop-down menu. #### Info:: Turning off with the poweroff command You may also turn the virtual machine off by connecting to it via the SSH protocol and running the following command: # poweroff","title":"1.  Creating and Configuring the Wallarm Filter Node Instance in the Amazon Cloud"},{"location":"en/admin-en/installation-guides/amazon-cloud/create-image/#2-creating-an-amazon-machine-image","text":"You can now create a virtual machine image based on the configured filter node instance. To create an image, perform the following steps: Proceed to the Instances tab on the Amazon EC2 dashboard. Select your configured filter node instance. Launch the image creation wizard by selecting \u201cImage\u201d and then \u201cCreate Image\u201d in the Actions drop-down menu. The Create Image form will appear. Enter the image name into the Image name field. You can leave the remaining fields unaltered. Click the Create Image button to launch the virtual machine image creation process. When the image creation process is finished, the corresponding message is displayed. Navigate to the \u201cAMIs\u201d tab on the Amazon EC2 dashboard to make sure that the image was successfully created and has the \u201cAvailable\u201d status. #### Info:: Image visibility Because the prepared image contains settings that are specific to your application and the Wallarm token, it is not recommended to change the image visibility setting and make it public (by default, AMIs are created with the \u201cPrivate\u201d visibility setting). Now you can set up the auto-scaling of Wallarm filter nodes in the Amazon cloud using the prepared image.","title":"2.  Creating an Amazon Machine Image"},{"location":"en/admin-en/installation-guides/amazon-cloud/load-balancing-guide/","text":"Creating a Load Balancer \u00b6 Now, once you have a configured filter node Auto Scaling Group, you need to create and configure a Load Balancer that distributes incoming HTTP and HTTPS connections among several filter nodes from the Auto Scaling Group. Load Balancer creation process includes the following steps: Creating a Load Balancer Setting Up an Auto Scaling Group for Using the Created Balancer 1. Creating a Load Balancer \u00b6 You can configure the following types of Load Balancers in the Amazon cloud: Classic Load Balancer Network Load Balancer Application Load Balancer #### Info:: Load Balancers differences To see detailed information about the differences between the Load Balancers, proceed to this [link][link-aws-lb-comparison]. This document demonstrates configuring and using the Network Load Balancer that distributes traffic at the transport level of the OSI/ISO network model. Create a Load Balancer by completing the following actions: Navigate to the Load Balancers tab on the Amazon EC2 dashboard and click the Create Load Balancer button. Create a Network Load Balancer by clicking the corresponding Create button. Configure the basic Load Balancer parameters: The name of the balancer (the Name parameter). The type of balancer (the \u201cScheme\u201d parameter). Select the \u201cinternet-facing\u201d type for the balancer to be available on the internet. Specify ports for the balancer to listen to using the Listeners parameter group. Specify the required VPC and Availability Zones in which the balancer should be working. #### Info:: Check the Auto Scaling Group availability Make sure you selected the VPC and Availability Zones that contain the previously created Auto Scaling Group for the load balancer to operate properly. Proceed to the next step by clicking the Next: Configure Security Settings button. Configure the security parameters if necessary. Continue to the next step by clicking the Next: Configure Routing button. Configure the routing of the incoming requests to the filter nodes in the Auto Scaling Group. Create a new target group and specify its name in the Name field. The Load Balancer will route incoming requests to the instances located in the specified target group (e.g., \u201cdemo-target\u201d). Configure the protocol and port to be used for request routing. Specify the TCP protocol and the 80 and 443 (if you have HTTPS traffic) ports for the filter node. If necessary, configure the availability checks using the Health Checks parameter group. Proceed to the next step by clicking the Next: Register Targets button. This step requires no actions. Switch to the next step by clicking the Next: Review button. Make sure that all of the parameters are specified correctly, and launch the Load Balancer creation process by clicking the Create button. #### Info:: Wait until the Load Balancer is initialized After the Load Balancer is created, some time must pass for it to be ready to receive traffic. 2. Setting Up an Auto Scaling Group for Using the Created Balancer \u00b6 Configure your Auto Scaling Group for using the Load Balancer you created earlier. This will allow the balancer to route traffic to the filter node instances that are launched in the group. To do this, complete the following actions: Navigate to the Auto Scaling Groups tab on the Amazon EC2 dashboard and select the Auto Scaling Group created earlier . Open the group configuration editing dialog by selecting \u201cEdit\u201d in the Actions dropdown menu. Select the \u201cdemo-target\u201d target group created when setting up the Load Balancer in the Target groups drop-down list. Apply the changes by clicking the Save button. Now the dynamically scaling set of the Wallarm filter nodes will process the incoming traffic to your application. To check the deployed filter nodes\u2019 operation, perform the following steps: Make sure that your application is accessible through the Load Balancer and the Wallarm filter nodes by referring to the balancer IP address or domain name using the browser. Make sure that the Wallarm services protect your application by performing a test attack .","title":"Setting Up Incoming Request Balancing"},{"location":"en/admin-en/installation-guides/amazon-cloud/load-balancing-guide/#creating-a-load-balancer","text":"Now, once you have a configured filter node Auto Scaling Group, you need to create and configure a Load Balancer that distributes incoming HTTP and HTTPS connections among several filter nodes from the Auto Scaling Group. Load Balancer creation process includes the following steps: Creating a Load Balancer Setting Up an Auto Scaling Group for Using the Created Balancer","title":"Creating a Load Balancer"},{"location":"en/admin-en/installation-guides/amazon-cloud/load-balancing-guide/#1-creating-a-load-balancer","text":"You can configure the following types of Load Balancers in the Amazon cloud: Classic Load Balancer Network Load Balancer Application Load Balancer #### Info:: Load Balancers differences To see detailed information about the differences between the Load Balancers, proceed to this [link][link-aws-lb-comparison]. This document demonstrates configuring and using the Network Load Balancer that distributes traffic at the transport level of the OSI/ISO network model. Create a Load Balancer by completing the following actions: Navigate to the Load Balancers tab on the Amazon EC2 dashboard and click the Create Load Balancer button. Create a Network Load Balancer by clicking the corresponding Create button. Configure the basic Load Balancer parameters: The name of the balancer (the Name parameter). The type of balancer (the \u201cScheme\u201d parameter). Select the \u201cinternet-facing\u201d type for the balancer to be available on the internet. Specify ports for the balancer to listen to using the Listeners parameter group. Specify the required VPC and Availability Zones in which the balancer should be working. #### Info:: Check the Auto Scaling Group availability Make sure you selected the VPC and Availability Zones that contain the previously created Auto Scaling Group for the load balancer to operate properly. Proceed to the next step by clicking the Next: Configure Security Settings button. Configure the security parameters if necessary. Continue to the next step by clicking the Next: Configure Routing button. Configure the routing of the incoming requests to the filter nodes in the Auto Scaling Group. Create a new target group and specify its name in the Name field. The Load Balancer will route incoming requests to the instances located in the specified target group (e.g., \u201cdemo-target\u201d). Configure the protocol and port to be used for request routing. Specify the TCP protocol and the 80 and 443 (if you have HTTPS traffic) ports for the filter node. If necessary, configure the availability checks using the Health Checks parameter group. Proceed to the next step by clicking the Next: Register Targets button. This step requires no actions. Switch to the next step by clicking the Next: Review button. Make sure that all of the parameters are specified correctly, and launch the Load Balancer creation process by clicking the Create button. #### Info:: Wait until the Load Balancer is initialized After the Load Balancer is created, some time must pass for it to be ready to receive traffic.","title":"1.  Creating a Load Balancer"},{"location":"en/admin-en/installation-guides/amazon-cloud/load-balancing-guide/#2-setting-up-an-auto-scaling-group-for-using-the-created-balancer","text":"Configure your Auto Scaling Group for using the Load Balancer you created earlier. This will allow the balancer to route traffic to the filter node instances that are launched in the group. To do this, complete the following actions: Navigate to the Auto Scaling Groups tab on the Amazon EC2 dashboard and select the Auto Scaling Group created earlier . Open the group configuration editing dialog by selecting \u201cEdit\u201d in the Actions dropdown menu. Select the \u201cdemo-target\u201d target group created when setting up the Load Balancer in the Target groups drop-down list. Apply the changes by clicking the Save button. Now the dynamically scaling set of the Wallarm filter nodes will process the incoming traffic to your application. To check the deployed filter nodes\u2019 operation, perform the following steps: Make sure that your application is accessible through the Load Balancer and the Wallarm filter nodes by referring to the balancer IP address or domain name using the browser. Make sure that the Wallarm services protect your application by performing a test attack .","title":"2.  Setting Up an Auto Scaling Group for Using the Created Balancer"},{"location":"en/admin-en/installation-guides/azure-cloud/autoscaling-overview/","text":"Filter Node Auto-Scaling: Overview \u00b6 You can set up Wallarm filter node auto-scaling on the Microsoft Azure platform to make sure that filter nodes are capable of handling traffic fluctuations (if there are any). Enabling auto-scaling allows the processing of incoming requests to the application using the filter nodes even when traffic soars significantly. #### Warning:: Prerequisites Setting up auto-scaling requires an image of the virtual machine with the Wallarm filter node. For detailed information about creating an image of the virtual machine with the Wallarm filter node on the Azure platform, proceed to this [link][link-create-image]. To auto-scale filter nodes on the Microsoft Azure platform, perform the following steps: Create and configure a virtual machine scale set Set up incoming requests balancing Create a load balancer Configure the load balancer","title":"Autoscaling overview"},{"location":"en/admin-en/installation-guides/azure-cloud/autoscaling-overview/#filter-node-auto-scaling-overview","text":"You can set up Wallarm filter node auto-scaling on the Microsoft Azure platform to make sure that filter nodes are capable of handling traffic fluctuations (if there are any). Enabling auto-scaling allows the processing of incoming requests to the application using the filter nodes even when traffic soars significantly. #### Warning:: Prerequisites Setting up auto-scaling requires an image of the virtual machine with the Wallarm filter node. For detailed information about creating an image of the virtual machine with the Wallarm filter node on the Azure platform, proceed to this [link][link-create-image]. To auto-scale filter nodes on the Microsoft Azure platform, perform the following steps: Create and configure a virtual machine scale set Set up incoming requests balancing Create a load balancer Configure the load balancer","title":"Filter Node Auto-Scaling: Overview"},{"location":"en/admin-en/installation-guides/azure-cloud/create-image/","text":"Creating an Image with the Wallarm Filter Node on the Microsoft Azure Platform \u00b6 To set up auto-scaling of the Wallarm filter nodes deployed on the Microsoft Azure platform, you first need virtual machine images. This document describes the procedure for preparing an image of the virtual machine with the Wallarm filter node installed. For detailed information about setting up auto-scaling, proceed to this link . To create an image with the Wallarm filter node on the Microsoft Azure platform, perform the following procedures: Creating and configuring a virtual machine with the filter node on the Microsoft Azure platform ; Creating an image on the basis of the configured virtual machine . 1. Creating and Configuring a Virtual Machine Containing the Filter Node on Microsoft Azure \u00b6 Before creating an image, you need to perform an initial configuration of a single Wallarm filter node. To configure a filter node, do the following: Create and configure a virtual machine with the filter node on the Microsoft Azure platform. #### Warning:: Provide the filter node with an internet connection The filter node requires access to a Wallarm API server for proper operation. The choice of Wallarm API server depends on the Wallarm Cloud you are using: * If you are using the EU cloud, your node needs to be granted access to https://api.wallarm.com:444 . * If you are using the US cloud, your node needs to be granted access to https://us1.api.wallarm.com:444 . #### Info:: Connecting to the virtual machine via a custom private key Make sure you have access to the private key from the key pair that is used to connect to your filter node via SSH. Connect the filter node to the Wallarm cloud. #### Warning:: Use a token to connect to the Wallarm cloud Please note that you need to connect the filter node to the Wallarm cloud using the addcloudnode script. Multiple filter nodes are allowed to connect to the Wallarm cloud using the same token. Thus, you will not need to manually connect each of the filter nodes to the Wallarm cloud when the size of the scale set increases. Configure the filter node to act as a reverse proxy for your web application. Make sure that the filter node is configured correctly and protects your web application against malicious requests. It is recommended to perform a virtual machine deprovision before creating an image so that you create a deprovisioned image of the virtual machine. Virtual machines created on the basis of such an image can be deployed in the scale set with new user accounts without any dependence on the user who created the image. Connect to the virtual machine via the SSH protocol using the private key created during filter node deployment on the Azure platform. Run the following deprovision command: # waagent -deprovision+user Enter y to confirm deprovisioning. Wait until the deprovision process is finished. #### Warning:: The deprovision process During the deprovision process, some of the files and the existing user account that was used to connect to the machine via SSH are deleted from the virtual machine. To see detailed information about the deprovision procedure, proceed to this link . Note that the filter node configuration is not affected by the deprovision procedure. After you have finished configuring the virtual machine, turn it off by completing the following actions: Navigate to the \u201c Virtual Machines \u201d page. Open the drop-down menu by clicking the menu button on the right of the \u201cSubscription\u201d column. Select \u201cStop\u201d in the drop-down menu. 2. Creating a Virtual Machine Image \u00b6 To create an image and use it successfully in the future, virtual machine deprovision is required. #### Info:: Detailed information To see detailed information about the virtual machine deprovision process, proceed to this [link][anchor-node]. You can now create a virtual machine image based on the configured filter node instance. To create an image, perform the following steps: Proceed to the \u201c Virtual Machines \u201d page and click the name, from the list, of the previously created virtual machine . Click the \u201cCapture\u201d button in the virtual machine overview window that appears. Enter the desired image name into the \u201cName\u201d field. Select the resource group that the image should be placed into from the \u201cResource group\u201d drop-down list. If necessary, you can create a new resource group by clicking the \u201cCreate\u201d button under the drop-down list. During the image creation process, the generalization of the base virtual machine is performed. After this action, the machine becomes unavailable for further use and cannot be launched. If you want to delete the base virtual machine after image capturing, select the \u201cAutomatically delete this virtual machine after creating the image\u201d checkbox. If necessary, turn on zone resiliency by clicking the \u201cOn\u201d button. This function replicates the image onto all of the availability zones of the current region. This ensures that the image is still accessible from other zones in case of an accident in one of the availability zones where the image is stored. #### Info:: Detailed information To see detailed information about availability zones on the Azure platform, proceed with this link . Click the \u201cCreate\u201d button to launch the virtual machine image creation process. Once the creation process is finished, make sure that the created image is present in the list on the \u201c Images \u201d page. You can find it by searching by name. Now you can set up the auto-scaling of Wallarm filter nodes on the Microsoft Azure platform using the prepared image.","title":"Create image"},{"location":"en/admin-en/installation-guides/azure-cloud/create-image/#creating-an-image-with-the-wallarm-filter-node-on-the-microsoft-azure-platform","text":"To set up auto-scaling of the Wallarm filter nodes deployed on the Microsoft Azure platform, you first need virtual machine images. This document describes the procedure for preparing an image of the virtual machine with the Wallarm filter node installed. For detailed information about setting up auto-scaling, proceed to this link . To create an image with the Wallarm filter node on the Microsoft Azure platform, perform the following procedures: Creating and configuring a virtual machine with the filter node on the Microsoft Azure platform ; Creating an image on the basis of the configured virtual machine .","title":"Creating an Image with the Wallarm Filter Node on the Microsoft Azure Platform"},{"location":"en/admin-en/installation-guides/azure-cloud/create-image/#1-creating-and-configuring-a-virtual-machine-containing-the-filter-node-on-microsoft-azure","text":"Before creating an image, you need to perform an initial configuration of a single Wallarm filter node. To configure a filter node, do the following: Create and configure a virtual machine with the filter node on the Microsoft Azure platform. #### Warning:: Provide the filter node with an internet connection The filter node requires access to a Wallarm API server for proper operation. The choice of Wallarm API server depends on the Wallarm Cloud you are using: * If you are using the EU cloud, your node needs to be granted access to https://api.wallarm.com:444 . * If you are using the US cloud, your node needs to be granted access to https://us1.api.wallarm.com:444 . #### Info:: Connecting to the virtual machine via a custom private key Make sure you have access to the private key from the key pair that is used to connect to your filter node via SSH. Connect the filter node to the Wallarm cloud. #### Warning:: Use a token to connect to the Wallarm cloud Please note that you need to connect the filter node to the Wallarm cloud using the addcloudnode script. Multiple filter nodes are allowed to connect to the Wallarm cloud using the same token. Thus, you will not need to manually connect each of the filter nodes to the Wallarm cloud when the size of the scale set increases. Configure the filter node to act as a reverse proxy for your web application. Make sure that the filter node is configured correctly and protects your web application against malicious requests. It is recommended to perform a virtual machine deprovision before creating an image so that you create a deprovisioned image of the virtual machine. Virtual machines created on the basis of such an image can be deployed in the scale set with new user accounts without any dependence on the user who created the image. Connect to the virtual machine via the SSH protocol using the private key created during filter node deployment on the Azure platform. Run the following deprovision command: # waagent -deprovision+user Enter y to confirm deprovisioning. Wait until the deprovision process is finished. #### Warning:: The deprovision process During the deprovision process, some of the files and the existing user account that was used to connect to the machine via SSH are deleted from the virtual machine. To see detailed information about the deprovision procedure, proceed to this link . Note that the filter node configuration is not affected by the deprovision procedure. After you have finished configuring the virtual machine, turn it off by completing the following actions: Navigate to the \u201c Virtual Machines \u201d page. Open the drop-down menu by clicking the menu button on the right of the \u201cSubscription\u201d column. Select \u201cStop\u201d in the drop-down menu.","title":"1.  Creating and Configuring a Virtual Machine Containing the Filter Node on Microsoft Azure"},{"location":"en/admin-en/installation-guides/azure-cloud/create-image/#2-creating-a-virtual-machine-image","text":"To create an image and use it successfully in the future, virtual machine deprovision is required. #### Info:: Detailed information To see detailed information about the virtual machine deprovision process, proceed to this [link][anchor-node]. You can now create a virtual machine image based on the configured filter node instance. To create an image, perform the following steps: Proceed to the \u201c Virtual Machines \u201d page and click the name, from the list, of the previously created virtual machine . Click the \u201cCapture\u201d button in the virtual machine overview window that appears. Enter the desired image name into the \u201cName\u201d field. Select the resource group that the image should be placed into from the \u201cResource group\u201d drop-down list. If necessary, you can create a new resource group by clicking the \u201cCreate\u201d button under the drop-down list. During the image creation process, the generalization of the base virtual machine is performed. After this action, the machine becomes unavailable for further use and cannot be launched. If you want to delete the base virtual machine after image capturing, select the \u201cAutomatically delete this virtual machine after creating the image\u201d checkbox. If necessary, turn on zone resiliency by clicking the \u201cOn\u201d button. This function replicates the image onto all of the availability zones of the current region. This ensures that the image is still accessible from other zones in case of an accident in one of the availability zones where the image is stored. #### Info:: Detailed information To see detailed information about availability zones on the Azure platform, proceed with this link . Click the \u201cCreate\u201d button to launch the virtual machine image creation process. Once the creation process is finished, make sure that the created image is present in the list on the \u201c Images \u201d page. You can find it by searching by name. Now you can set up the auto-scaling of Wallarm filter nodes on the Microsoft Azure platform using the prepared image.","title":"2.  Creating a Virtual Machine Image"},{"location":"en/admin-en/installation-guides/azure-cloud/create-scale-set/","text":"Creating and Configuring a Virtual Machine Scale Set \u00b6 To create and configure a virtual machine scale set for Wallarm filter node auto-scaling, proceed with the following steps: Proceed to the \u201c Virtual machine scale sets \u201d page and click the \u201cAdd\u201d button to create a virtual machine scale set. Perform general virtual machine scale set configuration by entering the required data into the \u201cBasics\u201d section of the form. Enter the name of the scale set into the \u201cVirtual machine scale set name\u201d field. Click the \u201cBrowse all images\u201d link in the \u201cOperating system disk image\u201d setting to specify the image to be used as the basis for the deployed virtual machines. In the window that appears, proceed to the \u201cMy Items\u201d tab and select the previously created image from the list. Select the Azure subscription from the \u201cSubscription\u201d drop-down list. Select the resource group that the deployed virtual machines should be placed into from the \u201cResource group\u201d drop-down list. If necessary, select the zones that the filter nodes should be deployed in from the \u201cAvailability zone\u201d drop-down list. In this document, the availability zones for the scale set are not specified for the purpose of the demonstration. #### Info:: Load balancer requirements If you specify the availability zones for the virtual machine scaling set, you need to use the \u201cStandard\u201d load balancer SKU instead of the \u201cBasic\u201d SKU. To see detailed information about creating a load balancer, proceed with this link . #### Info:: Availability zones To see detailed information about availability zones on the Azure platform, proceed to this link . Enter the desired username for access to the virtual machines into the \u201cUsername\u201d field. Select \u201cSSH public key\u201d as the desired \u201cAuthentication type\u201d to be able to connect to the virtual machines in the scale set via SSH keys. #### Info:: Authentication via password You may also enable authentication with a username and a password; however, connecting to the virtual machines via SSH keys is preferred. Generate a pair of SSH keys and paste a public key with the OpenSSH format into the \u201cSSH public key\u201d field. Save the private key to use for connecting to virtual machines in the future. #### Info:: Generating an SSH key pair To see detailed information about the SSH key pair generation process, proceed to this link . Configure virtual machine scale set auto-scaling by entering the required data in the \u201cAutoscale\u201d section. Select \u201cEnabled\u201d in the \u201cAutoscale\u201d parameter to enable virtual machine set auto-scaling. Specify the minimum size of the set in the \u201cMinimum number of VMs\u201d field (for example, two virtual machines). Specify the maximum size of the set in the \u201cMaximum number of VMs\u201d field (for example, ten virtual machines). Configure the rule for scale set size increase in the \u201cScale out\u201d section. Enter the average CPU load percentage (for example, 60 percent) into the \u201cCPU threshold (%)\u201d field. Upon reaching this CPU load, the scale set size increases. Enter the quantity of virtual machines to be added to the scale set upon reaching the \u201cCPU threshold (%)\u201d field value into the \u201cNumber of VMs to increase by\u201d field. Configure the rule for scale set size decrease in the \u201cScale in\u201d section. Enter the average CPU load percentage (for example, 30 percent) into the \u201cCPU threshold (%)\u201d field. Upon reaching this CPU load, the scale set size decreases. Enter the quantity of virtual machines to be removed from the scale set upon reaching the \u201cCPU threshold (%)\u201d field value into the \u201cNumber of VMs to decrease by\u201d field. Configure the network parameters for the scale set by entering the required data in the \u201cNetworking\u201d section. Select \u201cNone\u201d in the \u201cChoose load balancing options\u201d parameter to configure a load balancer for the scale set later . Select the necessary virtual network and subnet where the virtual machines for the scale set should be deployed. Select \u201cOff\u201d in the \u201cPublic IP address per instance\u201d parameter. Because further traffic routing is conducted by the load balancer, there is no need to assign a public IP address for each filter node instance in the set. Make sure all of the parameters of the scale set are configured correctly and click the \u201cCreate\u201d button. The specified number of virtual machines will automatically launch upon the successful creation of the scale set. You can check that the scale set was created correctly by viewing the number of launched machines in the set and comparing this data point with the number of filter nodes connected to the Wallarm cloud. You can do this using the Wallarm website. For example, if two virtual machines with filter nodes are currently launched, the Wallarm website will display the \u201c2/2 nodes are active\u201d label for the corresponding cloud node on the Nodes tab. You can now proceed to creating and configuring a load balancer .","title":"Create scale set"},{"location":"en/admin-en/installation-guides/azure-cloud/create-scale-set/#creating-and-configuring-a-virtual-machine-scale-set","text":"To create and configure a virtual machine scale set for Wallarm filter node auto-scaling, proceed with the following steps: Proceed to the \u201c Virtual machine scale sets \u201d page and click the \u201cAdd\u201d button to create a virtual machine scale set. Perform general virtual machine scale set configuration by entering the required data into the \u201cBasics\u201d section of the form. Enter the name of the scale set into the \u201cVirtual machine scale set name\u201d field. Click the \u201cBrowse all images\u201d link in the \u201cOperating system disk image\u201d setting to specify the image to be used as the basis for the deployed virtual machines. In the window that appears, proceed to the \u201cMy Items\u201d tab and select the previously created image from the list. Select the Azure subscription from the \u201cSubscription\u201d drop-down list. Select the resource group that the deployed virtual machines should be placed into from the \u201cResource group\u201d drop-down list. If necessary, select the zones that the filter nodes should be deployed in from the \u201cAvailability zone\u201d drop-down list. In this document, the availability zones for the scale set are not specified for the purpose of the demonstration. #### Info:: Load balancer requirements If you specify the availability zones for the virtual machine scaling set, you need to use the \u201cStandard\u201d load balancer SKU instead of the \u201cBasic\u201d SKU. To see detailed information about creating a load balancer, proceed with this link . #### Info:: Availability zones To see detailed information about availability zones on the Azure platform, proceed to this link . Enter the desired username for access to the virtual machines into the \u201cUsername\u201d field. Select \u201cSSH public key\u201d as the desired \u201cAuthentication type\u201d to be able to connect to the virtual machines in the scale set via SSH keys. #### Info:: Authentication via password You may also enable authentication with a username and a password; however, connecting to the virtual machines via SSH keys is preferred. Generate a pair of SSH keys and paste a public key with the OpenSSH format into the \u201cSSH public key\u201d field. Save the private key to use for connecting to virtual machines in the future. #### Info:: Generating an SSH key pair To see detailed information about the SSH key pair generation process, proceed to this link . Configure virtual machine scale set auto-scaling by entering the required data in the \u201cAutoscale\u201d section. Select \u201cEnabled\u201d in the \u201cAutoscale\u201d parameter to enable virtual machine set auto-scaling. Specify the minimum size of the set in the \u201cMinimum number of VMs\u201d field (for example, two virtual machines). Specify the maximum size of the set in the \u201cMaximum number of VMs\u201d field (for example, ten virtual machines). Configure the rule for scale set size increase in the \u201cScale out\u201d section. Enter the average CPU load percentage (for example, 60 percent) into the \u201cCPU threshold (%)\u201d field. Upon reaching this CPU load, the scale set size increases. Enter the quantity of virtual machines to be added to the scale set upon reaching the \u201cCPU threshold (%)\u201d field value into the \u201cNumber of VMs to increase by\u201d field. Configure the rule for scale set size decrease in the \u201cScale in\u201d section. Enter the average CPU load percentage (for example, 30 percent) into the \u201cCPU threshold (%)\u201d field. Upon reaching this CPU load, the scale set size decreases. Enter the quantity of virtual machines to be removed from the scale set upon reaching the \u201cCPU threshold (%)\u201d field value into the \u201cNumber of VMs to decrease by\u201d field. Configure the network parameters for the scale set by entering the required data in the \u201cNetworking\u201d section. Select \u201cNone\u201d in the \u201cChoose load balancing options\u201d parameter to configure a load balancer for the scale set later . Select the necessary virtual network and subnet where the virtual machines for the scale set should be deployed. Select \u201cOff\u201d in the \u201cPublic IP address per instance\u201d parameter. Because further traffic routing is conducted by the load balancer, there is no need to assign a public IP address for each filter node instance in the set. Make sure all of the parameters of the scale set are configured correctly and click the \u201cCreate\u201d button. The specified number of virtual machines will automatically launch upon the successful creation of the scale set. You can check that the scale set was created correctly by viewing the number of launched machines in the set and comparing this data point with the number of filter nodes connected to the Wallarm cloud. You can do this using the Wallarm website. For example, if two virtual machines with filter nodes are currently launched, the Wallarm website will display the \u201c2/2 nodes are active\u201d label for the corresponding cloud node on the Nodes tab. You can now proceed to creating and configuring a load balancer .","title":"Creating and Configuring a Virtual Machine Scale Set"},{"location":"en/admin-en/installation-guides/azure-cloud/load-balancing-guide/","text":"Setting Up Incoming Requests Balancing \u00b6 Creating a Load Balancer \u00b6 Now that you have a configured filter node scale set, you need to create and configure a load balancer, which distributes incoming traffic between several filter nodes in a scale set. To create a load balancer, perform the following actions: Go to the \u201cLoad balancers\u201d page and click the \u201cAdd\u201d button. Select a resource group to which the load balancer should be added from the \u201cResource group\u201d drop-down list. Enter the desired load balancer name into the \u201cName\u201d field. Select the \u201cPublic\u201d option in the \u201cType\u201d setting for the load balancer to receive requests from external IP addresses. Select the necessary balancer SKU in the \u201cSKU\u201d setting. \u201cBasic\u201d: provides the basic functions of a load balancer and supports up to 100 deployed virtual machines in a scale set. \u201cStandard\u201d: provides advanced functions of a load balancer and supports up to 1000 deployed virtual machines in a scale set located in various availability zones. #### Info:: Selecting a load balancer If you specified availability zones for the virtual machines to be deployed in when creating the scale set, you need to select the \u201cStandard\u201d load balancer SKU. This is necessary because the load balancer and the scale set have to be located in a single availability zone to operate correctly. Working with availability zones is only supported by the standard load balancer. In this document, the \u201cBasic\u201d SKU is used for demonstration because no availability zones are specified in the filter nodes scale set creation guide. To see detailed information about the differences between the load balancer SKUs on the Microsoft Azure platform, proceed to this link . Configure the load balancer\u2019s external IP address parameters in the \u201cPublic IP address\u201d section. Select \u201cCreate\u201d in the \u201cPublic IP address\u201d setting to create a new IP address for the load balancer. Enter the desired IP address name into the \u201cPublic IP address name\u201d field. Select the IP address type in the \u201cAssignment\u201d setting. \u201cDynamic\u201d: assign a new IP address for the load balancer when the first virtual machine is added to the scale set. When the load balancer is deleted or stopped, its IP address is released and can be used by other resources. \u201cStatic\u201d: assign the IP address for the load balancer upon its creation. This IP address is reserved for use by this load balancer and it is guaranteed not to be released if the load balancer stops. #### Info:: To see detailed information about IP address types on the Microsoft Azure platform, proceed to this link . Leave the \u201cAdd public IPv6 address\u201d setting off (the \u201cNo\u201d option selected). Press the \u201cReview + Create\u201d button. Make sure all the entered data is correct and click the \u201cCreate\u201d button. After creating a load balancer, you need to set it up to work with a scale set created earlier . Configuring the Load Balancer \u00b6 To configure the load balancer created earlier , perform the following actions: Proceed to the \u201c Load balancers \u201d page and select the necessary load balancer from the list to open its settings window. The load balancer settings menu is on the left of its description. Configure the load balancer to use the scale set created earlier by placing it into the balancer backend pool in the \u201cBackend pools\u201d section. Proceed to the \u201cBackend pools\u201d section in the load balancer settings menu and click the \u201cAdd\u201d button to create a backend pool for the load balancer to use. Enter the desired backend pool name into the \u201cName\u201d field. Select \u201cVirtual machine scale set\u201d from the \u201cAssociated to\u201d drop-down list. Select the scale set from the \u201cVirtual Machine Scale Set\u201d drop-down list to set it as a load balancer backend pool. Click the \u201cOK\u201d button. Configure scale set virtual machine availability check-up rules in the \u201cHealth Probes\u201d section. Proceed to the \u201cHealth Probes\u201d section in the load balancer settings menu and click the \u201cAdd\u201d button to create a new rule. Enter the desired name of the rule into the \u201cName\u201d field. Select the protocol that should be used to check the availability of the virtual machines from the \u201cProtocol\u201d drop-down list. In this document, the TCP protocol is used to check virtual machine availability. Enter the port to which the balancer should send the health check requests into the \u201cPort\u201d field. Enter the necessary interval in seconds for health check queries into the \u201cInterval\u201d field. Enter the number of failed health check requests required to recognize the virtual machine as an unavailable one into the \u201cUnhealthy threshold\u201d field. \u041d\u0430\u0436\u043c\u0438\u0442\u0435 \u043d\u0430 \u043a\u043d\u043e\u043f\u043a\u0443 \u00abOK\u00bb; Configure the traffic distribution rules for the load balancer in the \u201cLoad balancing rules\u201d section. Proceed to the \u201cLoad balancing rules\u201d section in the load balancer settings menu and click the \u201cAdd\u201d button to create a new rule. Enter the desired name of the rule into the \u201cName\u201d field. Select the IP address version that the rule should be applied to in the \u201cIP version\u201d setting. Select the protocol that the rule should be applied to in the \u201cProtocol\u201d setting. Enter the port to receive the requests that should be processed according to the new rule into the \u201cPort\u201d field. Enter the port to which the load balancer should redirect the incoming requests into the \u201cBackend port\u201d field. #### Info:: Port values Ports entered into the \u201cPort\u201d and \u201cBackend port\u201d fields may differ. Select the backend pool configured on the basis of the scale set from the \u201cBackend pool\u201d drop-down list. Select the virtual machine health check rule configured earlier from the \u201cHealth probe\u201d drop-down list. Specify the time period in minutes during which the connection with the client should be maintained despite the absence of new incoming requests using the \u201cIdle timeout (minutes)\u201d slider of the field next to it. In this document, a floating IP is not required, therefore the \u201cFloating IP\u201d function is off. If necessary, you can enable floating IP by selecting \u201cEnabled\u201d in the \u201cFloating IP (direct server return)\u201d setting. To see more information about this function, proceed to this link . Click the \u201cOK\u201d button. You need to upgrade virtual machines running on the scale set to apply the changes that were made. Perform the following actions: Proceed to the \u201cVirtual machine scale sets\u201d page and click the required scale set. Proceed to the \u201cInstances\u201d section of the settings. Select all of the virtual machines by selecting the checkboxes next to each of the entries in the list and clicking the \u201cUpgrade\u201d button. Confirm the virtual machines\u2019 upgrade by clicking \u201cYes.\u201d #### Info:: Public IP load balancer address assignment If you selected a dynamic IP address when creating a load balancer, it is assigned to the balancer after the virtual machine upgrade. Now the dynamically auto-scaling set of the Wallarm filter nodes will process the incoming traffic to your application. To check the deployed filter nodes\u2019 operation, perform the following steps: Make sure that your application is accessible through the load balancer and the Wallarm filter nodes by referring to the balancer IP address or domain name using your browser. Make sure that the Wallarm services protect your application by performing a test attack .","title":"Load balancing guide"},{"location":"en/admin-en/installation-guides/azure-cloud/load-balancing-guide/#setting-up-incoming-requests-balancing","text":"","title":"Setting Up Incoming Requests Balancing"},{"location":"en/admin-en/installation-guides/azure-cloud/load-balancing-guide/#creating-a-load-balancer","text":"Now that you have a configured filter node scale set, you need to create and configure a load balancer, which distributes incoming traffic between several filter nodes in a scale set. To create a load balancer, perform the following actions: Go to the \u201cLoad balancers\u201d page and click the \u201cAdd\u201d button. Select a resource group to which the load balancer should be added from the \u201cResource group\u201d drop-down list. Enter the desired load balancer name into the \u201cName\u201d field. Select the \u201cPublic\u201d option in the \u201cType\u201d setting for the load balancer to receive requests from external IP addresses. Select the necessary balancer SKU in the \u201cSKU\u201d setting. \u201cBasic\u201d: provides the basic functions of a load balancer and supports up to 100 deployed virtual machines in a scale set. \u201cStandard\u201d: provides advanced functions of a load balancer and supports up to 1000 deployed virtual machines in a scale set located in various availability zones. #### Info:: Selecting a load balancer If you specified availability zones for the virtual machines to be deployed in when creating the scale set, you need to select the \u201cStandard\u201d load balancer SKU. This is necessary because the load balancer and the scale set have to be located in a single availability zone to operate correctly. Working with availability zones is only supported by the standard load balancer. In this document, the \u201cBasic\u201d SKU is used for demonstration because no availability zones are specified in the filter nodes scale set creation guide. To see detailed information about the differences between the load balancer SKUs on the Microsoft Azure platform, proceed to this link . Configure the load balancer\u2019s external IP address parameters in the \u201cPublic IP address\u201d section. Select \u201cCreate\u201d in the \u201cPublic IP address\u201d setting to create a new IP address for the load balancer. Enter the desired IP address name into the \u201cPublic IP address name\u201d field. Select the IP address type in the \u201cAssignment\u201d setting. \u201cDynamic\u201d: assign a new IP address for the load balancer when the first virtual machine is added to the scale set. When the load balancer is deleted or stopped, its IP address is released and can be used by other resources. \u201cStatic\u201d: assign the IP address for the load balancer upon its creation. This IP address is reserved for use by this load balancer and it is guaranteed not to be released if the load balancer stops. #### Info:: To see detailed information about IP address types on the Microsoft Azure platform, proceed to this link . Leave the \u201cAdd public IPv6 address\u201d setting off (the \u201cNo\u201d option selected). Press the \u201cReview + Create\u201d button. Make sure all the entered data is correct and click the \u201cCreate\u201d button. After creating a load balancer, you need to set it up to work with a scale set created earlier .","title":"Creating a Load Balancer"},{"location":"en/admin-en/installation-guides/azure-cloud/load-balancing-guide/#configuring-the-load-balancer","text":"To configure the load balancer created earlier , perform the following actions: Proceed to the \u201c Load balancers \u201d page and select the necessary load balancer from the list to open its settings window. The load balancer settings menu is on the left of its description. Configure the load balancer to use the scale set created earlier by placing it into the balancer backend pool in the \u201cBackend pools\u201d section. Proceed to the \u201cBackend pools\u201d section in the load balancer settings menu and click the \u201cAdd\u201d button to create a backend pool for the load balancer to use. Enter the desired backend pool name into the \u201cName\u201d field. Select \u201cVirtual machine scale set\u201d from the \u201cAssociated to\u201d drop-down list. Select the scale set from the \u201cVirtual Machine Scale Set\u201d drop-down list to set it as a load balancer backend pool. Click the \u201cOK\u201d button. Configure scale set virtual machine availability check-up rules in the \u201cHealth Probes\u201d section. Proceed to the \u201cHealth Probes\u201d section in the load balancer settings menu and click the \u201cAdd\u201d button to create a new rule. Enter the desired name of the rule into the \u201cName\u201d field. Select the protocol that should be used to check the availability of the virtual machines from the \u201cProtocol\u201d drop-down list. In this document, the TCP protocol is used to check virtual machine availability. Enter the port to which the balancer should send the health check requests into the \u201cPort\u201d field. Enter the necessary interval in seconds for health check queries into the \u201cInterval\u201d field. Enter the number of failed health check requests required to recognize the virtual machine as an unavailable one into the \u201cUnhealthy threshold\u201d field. \u041d\u0430\u0436\u043c\u0438\u0442\u0435 \u043d\u0430 \u043a\u043d\u043e\u043f\u043a\u0443 \u00abOK\u00bb; Configure the traffic distribution rules for the load balancer in the \u201cLoad balancing rules\u201d section. Proceed to the \u201cLoad balancing rules\u201d section in the load balancer settings menu and click the \u201cAdd\u201d button to create a new rule. Enter the desired name of the rule into the \u201cName\u201d field. Select the IP address version that the rule should be applied to in the \u201cIP version\u201d setting. Select the protocol that the rule should be applied to in the \u201cProtocol\u201d setting. Enter the port to receive the requests that should be processed according to the new rule into the \u201cPort\u201d field. Enter the port to which the load balancer should redirect the incoming requests into the \u201cBackend port\u201d field. #### Info:: Port values Ports entered into the \u201cPort\u201d and \u201cBackend port\u201d fields may differ. Select the backend pool configured on the basis of the scale set from the \u201cBackend pool\u201d drop-down list. Select the virtual machine health check rule configured earlier from the \u201cHealth probe\u201d drop-down list. Specify the time period in minutes during which the connection with the client should be maintained despite the absence of new incoming requests using the \u201cIdle timeout (minutes)\u201d slider of the field next to it. In this document, a floating IP is not required, therefore the \u201cFloating IP\u201d function is off. If necessary, you can enable floating IP by selecting \u201cEnabled\u201d in the \u201cFloating IP (direct server return)\u201d setting. To see more information about this function, proceed to this link . Click the \u201cOK\u201d button. You need to upgrade virtual machines running on the scale set to apply the changes that were made. Perform the following actions: Proceed to the \u201cVirtual machine scale sets\u201d page and click the required scale set. Proceed to the \u201cInstances\u201d section of the settings. Select all of the virtual machines by selecting the checkboxes next to each of the entries in the list and clicking the \u201cUpgrade\u201d button. Confirm the virtual machines\u2019 upgrade by clicking \u201cYes.\u201d #### Info:: Public IP load balancer address assignment If you selected a dynamic IP address when creating a load balancer, it is assigned to the balancer after the virtual machine upgrade. Now the dynamically auto-scaling set of the Wallarm filter nodes will process the incoming traffic to your application. To check the deployed filter nodes\u2019 operation, perform the following steps: Make sure that your application is accessible through the load balancer and the Wallarm filter nodes by referring to the balancer IP address or domain name using your browser. Make sure that the Wallarm services protect your application by performing a test attack .","title":"Configuring the Load Balancer"},{"location":"en/admin-en/installation-guides/envoy/envoy-docker/","text":"Installing with Docker (Using the Envoy-Based Docker Image) \u00b6 An Envoy-based filter node can be deployed as a Docker container. This Docker container is a thick one and contains all the subsystems of the filter node. Quick Deployment Procedure \u00b6 To quickly deploy a filter node, execute the following command: # docker run -d -e DEPLOY_USER=\"deploy@example.com\" -e DEPLOY_PASSWORD=\"very_secret\" -e WALLARM_API_HOST=api.wallarm.com -e ENVOY_BACKEND=\"example.com\" -e TARANTOOL_MEMORY_GB=memvalue -p 80:80 wallarm/envoy In this command insert your specific parameters as follows: deploy@example.com \u2014login for your Wallarm account very_secret \u2014password for your Wallarm account api.wallarm.com \u2014the name of the Wallarm API server. The name to choose depends on the Wallarm cloud you are using: If you log in to the https://us1.my.wallarm.com portal with your Wallarm account, then you are using the American cloud. Set the WALLARM_API_HOST=us1.api.wallarm.com environment variable. If you log in to the https://my.wallarm.com portal with your Wallarm account, then you are using the European cloud. Either set the WALLARM_API_HOST=us1.api.wallarm.com environment variable or omit it (a node registers itself in the European cloud by default) example.com \u2014the name or IP address of the web application to protect memvalue \u2014the amount of memory allocated to Tarantool (in gigabytes) After running the command the following will happen: The filter node will automatically register itself in the Wallarm cloud. The protected web application will be available at http://<Docker host name or IP address>:80 . Common Deployment Procedure \u00b6 The common deployment procedure is described in this section. 1. Choose How to Connect a Filter Node to the Wallarm Cloud \u00b6 A filter node interacts with the Wallarm cloud and should be connected to the cloud. The cloud is located on a remote server. You have the following options to connect the node to the cloud: use automatic registration use prepared credentials use a prepared configuration file containing the node's credentials #### Warning:: Registration of a New Node Automatic registration should be used when deploying a new filter node. Automatic Registration \u00b6 Specify the login and password pair that corresponds to a Wallarm account to automatically register the filter node in the Wallarm cloud. To do so, pass both the login and password values to the node's container via the DEPLOY_USER and DEPLOY_PASSWORD environment variables accordingly (using the -e parameter of the docker run command). The filter node will try to automatically register itself in the Wallarm cloud on the first start. If a filter node with the same name as the node's container identifier is already registered in the cloud, then the registration process will fail. To avoid this, pass the DEPLOY_FORCE=true environment variable to the container. Example: # docker run -d -e DEPLOY_USER=\"deploy@example.com\" -e DEPLOY_PASSWORD=\"very_secret\" -e DEPLOY_FORCE=true -e WALLARM_API_HOST=api.wallarm.com -e ENVOY_BACKEND=\"example.com\" -e TARANTOOL_MEMORY_GB=memvalue -p 80:80 wallarm/envoy If the registration process finishes successfully, then the container's /etc/wallarm directory will be populated with the license file ( license.key ), a file with the credentials for the filter node to access the cloud ( node.yaml ), and other files required for proper node operation. On the next start of the same filter node, registration will not be required. The filter node communicates with the cloud using the following artifacts acquired during the automatic registration: The uuid and secret values (they are placed in the /etc/wallarm/node.yaml file). The Wallarm license key (it is placed in the /etc/wallarm/license.key file). To connect the already registered filter node to the cloud, pass to its container either the uuid and secret values via the environment variables and the license.key file or the node.yaml and license.key files. Use of Prepared Credentials \u00b6 Pass to the filter node's container the uuid and secret values via the corresponding NODE_UUID and NODE_SECRET environment variables and the license.key file via Docker volumes. Example: # docker run -d -e NODE_UUID=\"some_uuid\" -e NODE_SECRET=\"some_secret\" -v /configs/license.key:/etc/wallarm/license.key -e WALLARM_API_HOST=api.wallarm.com -e ENVOY_BACKEND=\"example.com\" -e TARANTOOL_MEMORY_GB=memvalue -p 80:80 wallarm/envoy Use of a Prepared Configuration File Containing Credentials \u00b6 Pass the following files to the filter node's container via Docker volumes: the node.yaml file, containing the credentials for the filter node to access the Wallarm cloud. the license.key file. Example: # docker run -d -v /configs/license.key:/etc/wallarm/license.key -v /configs/node.yaml:/etc/wallarm/node.yaml -e WALLARM_API_HOST=api.wallarm.com -e ENVOY_BACKEND=\"example.com\" -e TARANTOOL_MEMORY_GB=memvalue -p 80:80 wallarm/envoy 2. Choose How to Configure a Filter Node \u00b6 A filter node is configured via the /etc/envoy/envoy.yaml Envoy YAML configuration file. To configure the filter node, you can either run the container with the filter mode in the simplified configuration mode or use a prepared Envoy configuration file. Running Node in the Simplified Configuration Mode \u00b6 When in the simplified configuration mode, a filter node automatically creates a minimal Envoy configuration file to protect the specified web application. To run a node in the simplified configuration mode, pass the web application's name or IP address to the node's container via the ENVOY_BACKEND environment variable. According to the generated configuration file, the filter node is placed in the \u201cblocking\u201d operation mode, which will result in the blocking of all attacks targeted to the protected application. To run the filter node in the other operation modes (e.g., monitoring mode), create an appropriate Envoy configuration file and pass it to the node's Docker container (see this document for more information about fine-tuning an Envoy-based filter node). Using a Prepared Envoy Configuration File \u00b6 To use a prepared Envoy configuration file, mount the corresponding YAML file into the node's container as a /etc/envoy/envoy.yaml file. Example: # docker run -d -e DEPLOY_USER=\"deploy@example.com\" -e DEPLOY_PASSWORD=\"very_secret\" -v /configs/envoy.yaml:/etc/envoy/envoy.yaml -e WALLARM_API_HOST=api.wallarm.com -e TARANTOOL_MEMORY_GB=memvalue -p 80:80 wallarm/envoy #### Info:: Note on the Configuration Mode The majority of the commands mentioned in this document use the simplified configuration mode and the `ENVOY_BACKEND` environment variable; however, you can use a prepared Envoy configuration file in these commands as well. 3. Choose the Amount of Memory to Allocate to Tarantool \u00b6 The postanalytics module operates using the in-memory database Tarantool. The amount of allocated memory determines the quality of the work of the statistical algorithms. The recommended value is 75 percent of the total server memory. For example, if the server has 32 GB of memory, the recommended allocation size is 24 GB. When deploying a container with a filter node, specify the amount of memory to be allocated to the Tarantool (in gigabytes) by passing the TARANTOOL_MEMORY_GB environment variable into the node's container. Example: # docker run -d -e DEPLOY_USER=\"deploy@example.com\" -e DEPLOY_PASSWORD=\"very_secret\" -v /configs/envoy.yaml:/etc/envoy/envoy.yaml -e WALLARM_API_HOST=api.wallarm.com -e TARANTOOL_MEMORY_GB=16 -p 80:80 wallarm/envoy In this example, 16 gigabytes of memory are allocated to Tarantool. 4. Configure Log Rotation (If Necessary) \u00b6 The log file rotation is preconfigured and enabled by default. You can adjust the rotation settings if necessary. These settings are located in the /etc/logrotate.d directory of the filter node's container. The Installation Is Complete \u00b6 Now the deployment is complete. Check that the filter node runs and filters the traffic. See Check the filter node operation .","title":"Envoy docker"},{"location":"en/admin-en/installation-guides/envoy/envoy-docker/#installing-with-docker-using-the-envoy-based-docker-image","text":"An Envoy-based filter node can be deployed as a Docker container. This Docker container is a thick one and contains all the subsystems of the filter node.","title":"Installing with Docker (Using the Envoy-Based Docker Image)"},{"location":"en/admin-en/installation-guides/envoy/envoy-docker/#quick-deployment-procedure","text":"To quickly deploy a filter node, execute the following command: # docker run -d -e DEPLOY_USER=\"deploy@example.com\" -e DEPLOY_PASSWORD=\"very_secret\" -e WALLARM_API_HOST=api.wallarm.com -e ENVOY_BACKEND=\"example.com\" -e TARANTOOL_MEMORY_GB=memvalue -p 80:80 wallarm/envoy In this command insert your specific parameters as follows: deploy@example.com \u2014login for your Wallarm account very_secret \u2014password for your Wallarm account api.wallarm.com \u2014the name of the Wallarm API server. The name to choose depends on the Wallarm cloud you are using: If you log in to the https://us1.my.wallarm.com portal with your Wallarm account, then you are using the American cloud. Set the WALLARM_API_HOST=us1.api.wallarm.com environment variable. If you log in to the https://my.wallarm.com portal with your Wallarm account, then you are using the European cloud. Either set the WALLARM_API_HOST=us1.api.wallarm.com environment variable or omit it (a node registers itself in the European cloud by default) example.com \u2014the name or IP address of the web application to protect memvalue \u2014the amount of memory allocated to Tarantool (in gigabytes) After running the command the following will happen: The filter node will automatically register itself in the Wallarm cloud. The protected web application will be available at http://<Docker host name or IP address>:80 .","title":"Quick Deployment Procedure"},{"location":"en/admin-en/installation-guides/envoy/envoy-docker/#common-deployment-procedure","text":"The common deployment procedure is described in this section.","title":"Common Deployment Procedure"},{"location":"en/admin-en/installation-guides/envoy/envoy-docker/#1-choose-how-to-connect-a-filter-node-to-the-wallarm-cloud","text":"A filter node interacts with the Wallarm cloud and should be connected to the cloud. The cloud is located on a remote server. You have the following options to connect the node to the cloud: use automatic registration use prepared credentials use a prepared configuration file containing the node's credentials #### Warning:: Registration of a New Node Automatic registration should be used when deploying a new filter node.","title":"1.  Choose How to Connect a Filter Node to the Wallarm Cloud"},{"location":"en/admin-en/installation-guides/envoy/envoy-docker/#automatic-registration","text":"Specify the login and password pair that corresponds to a Wallarm account to automatically register the filter node in the Wallarm cloud. To do so, pass both the login and password values to the node's container via the DEPLOY_USER and DEPLOY_PASSWORD environment variables accordingly (using the -e parameter of the docker run command). The filter node will try to automatically register itself in the Wallarm cloud on the first start. If a filter node with the same name as the node's container identifier is already registered in the cloud, then the registration process will fail. To avoid this, pass the DEPLOY_FORCE=true environment variable to the container. Example: # docker run -d -e DEPLOY_USER=\"deploy@example.com\" -e DEPLOY_PASSWORD=\"very_secret\" -e DEPLOY_FORCE=true -e WALLARM_API_HOST=api.wallarm.com -e ENVOY_BACKEND=\"example.com\" -e TARANTOOL_MEMORY_GB=memvalue -p 80:80 wallarm/envoy If the registration process finishes successfully, then the container's /etc/wallarm directory will be populated with the license file ( license.key ), a file with the credentials for the filter node to access the cloud ( node.yaml ), and other files required for proper node operation. On the next start of the same filter node, registration will not be required. The filter node communicates with the cloud using the following artifacts acquired during the automatic registration: The uuid and secret values (they are placed in the /etc/wallarm/node.yaml file). The Wallarm license key (it is placed in the /etc/wallarm/license.key file). To connect the already registered filter node to the cloud, pass to its container either the uuid and secret values via the environment variables and the license.key file or the node.yaml and license.key files.","title":"Automatic Registration"},{"location":"en/admin-en/installation-guides/envoy/envoy-docker/#use-of-prepared-credentials","text":"Pass to the filter node's container the uuid and secret values via the corresponding NODE_UUID and NODE_SECRET environment variables and the license.key file via Docker volumes. Example: # docker run -d -e NODE_UUID=\"some_uuid\" -e NODE_SECRET=\"some_secret\" -v /configs/license.key:/etc/wallarm/license.key -e WALLARM_API_HOST=api.wallarm.com -e ENVOY_BACKEND=\"example.com\" -e TARANTOOL_MEMORY_GB=memvalue -p 80:80 wallarm/envoy","title":"Use of Prepared Credentials"},{"location":"en/admin-en/installation-guides/envoy/envoy-docker/#use-of-a-prepared-configuration-file-containing-credentials","text":"Pass the following files to the filter node's container via Docker volumes: the node.yaml file, containing the credentials for the filter node to access the Wallarm cloud. the license.key file. Example: # docker run -d -v /configs/license.key:/etc/wallarm/license.key -v /configs/node.yaml:/etc/wallarm/node.yaml -e WALLARM_API_HOST=api.wallarm.com -e ENVOY_BACKEND=\"example.com\" -e TARANTOOL_MEMORY_GB=memvalue -p 80:80 wallarm/envoy","title":"Use of a Prepared Configuration File Containing Credentials"},{"location":"en/admin-en/installation-guides/envoy/envoy-docker/#2-choose-how-to-configure-a-filter-node","text":"A filter node is configured via the /etc/envoy/envoy.yaml Envoy YAML configuration file. To configure the filter node, you can either run the container with the filter mode in the simplified configuration mode or use a prepared Envoy configuration file.","title":"2.  Choose How to Configure a Filter Node"},{"location":"en/admin-en/installation-guides/envoy/envoy-docker/#running-node-in-the-simplified-configuration-mode","text":"When in the simplified configuration mode, a filter node automatically creates a minimal Envoy configuration file to protect the specified web application. To run a node in the simplified configuration mode, pass the web application's name or IP address to the node's container via the ENVOY_BACKEND environment variable. According to the generated configuration file, the filter node is placed in the \u201cblocking\u201d operation mode, which will result in the blocking of all attacks targeted to the protected application. To run the filter node in the other operation modes (e.g., monitoring mode), create an appropriate Envoy configuration file and pass it to the node's Docker container (see this document for more information about fine-tuning an Envoy-based filter node).","title":"Running Node in the Simplified Configuration Mode"},{"location":"en/admin-en/installation-guides/envoy/envoy-docker/#using-a-prepared-envoy-configuration-file","text":"To use a prepared Envoy configuration file, mount the corresponding YAML file into the node's container as a /etc/envoy/envoy.yaml file. Example: # docker run -d -e DEPLOY_USER=\"deploy@example.com\" -e DEPLOY_PASSWORD=\"very_secret\" -v /configs/envoy.yaml:/etc/envoy/envoy.yaml -e WALLARM_API_HOST=api.wallarm.com -e TARANTOOL_MEMORY_GB=memvalue -p 80:80 wallarm/envoy #### Info:: Note on the Configuration Mode The majority of the commands mentioned in this document use the simplified configuration mode and the `ENVOY_BACKEND` environment variable; however, you can use a prepared Envoy configuration file in these commands as well.","title":"Using a Prepared Envoy Configuration File"},{"location":"en/admin-en/installation-guides/envoy/envoy-docker/#3-choose-the-amount-of-memory-to-allocate-to-tarantool","text":"The postanalytics module operates using the in-memory database Tarantool. The amount of allocated memory determines the quality of the work of the statistical algorithms. The recommended value is 75 percent of the total server memory. For example, if the server has 32 GB of memory, the recommended allocation size is 24 GB. When deploying a container with a filter node, specify the amount of memory to be allocated to the Tarantool (in gigabytes) by passing the TARANTOOL_MEMORY_GB environment variable into the node's container. Example: # docker run -d -e DEPLOY_USER=\"deploy@example.com\" -e DEPLOY_PASSWORD=\"very_secret\" -v /configs/envoy.yaml:/etc/envoy/envoy.yaml -e WALLARM_API_HOST=api.wallarm.com -e TARANTOOL_MEMORY_GB=16 -p 80:80 wallarm/envoy In this example, 16 gigabytes of memory are allocated to Tarantool.","title":"3.  Choose the Amount of Memory to Allocate to Tarantool"},{"location":"en/admin-en/installation-guides/envoy/envoy-docker/#4-configure-log-rotation-if-necessary","text":"The log file rotation is preconfigured and enabled by default. You can adjust the rotation settings if necessary. These settings are located in the /etc/logrotate.d directory of the filter node's container.","title":"4.  Configure Log Rotation (If Necessary)"},{"location":"en/admin-en/installation-guides/envoy/envoy-docker/#the-installation-is-complete","text":"Now the deployment is complete. Check that the filter node runs and filters the traffic. See Check the filter node operation .","title":"The Installation Is Complete"},{"location":"en/admin-en/installation-guides/google-cloud/autoscaling-overview/","text":"Setting Up Filter Node Auto-Scaling on the Google Cloud Platform: Overview \u00b6 You can set up Wallarm filter node auto-scaling on the Google Cloud Platform (GCP) to make sure that filter nodes are capable of handling traffic fluctuations (if there are any). Enabling auto-scaling allows the processing of incoming requests to the application using the filter nodes even when traffic soars significantly. #### Warning:: Prerequisites Setting up auto-scaling requires the image of the virtual machine with the Wallarm filter node. For detailed information about creating an image of the virtual machine with the Wallarm filter node on GCP, proceed to this [link][link-doc-image-creation]. Connecting to the instance via a custom private key If during base instance creation process you have enabled connection to the instance via a custom SSH key pair, make sure you have access to the private key from this key pair. To auto-scale filter nodes on the Google Cloud Platform, perform the following steps: Set up filter node auto-scaling: Create a filter node instance template ; Create a managed instance group with auto-scaling enabled ; Set up incoming requests balancing . #### Info:: Required rights Before setting up auto-scaling, make sure that your GCP account has the `Compute Admin` role.","title":"Overview"},{"location":"en/admin-en/installation-guides/google-cloud/autoscaling-overview/#setting-up-filter-node-auto-scaling-on-the-google-cloud-platform-overview","text":"You can set up Wallarm filter node auto-scaling on the Google Cloud Platform (GCP) to make sure that filter nodes are capable of handling traffic fluctuations (if there are any). Enabling auto-scaling allows the processing of incoming requests to the application using the filter nodes even when traffic soars significantly. #### Warning:: Prerequisites Setting up auto-scaling requires the image of the virtual machine with the Wallarm filter node. For detailed information about creating an image of the virtual machine with the Wallarm filter node on GCP, proceed to this [link][link-doc-image-creation]. Connecting to the instance via a custom private key If during base instance creation process you have enabled connection to the instance via a custom SSH key pair, make sure you have access to the private key from this key pair. To auto-scale filter nodes on the Google Cloud Platform, perform the following steps: Set up filter node auto-scaling: Create a filter node instance template ; Create a managed instance group with auto-scaling enabled ; Set up incoming requests balancing . #### Info:: Required rights Before setting up auto-scaling, make sure that your GCP account has the `Compute Admin` role.","title":"Setting Up Filter Node Auto-Scaling on the Google Cloud Platform: Overview"},{"location":"en/admin-en/installation-guides/google-cloud/create-image/","text":"Creating an Image with the Wallarm Filter Node on the Google Cloud Platform \u00b6 To set up auto-scaling of the Wallarm filter nodes deployed on the Google Cloud Platform (GCP) you first need virtual machine images. This document describes the procedure for preparing an image of the virtual machine with the Wallarm filter node installed. For detailed information about setting up auto-scaling, proceed to this link . To create an image with the Wallarm filter node on GCP, perform the following procedures: Creating and configuring the filter node instance on the Google Cloud Platform . Creating a virtual machine image on the basis of the configured filter node instance . 1. Creating and Configuring the Filter Node Instance on the Google Cloud Platform \u00b6 Before creating an image, you need to perform an initial configuration of a single Wallarm filter node. To configure a filter node, do the following: Create and configure a filter node instance on GCP. > #### Warning:: Provide the filter node with an internet connection > The filter node requires access to a Wallarm API server for proper operation. The choice of Wallarm API server depends on the Wallarm Cloud you are using: > * If you are using the EU cloud, your node needs to be granted access to https://api.wallarm.com:444 . > * If you are using the US cloud, your node needs to be granted access to https://us1.api.wallarm.com:444 . Connecting to the instance via a custom private key If during base instance creation process you have enabled connection to the instance via a custom SSH key pair, make sure you have access to the private key from this key pair. Connect the filter node to the Wallarm cloud. #### Warning:: Use a token to connect to the Wallarm cloud Please note that you need to connect the filter node to the Wallarm cloud using a token. Multiple filter nodes are allowed to connect to the Wallarm cloud using the same token. Thus, you will not need to manually connect each of the filter nodes to the Wallarm cloud when they auto-scale. Configure the filter node to act as a reverse proxy for your web application. Make sure that the filter node is configured correctly and protects your web application against malicious requests. After you have finished configuring the filter node, turn the virtual machine off by completing the following actions: Navigate to the VM Instances page in the Compute Engine section of the menu. Open the drop-down menu by clicking the menu button on the right of the Connect column. Select \u201cStop\u201d in the drop-down menu. #### Info:: Turning off using the `poweroff` command You may also turn the virtual machine off by connecting to it via the SSH protocol and running the following command: term # poweroff 2. Creating a Virtual Machine Image \u00b6 You can now create a virtual machine image based on the configured filter node instance. To create an image, perform the following steps: Navigate to the Images page in the Compute Engine section of the menu and click the Create image button. Enter the image name into the Name field. Select \u201cDisk\u201d from the Source drop-down list. Select the name of the previously created virtual machine instance from the Source disk drop-down list. Click the Create button to launch the virtual machine image creation process. Once the image creation process is finished, you will be directed to a page that contains the list of available images. Make sure that the image was successfully created and is present in the list. Now you can set up the auto-scaling of Wallarm filter nodes on the Google Cloud Platform using the prepared image.","title":"Creating an Image with the Wallarm Filter Node"},{"location":"en/admin-en/installation-guides/google-cloud/create-image/#creating-an-image-with-the-wallarm-filter-node-on-the-google-cloud-platform","text":"To set up auto-scaling of the Wallarm filter nodes deployed on the Google Cloud Platform (GCP) you first need virtual machine images. This document describes the procedure for preparing an image of the virtual machine with the Wallarm filter node installed. For detailed information about setting up auto-scaling, proceed to this link . To create an image with the Wallarm filter node on GCP, perform the following procedures: Creating and configuring the filter node instance on the Google Cloud Platform . Creating a virtual machine image on the basis of the configured filter node instance .","title":"Creating an Image with the Wallarm Filter Node on the Google Cloud Platform"},{"location":"en/admin-en/installation-guides/google-cloud/create-image/#1-creating-and-configuring-the-filter-node-instance-on-the-google-cloud-platform","text":"Before creating an image, you need to perform an initial configuration of a single Wallarm filter node. To configure a filter node, do the following: Create and configure a filter node instance on GCP. > #### Warning:: Provide the filter node with an internet connection > The filter node requires access to a Wallarm API server for proper operation. The choice of Wallarm API server depends on the Wallarm Cloud you are using: > * If you are using the EU cloud, your node needs to be granted access to https://api.wallarm.com:444 . > * If you are using the US cloud, your node needs to be granted access to https://us1.api.wallarm.com:444 . Connecting to the instance via a custom private key If during base instance creation process you have enabled connection to the instance via a custom SSH key pair, make sure you have access to the private key from this key pair. Connect the filter node to the Wallarm cloud. #### Warning:: Use a token to connect to the Wallarm cloud Please note that you need to connect the filter node to the Wallarm cloud using a token. Multiple filter nodes are allowed to connect to the Wallarm cloud using the same token. Thus, you will not need to manually connect each of the filter nodes to the Wallarm cloud when they auto-scale. Configure the filter node to act as a reverse proxy for your web application. Make sure that the filter node is configured correctly and protects your web application against malicious requests. After you have finished configuring the filter node, turn the virtual machine off by completing the following actions: Navigate to the VM Instances page in the Compute Engine section of the menu. Open the drop-down menu by clicking the menu button on the right of the Connect column. Select \u201cStop\u201d in the drop-down menu. #### Info:: Turning off using the `poweroff` command You may also turn the virtual machine off by connecting to it via the SSH protocol and running the following command: term # poweroff","title":"1.  Creating and Configuring the Filter Node Instance on the Google Cloud Platform"},{"location":"en/admin-en/installation-guides/google-cloud/create-image/#2-creating-a-virtual-machine-image","text":"You can now create a virtual machine image based on the configured filter node instance. To create an image, perform the following steps: Navigate to the Images page in the Compute Engine section of the menu and click the Create image button. Enter the image name into the Name field. Select \u201cDisk\u201d from the Source drop-down list. Select the name of the previously created virtual machine instance from the Source disk drop-down list. Click the Create button to launch the virtual machine image creation process. Once the image creation process is finished, you will be directed to a page that contains the list of available images. Make sure that the image was successfully created and is present in the list. Now you can set up the auto-scaling of Wallarm filter nodes on the Google Cloud Platform using the prepared image.","title":"2.  Creating a Virtual Machine Image"},{"location":"en/admin-en/installation-guides/google-cloud/creating-autoscaling-group/","text":"Creating a Managed Instance Group with Enabled Auto-Scaling \u00b6 To create a managed instance group and configure its auto-scaling, perform the following steps: Navigate to the \u201cInstance groups\u201d page in the \u201cCompute Engine\u201d section of the menu and click the \u201cCreate instance group\u201d button. Enter the instance group name into the \u201cName\u201d field. Select \u201cManaged instance group\u201d in the \u201cGroup type\u201d setting. Enable auto-scaling for the instance group by selecting the \u201cOn\u201d option from the \u201cAutoscaling\u201d drop-down list. Select the required scaling policy from the \u201cAutoscaling policy\u201d drop-down list. Scaling policies contain rules for increasing and decreasing the size of the instance group. The system determines when it should add or remove an instance from the group to keep the metric on which the policy is based at the target level defined by the user. You can select one of the following policies: CPU Usage: The size of the group is controlled to keep the average processor load of the virtual machines in the group at the required level ( CPU usage policy documentation ). HTTP Load Balancing Usage: The size of the group is controlled to keep the load of the HTTP traffic balancer at the required level ( HTTP load balancing usage policy documentation ). Stackdriver Monitoring Metric: The size of the group is controlled to keep the selected metric from the Stackdriver Monitoring instrument at the required level ( Stackdriver Monitoring Metric policy documentation ). Multiple Metrics: The decision to change the size of the group is made on the basis of multiple metrics ( multiple metrics policy documentation ). This guide uses the \u201cCPU usage\u201d policy to demonstrate the principles of working with the auto-scaling mechanism. To apply this policy, specify the required average processors' load level in the \u201cTarget CPU usage\u201d field (in percentages). !!! info \"Example The following configuration describes the control of the instance group size to keep the average virtual machine processors' load at the 60 percent level. Specify the minimum instance group size in the \u201cMinimum number of instances\u201d field (e.g., two instances). Specify the maximum instance group size in the \u201cMaximum number of instances\u201d field (e.g., 10 instances). Specify the period of time during which the metric values should not be recorded from the newly added instance in the \u201cCool down period\u201d field (e.g., 60 seconds). This may be necessary if you see resource consumption leaps after adding a new instance. !!! info \"Cooldown period requirements The cooldown period must be longer than the time required for instance initialization. Make sure all of the parameters of the instance group are configured correctly and then click the \u201cCreate\u201d button. The specified number of instances will automatically launch upon the successful creation of the auto-scaling group. You can check that the auto-scaling group was created correctly by viewing the number of launched instances in the group and comparing this data point with the number of filter nodes connected to the Wallarm cloud. You can do this using the Wallarm website. For example, if two instances with filter nodes are concurrently operating, the Wallarm website will display the \u201c2/2 nodes are active\u201d label for the corresponding cloud node on the Nodes tab. You can now proceed with the creation and configuration of a load balancer .","title":"Creating a Managed Instance Group with Enabled Auto-Scaling"},{"location":"en/admin-en/installation-guides/google-cloud/creating-autoscaling-group/#creating-a-managed-instance-group-with-enabled-auto-scaling","text":"To create a managed instance group and configure its auto-scaling, perform the following steps: Navigate to the \u201cInstance groups\u201d page in the \u201cCompute Engine\u201d section of the menu and click the \u201cCreate instance group\u201d button. Enter the instance group name into the \u201cName\u201d field. Select \u201cManaged instance group\u201d in the \u201cGroup type\u201d setting. Enable auto-scaling for the instance group by selecting the \u201cOn\u201d option from the \u201cAutoscaling\u201d drop-down list. Select the required scaling policy from the \u201cAutoscaling policy\u201d drop-down list. Scaling policies contain rules for increasing and decreasing the size of the instance group. The system determines when it should add or remove an instance from the group to keep the metric on which the policy is based at the target level defined by the user. You can select one of the following policies: CPU Usage: The size of the group is controlled to keep the average processor load of the virtual machines in the group at the required level ( CPU usage policy documentation ). HTTP Load Balancing Usage: The size of the group is controlled to keep the load of the HTTP traffic balancer at the required level ( HTTP load balancing usage policy documentation ). Stackdriver Monitoring Metric: The size of the group is controlled to keep the selected metric from the Stackdriver Monitoring instrument at the required level ( Stackdriver Monitoring Metric policy documentation ). Multiple Metrics: The decision to change the size of the group is made on the basis of multiple metrics ( multiple metrics policy documentation ). This guide uses the \u201cCPU usage\u201d policy to demonstrate the principles of working with the auto-scaling mechanism. To apply this policy, specify the required average processors' load level in the \u201cTarget CPU usage\u201d field (in percentages). !!! info \"Example The following configuration describes the control of the instance group size to keep the average virtual machine processors' load at the 60 percent level. Specify the minimum instance group size in the \u201cMinimum number of instances\u201d field (e.g., two instances). Specify the maximum instance group size in the \u201cMaximum number of instances\u201d field (e.g., 10 instances). Specify the period of time during which the metric values should not be recorded from the newly added instance in the \u201cCool down period\u201d field (e.g., 60 seconds). This may be necessary if you see resource consumption leaps after adding a new instance. !!! info \"Cooldown period requirements The cooldown period must be longer than the time required for instance initialization. Make sure all of the parameters of the instance group are configured correctly and then click the \u201cCreate\u201d button. The specified number of instances will automatically launch upon the successful creation of the auto-scaling group. You can check that the auto-scaling group was created correctly by viewing the number of launched instances in the group and comparing this data point with the number of filter nodes connected to the Wallarm cloud. You can do this using the Wallarm website. For example, if two instances with filter nodes are concurrently operating, the Wallarm website will display the \u201c2/2 nodes are active\u201d label for the corresponding cloud node on the Nodes tab. You can now proceed with the creation and configuration of a load balancer .","title":"Creating a Managed Instance Group with Enabled Auto-Scaling"},{"location":"en/admin-en/installation-guides/google-cloud/creating-instance-template/","text":"Creating a Filter Node Instance Template \u00b6 A filter node instance template will be used later as the base when creating a managed instance group. To create a filter node instance template, perform the following: Navigate to the \u201cInstance templates\u201d page in the \u201cCompute Engine\u201d section of the menu and click the \u201cCreate instance template\u201d button. Enter the template name into the \u201cName\u201d field. Select the virtual machine type to be used to launch a virtual machine with the filter node on from the \u201cMachine type\u201d field. #### Warning:: Select the proper instance type Select the same instance type that you used when you initially configured the filter node (or a more powerful one). Using a less powerful instance type may lead to issues in filter node operation. Click the \u201cChange\u201d button in the \u201cBoot disk\u201d setting. In the window that appears, navigate to the \u201cCustom images\u201d tab and select the name of the project where you created your virtual machine image from the \u201cShow images from\u201d drop-down list. Select the previously created image from the list of available images of the project and click the \u201cSelect\u201d button. For the instances based on the template to be identical to the basic instance, configure all of the remaining parameters in the same way as you configured the parameters when creating your base instance . #### Info:: Configuring the firewall Make sure that the firewall does not block HTTP traffic to the created template. To enable HTTP traffic, select the \u201cAllow HTTP traffic\u201d checkbox. Connecting to the instance via a custom private key If during base instance creation process you have enabled connection to the instance via a custom SSH key pair, make sure you have access to the private key from this key pair. Click the \u201cCreate\u201d button and wait until the template creation process is finished. After creating the instance template, you can proceed with the creation of a managed instance group with enabled auto-scaling.","title":"Creating a Filter Node Instance Template"},{"location":"en/admin-en/installation-guides/google-cloud/creating-instance-template/#creating-a-filter-node-instance-template","text":"A filter node instance template will be used later as the base when creating a managed instance group. To create a filter node instance template, perform the following: Navigate to the \u201cInstance templates\u201d page in the \u201cCompute Engine\u201d section of the menu and click the \u201cCreate instance template\u201d button. Enter the template name into the \u201cName\u201d field. Select the virtual machine type to be used to launch a virtual machine with the filter node on from the \u201cMachine type\u201d field. #### Warning:: Select the proper instance type Select the same instance type that you used when you initially configured the filter node (or a more powerful one). Using a less powerful instance type may lead to issues in filter node operation. Click the \u201cChange\u201d button in the \u201cBoot disk\u201d setting. In the window that appears, navigate to the \u201cCustom images\u201d tab and select the name of the project where you created your virtual machine image from the \u201cShow images from\u201d drop-down list. Select the previously created image from the list of available images of the project and click the \u201cSelect\u201d button. For the instances based on the template to be identical to the basic instance, configure all of the remaining parameters in the same way as you configured the parameters when creating your base instance . #### Info:: Configuring the firewall Make sure that the firewall does not block HTTP traffic to the created template. To enable HTTP traffic, select the \u201cAllow HTTP traffic\u201d checkbox. Connecting to the instance via a custom private key If during base instance creation process you have enabled connection to the instance via a custom SSH key pair, make sure you have access to the private key from this key pair. Click the \u201cCreate\u201d button and wait until the template creation process is finished. After creating the instance template, you can proceed with the creation of a managed instance group with enabled auto-scaling.","title":"Creating a Filter Node Instance Template"},{"location":"en/admin-en/installation-guides/google-cloud/load-balancing-guide/","text":"Setting up Incoming Request Balancing \u00b6 Now that you have a configured managed instance group with enabled auto-scaling, you need to create and configure a Load Balancer that distributes incoming HTTP and HTTPS connections between several filter nodes from the instance group. You can configure the following types of Load Balancers on the Google Cloud Platform: HTTP(S) Load Balancer, TCP Load Balancer, UDP Load Balancer. #### Info:: The differences between Load Balancers For detailed information about the differences between Load Balancers, proceed to this [link][link-lb-comparison]. This document demonstrates how to configure and use the TCP Load Balancer that distributes traffic at the transport level of the OSI/ISO network model. Create a TCP Load Balancer for your instance group by completing the following actions: Navigate to the \u201cLoad balancing\u201d page in the \u201cNetwork services\u201d section of the menu and click the \u201cCreate load balancer\u201d button. Click the \u201cStart configuration\u201d button on the \u201cTCP load balancing\u201d card. Select the required options in the following settings: Select the \u201cFrom Internet to my VMs\u201d option in the \u201cInternet facing or internal only\u201d setting so that the load balancer will control incoming requests from clients to your server. Select the \u201cSingle region only\u201d option in the \u201cMultiple regions or single region\u201d setting. #### Info:: Traffic balancing for resources located in different regions This guide describes the configuration of the load balancer for one instance group located in a single region. In the case of balancing traffic for several resources located in multiple regions, select the \u201cMultiple regions (or not sure yet)\u201d option. Click the \u201cContinue\u201d button. Enter the load balancer name into the \u201cName\u201d field. Click the \u201cBackend configuration\u201d to use the created instance group as the backend to which the load balancer will route the incoming requests. Fill in the form with the following data: Select the region where the instance group is located from the \u201cRegion\u201d drop-down list. Navigate to the \u201cSelect existing instance groups\u201d tab in the \u201cBackends\u201d setting and select the name of the instance group from the \u201cAdd an instance group\u201d drop-down list. If necessary, specify the backup pool by selecting the \u201cCreate a backup pool\u201d option from the \u201cBackup Pool\u201d drop-down list. #### Info:: Using a backup pool A backup pool processes the requests if the instance group selected in the previous setting is unavailable. For detailed information about configuring a backup pool, proceed to this link . This document does not describe the backup pool configuration. If necessary, configure the group instances availability checkup by selecting the \u201cCreate a health check\u201d option in the \u201cHealth check\u201d drop-down list. For detailed information about the machine availability checkup, proceed to this link . The availability checkup The availability checkup is not configured in the scope of this document. Thus, here the \u201cNo health check\u201d option is selected in the \u201cHealth check\u201d drop-down list. If necessary, configure the method of choosing an instance for request processing by selecting the corresponding option in the \u201cSession affinity\u201d drop-down list. Detailed information about selecting an instance for request processing is available at this link . Configuring a method of choosing an instance The method of choosing an instance for request processing is not in the scope of this document. Thus, here the \u201cNone\u201d option is selected in the \u201cSession affinity\u201d drop-down list. Click the \u201cFrontend configuration\u201d button to specify the IP addresses and ports to which clients will send their requests. Fill in the form for new IP addresses and ports creation with the required data: If necessary, enter the new IP address and port pair's name into the \u201cName\u201d field. Select the required network service tier in the \u201cNetwork Service Tier\u201d setting. For detailed information about network service tiers, proceed to this link ; Select the IP address where the load balancer will receive requests from the \u201cIP\u201d drop-down list. Select the \u201cEphemeral\u201d option if you want the load balancer to obtain a new IP address upon each virtual machine startup. Select the \u201cCreate IP address\u201d option to generate a static IP address for your load balancer. In the form that appears, enter the name of the new IP address into the \u201cName\u201d field and click the \u201cReserve\u201d button. Enter the port where the load balancer will receive requests in the \u201cPort\u201d field. #### Info:: Choosing the port In this document, port 80 is specified for receiving requests via the HTTP protocol. Click the \u201cDone\u201d button to create the configured IP address and port pair. #### Info:: Required frontend ports In this document, the balancer is configured for receiving requests via the HTTP protocol. If your instance group receives requests via the HTTPS protocol, create another IP address and port pair that specifies port 443 . Click the \u201cCreate\u201d button to create the configured load balancer. Wait until the load balancer creation process is finished and the load balancer connects to the instance group that you created earlier. Because the created TCP balancer uses the Backend service (which works together with the backend created for your instance group), the instance group requires no configuration modifications for the balancer to connect to it. Now the dynamically scaling set of the Wallarm filter nodes will process the incoming traffic to your application. To check the deployed filter nodes\u2019 operation, perform the following steps: Make sure that your application is accessible through the load balancer and the Wallarm filter nodes by referring to the balancer IP address or domain name using your browser. Make sure that the Wallarm services protect your application by performing a test attack .","title":"Setting up Incoming Request Balancing"},{"location":"en/admin-en/installation-guides/google-cloud/load-balancing-guide/#setting-up-incoming-request-balancing","text":"Now that you have a configured managed instance group with enabled auto-scaling, you need to create and configure a Load Balancer that distributes incoming HTTP and HTTPS connections between several filter nodes from the instance group. You can configure the following types of Load Balancers on the Google Cloud Platform: HTTP(S) Load Balancer, TCP Load Balancer, UDP Load Balancer. #### Info:: The differences between Load Balancers For detailed information about the differences between Load Balancers, proceed to this [link][link-lb-comparison]. This document demonstrates how to configure and use the TCP Load Balancer that distributes traffic at the transport level of the OSI/ISO network model. Create a TCP Load Balancer for your instance group by completing the following actions: Navigate to the \u201cLoad balancing\u201d page in the \u201cNetwork services\u201d section of the menu and click the \u201cCreate load balancer\u201d button. Click the \u201cStart configuration\u201d button on the \u201cTCP load balancing\u201d card. Select the required options in the following settings: Select the \u201cFrom Internet to my VMs\u201d option in the \u201cInternet facing or internal only\u201d setting so that the load balancer will control incoming requests from clients to your server. Select the \u201cSingle region only\u201d option in the \u201cMultiple regions or single region\u201d setting. #### Info:: Traffic balancing for resources located in different regions This guide describes the configuration of the load balancer for one instance group located in a single region. In the case of balancing traffic for several resources located in multiple regions, select the \u201cMultiple regions (or not sure yet)\u201d option. Click the \u201cContinue\u201d button. Enter the load balancer name into the \u201cName\u201d field. Click the \u201cBackend configuration\u201d to use the created instance group as the backend to which the load balancer will route the incoming requests. Fill in the form with the following data: Select the region where the instance group is located from the \u201cRegion\u201d drop-down list. Navigate to the \u201cSelect existing instance groups\u201d tab in the \u201cBackends\u201d setting and select the name of the instance group from the \u201cAdd an instance group\u201d drop-down list. If necessary, specify the backup pool by selecting the \u201cCreate a backup pool\u201d option from the \u201cBackup Pool\u201d drop-down list. #### Info:: Using a backup pool A backup pool processes the requests if the instance group selected in the previous setting is unavailable. For detailed information about configuring a backup pool, proceed to this link . This document does not describe the backup pool configuration. If necessary, configure the group instances availability checkup by selecting the \u201cCreate a health check\u201d option in the \u201cHealth check\u201d drop-down list. For detailed information about the machine availability checkup, proceed to this link . The availability checkup The availability checkup is not configured in the scope of this document. Thus, here the \u201cNo health check\u201d option is selected in the \u201cHealth check\u201d drop-down list. If necessary, configure the method of choosing an instance for request processing by selecting the corresponding option in the \u201cSession affinity\u201d drop-down list. Detailed information about selecting an instance for request processing is available at this link . Configuring a method of choosing an instance The method of choosing an instance for request processing is not in the scope of this document. Thus, here the \u201cNone\u201d option is selected in the \u201cSession affinity\u201d drop-down list. Click the \u201cFrontend configuration\u201d button to specify the IP addresses and ports to which clients will send their requests. Fill in the form for new IP addresses and ports creation with the required data: If necessary, enter the new IP address and port pair's name into the \u201cName\u201d field. Select the required network service tier in the \u201cNetwork Service Tier\u201d setting. For detailed information about network service tiers, proceed to this link ; Select the IP address where the load balancer will receive requests from the \u201cIP\u201d drop-down list. Select the \u201cEphemeral\u201d option if you want the load balancer to obtain a new IP address upon each virtual machine startup. Select the \u201cCreate IP address\u201d option to generate a static IP address for your load balancer. In the form that appears, enter the name of the new IP address into the \u201cName\u201d field and click the \u201cReserve\u201d button. Enter the port where the load balancer will receive requests in the \u201cPort\u201d field. #### Info:: Choosing the port In this document, port 80 is specified for receiving requests via the HTTP protocol. Click the \u201cDone\u201d button to create the configured IP address and port pair. #### Info:: Required frontend ports In this document, the balancer is configured for receiving requests via the HTTP protocol. If your instance group receives requests via the HTTPS protocol, create another IP address and port pair that specifies port 443 . Click the \u201cCreate\u201d button to create the configured load balancer. Wait until the load balancer creation process is finished and the load balancer connects to the instance group that you created earlier. Because the created TCP balancer uses the Backend service (which works together with the backend created for your instance group), the instance group requires no configuration modifications for the balancer to connect to it. Now the dynamically scaling set of the Wallarm filter nodes will process the incoming traffic to your application. To check the deployed filter nodes\u2019 operation, perform the following steps: Make sure that your application is accessible through the load balancer and the Wallarm filter nodes by referring to the balancer IP address or domain name using your browser. Make sure that the Wallarm services protect your application by performing a test attack .","title":"Setting up Incoming Request Balancing"},{"location":"en/admin-en/installation-guides/ingress-plus/assembly/","text":"Building Wallarm NGINX Plus Ingress Controller from the Source Files \u00b6 #### Info:: Check if you have an NGINX Plus license before you start. You can obtain a 30-day trial license by navigating to the [NGINX site][link-nginx-website]. The license consists of two files: * The `nginx-repo.key` key file, * The `nginx-repo.crt` certificate file. To build the Wallarm NGINX Plus Ingress controller from the source files, do the following: Set up a build environment Build the Ingress controller #### Info:: It is suggested that you build the software on the Linux operating system. Setting up a Build Environment \u00b6 Make sure that the following tools are installed on your machine: Docker ( official documentation ), Git ( official documentation ), GNU Make ( official documentation ). It is also required that you have a private Docker repository. Services that provide you with the means to access and manage Docker repositories are known as Docker registries. You should create a Docker repository if you do not have one. You can use your own Docker registry or use any service that will provide you with a hosted private Docker repository (e.g., Docker Hub , Google Container Registry , Microsoft Azure Container Registry ). #### Warning:: It is strongly recommended that you do not host a Docker image of the Wallarm NGINX Plus Ingress controller in the public Docker repository due to the risk of exposing the NGINX Plus license files to the public. #### Info:: It is sufficient to obtain access to the Docker Hub registry in order to complete this guide. The registry will provide you with one free-of-charge private Docker repository. You should gather the following information to continue: The login and password pair that you use to access the Docker registry The name of the Docker registry A path to the repository #### Info:: Docker registry name Depending on the service provider chosen, the name of the Docker registry and the path to the repository can be different. Please consult with your service provider\u2019s documentation for more information. There are some well-known names for the Docker registries: * docker.io for Docker Hub, * gcr.io for Google Container Registry, * <your repository name>.azurecr.io for Microsoft Azure Container Registry. The Docker\u2019s registry name is a part of the path to the repository. For example, if you are using Docker Hub, the path to access the repository example-repository created by user john will be as follows: `docker.io/john/example-repository` Building the Ingress Controller \u00b6 Log in to your Docker registry by executing the following command: # docker login <name of the Docker registry> You should provide the login and password that you use to access the Docker registry when prompted. #### Info:: Example: To log in to the Docker Hub registry execute the following command: # docker login docker.io #### Warning:: Depending on your system settings, you could be required to elevate privileges either by issuing the sudo command or running the command as the root user in order to execute the docker command. You have the option to allow executing the docker command by the currently logged-in user. To do so, you have to add the user to the docker group. However, you must remember that having membership in this group is equal to having the root user\u2019s privileges. This may potentially lead to severe security-related issues. You can obtain more detailed information here . #### Info:: Your service provider may provide additional tools to manage Docker registries. For example, Microsoft ships an az acr tool to manage the Microsoft Azure Container Registry, whereas Google provides you with a gcloud tool to manage the Google Container Registry. You can use these tools instead of the docker login command to log in to the specific registries. Please consult your service provider\u2019s documentation for more information. Clone the Wallarm NGINX Ingress Plus repository by executing the following command: $ git clone https://github.com/wallarm/ingress-plus/ Change your working directory to the ingress-plus/ by executing the following command: $ cd ingress-plus/ Copy the NGINX Plus key and certificate files in the working directory. If you do not have the files, you have to obtain an NGINX Plus license. An scp utility or similar tool could be used to perform the copy operation. Make sure that you have copied all necessary files by executing the following command: $ ls nginx-repo.* You should be provided with the following output: nginx-repo.crt nginx-repo.key Initiate the building process by executing the following commands one by one: $ make clean $ make DOCKERFILE=DockerfileForPlus PREFIX=<the path to your Docker repository> Note that you should provide the path to your Docker repository as the value of the PREFIX argument in the make command. A Docker image will be pushed to that repository when the build process is complete. #### Info:: Example To publish the image to the private repository example-repository , created by user john and hosted on Docker Hub, provide the following PREFIX argument to the make command: $ make DOCKERFILE=DockerfileForPlus PREFIX=docker.io/john/example-repository You can obtain more detailed information about the values of paths to Docker repositories here . You can start deployment of the Ingress controller once the build process finishes.","title":"Building the Wallarm NGINX Plus Ingress Controller"},{"location":"en/admin-en/installation-guides/ingress-plus/assembly/#building-wallarm-nginx-plus-ingress-controller-from-the-source-files","text":"#### Info:: Check if you have an NGINX Plus license before you start. You can obtain a 30-day trial license by navigating to the [NGINX site][link-nginx-website]. The license consists of two files: * The `nginx-repo.key` key file, * The `nginx-repo.crt` certificate file. To build the Wallarm NGINX Plus Ingress controller from the source files, do the following: Set up a build environment Build the Ingress controller #### Info:: It is suggested that you build the software on the Linux operating system.","title":"Building Wallarm NGINX Plus Ingress Controller from the Source Files"},{"location":"en/admin-en/installation-guides/ingress-plus/assembly/#setting-up-a-build-environment","text":"Make sure that the following tools are installed on your machine: Docker ( official documentation ), Git ( official documentation ), GNU Make ( official documentation ). It is also required that you have a private Docker repository. Services that provide you with the means to access and manage Docker repositories are known as Docker registries. You should create a Docker repository if you do not have one. You can use your own Docker registry or use any service that will provide you with a hosted private Docker repository (e.g., Docker Hub , Google Container Registry , Microsoft Azure Container Registry ). #### Warning:: It is strongly recommended that you do not host a Docker image of the Wallarm NGINX Plus Ingress controller in the public Docker repository due to the risk of exposing the NGINX Plus license files to the public. #### Info:: It is sufficient to obtain access to the Docker Hub registry in order to complete this guide. The registry will provide you with one free-of-charge private Docker repository. You should gather the following information to continue: The login and password pair that you use to access the Docker registry The name of the Docker registry A path to the repository #### Info:: Docker registry name Depending on the service provider chosen, the name of the Docker registry and the path to the repository can be different. Please consult with your service provider\u2019s documentation for more information. There are some well-known names for the Docker registries: * docker.io for Docker Hub, * gcr.io for Google Container Registry, * <your repository name>.azurecr.io for Microsoft Azure Container Registry. The Docker\u2019s registry name is a part of the path to the repository. For example, if you are using Docker Hub, the path to access the repository example-repository created by user john will be as follows: `docker.io/john/example-repository`","title":"Setting up a Build Environment"},{"location":"en/admin-en/installation-guides/ingress-plus/assembly/#building-the-ingress-controller","text":"Log in to your Docker registry by executing the following command: # docker login <name of the Docker registry> You should provide the login and password that you use to access the Docker registry when prompted. #### Info:: Example: To log in to the Docker Hub registry execute the following command: # docker login docker.io #### Warning:: Depending on your system settings, you could be required to elevate privileges either by issuing the sudo command or running the command as the root user in order to execute the docker command. You have the option to allow executing the docker command by the currently logged-in user. To do so, you have to add the user to the docker group. However, you must remember that having membership in this group is equal to having the root user\u2019s privileges. This may potentially lead to severe security-related issues. You can obtain more detailed information here . #### Info:: Your service provider may provide additional tools to manage Docker registries. For example, Microsoft ships an az acr tool to manage the Microsoft Azure Container Registry, whereas Google provides you with a gcloud tool to manage the Google Container Registry. You can use these tools instead of the docker login command to log in to the specific registries. Please consult your service provider\u2019s documentation for more information. Clone the Wallarm NGINX Ingress Plus repository by executing the following command: $ git clone https://github.com/wallarm/ingress-plus/ Change your working directory to the ingress-plus/ by executing the following command: $ cd ingress-plus/ Copy the NGINX Plus key and certificate files in the working directory. If you do not have the files, you have to obtain an NGINX Plus license. An scp utility or similar tool could be used to perform the copy operation. Make sure that you have copied all necessary files by executing the following command: $ ls nginx-repo.* You should be provided with the following output: nginx-repo.crt nginx-repo.key Initiate the building process by executing the following commands one by one: $ make clean $ make DOCKERFILE=DockerfileForPlus PREFIX=<the path to your Docker repository> Note that you should provide the path to your Docker repository as the value of the PREFIX argument in the make command. A Docker image will be pushed to that repository when the build process is complete. #### Info:: Example To publish the image to the private repository example-repository , created by user john and hosted on Docker Hub, provide the following PREFIX argument to the make command: $ make DOCKERFILE=DockerfileForPlus PREFIX=docker.io/john/example-repository You can obtain more detailed information about the values of paths to Docker repositories here . You can start deployment of the Ingress controller once the build process finishes.","title":"Building the Ingress Controller"},{"location":"en/admin-en/installation-guides/ingress-plus/deploy/","text":"Deploying the Wallarm NGINX Plus Ingress Controller \u00b6 #### Warning:: Supported Kubernetes Platform Please note, that the Wallarm NGINX or NGINX Plus Ingress controllers run only on the Kubernetes platform version 1.15 and lower. Given that you have the Wallarm NGINX Plus Ingress controller image pushed to your private Docker repository, you are ready to deploy the Ingress controller in your Kubernetes cluster. To deploy the Ingress controller, do the following: Set up a deployment environment Configure the Ingress controller Deploy the Ingress controller #### Info:: RBAC support If a Role-Based Access Control (RBAC) mechanism is enabled in your Kubernetes cluster, you should perform additional steps to get your Ingress controller properly configured. This guide will provide you with the basic configurations for either RBAC-enabled clusters or RBAC-disabled clusters. If your cluster has the RBAC configured in a specific way or if you need additional information about role-based cluster access management, refer to the official Kubernetes documentation . If you use a Kubernetes cluster from a cloud service provider, you could refer to the provider\u2019s documentation as well. 1. Setting up the Deployment Environment \u00b6 To set up the deployment environment, do the following: Set up Kubectl to interact with your Kubernetes cluster Set up Helm to interact with your Kubernetes cluster Create a Kubernetes secret to access your Docker registry Obtain a token to connect the Ingress controller to the Wallarm cloud Make sure that the following tools are installed on your machine: Helm ( official documentation ), Git ( official documentation ), Kubectl ( official documentation ). 1. Setting up Kubectl to Interact with Your Kubernetes Cluster \u00b6 The basic setup instructions are available here . If you use a Kubernetes cluster from a cloud service provider, refer to the provider\u2019s documentation (e.g., Microsoft or Google documentation). After you have successfully configured the Kubectl tool, check if it is in an operational state. To do that, execute the command: $ kubectl get nodes The output of the command must contain no errors but include a list of all Kubernetes cluster nodes. #### Info:: Example ``` $ kubectl get nodes NAME STATUS ROLES AGE VERSION gke-ingress-scratch-default-pool-a3fd18a6-smfn Ready <none> 3d v1.11.3-gke.18 ``` 2. Setting up Helm to Interact with Your Kubernetes Cluster \u00b6 #### Info:: Helm is a two-component tool comprising * The client part named Helm that sends commands to the Tiller server * The server part named Tiller that installs directly into you Kubernetes cluster and does all the backstage work of deployment applications via Helm Charts. Helm and Tiller communicate in an open way by default, with no encryption of any messages. You could add SSL encryption for better security. You need an [OpenSSL][link-open-ssl-website] tool if you want to do that. More information about securing Helm and Tiller can be obtained [here][link-ssl-helm-tiller]. Depending on whether RBAC is enabled in your cluster, you should take different approaches while configuring Helm. If you Kubernetes cluster is RBAC-enabled, do the following to set up Helm: Make sure that the Kubectl tool works in the context with the necessary permissions (Kubectl should be run by the user whose account has been correctly assigned a cluster-admin role in your cluster). #### Info:: Some Kubernetes cluster service providers (e.g., Microsoft) create and bind the cluster-admin role to the user account while the Kubectl tool is being initialized, whereas others do not. In the latter case, it is necessary to manually create the role binding. For example, if you use Google Kubernetes Engine, bind the role to your account by executing the following command: $ kubectl create clusterrolebinding user-admin-binding --clusterrole=cluster-admin --user=$(gcloud config get-value account) To obtain more detailed information, refer to your service provider\u2019s documentation. Create a YAML text file helm-rbac.yaml (you can choose any name you like) containing the following text: apiVersion: v1 kind: ServiceAccount metadata: name: tiller-account namespace: kube-system --- apiVersion: rbac.authorization.k8s.io/v1 kind: ClusterRoleBinding metadata: name: tiller-admin-binding roleRef: apiGroup: rbac.authorization.k8s.io kind: ClusterRole name: cluster-admin subjects: - kind: ServiceAccount name: tiller-account namespace: kube-system The service account tiller-account is specified here and is bound to the cluster role cluster-admin . Apply the configuration from the file helm-rbac.yaml by executing the following command: $ kubectl apply -f helm-rbac.yaml You should be provided with the following output: serviceaccount \"tiller-account\" created clusterrolebinding.rbac.authorization.k8s.io \"tiller-admin-binding\" created To initialize Tiller with the privilege level of the created service account tiller-account , execute the following command: $ helm init --service-account=tiller-account If the command helm init was successfully executed, you will be presented with an output similar to the following: Tiller (the Helm server-side component) has been installed into your Kubernetes Cluster. Please note: by default, Tiller is deployed with an insecure 'allow unauthenticated users' policy. To prevent this, run `helm init` with the --tiller-tls-verify flag. For more information on securing your installation see: https://docs.helm.sh/using_helm/#securing-your-helm-installation Happy Helming! Check if Helm is in an operational state by executing the command helm ls --all . The output of the command must contain no errors but include the list of all Helm Chart deployments in your cluster (note that the list might be empty; this is normal). 3. Creating a Kubernetes Secret to Access Your Docker Registry \u00b6 Helm requires a Kubernetes secret to access your Docker registry. Provided with the secret, Helm will be able to pull the Wallarm NGINX Ingress Plus controller Docker image from your private repository during the deployment process. A secret to access a Docker registry comprises the registry name and the credentials used to access the registry (a login and password pair for the Docker registry). To create the Kubernetes secret for a Docker registry, execute the following command: $ kubectl create secret docker-registry <secret\u2019s name> --docker-server=<FQDN or IP address of the Docker registry> --docker-username=<login for accessing the Docker registry> --docker-password=<password for accessing the Docker registry> You should provide the following values to the command: The secret\u2019s name The name of the Docker registry as a value to the --docker-server parameter The login for accessing the registry as a value to the --docker-username parameter The password for accessing the registry as a value to the --docker-password parameter #### Info:: Example To create a secret my-secret for accessing a Docker Hub registry with the credentials of the user with the login example-user and the password pAssw0rd , execute the following command: $ kubectl create secret docker-registry my-secret --docker-server=https://index.docker.io/v1/ --docker-username=example-user --docker-password=pAssw0rd #### Info:: Depending on the Docker registry in use, the value of the `--docker-server` parameter can be different. Consult your service provider\u2019s documentation to find the correct value of the parameter. #### Info:: Kubernetes secret configuration You can obtain more information about the configuration of a Kubernetes secret [here][link-kubernetes-docs-secret]. 4. Obtaining a Token to Connect the Wallarm NGINX Plus Ingress Controller to the Wallarm Cloud \u00b6 The Wallarm NGINX Plus Ingress controller interacts with the Wallarm cloud during operation. The Ingress controller is connected to the cloud with the use of a token. To obtain the token, do the following: Log in to the Wallarm portal in the EU or US cloud with your Wallarm account. If you do not have one, you should create a 14-day trial account by navigating to --8\u2190 \"en/cloud-include/wallarm-signup.md\" . Navigate to the Nodes tab and select the Create new node button. Set an appropriate name for a node (\u00abnode\u00bb is another name for your Ingress controller installation). Choose the \u00abCloud\u00bb option from the Type of installation drop-down menu. Select the Create button. Copy the token value from the pop-up window. 2. Configuring the Wallarm NGINX Plus Ingress Controller \u00b6 To configure the deployment of your Ingress controller, do the following: Clone the Wallarm NGINX Plus Ingress controller repository, if you have not done that yet, by executing the following command: $ git clone https://github.com/wallarm/ingress-plus/ Change your working directory to ingress-plus/deployments/helm-chart/ by executing the following command: $ cd ingress-plus/deployments/helm-chart/ The file values-plus.yaml is a template of a deployment configuration required to deploy the Wallarm NGINX Plus Ingress controller with the use of Helm Chart. Copy the template file to the file named wl-ingress-plus.yaml (you can choose any other file name). Open the wl-ingress-plus.yaml file in a text editor (e.g., Nano text editor): $ cp values-plus.yaml wl-ingress-plus.yaml $ nano wl-ingress-plus.yaml Make changes to the content of the file as follows: Set the path to your private Docker repository (containing the Docker image of Wallarm NGINX Ingress Plus controller) as the value of the controller.image.repository parameter. Additionally, make sure that the version of the Docker image (or tag) hosted in your repository is identical to the value of the controller.image.tag parameter: controller: ...omitted for clarity... image: repository: <path to the Docker repository> tag: \"<version of the Ingress controller build>\" ...omitted for clarity... #### Info:: Example The following parameters set the example.com/example-repository as the path to the Docker repository and 1.3.2 as the tag: image: repository: example.com/example-repository tag: \"1.3.2\" Set the value of the token you obtained earlier as the value of the controller.wallarm.token parameter: controller: ...omitted for clarity... wallarm: enabled: true token: \"<the value of the token>\" ...omitted for clarity... #### Info:: Example The following parameter sets qwerty as the token value: token: \"qwerty\" Add the imagePullSecrets parameter pointing to the Kubernetes secret you created earlier to the controller.wallarm section: controller: ...omitted for clarity... wallarm: imagePullSecrets: - name: <the name of the secret> ...omitted for clarity... #### Info:: Example The following parameter sets my-secret as the secret for pulling the Docker image from the repository: imagePullSecrets: - name: my-secret Save the changes you made to the file. #### Info:: It is recommended that you set your own values for the TLS key and certificate instead of the default ones in the controller.defaultTLS section. You can use OpenSSL to generate the certificate and the key. You might be interested in the information about available Helm Chart parameters and about how to set a Kubernetes secret for a TLS certificate and key. If your Kubernetes cluster is an RBAC-disabled one, you should change a few parameters in the file in addition to those you changed in the previous steps: Set the value of the controller:serviceAccountName parameter to the empty string: controller: ...omitted for clarity... serviceAccountName: ...omitted for clarity... Set the value of the rbac.create parameter to false : rbac: create: false Save the changes you made to the file. 3. Deploying the Wallarm NGINX Plus Ingress Controller \u00b6 Execute the following command to deploy the Wallarm NGINX Plus Ingress controller with the use of the parameters listed in the file wl-ingress-plus.yaml : $ helm install --name wl-ingress-plus -f wl-ingress-plus.yaml . #### Info:: Feel free to use any suitable name as the value of the `--name` parameter as long as it is not used by other deployments made with Helm. Make sure that the controller was correctly deployed by executing the following commands one by one: $ helm ls $ kubectl get pods,deployments,svc You should be provided with an output similar to the following (the names of your Kubernetes pods may differ from those shown in the example output): $ helm ls NAME REVISION UPDATED STATUS CHART APP VERSION NAMESPACE wl-ingress-plus 1 Mon Dec 10 11:09:55 2018 DEPLOYED wallarm-ingress-plus-1.0.3 1.3.2 default $ kubectl get pods,deployments,svc NAME READY STATUS RESTARTS AGE pod/nginx-ingress-75b6958849-wdv7s 3/3 Running 0 13m pod/nginx-ingress-wallarm-tarantool-846c69b49b-qcqdq 8/8 Running 0 13m NAME DESIRED CURRENT UP-TO-DATE AVAILABLE AGE deployment.extensions/nginx-ingress 1 1 1 1 13m deployment.extensions/nginx-ingress-wallarm-tarantool 1 1 1 1 13m NAME TYPE CLUSTER-IP EXTERNAL-IP PORT(S) AGE service/kubernetes ClusterIP 10.0.0.1 <none> 443/TCP 5d service/nginx-ingress LoadBalancer 10.0.86.245 <pending> 80:30614/TCP,443:31593/TCP 13m service/nginx-ingress-wallarm-tarantool ClusterIP 10.0.81.30 <none> 3313/TCP 13m An Ingress controller works in conjunction with an Ingress resource that describes the incoming HTTP and HTTPS traffic routing rules, thereby allowing the traffic to reach your services deployed in the Kubernetes cluster. As your next step, you should deploy the Ingress resource for the Ingress controller to work.","title":"Deploying the Wallarm NGINX Plus Ingress Controller"},{"location":"en/admin-en/installation-guides/ingress-plus/deploy/#deploying-the-wallarm-nginx-plus-ingress-controller","text":"#### Warning:: Supported Kubernetes Platform Please note, that the Wallarm NGINX or NGINX Plus Ingress controllers run only on the Kubernetes platform version 1.15 and lower. Given that you have the Wallarm NGINX Plus Ingress controller image pushed to your private Docker repository, you are ready to deploy the Ingress controller in your Kubernetes cluster. To deploy the Ingress controller, do the following: Set up a deployment environment Configure the Ingress controller Deploy the Ingress controller #### Info:: RBAC support If a Role-Based Access Control (RBAC) mechanism is enabled in your Kubernetes cluster, you should perform additional steps to get your Ingress controller properly configured. This guide will provide you with the basic configurations for either RBAC-enabled clusters or RBAC-disabled clusters. If your cluster has the RBAC configured in a specific way or if you need additional information about role-based cluster access management, refer to the official Kubernetes documentation . If you use a Kubernetes cluster from a cloud service provider, you could refer to the provider\u2019s documentation as well.","title":"Deploying the Wallarm NGINX Plus Ingress Controller"},{"location":"en/admin-en/installation-guides/ingress-plus/deploy/#1-setting-up-the-deployment-environment","text":"To set up the deployment environment, do the following: Set up Kubectl to interact with your Kubernetes cluster Set up Helm to interact with your Kubernetes cluster Create a Kubernetes secret to access your Docker registry Obtain a token to connect the Ingress controller to the Wallarm cloud Make sure that the following tools are installed on your machine: Helm ( official documentation ), Git ( official documentation ), Kubectl ( official documentation ).","title":"1.  Setting up the Deployment Environment"},{"location":"en/admin-en/installation-guides/ingress-plus/deploy/#1-setting-up-kubectl-to-interact-with-your-kubernetes-cluster","text":"The basic setup instructions are available here . If you use a Kubernetes cluster from a cloud service provider, refer to the provider\u2019s documentation (e.g., Microsoft or Google documentation). After you have successfully configured the Kubectl tool, check if it is in an operational state. To do that, execute the command: $ kubectl get nodes The output of the command must contain no errors but include a list of all Kubernetes cluster nodes. #### Info:: Example ``` $ kubectl get nodes NAME STATUS ROLES AGE VERSION gke-ingress-scratch-default-pool-a3fd18a6-smfn Ready <none> 3d v1.11.3-gke.18 ```","title":"1.  Setting up Kubectl to Interact with Your Kubernetes Cluster"},{"location":"en/admin-en/installation-guides/ingress-plus/deploy/#2-setting-up-helm-to-interact-with-your-kubernetes-cluster","text":"#### Info:: Helm is a two-component tool comprising * The client part named Helm that sends commands to the Tiller server * The server part named Tiller that installs directly into you Kubernetes cluster and does all the backstage work of deployment applications via Helm Charts. Helm and Tiller communicate in an open way by default, with no encryption of any messages. You could add SSL encryption for better security. You need an [OpenSSL][link-open-ssl-website] tool if you want to do that. More information about securing Helm and Tiller can be obtained [here][link-ssl-helm-tiller]. Depending on whether RBAC is enabled in your cluster, you should take different approaches while configuring Helm. If you Kubernetes cluster is RBAC-enabled, do the following to set up Helm: Make sure that the Kubectl tool works in the context with the necessary permissions (Kubectl should be run by the user whose account has been correctly assigned a cluster-admin role in your cluster). #### Info:: Some Kubernetes cluster service providers (e.g., Microsoft) create and bind the cluster-admin role to the user account while the Kubectl tool is being initialized, whereas others do not. In the latter case, it is necessary to manually create the role binding. For example, if you use Google Kubernetes Engine, bind the role to your account by executing the following command: $ kubectl create clusterrolebinding user-admin-binding --clusterrole=cluster-admin --user=$(gcloud config get-value account) To obtain more detailed information, refer to your service provider\u2019s documentation. Create a YAML text file helm-rbac.yaml (you can choose any name you like) containing the following text: apiVersion: v1 kind: ServiceAccount metadata: name: tiller-account namespace: kube-system --- apiVersion: rbac.authorization.k8s.io/v1 kind: ClusterRoleBinding metadata: name: tiller-admin-binding roleRef: apiGroup: rbac.authorization.k8s.io kind: ClusterRole name: cluster-admin subjects: - kind: ServiceAccount name: tiller-account namespace: kube-system The service account tiller-account is specified here and is bound to the cluster role cluster-admin . Apply the configuration from the file helm-rbac.yaml by executing the following command: $ kubectl apply -f helm-rbac.yaml You should be provided with the following output: serviceaccount \"tiller-account\" created clusterrolebinding.rbac.authorization.k8s.io \"tiller-admin-binding\" created To initialize Tiller with the privilege level of the created service account tiller-account , execute the following command: $ helm init --service-account=tiller-account If the command helm init was successfully executed, you will be presented with an output similar to the following: Tiller (the Helm server-side component) has been installed into your Kubernetes Cluster. Please note: by default, Tiller is deployed with an insecure 'allow unauthenticated users' policy. To prevent this, run `helm init` with the --tiller-tls-verify flag. For more information on securing your installation see: https://docs.helm.sh/using_helm/#securing-your-helm-installation Happy Helming! Check if Helm is in an operational state by executing the command helm ls --all . The output of the command must contain no errors but include the list of all Helm Chart deployments in your cluster (note that the list might be empty; this is normal).","title":"2.  Setting up Helm to Interact with Your Kubernetes Cluster"},{"location":"en/admin-en/installation-guides/ingress-plus/deploy/#3-creating-a-kubernetes-secret-to-access-your-docker-registry","text":"Helm requires a Kubernetes secret to access your Docker registry. Provided with the secret, Helm will be able to pull the Wallarm NGINX Ingress Plus controller Docker image from your private repository during the deployment process. A secret to access a Docker registry comprises the registry name and the credentials used to access the registry (a login and password pair for the Docker registry). To create the Kubernetes secret for a Docker registry, execute the following command: $ kubectl create secret docker-registry <secret\u2019s name> --docker-server=<FQDN or IP address of the Docker registry> --docker-username=<login for accessing the Docker registry> --docker-password=<password for accessing the Docker registry> You should provide the following values to the command: The secret\u2019s name The name of the Docker registry as a value to the --docker-server parameter The login for accessing the registry as a value to the --docker-username parameter The password for accessing the registry as a value to the --docker-password parameter #### Info:: Example To create a secret my-secret for accessing a Docker Hub registry with the credentials of the user with the login example-user and the password pAssw0rd , execute the following command: $ kubectl create secret docker-registry my-secret --docker-server=https://index.docker.io/v1/ --docker-username=example-user --docker-password=pAssw0rd #### Info:: Depending on the Docker registry in use, the value of the `--docker-server` parameter can be different. Consult your service provider\u2019s documentation to find the correct value of the parameter. #### Info:: Kubernetes secret configuration You can obtain more information about the configuration of a Kubernetes secret [here][link-kubernetes-docs-secret].","title":"3.  Creating a Kubernetes Secret to Access Your Docker Registry"},{"location":"en/admin-en/installation-guides/ingress-plus/deploy/#4-obtaining-a-token-to-connect-the-wallarm-nginx-plus-ingress-controller-to-the-wallarm-cloud","text":"The Wallarm NGINX Plus Ingress controller interacts with the Wallarm cloud during operation. The Ingress controller is connected to the cloud with the use of a token. To obtain the token, do the following: Log in to the Wallarm portal in the EU or US cloud with your Wallarm account. If you do not have one, you should create a 14-day trial account by navigating to --8\u2190 \"en/cloud-include/wallarm-signup.md\" . Navigate to the Nodes tab and select the Create new node button. Set an appropriate name for a node (\u00abnode\u00bb is another name for your Ingress controller installation). Choose the \u00abCloud\u00bb option from the Type of installation drop-down menu. Select the Create button. Copy the token value from the pop-up window.","title":"4.  Obtaining a Token to Connect the Wallarm NGINX Plus Ingress Controller to the Wallarm Cloud"},{"location":"en/admin-en/installation-guides/ingress-plus/deploy/#2-configuring-the-wallarm-nginx-plus-ingress-controller","text":"To configure the deployment of your Ingress controller, do the following: Clone the Wallarm NGINX Plus Ingress controller repository, if you have not done that yet, by executing the following command: $ git clone https://github.com/wallarm/ingress-plus/ Change your working directory to ingress-plus/deployments/helm-chart/ by executing the following command: $ cd ingress-plus/deployments/helm-chart/ The file values-plus.yaml is a template of a deployment configuration required to deploy the Wallarm NGINX Plus Ingress controller with the use of Helm Chart. Copy the template file to the file named wl-ingress-plus.yaml (you can choose any other file name). Open the wl-ingress-plus.yaml file in a text editor (e.g., Nano text editor): $ cp values-plus.yaml wl-ingress-plus.yaml $ nano wl-ingress-plus.yaml Make changes to the content of the file as follows: Set the path to your private Docker repository (containing the Docker image of Wallarm NGINX Ingress Plus controller) as the value of the controller.image.repository parameter. Additionally, make sure that the version of the Docker image (or tag) hosted in your repository is identical to the value of the controller.image.tag parameter: controller: ...omitted for clarity... image: repository: <path to the Docker repository> tag: \"<version of the Ingress controller build>\" ...omitted for clarity... #### Info:: Example The following parameters set the example.com/example-repository as the path to the Docker repository and 1.3.2 as the tag: image: repository: example.com/example-repository tag: \"1.3.2\" Set the value of the token you obtained earlier as the value of the controller.wallarm.token parameter: controller: ...omitted for clarity... wallarm: enabled: true token: \"<the value of the token>\" ...omitted for clarity... #### Info:: Example The following parameter sets qwerty as the token value: token: \"qwerty\" Add the imagePullSecrets parameter pointing to the Kubernetes secret you created earlier to the controller.wallarm section: controller: ...omitted for clarity... wallarm: imagePullSecrets: - name: <the name of the secret> ...omitted for clarity... #### Info:: Example The following parameter sets my-secret as the secret for pulling the Docker image from the repository: imagePullSecrets: - name: my-secret Save the changes you made to the file. #### Info:: It is recommended that you set your own values for the TLS key and certificate instead of the default ones in the controller.defaultTLS section. You can use OpenSSL to generate the certificate and the key. You might be interested in the information about available Helm Chart parameters and about how to set a Kubernetes secret for a TLS certificate and key. If your Kubernetes cluster is an RBAC-disabled one, you should change a few parameters in the file in addition to those you changed in the previous steps: Set the value of the controller:serviceAccountName parameter to the empty string: controller: ...omitted for clarity... serviceAccountName: ...omitted for clarity... Set the value of the rbac.create parameter to false : rbac: create: false Save the changes you made to the file.","title":"2.  Configuring the Wallarm NGINX Plus Ingress Controller"},{"location":"en/admin-en/installation-guides/ingress-plus/deploy/#3-deploying-the-wallarm-nginx-plus-ingress-controller","text":"Execute the following command to deploy the Wallarm NGINX Plus Ingress controller with the use of the parameters listed in the file wl-ingress-plus.yaml : $ helm install --name wl-ingress-plus -f wl-ingress-plus.yaml . #### Info:: Feel free to use any suitable name as the value of the `--name` parameter as long as it is not used by other deployments made with Helm. Make sure that the controller was correctly deployed by executing the following commands one by one: $ helm ls $ kubectl get pods,deployments,svc You should be provided with an output similar to the following (the names of your Kubernetes pods may differ from those shown in the example output): $ helm ls NAME REVISION UPDATED STATUS CHART APP VERSION NAMESPACE wl-ingress-plus 1 Mon Dec 10 11:09:55 2018 DEPLOYED wallarm-ingress-plus-1.0.3 1.3.2 default $ kubectl get pods,deployments,svc NAME READY STATUS RESTARTS AGE pod/nginx-ingress-75b6958849-wdv7s 3/3 Running 0 13m pod/nginx-ingress-wallarm-tarantool-846c69b49b-qcqdq 8/8 Running 0 13m NAME DESIRED CURRENT UP-TO-DATE AVAILABLE AGE deployment.extensions/nginx-ingress 1 1 1 1 13m deployment.extensions/nginx-ingress-wallarm-tarantool 1 1 1 1 13m NAME TYPE CLUSTER-IP EXTERNAL-IP PORT(S) AGE service/kubernetes ClusterIP 10.0.0.1 <none> 443/TCP 5d service/nginx-ingress LoadBalancer 10.0.86.245 <pending> 80:30614/TCP,443:31593/TCP 13m service/nginx-ingress-wallarm-tarantool ClusterIP 10.0.81.30 <none> 3313/TCP 13m An Ingress controller works in conjunction with an Ingress resource that describes the incoming HTTP and HTTPS traffic routing rules, thereby allowing the traffic to reach your services deployed in the Kubernetes cluster. As your next step, you should deploy the Ingress resource for the Ingress controller to work.","title":"3.  Deploying the Wallarm NGINX Plus Ingress Controller"},{"location":"en/admin-en/installation-guides/ingress-plus/introduction/","text":"Introduction \u00b6 This guide will use \u201cWallarm NGINX Plus Ingress controller\u201d as the shortened name for the \u201cNGINX Plus Ingress controller with integrated Wallarm services.\u201d You should build the Wallarm NGINX Plus Ingress controller from the source files before using it. This guide describes the process of building the Wallarm NGINX Plus Ingress controller from the source files, as well the processes of configuration and deployment of the software. To deploy the Wallarm NGINX Plus Ingress controller, do the following: Build the Ingress controller from the source files . Deploy the Ingress controller . Create an Ingress resource . (Optional) Check if the Wallarm services are in an operational state . #### Warning:: Supported Kubernetes Platform Please note, that the Wallarm NGINX or NGINX Plus Ingress controllers run only on the Kubernetes platform version 1.15 and lower.","title":"Introduction"},{"location":"en/admin-en/installation-guides/ingress-plus/introduction/#introduction","text":"This guide will use \u201cWallarm NGINX Plus Ingress controller\u201d as the shortened name for the \u201cNGINX Plus Ingress controller with integrated Wallarm services.\u201d You should build the Wallarm NGINX Plus Ingress controller from the source files before using it. This guide describes the process of building the Wallarm NGINX Plus Ingress controller from the source files, as well the processes of configuration and deployment of the software. To deploy the Wallarm NGINX Plus Ingress controller, do the following: Build the Ingress controller from the source files . Deploy the Ingress controller . Create an Ingress resource . (Optional) Check if the Wallarm services are in an operational state . #### Warning:: Supported Kubernetes Platform Please note, that the Wallarm NGINX or NGINX Plus Ingress controllers run only on the Kubernetes platform version 1.15 and lower.","title":"Introduction"},{"location":"en/admin-en/installation-guides/ingress-plus/resource-creation/","text":"Creating an Ingress Resource \u00b6 In order to get the Ingress controller fully operational, you should deploy an Ingress resource. The Ingress resource sets the routing rules for incoming HTTP and HTTPS traffic so that such traffic can reach your services. To deploy an Ingress resource, do the following: Create a file containing the settings for the Ingress resource Deploy the Ingress resource This guide also provides you with an example of an Ingress resource for the Caf\u00e9 demonstration application. Make sure that the following tool is installed on your machine: Kubectl ( official documentation ). 1. Creating a File Containing the Settings for the Ingress Resource \u00b6 Create a YAML text file ingress.yaml (you can choose any name you like) containing the following text: apiVersion: extensions/v1beta1 kind: Ingress metadata: name: <the name of the Ingress resource> annotations: wallarm.com/mode: \"monitoring\" spec: rules: - host: <your application\u2019s domain name> http: paths: - path: / backend: serviceName: <service name> servicePort: <service port> The Ingress resource deployed with these settings will balance the incoming HTTP and HTTPS traffic with the Host header. You can add several host entries to the spec.rules section. You could define routing rules for each domain name that is set using the host parameter. The file describes the following behavior: if the user navigates to / , they are redirected to the certain service deployed in the Kubernetes cluster. You can obtain more information about Ingress resource deployment process here . 2. Deploying the Ingress Resource \u00b6 To deploy the Ingress resource described by the ingress.yaml file, execute the following command: $ kubectl apply -f ingress.yaml Given that the resource deployment was successful, you will be provided with the following output: ingress.extensions/<the name of the Ingress resource> created Check out the newly deployed Ingress resource by executing the following command: $ kubectl get ingress <the name of the Ingress resource> An example of output: NAME HOSTS ADDRESS PORTS AGE cafe-ingress cafe.example.com <Ingress IP addr> 80, 443 1h Obtain a detailed description of the Ingress resource by executing the following command: $ kubectl describe ingress <the name of the Ingress resource> You will be given the following information in the description: The IP address and the port numbers on which the Ingress controller is listening The Ingress routing rules An event list Make sure that you set up the correct DNS records pointing to the Ingress controller\u2019s IP address for the required domain names. Now you can check the Ingress operation by navigating in your browser to the necessary address assigned to your application (e.g., www.example.com ). Given that you correctly deployed the Wallarm NGINX Plus Ingress controller and the Ingress resource, you should be redirected to your application\u2019s webpage.","title":"Creating an Ingress Resource"},{"location":"en/admin-en/installation-guides/ingress-plus/resource-creation/#creating-an-ingress-resource","text":"In order to get the Ingress controller fully operational, you should deploy an Ingress resource. The Ingress resource sets the routing rules for incoming HTTP and HTTPS traffic so that such traffic can reach your services. To deploy an Ingress resource, do the following: Create a file containing the settings for the Ingress resource Deploy the Ingress resource This guide also provides you with an example of an Ingress resource for the Caf\u00e9 demonstration application. Make sure that the following tool is installed on your machine: Kubectl ( official documentation ).","title":"Creating an Ingress Resource"},{"location":"en/admin-en/installation-guides/ingress-plus/resource-creation/#1-creating-a-file-containing-the-settings-for-the-ingress-resource","text":"Create a YAML text file ingress.yaml (you can choose any name you like) containing the following text: apiVersion: extensions/v1beta1 kind: Ingress metadata: name: <the name of the Ingress resource> annotations: wallarm.com/mode: \"monitoring\" spec: rules: - host: <your application\u2019s domain name> http: paths: - path: / backend: serviceName: <service name> servicePort: <service port> The Ingress resource deployed with these settings will balance the incoming HTTP and HTTPS traffic with the Host header. You can add several host entries to the spec.rules section. You could define routing rules for each domain name that is set using the host parameter. The file describes the following behavior: if the user navigates to / , they are redirected to the certain service deployed in the Kubernetes cluster. You can obtain more information about Ingress resource deployment process here .","title":"1.  Creating a File Containing the Settings for the Ingress Resource"},{"location":"en/admin-en/installation-guides/ingress-plus/resource-creation/#2-deploying-the-ingress-resource","text":"To deploy the Ingress resource described by the ingress.yaml file, execute the following command: $ kubectl apply -f ingress.yaml Given that the resource deployment was successful, you will be provided with the following output: ingress.extensions/<the name of the Ingress resource> created Check out the newly deployed Ingress resource by executing the following command: $ kubectl get ingress <the name of the Ingress resource> An example of output: NAME HOSTS ADDRESS PORTS AGE cafe-ingress cafe.example.com <Ingress IP addr> 80, 443 1h Obtain a detailed description of the Ingress resource by executing the following command: $ kubectl describe ingress <the name of the Ingress resource> You will be given the following information in the description: The IP address and the port numbers on which the Ingress controller is listening The Ingress routing rules An event list Make sure that you set up the correct DNS records pointing to the Ingress controller\u2019s IP address for the required domain names. Now you can check the Ingress operation by navigating in your browser to the necessary address assigned to your application (e.g., www.example.com ). Given that you correctly deployed the Wallarm NGINX Plus Ingress controller and the Ingress resource, you should be redirected to your application\u2019s webpage.","title":"2.  Deploying the Ingress Resource"},{"location":"en/admin-en/installation-guides/ingress-plus/wallarm-services-check/","text":"Checking the Operation of the Wallarm Services \u00b6 Make sure that the following tools are installed on your machine: Git ( official documentation ). Kubectl ( official documentation ). Curl ( official documentation ) To check if the Wallarm services work on the deployed Ingress controller, do the following: Clone the Wallarm NGINX Plus Ingress controller repository (if you have not done so yet) by executing the following command: $ git clone https://github.com/wallarm/ingress-plus/ Change your working directory to ingress-plus/examples/complete-example/ by executing the following command: $ cd ingress-plus/examples/complete-example/ Set the necessary environment variables by executing the following commands one by one: $ IC_IP=<the IP address of the Ingress controller> $ IC_HTTPS_PORT=<the HTTPS port of the Ingress controller> Deploy the demonstration application named Caf\u00e9 by executing the following commands one by one: $ kubectl apply -f cafe.yaml $ kubectl apply -f cafe-secret.yaml Open the YAML text file cafe-ingress.yaml with any text editor of your choice (e.g., Nano text editor) and add the annotations section (containing Wallarm-specific parameters) in the metadata section: ...omitted for clarity... metadata: name: cafe-ingress annotations: wallarm.com/mode: \"monitoring\" ...omitted for clarity... Save the changes you made to the file. Deploy the Ingress resource named cafe-ingress by executing the following command: $ kubectl apply -f cafe-ingress.yaml Now you should have the deployed application that is served by two backends in the following way: If the user navigates to the cafe.example.com/tea path , they will be served with the webpage from the tea-svc service If the user navigates to the cafe.example.com/coffee path , they will be served with the webpage from the coffee-svc service Check if the application is in an operational state by executing the following command: $ curl --resolve cafe.example.com:$IC_HTTPS_PORT:$IC_IP https://cafe.example.com:$IC_HTTPS_PORT/tea --insecure You should obtain an output similar to the following: Server address: 10.244.0.93:80 Server name: tea-7d57856c44-29p2g Date: 12/Dec/2018:08:53:23 +0000 URI: /tea Request ID: 3c58ec15740a85ecf236836387dcaa32 Do a test SQLi attack at the cafe.example.com/coffee resource by executing the following command: $ curl --resolve cafe.example.com:$IC_HTTPS_PORT:$IC_IP https://cafe.example.com:$IC_HTTPS_PORT/coffee/UNION%20SELECT --insecure You should obtain an output similar to the following: Server address: 10.244.0.90:80 Server name: coffee-7dbb5795f6-ktd49 Date: 12/Dec/2018:08:58:10 +0000 URI: /coffee/UNION%20SELECT Request ID: c1482cd43a4b285d68a16f31b818c847 Log in to the Wallarm portal in the EU or US cloud with your Wallarm account. You should see the SQLi attack you have just performed in the Events tab. Change the behavior of the Ingress controller so that it blocks the attacker instead of just monitoring attacks. To do that, modify the existing Ingress resource named cafe-ingress by executing the following command: $ kubectl annotate --overwrite ingress cafe-ingress wallarm.com/mode=block Repeat the SQLi attack at the cafe.example.com/coffee webpage by executing the following command: $ curl --resolve cafe.example.com:$IC_HTTPS_PORT:$IC_IP https://cafe.example.com:$IC_HTTPS_PORT/coffee/UNION%20SELECT --insecure You should obtain an output similar to the following: <html> <head><title>403 Forbidden</title></head> <body bgcolor=\"white\"> <center><h1>403 Forbidden</h1></center> <hr><center>nginx/1.15.2</center> </body> </html> If you get a \u00ab403 Forbidden\u00bb response, then the Wallarm services are set up correctly and are operational. #### Info:: The blocking behavior of the Ingress controller will also work for the cafe.example.com/tea webpage.","title":"Checking the Operation of the Wallarm Services"},{"location":"en/admin-en/installation-guides/ingress-plus/wallarm-services-check/#checking-the-operation-of-the-wallarm-services","text":"Make sure that the following tools are installed on your machine: Git ( official documentation ). Kubectl ( official documentation ). Curl ( official documentation ) To check if the Wallarm services work on the deployed Ingress controller, do the following: Clone the Wallarm NGINX Plus Ingress controller repository (if you have not done so yet) by executing the following command: $ git clone https://github.com/wallarm/ingress-plus/ Change your working directory to ingress-plus/examples/complete-example/ by executing the following command: $ cd ingress-plus/examples/complete-example/ Set the necessary environment variables by executing the following commands one by one: $ IC_IP=<the IP address of the Ingress controller> $ IC_HTTPS_PORT=<the HTTPS port of the Ingress controller> Deploy the demonstration application named Caf\u00e9 by executing the following commands one by one: $ kubectl apply -f cafe.yaml $ kubectl apply -f cafe-secret.yaml Open the YAML text file cafe-ingress.yaml with any text editor of your choice (e.g., Nano text editor) and add the annotations section (containing Wallarm-specific parameters) in the metadata section: ...omitted for clarity... metadata: name: cafe-ingress annotations: wallarm.com/mode: \"monitoring\" ...omitted for clarity... Save the changes you made to the file. Deploy the Ingress resource named cafe-ingress by executing the following command: $ kubectl apply -f cafe-ingress.yaml Now you should have the deployed application that is served by two backends in the following way: If the user navigates to the cafe.example.com/tea path , they will be served with the webpage from the tea-svc service If the user navigates to the cafe.example.com/coffee path , they will be served with the webpage from the coffee-svc service Check if the application is in an operational state by executing the following command: $ curl --resolve cafe.example.com:$IC_HTTPS_PORT:$IC_IP https://cafe.example.com:$IC_HTTPS_PORT/tea --insecure You should obtain an output similar to the following: Server address: 10.244.0.93:80 Server name: tea-7d57856c44-29p2g Date: 12/Dec/2018:08:53:23 +0000 URI: /tea Request ID: 3c58ec15740a85ecf236836387dcaa32 Do a test SQLi attack at the cafe.example.com/coffee resource by executing the following command: $ curl --resolve cafe.example.com:$IC_HTTPS_PORT:$IC_IP https://cafe.example.com:$IC_HTTPS_PORT/coffee/UNION%20SELECT --insecure You should obtain an output similar to the following: Server address: 10.244.0.90:80 Server name: coffee-7dbb5795f6-ktd49 Date: 12/Dec/2018:08:58:10 +0000 URI: /coffee/UNION%20SELECT Request ID: c1482cd43a4b285d68a16f31b818c847 Log in to the Wallarm portal in the EU or US cloud with your Wallarm account. You should see the SQLi attack you have just performed in the Events tab. Change the behavior of the Ingress controller so that it blocks the attacker instead of just monitoring attacks. To do that, modify the existing Ingress resource named cafe-ingress by executing the following command: $ kubectl annotate --overwrite ingress cafe-ingress wallarm.com/mode=block Repeat the SQLi attack at the cafe.example.com/coffee webpage by executing the following command: $ curl --resolve cafe.example.com:$IC_HTTPS_PORT:$IC_IP https://cafe.example.com:$IC_HTTPS_PORT/coffee/UNION%20SELECT --insecure You should obtain an output similar to the following: <html> <head><title>403 Forbidden</title></head> <body bgcolor=\"white\"> <center><h1>403 Forbidden</h1></center> <hr><center>nginx/1.15.2</center> </body> </html> If you get a \u00ab403 Forbidden\u00bb response, then the Wallarm services are set up correctly and are operational. #### Info:: The blocking behavior of the Ingress controller will also work for the cafe.example.com/tea webpage.","title":"Checking the Operation of the Wallarm Services"},{"location":"en/admin-en/installation-guides/kubernetes/wallarm-sidecar-container-helm/","text":"Kubernetes Deployment Based on Helm Charts \u00b6 Prerequisites \u00b6 Local or cloud (EKS, GKE, AKE, etc) cluster running any version of Kubernetes Application packaged as a Helm chart Pod exposed to the public Internet or other potential sources of malicious web and API attacks Kubernetes ingress controller or external load balancer (like AWS ELB or ALB) adds HTTP request header X-Forwarded-For which contains the real public IP address of connecting client Wallarm account in the EU cloud or US cloud Username and password of the user with the Deploy role added to your Wallarm account. To add a new user, please follow the instructions Installation \u00b6 Create Wallarm ConfigMap. Update the definition of the Deployment object in Kubernetes. Update the definition of the Service object in Kubernetes. Update the Helm chart configuration file. Test Wallarm sidecar container. Step 1: Creating Wallarm ConfigMap \u00b6 Go to the Helm chart directory > the templates folder and create the wallarm-sidecar-configmap.yaml template with the following content: apiVersion: v1 kind: ConfigMap metadata: name: wallarm-sidecar-nginx-conf data: default: | map $remote_addr $wallarm_mode_real { default {{ .Values.wallarm.mode | quote }}; # please leave the block with IP addresses and rules for your cloud below # IP addresses and rules for US cloud scanners 23.239.18.250 off;104.237.155.105 off;45.56.71.221 off;45.79.194.128 off;104.237.151.202 off;45.33.15.249 off;45.33.43.225 off;45.79.10.15 off;45.33.79.18 off;45.79.75.59 off;23.239.30.236 off;50.116.11.251 off;45.56.123.144 off;45.79.143.18 off;172.104.21.210 off;74.207.237.202 off;45.79.186.159 off;45.79.216.187 off;45.33.16.32 off;96.126.127.23 off;172.104.208.113 off;192.81.135.28 off;35.236.51.79 off;35.236.75.97 off;35.236.111.124 off;35.236.108.88 off;35.236.16.246 off;35.236.61.185 off;35.236.110.91 off;35.236.14.198 off;35.235.124.137 off;35.236.48.47 off;35.236.100.176 off;35.236.18.117 off;35.235.112.188 off;35.236.55.214 off;35.236.126.84 off;35.236.3.158 off;35.236.127.211 off;35.236.118.146 off;35.236.20.89 off;35.236.1.4 off; # IP addresses and rules for European cloud scanners 139.162.130.66 off;139.162.144.202 off;139.162.151.10 off;139.162.151.155 off;139.162.156.102 off;139.162.157.131 off;139.162.158.79 off;139.162.159.137 off;139.162.159.244 off;139.162.163.61 off;139.162.164.41 off;139.162.166.202 off;139.162.167.19 off;139.162.167.51 off;139.162.168.17 off;139.162.170.84 off;139.162.171.141 off;139.162.172.35 off;139.162.174.220 off;139.162.174.26 off;139.162.175.71 off;139.162.176.169 off;139.162.178.148 off;139.162.179.214 off;139.162.180.37 off;139.162.182.156 off;139.162.182.20 off;139.162.184.225 off;139.162.185.243 off;139.162.186.136 off;139.162.187.138 off;139.162.188.246 off;139.162.190.22 off;139.162.190.86 off;139.162.191.89 off;85.90.246.120 off;104.200.29.36 off;104.237.151.23 off;173.230.130.253 off;173.230.138.206 off;173.230.156.200 off;173.230.158.207 off;173.255.192.83 off;173.255.193.92 off;173.255.200.80 off;173.255.214.180 off;192.155.82.205 off;23.239.11.21 off;23.92.18.13 off;23.92.30.204 off;45.33.105.35 off;45.33.33.19 off;45.33.41.31 off;45.33.64.71 off;45.33.65.37 off;45.33.72.81 off;45.33.73.43 off;45.33.80.65 off;45.33.81.109 off;45.33.88.42 off;45.33.97.86 off;45.33.98.89 off;45.56.102.9 off;45.56.104.7 off;45.56.113.41 off;45.56.114.24 off;45.56.119.39 off;50.116.35.43 off;50.116.42.181 off;50.116.43.110 off;66.175.222.237 off;66.228.58.101 off;69.164.202.55 off;72.14.181.105 off;72.14.184.100 off;72.14.191.76 off;172.104.150.243 off;139.162.190.165 off;139.162.130.123 off;139.162.132.87 off;139.162.145.238 off;139.162.146.245 off;139.162.162.71 off;139.162.171.208 off;139.162.184.33 off;139.162.186.129 off;172.104.128.103 off;172.104.128.67 off;172.104.139.37 off;172.104.146.90 off;172.104.151.59 off;172.104.152.244 off;172.104.152.96 off;172.104.154.128 off;172.104.229.59 off;172.104.250.27 off;172.104.252.112 off;45.33.115.7 off;45.56.69.211 off;45.79.16.240 off;50.116.23.110 off;85.90.246.49 off;172.104.139.18 off;172.104.152.28 off;139.162.177.83 off;172.104.240.115 off;172.105.64.135 off;139.162.153.16 off;172.104.241.162 off;139.162.167.48 off;172.104.233.100 off;172.104.157.26 off;172.105.65.182 off;178.32.42.221 off;46.105.75.84 off;51.254.85.145 off;188.165.30.182 off;188.165.136.41 off;188.165.137.10 off;54.36.135.252 off;54.36.135.253 off;54.36.135.254 off;54.36.135.255 off;54.36.131.128 off;54.36.131.129 off; } server { listen 80 default_server; listen [::]:80 default_server ipv6only=on; server_name localhost; root /usr/share/nginx/html; index index.html index.htm; wallarm_mode $wallarm_mode_real; # wallarm_instance 1; {{ if eq .Values.wallarm.enable_ip_blocking \"true\" }} wallarm_acl default; {{ end }} set_real_ip_from 0.0.0.0/0; real_ip_header X-Forwarded-For; location / { proxy_pass http://localhost:{{ .Values.wallarm.app_container_port }}; include proxy_params; } } Step 2: Updating the Deployment Object in Kubernetes \u00b6 Return to the Helm chart directory > the templates folder and open the template defining the Deployment object for the pod you want to add the WAF node to. For example: apiVersion: apps/v1 kind: Deployment metadata: name: myapp spec: selector: matchLabels: app: myapp template: metadata: labels: app: myapp spec: containers: - name: myapp # definition of your main app container image: <Image> resources: limits: memory: \"128Mi\" cpu: \"500m\" ports: - containerPort: 8080 # port on which the application container accepts incoming requests Copy the following elements to the template: the checksum/config annotation to the spec.template.metadata.annotations section to update the running pods after a change in the previously created ConfigMap object, the wallarm sidecar container definition to the spec.template.spec.containers section, the wallarm-nginx-conf volume definition to the spec.template.spec.volumes section. An example of the template with added elements is provided below. Elements for copying are indicated by the Wallarm element comment. apiVersion: apps/v1 kind: Deployment metadata: annotations: checksum/config: {{ include (print $.Template.BasePath \"/wallarm-sidecar-configmap.yaml\") . | sha256sum }} # Wallarm element: annotation to update running pods after changing Wallarm ConfigMap name: myapp spec: selector: matchLabels: app: myapp template: metadata: labels: app: myapp spec: containers: - name: wallarm # Wallarm element: definition of Wallarm sidecar container image: {{ .Values.wallarm.image.repository }}:{{ .Values.wallarm.image.tag }} imagePullPolicy: {{ .Values.wallarm.image.pullPolicy | quote }} env: - name: WALLARM_API_HOST value: {{ .Values.wallarm.wallarm_host_api | quote }} - name: DEPLOY_USER value: {{ .Values.wallarm.deploy_username | quote }} - name: DEPLOY_PASSWORD value: {{ .Values.wallarm.deploy_password | quote }} - name: DEPLOY_FORCE value: \"true\" - name: TARANTOOL_MEMORY_GB value: {{ .Values.wallarm.tarantool_memory_gb | quote }} ports: - name: http containerPort: 80 # port on which the Wallarm sidecar container accepts requests from the Service object volumeMounts: - mountPath: /etc/nginx/sites-enabled readOnly: true name: wallarm-nginx-conf - name: myapp # definition of your main app container image: <Image> resources: limits: memory: \"128Mi\" cpu: \"500m\" ports: - containerPort: 8080 # port on which the application container accepts incoming requests volumes: - name: wallarm-nginx-conf # Wallarm element: definition of the wallarm-nginx-conf volume configMap: name: wallarm-sidecar-nginx-conf items: - key: default path: default Update the ports.containerPort value in sidecar container definition following the code comments. Step 3: Updating the Service Object in Kubernetes \u00b6 Return to the Helm chart directory > the templates folder and open the template defining the Service object which points to Deployment modified in the previous step. For example: apiVersion: v1 kind: Service metadata: name: myapp spec: selector: app: myapp ports: - port: {{ .Values.service.port }} targetPort: 8080 # Wallarm sidecar container port; the value must be identical to ports.containerPort in definition of Wallarm sidecar container Make sure the ports.targetPort value is identical to ports.containerPort from the definition of Wallarm sidecar container. Step 4: Updating the Helm Chart Configuration File \u00b6 Return to the Helm chart directory and open the values.yaml file. Copy the wallarm object definition provided below to values.yaml and update parameter values following the code comments. wallarm: image: repository: wallarm/node tag: 2.14 pullPolicy: Always wallarm_host_api: \"api.wallarm.com\" # Wallarm API endpoint: \"api.wallarm.com\" for the EU cloud, \"us1.api.wallarm.com\" for the US cloud deploy_username: \"username\" # username of the user with the Deploy role deploy_password: \"password\" # password of the user with the Deploy role app_container_port: 80 # port on which the container accepts incoming requests, the value must be identical to ports.containerPort in definition of your main app container mode: \"block\" # request filtering modes: \"off\" to disable request processing, \"monitoring\" to process but not block requests, \"block\" to process all requests and block the malicious ones tarantool_memory_gb: 2 # amount of memory in GB for request analytics data, recommended value is 75% of the total server memory Make sure the values.yaml file is valid using the following command: # helm lint Deploy the modified Helm chart in the Kubernetes cluster using the following command: # helm upgrade RELEASE CHART RELEASE is the name of an existing Helm chart, CHART is the path to the Helm chart directory. #### Warning:: NetworkPolicy Object in Kubernetes If the application also uses the NetworkPolicy object it should be updated to reflect the Wallarm sidecar container port specified above. Step 5: Testing Wallarm Sidecar Container \u00b6 Get the list of pods using the following command: # kubectl get pods The number of containers in the pod should increase and the status of the pod should be \"Running\". NAME READY STATUS RESTARTS AGE mychart-856f957bbd-cr4kt 2/2 Running 0 3m48s Go to your Wallarm account > Nodes by the link below and make sure that a new node is displayed. The created node is used to filter requests to your application. * https://my.wallarm.com/nodes/ for the EU cloud * https://us1.my.wallarm.com/nodes/ for the US cloud Send a malicious test attack request to the application as described in this instruction . Go to your Wallarm account > Events by the link below and make sure that an attack is displayed in the list: * https://my.wallarm.com/events/ for the EU cloud * https://us1.my.wallarm.com/events/ for the US cloud","title":"Kubernetes Deployment Based on Helm Charts"},{"location":"en/admin-en/installation-guides/kubernetes/wallarm-sidecar-container-helm/#kubernetes-deployment-based-on-helm-charts","text":"","title":"Kubernetes Deployment Based on Helm Charts"},{"location":"en/admin-en/installation-guides/kubernetes/wallarm-sidecar-container-helm/#prerequisites","text":"Local or cloud (EKS, GKE, AKE, etc) cluster running any version of Kubernetes Application packaged as a Helm chart Pod exposed to the public Internet or other potential sources of malicious web and API attacks Kubernetes ingress controller or external load balancer (like AWS ELB or ALB) adds HTTP request header X-Forwarded-For which contains the real public IP address of connecting client Wallarm account in the EU cloud or US cloud Username and password of the user with the Deploy role added to your Wallarm account. To add a new user, please follow the instructions","title":"Prerequisites"},{"location":"en/admin-en/installation-guides/kubernetes/wallarm-sidecar-container-helm/#installation","text":"Create Wallarm ConfigMap. Update the definition of the Deployment object in Kubernetes. Update the definition of the Service object in Kubernetes. Update the Helm chart configuration file. Test Wallarm sidecar container.","title":"Installation"},{"location":"en/admin-en/installation-guides/kubernetes/wallarm-sidecar-container-helm/#step-1-creating-wallarm-configmap","text":"Go to the Helm chart directory > the templates folder and create the wallarm-sidecar-configmap.yaml template with the following content: apiVersion: v1 kind: ConfigMap metadata: name: wallarm-sidecar-nginx-conf data: default: | map $remote_addr $wallarm_mode_real { default {{ .Values.wallarm.mode | quote }}; # please leave the block with IP addresses and rules for your cloud below # IP addresses and rules for US cloud scanners 23.239.18.250 off;104.237.155.105 off;45.56.71.221 off;45.79.194.128 off;104.237.151.202 off;45.33.15.249 off;45.33.43.225 off;45.79.10.15 off;45.33.79.18 off;45.79.75.59 off;23.239.30.236 off;50.116.11.251 off;45.56.123.144 off;45.79.143.18 off;172.104.21.210 off;74.207.237.202 off;45.79.186.159 off;45.79.216.187 off;45.33.16.32 off;96.126.127.23 off;172.104.208.113 off;192.81.135.28 off;35.236.51.79 off;35.236.75.97 off;35.236.111.124 off;35.236.108.88 off;35.236.16.246 off;35.236.61.185 off;35.236.110.91 off;35.236.14.198 off;35.235.124.137 off;35.236.48.47 off;35.236.100.176 off;35.236.18.117 off;35.235.112.188 off;35.236.55.214 off;35.236.126.84 off;35.236.3.158 off;35.236.127.211 off;35.236.118.146 off;35.236.20.89 off;35.236.1.4 off; # IP addresses and rules for European cloud scanners 139.162.130.66 off;139.162.144.202 off;139.162.151.10 off;139.162.151.155 off;139.162.156.102 off;139.162.157.131 off;139.162.158.79 off;139.162.159.137 off;139.162.159.244 off;139.162.163.61 off;139.162.164.41 off;139.162.166.202 off;139.162.167.19 off;139.162.167.51 off;139.162.168.17 off;139.162.170.84 off;139.162.171.141 off;139.162.172.35 off;139.162.174.220 off;139.162.174.26 off;139.162.175.71 off;139.162.176.169 off;139.162.178.148 off;139.162.179.214 off;139.162.180.37 off;139.162.182.156 off;139.162.182.20 off;139.162.184.225 off;139.162.185.243 off;139.162.186.136 off;139.162.187.138 off;139.162.188.246 off;139.162.190.22 off;139.162.190.86 off;139.162.191.89 off;85.90.246.120 off;104.200.29.36 off;104.237.151.23 off;173.230.130.253 off;173.230.138.206 off;173.230.156.200 off;173.230.158.207 off;173.255.192.83 off;173.255.193.92 off;173.255.200.80 off;173.255.214.180 off;192.155.82.205 off;23.239.11.21 off;23.92.18.13 off;23.92.30.204 off;45.33.105.35 off;45.33.33.19 off;45.33.41.31 off;45.33.64.71 off;45.33.65.37 off;45.33.72.81 off;45.33.73.43 off;45.33.80.65 off;45.33.81.109 off;45.33.88.42 off;45.33.97.86 off;45.33.98.89 off;45.56.102.9 off;45.56.104.7 off;45.56.113.41 off;45.56.114.24 off;45.56.119.39 off;50.116.35.43 off;50.116.42.181 off;50.116.43.110 off;66.175.222.237 off;66.228.58.101 off;69.164.202.55 off;72.14.181.105 off;72.14.184.100 off;72.14.191.76 off;172.104.150.243 off;139.162.190.165 off;139.162.130.123 off;139.162.132.87 off;139.162.145.238 off;139.162.146.245 off;139.162.162.71 off;139.162.171.208 off;139.162.184.33 off;139.162.186.129 off;172.104.128.103 off;172.104.128.67 off;172.104.139.37 off;172.104.146.90 off;172.104.151.59 off;172.104.152.244 off;172.104.152.96 off;172.104.154.128 off;172.104.229.59 off;172.104.250.27 off;172.104.252.112 off;45.33.115.7 off;45.56.69.211 off;45.79.16.240 off;50.116.23.110 off;85.90.246.49 off;172.104.139.18 off;172.104.152.28 off;139.162.177.83 off;172.104.240.115 off;172.105.64.135 off;139.162.153.16 off;172.104.241.162 off;139.162.167.48 off;172.104.233.100 off;172.104.157.26 off;172.105.65.182 off;178.32.42.221 off;46.105.75.84 off;51.254.85.145 off;188.165.30.182 off;188.165.136.41 off;188.165.137.10 off;54.36.135.252 off;54.36.135.253 off;54.36.135.254 off;54.36.135.255 off;54.36.131.128 off;54.36.131.129 off; } server { listen 80 default_server; listen [::]:80 default_server ipv6only=on; server_name localhost; root /usr/share/nginx/html; index index.html index.htm; wallarm_mode $wallarm_mode_real; # wallarm_instance 1; {{ if eq .Values.wallarm.enable_ip_blocking \"true\" }} wallarm_acl default; {{ end }} set_real_ip_from 0.0.0.0/0; real_ip_header X-Forwarded-For; location / { proxy_pass http://localhost:{{ .Values.wallarm.app_container_port }}; include proxy_params; } }","title":"Step 1: Creating Wallarm ConfigMap"},{"location":"en/admin-en/installation-guides/kubernetes/wallarm-sidecar-container-helm/#step-2-updating-the-deployment-object-in-kubernetes","text":"Return to the Helm chart directory > the templates folder and open the template defining the Deployment object for the pod you want to add the WAF node to. For example: apiVersion: apps/v1 kind: Deployment metadata: name: myapp spec: selector: matchLabels: app: myapp template: metadata: labels: app: myapp spec: containers: - name: myapp # definition of your main app container image: <Image> resources: limits: memory: \"128Mi\" cpu: \"500m\" ports: - containerPort: 8080 # port on which the application container accepts incoming requests Copy the following elements to the template: the checksum/config annotation to the spec.template.metadata.annotations section to update the running pods after a change in the previously created ConfigMap object, the wallarm sidecar container definition to the spec.template.spec.containers section, the wallarm-nginx-conf volume definition to the spec.template.spec.volumes section. An example of the template with added elements is provided below. Elements for copying are indicated by the Wallarm element comment. apiVersion: apps/v1 kind: Deployment metadata: annotations: checksum/config: {{ include (print $.Template.BasePath \"/wallarm-sidecar-configmap.yaml\") . | sha256sum }} # Wallarm element: annotation to update running pods after changing Wallarm ConfigMap name: myapp spec: selector: matchLabels: app: myapp template: metadata: labels: app: myapp spec: containers: - name: wallarm # Wallarm element: definition of Wallarm sidecar container image: {{ .Values.wallarm.image.repository }}:{{ .Values.wallarm.image.tag }} imagePullPolicy: {{ .Values.wallarm.image.pullPolicy | quote }} env: - name: WALLARM_API_HOST value: {{ .Values.wallarm.wallarm_host_api | quote }} - name: DEPLOY_USER value: {{ .Values.wallarm.deploy_username | quote }} - name: DEPLOY_PASSWORD value: {{ .Values.wallarm.deploy_password | quote }} - name: DEPLOY_FORCE value: \"true\" - name: TARANTOOL_MEMORY_GB value: {{ .Values.wallarm.tarantool_memory_gb | quote }} ports: - name: http containerPort: 80 # port on which the Wallarm sidecar container accepts requests from the Service object volumeMounts: - mountPath: /etc/nginx/sites-enabled readOnly: true name: wallarm-nginx-conf - name: myapp # definition of your main app container image: <Image> resources: limits: memory: \"128Mi\" cpu: \"500m\" ports: - containerPort: 8080 # port on which the application container accepts incoming requests volumes: - name: wallarm-nginx-conf # Wallarm element: definition of the wallarm-nginx-conf volume configMap: name: wallarm-sidecar-nginx-conf items: - key: default path: default Update the ports.containerPort value in sidecar container definition following the code comments.","title":"Step 2: Updating the Deployment Object in Kubernetes"},{"location":"en/admin-en/installation-guides/kubernetes/wallarm-sidecar-container-helm/#step-3-updating-the-service-object-in-kubernetes","text":"Return to the Helm chart directory > the templates folder and open the template defining the Service object which points to Deployment modified in the previous step. For example: apiVersion: v1 kind: Service metadata: name: myapp spec: selector: app: myapp ports: - port: {{ .Values.service.port }} targetPort: 8080 # Wallarm sidecar container port; the value must be identical to ports.containerPort in definition of Wallarm sidecar container Make sure the ports.targetPort value is identical to ports.containerPort from the definition of Wallarm sidecar container.","title":"Step 3: Updating the Service Object in Kubernetes"},{"location":"en/admin-en/installation-guides/kubernetes/wallarm-sidecar-container-helm/#step-4-updating-the-helm-chart-configuration-file","text":"Return to the Helm chart directory and open the values.yaml file. Copy the wallarm object definition provided below to values.yaml and update parameter values following the code comments. wallarm: image: repository: wallarm/node tag: 2.14 pullPolicy: Always wallarm_host_api: \"api.wallarm.com\" # Wallarm API endpoint: \"api.wallarm.com\" for the EU cloud, \"us1.api.wallarm.com\" for the US cloud deploy_username: \"username\" # username of the user with the Deploy role deploy_password: \"password\" # password of the user with the Deploy role app_container_port: 80 # port on which the container accepts incoming requests, the value must be identical to ports.containerPort in definition of your main app container mode: \"block\" # request filtering modes: \"off\" to disable request processing, \"monitoring\" to process but not block requests, \"block\" to process all requests and block the malicious ones tarantool_memory_gb: 2 # amount of memory in GB for request analytics data, recommended value is 75% of the total server memory Make sure the values.yaml file is valid using the following command: # helm lint Deploy the modified Helm chart in the Kubernetes cluster using the following command: # helm upgrade RELEASE CHART RELEASE is the name of an existing Helm chart, CHART is the path to the Helm chart directory. #### Warning:: NetworkPolicy Object in Kubernetes If the application also uses the NetworkPolicy object it should be updated to reflect the Wallarm sidecar container port specified above.","title":"Step 4: Updating the Helm Chart Configuration File"},{"location":"en/admin-en/installation-guides/kubernetes/wallarm-sidecar-container-helm/#step-5-testing-wallarm-sidecar-container","text":"Get the list of pods using the following command: # kubectl get pods The number of containers in the pod should increase and the status of the pod should be \"Running\". NAME READY STATUS RESTARTS AGE mychart-856f957bbd-cr4kt 2/2 Running 0 3m48s Go to your Wallarm account > Nodes by the link below and make sure that a new node is displayed. The created node is used to filter requests to your application. * https://my.wallarm.com/nodes/ for the EU cloud * https://us1.my.wallarm.com/nodes/ for the US cloud Send a malicious test attack request to the application as described in this instruction . Go to your Wallarm account > Events by the link below and make sure that an attack is displayed in the list: * https://my.wallarm.com/events/ for the EU cloud * https://us1.my.wallarm.com/events/ for the US cloud","title":"Step 5: Testing Wallarm Sidecar Container"},{"location":"en/admin-en/installation-guides/kubernetes/wallarm-sidecar-container-manifest/","text":"Kubernetes Deployment Based on Manifests \u00b6 Prerequisites \u00b6 Local or cloud (EKS, GKE, AKE, etc) cluster running any version of Kubernetes Application defined in plain Kubernetes manifest files Pod exposed to the public Internet or other potential sources of malicious web and API attacks Kubernetes ingress controller or external load balancer (like AWS ELB or ALB) adds HTTP request header X-Forwarded-For which contains the real public IP address of connecting client Wallarm account in the EU cloud or US cloud Username and password of the user with the Deploy role added to your Wallarm account. To add a new user, please follow the instructions Installation \u00b6 Create Wallarm ConfigMap. Update the definition of the Deployment object in Kubernetes. Update the definition of the Service object in Kubernetes. Deploy the manifest to the Kubernetes cluster. Test Wallarm sidecar container. Step 1: Creating Wallarm ConfigMap \u00b6 Create a new manifest file or add a new object to the existing manifest for a new Kubernetes ConfigMap object which will hold Nginx configuration file for Wallarm sidecar container: apiVersion: v1 kind: ConfigMap metadata: name: wallarm-sidecar-nginx-conf data: default: | map $remote_addr $wallarm_mode_real { default <WALLARM_MODE>; # please replace <WALLARM_MODE> by the request filtering mode: off to disable request processing, monitoring to process but not block requests, block to process all requests and block the malicious ones # please leave the block with IP addresses and rules for your cloud below # IP addresses and rules for US cloud scanners 23.239.18.250 off;104.237.155.105 off;45.56.71.221 off;45.79.194.128 off;104.237.151.202 off;45.33.15.249 off;45.33.43.225 off;45.79.10.15 off;45.33.79.18 off;45.79.75.59 off;23.239.30.236 off;50.116.11.251 off;45.56.123.144 off;45.79.143.18 off;172.104.21.210 off;74.207.237.202 off;45.79.186.159 off;45.79.216.187 off;45.33.16.32 off;96.126.127.23 off;172.104.208.113 off;192.81.135.28 off;35.236.51.79 off;35.236.75.97 off;35.236.111.124 off;35.236.108.88 off;35.236.16.246 off;35.236.61.185 off;35.236.110.91 off;35.236.14.198 off;35.235.124.137 off;35.236.48.47 off;35.236.100.176 off;35.236.18.117 off;35.235.112.188 off;35.236.55.214 off;35.236.126.84 off;35.236.3.158 off;35.236.127.211 off;35.236.118.146 off;35.236.20.89 off;35.236.1.4 off; # IP addresses and rules for European cloud scanners 139.162.130.66 off;139.162.144.202 off;139.162.151.10 off;139.162.151.155 off;139.162.156.102 off;139.162.157.131 off;139.162.158.79 off;139.162.159.137 off;139.162.159.244 off;139.162.163.61 off;139.162.164.41 off;139.162.166.202 off;139.162.167.19 off;139.162.167.51 off;139.162.168.17 off;139.162.170.84 off;139.162.171.141 off;139.162.172.35 off;139.162.174.220 off;139.162.174.26 off;139.162.175.71 off;139.162.176.169 off;139.162.178.148 off;139.162.179.214 off;139.162.180.37 off;139.162.182.156 off;139.162.182.20 off;139.162.184.225 off;139.162.185.243 off;139.162.186.136 off;139.162.187.138 off;139.162.188.246 off;139.162.190.22 off;139.162.190.86 off;139.162.191.89 off;85.90.246.120 off;104.200.29.36 off;104.237.151.23 off;173.230.130.253 off;173.230.138.206 off;173.230.156.200 off;173.230.158.207 off;173.255.192.83 off;173.255.193.92 off;173.255.200.80 off;173.255.214.180 off;192.155.82.205 off;23.239.11.21 off;23.92.18.13 off;23.92.30.204 off;45.33.105.35 off;45.33.33.19 off;45.33.41.31 off;45.33.64.71 off;45.33.65.37 off;45.33.72.81 off;45.33.73.43 off;45.33.80.65 off;45.33.81.109 off;45.33.88.42 off;45.33.97.86 off;45.33.98.89 off;45.56.102.9 off;45.56.104.7 off;45.56.113.41 off;45.56.114.24 off;45.56.119.39 off;50.116.35.43 off;50.116.42.181 off;50.116.43.110 off;66.175.222.237 off;66.228.58.101 off;69.164.202.55 off;72.14.181.105 off;72.14.184.100 off;72.14.191.76 off;172.104.150.243 off;139.162.190.165 off;139.162.130.123 off;139.162.132.87 off;139.162.145.238 off;139.162.146.245 off;139.162.162.71 off;139.162.171.208 off;139.162.184.33 off;139.162.186.129 off;172.104.128.103 off;172.104.128.67 off;172.104.139.37 off;172.104.146.90 off;172.104.151.59 off;172.104.152.244 off;172.104.152.96 off;172.104.154.128 off;172.104.229.59 off;172.104.250.27 off;172.104.252.112 off;45.33.115.7 off;45.56.69.211 off;45.79.16.240 off;50.116.23.110 off;85.90.246.49 off;172.104.139.18 off;172.104.152.28 off;139.162.177.83 off;172.104.240.115 off;172.105.64.135 off;139.162.153.16 off;172.104.241.162 off;139.162.167.48 off;172.104.233.100 off;172.104.157.26 off;172.105.65.182 off;178.32.42.221 off;46.105.75.84 off;51.254.85.145 off;188.165.30.182 off;188.165.136.41 off;188.165.137.10 off;54.36.135.252 off;54.36.135.253 off;54.36.135.254 off;54.36.135.255 off;54.36.131.128 off;54.36.131.129 off; } server { listen 80 default_server; listen [::]:80 default_server ipv6only=on; server_name localhost; root /usr/share/nginx/html; index index.html index.htm; wallarm_mode $wallarm_mode_real; # wallarm_instance 1; set_real_ip_from 0.0.0.0/0; real_ip_header X-Forwarded-For; location / { proxy_pass http://localhost:<APP_CONTAINER_PORT>; # please replace <APP_CONTAINER_PORT> by the port number on which the container accepts incoming requests, the value must be identical to ports.containerPort in definition of your main app container include proxy_params; } } Update parameter values following the code comments. Step 2: Updating the Deployment Object in Kubernetes \u00b6 Go to Kubernetes manifests and open the template defining the Deployment object for the pod you want to add the WAF node to. For example: apiVersion: apps/v1 kind: Deployment metadata: name: myapp spec: selector: matchLabels: app: myapp template: metadata: labels: app: myapp spec: containers: - name: myapp # definition of your main app container image: <Image> resources: limits: memory: \"128Mi\" cpu: \"500m\" ports: - containerPort: 8080 # port on which the application container accepts incoming requests Copy the following elements to the template: the wallarm sidecar container definition to the spec.template.spec.containers section, the wallarm-nginx-conf volume definition to the spec.template.spec.volumes section. An example of the template with added elements is provided below. Elements for copying are indicated by the Wallarm element comment. apiVersion: apps/v1 kind: Deployment metadata: name: myapp spec: selector: matchLabels: app: myapp template: metadata: labels: app: myapp spec: containers: - name: wallarm # Wallarm element: definition of Wallarm sidecar container image: wallarm/node:2.14 imagePullPolicy: Always env: - name: WALLARM_API_HOST # Wallarm API endpoint: \"api.wallarm.com\" for the EU cloud, \"us1.api.wallarm.com\" for the US cloud value: \"api.wallarm.com\" - name: DEPLOY_USER # username of the user with the Deploy role value: \"username\" - name: DEPLOY_PASSWORD # password of the user with the Deploy role value: \"password\" - name: DEPLOY_FORCE value: \"true\" - name: WALLARM_ACL_ENABLE value: \"true\" - name: TARANTOOL_MEMORY_GB # amount of memory in GB for request analytics data, recommended value is 75% of the total server memory value: 2 ports: - name: http containerPort: 80 # port on which the Wallarm sidecar container accepts requests from the Service object volumeMounts: - mountPath: /etc/nginx/sites-enabled readOnly: true name: wallarm-nginx-conf - name: myapp # definition of your main app container image: <Image> resources: limits: memory: \"128Mi\" cpu: \"500m\" ports: - containerPort: 8080 # port on which the application container accepts incoming requests volumes: # - name: wallarm-nginx-conf # Wallarm element: definition of the wallarm-nginx-conf volume configMap: name: wallarm-sidecar-nginx-conf items: - key: default path: default Step 3: Updating the Service Object in Kubernetes \u00b6 Return to Kubernetes manifests and open the template defining the Service object which points to Deployment modified in the previous step. For example: apiVersion: v1 kind: Service metadata: name: myapp spec: selector: app: myapp ports: - port: {{ .Values.service.port }} targetPort: 8080 # Wallarm sidecar container port; the value must be identical to ports.containerPort in definition of Wallarm sidecar container Make sure the ports.targetPort value is identical to ports.containerPort from the definition of Wallarm sidecar container. Step 4: Deploying the Manifest to the Kubernetes Cluster \u00b6 Update or deploy the new application manifest in the Kubernetes cluster. #### Warning:: NetworkPolicy Object in Kubernetes If the application also uses the `NetworkPolicy` object it should be updated to reflect the Wallarm sidecar container port specified above. Step 5: Testing Wallarm Sidecar Container \u00b6 Get the list of pods using the following command: # kubectl get pods The number of containers in the pod should increase and the status of the pod should be \"Running\". NAME READY STATUS RESTARTS AGE mychart-856f957bbd-cr4kt 2/2 Running 0 3m48s Go to your Wallarm account > Nodes by the link below and make sure that a new node is displayed. The created node is used to filter requests to your application. * https://my.wallarm.com/nodes/ for the EU cloud * https://us1.my.wallarm.com/nodes/ for the US cloud Send a malicious test attack request to the application as described in this instruction . Go to your Wallarm account > Events by the link below and make sure that an attack is displayed in the list: * https://my.wallarm.com/events/ for the EU cloud * https://us1.my.wallarm.com/events/ for the US cloud","title":"Kubernetes Deployment Based on Manifests"},{"location":"en/admin-en/installation-guides/kubernetes/wallarm-sidecar-container-manifest/#kubernetes-deployment-based-on-manifests","text":"","title":"Kubernetes Deployment Based on Manifests"},{"location":"en/admin-en/installation-guides/kubernetes/wallarm-sidecar-container-manifest/#prerequisites","text":"Local or cloud (EKS, GKE, AKE, etc) cluster running any version of Kubernetes Application defined in plain Kubernetes manifest files Pod exposed to the public Internet or other potential sources of malicious web and API attacks Kubernetes ingress controller or external load balancer (like AWS ELB or ALB) adds HTTP request header X-Forwarded-For which contains the real public IP address of connecting client Wallarm account in the EU cloud or US cloud Username and password of the user with the Deploy role added to your Wallarm account. To add a new user, please follow the instructions","title":"Prerequisites"},{"location":"en/admin-en/installation-guides/kubernetes/wallarm-sidecar-container-manifest/#installation","text":"Create Wallarm ConfigMap. Update the definition of the Deployment object in Kubernetes. Update the definition of the Service object in Kubernetes. Deploy the manifest to the Kubernetes cluster. Test Wallarm sidecar container.","title":"Installation"},{"location":"en/admin-en/installation-guides/kubernetes/wallarm-sidecar-container-manifest/#step-1-creating-wallarm-configmap","text":"Create a new manifest file or add a new object to the existing manifest for a new Kubernetes ConfigMap object which will hold Nginx configuration file for Wallarm sidecar container: apiVersion: v1 kind: ConfigMap metadata: name: wallarm-sidecar-nginx-conf data: default: | map $remote_addr $wallarm_mode_real { default <WALLARM_MODE>; # please replace <WALLARM_MODE> by the request filtering mode: off to disable request processing, monitoring to process but not block requests, block to process all requests and block the malicious ones # please leave the block with IP addresses and rules for your cloud below # IP addresses and rules for US cloud scanners 23.239.18.250 off;104.237.155.105 off;45.56.71.221 off;45.79.194.128 off;104.237.151.202 off;45.33.15.249 off;45.33.43.225 off;45.79.10.15 off;45.33.79.18 off;45.79.75.59 off;23.239.30.236 off;50.116.11.251 off;45.56.123.144 off;45.79.143.18 off;172.104.21.210 off;74.207.237.202 off;45.79.186.159 off;45.79.216.187 off;45.33.16.32 off;96.126.127.23 off;172.104.208.113 off;192.81.135.28 off;35.236.51.79 off;35.236.75.97 off;35.236.111.124 off;35.236.108.88 off;35.236.16.246 off;35.236.61.185 off;35.236.110.91 off;35.236.14.198 off;35.235.124.137 off;35.236.48.47 off;35.236.100.176 off;35.236.18.117 off;35.235.112.188 off;35.236.55.214 off;35.236.126.84 off;35.236.3.158 off;35.236.127.211 off;35.236.118.146 off;35.236.20.89 off;35.236.1.4 off; # IP addresses and rules for European cloud scanners 139.162.130.66 off;139.162.144.202 off;139.162.151.10 off;139.162.151.155 off;139.162.156.102 off;139.162.157.131 off;139.162.158.79 off;139.162.159.137 off;139.162.159.244 off;139.162.163.61 off;139.162.164.41 off;139.162.166.202 off;139.162.167.19 off;139.162.167.51 off;139.162.168.17 off;139.162.170.84 off;139.162.171.141 off;139.162.172.35 off;139.162.174.220 off;139.162.174.26 off;139.162.175.71 off;139.162.176.169 off;139.162.178.148 off;139.162.179.214 off;139.162.180.37 off;139.162.182.156 off;139.162.182.20 off;139.162.184.225 off;139.162.185.243 off;139.162.186.136 off;139.162.187.138 off;139.162.188.246 off;139.162.190.22 off;139.162.190.86 off;139.162.191.89 off;85.90.246.120 off;104.200.29.36 off;104.237.151.23 off;173.230.130.253 off;173.230.138.206 off;173.230.156.200 off;173.230.158.207 off;173.255.192.83 off;173.255.193.92 off;173.255.200.80 off;173.255.214.180 off;192.155.82.205 off;23.239.11.21 off;23.92.18.13 off;23.92.30.204 off;45.33.105.35 off;45.33.33.19 off;45.33.41.31 off;45.33.64.71 off;45.33.65.37 off;45.33.72.81 off;45.33.73.43 off;45.33.80.65 off;45.33.81.109 off;45.33.88.42 off;45.33.97.86 off;45.33.98.89 off;45.56.102.9 off;45.56.104.7 off;45.56.113.41 off;45.56.114.24 off;45.56.119.39 off;50.116.35.43 off;50.116.42.181 off;50.116.43.110 off;66.175.222.237 off;66.228.58.101 off;69.164.202.55 off;72.14.181.105 off;72.14.184.100 off;72.14.191.76 off;172.104.150.243 off;139.162.190.165 off;139.162.130.123 off;139.162.132.87 off;139.162.145.238 off;139.162.146.245 off;139.162.162.71 off;139.162.171.208 off;139.162.184.33 off;139.162.186.129 off;172.104.128.103 off;172.104.128.67 off;172.104.139.37 off;172.104.146.90 off;172.104.151.59 off;172.104.152.244 off;172.104.152.96 off;172.104.154.128 off;172.104.229.59 off;172.104.250.27 off;172.104.252.112 off;45.33.115.7 off;45.56.69.211 off;45.79.16.240 off;50.116.23.110 off;85.90.246.49 off;172.104.139.18 off;172.104.152.28 off;139.162.177.83 off;172.104.240.115 off;172.105.64.135 off;139.162.153.16 off;172.104.241.162 off;139.162.167.48 off;172.104.233.100 off;172.104.157.26 off;172.105.65.182 off;178.32.42.221 off;46.105.75.84 off;51.254.85.145 off;188.165.30.182 off;188.165.136.41 off;188.165.137.10 off;54.36.135.252 off;54.36.135.253 off;54.36.135.254 off;54.36.135.255 off;54.36.131.128 off;54.36.131.129 off; } server { listen 80 default_server; listen [::]:80 default_server ipv6only=on; server_name localhost; root /usr/share/nginx/html; index index.html index.htm; wallarm_mode $wallarm_mode_real; # wallarm_instance 1; set_real_ip_from 0.0.0.0/0; real_ip_header X-Forwarded-For; location / { proxy_pass http://localhost:<APP_CONTAINER_PORT>; # please replace <APP_CONTAINER_PORT> by the port number on which the container accepts incoming requests, the value must be identical to ports.containerPort in definition of your main app container include proxy_params; } } Update parameter values following the code comments.","title":"Step 1: Creating Wallarm ConfigMap"},{"location":"en/admin-en/installation-guides/kubernetes/wallarm-sidecar-container-manifest/#step-2-updating-the-deployment-object-in-kubernetes","text":"Go to Kubernetes manifests and open the template defining the Deployment object for the pod you want to add the WAF node to. For example: apiVersion: apps/v1 kind: Deployment metadata: name: myapp spec: selector: matchLabels: app: myapp template: metadata: labels: app: myapp spec: containers: - name: myapp # definition of your main app container image: <Image> resources: limits: memory: \"128Mi\" cpu: \"500m\" ports: - containerPort: 8080 # port on which the application container accepts incoming requests Copy the following elements to the template: the wallarm sidecar container definition to the spec.template.spec.containers section, the wallarm-nginx-conf volume definition to the spec.template.spec.volumes section. An example of the template with added elements is provided below. Elements for copying are indicated by the Wallarm element comment. apiVersion: apps/v1 kind: Deployment metadata: name: myapp spec: selector: matchLabels: app: myapp template: metadata: labels: app: myapp spec: containers: - name: wallarm # Wallarm element: definition of Wallarm sidecar container image: wallarm/node:2.14 imagePullPolicy: Always env: - name: WALLARM_API_HOST # Wallarm API endpoint: \"api.wallarm.com\" for the EU cloud, \"us1.api.wallarm.com\" for the US cloud value: \"api.wallarm.com\" - name: DEPLOY_USER # username of the user with the Deploy role value: \"username\" - name: DEPLOY_PASSWORD # password of the user with the Deploy role value: \"password\" - name: DEPLOY_FORCE value: \"true\" - name: WALLARM_ACL_ENABLE value: \"true\" - name: TARANTOOL_MEMORY_GB # amount of memory in GB for request analytics data, recommended value is 75% of the total server memory value: 2 ports: - name: http containerPort: 80 # port on which the Wallarm sidecar container accepts requests from the Service object volumeMounts: - mountPath: /etc/nginx/sites-enabled readOnly: true name: wallarm-nginx-conf - name: myapp # definition of your main app container image: <Image> resources: limits: memory: \"128Mi\" cpu: \"500m\" ports: - containerPort: 8080 # port on which the application container accepts incoming requests volumes: # - name: wallarm-nginx-conf # Wallarm element: definition of the wallarm-nginx-conf volume configMap: name: wallarm-sidecar-nginx-conf items: - key: default path: default","title":"Step 2: Updating the Deployment Object in Kubernetes"},{"location":"en/admin-en/installation-guides/kubernetes/wallarm-sidecar-container-manifest/#step-3-updating-the-service-object-in-kubernetes","text":"Return to Kubernetes manifests and open the template defining the Service object which points to Deployment modified in the previous step. For example: apiVersion: v1 kind: Service metadata: name: myapp spec: selector: app: myapp ports: - port: {{ .Values.service.port }} targetPort: 8080 # Wallarm sidecar container port; the value must be identical to ports.containerPort in definition of Wallarm sidecar container Make sure the ports.targetPort value is identical to ports.containerPort from the definition of Wallarm sidecar container.","title":"Step 3: Updating the Service Object in Kubernetes"},{"location":"en/admin-en/installation-guides/kubernetes/wallarm-sidecar-container-manifest/#step-4-deploying-the-manifest-to-the-kubernetes-cluster","text":"Update or deploy the new application manifest in the Kubernetes cluster. #### Warning:: NetworkPolicy Object in Kubernetes If the application also uses the `NetworkPolicy` object it should be updated to reflect the Wallarm sidecar container port specified above.","title":"Step 4: Deploying the Manifest to the Kubernetes Cluster"},{"location":"en/admin-en/installation-guides/kubernetes/wallarm-sidecar-container-manifest/#step-5-testing-wallarm-sidecar-container","text":"Get the list of pods using the following command: # kubectl get pods The number of containers in the pod should increase and the status of the pod should be \"Running\". NAME READY STATUS RESTARTS AGE mychart-856f957bbd-cr4kt 2/2 Running 0 3m48s Go to your Wallarm account > Nodes by the link below and make sure that a new node is displayed. The created node is used to filter requests to your application. * https://my.wallarm.com/nodes/ for the EU cloud * https://us1.my.wallarm.com/nodes/ for the US cloud Send a malicious test attack request to the application as described in this instruction . Go to your Wallarm account > Events by the link below and make sure that an attack is displayed in the list: * https://my.wallarm.com/events/ for the EU cloud * https://us1.my.wallarm.com/events/ for the US cloud","title":"Step 5: Testing Wallarm Sidecar Container"},{"location":"en/admin-en/installation-guides/kubernetes/wallarm-sidecar-container/","text":"How Wallarm Sidecar Container Works \u00b6 Wallarm WAF node installs as a sidecar container to the same pod as the main application container. The WAF node filters incoming requests and forwards valid requests to the application container. Kubernetes runs the sidecar container alongside the main container image. The sidecar container also shares the same lifecycle as the main application container, being created and retired alongside it. #### Info:: See also: * [Types of containers in Kubernetes pod](https://kubernetes.io/docs/concepts/workloads/pods/pod-overview/) Traffic Flow \u00b6 Normally Kubernetes uses a Service object with the ClusterIP or NodePort type to be exposed directly to the Internet or other Kubernetes applications. The following are examples of traffic flow for architecture with such Service object without Wallarm sidecar container and with it. Scheme of the traffic flow without Wallarm sidecar container \u00b6 An application container accepts incoming requests on port 8080/TCP and the Service object forwards incoming requests to the same port ( 8080/TCP ) on all healthy pods of the application (Kubernetes Deployment object). Scheme of the traffic flow with Wallarm sidecar container \u00b6 An application container accepts incoming requests on port 8080/TCP and the Service object forwards incoming requests to another port (for example, 80/TCP ) on Wallarm sidecar container. Wallarm sidecar container filters requests and forwards the valid ones to the 8080/TCP port on all healthy pods of the application (Kubernetes Deployment object). When a Wallarm WAF node sidecar container is added to a Kubernetes pod it is necessary to change the flow of HTTP requests hitting the pod. The detailed description of changing is provided in the instructions. Wallarm Sidecar Congtainer Installation \u00b6 The way of sidecar container installation depends on Kubernetes application deployment options. Please select your option below and follow the instructions: Kubernetes deployment based on Helm Charts Kubernetes deployment based on manifests","title":"How It Works"},{"location":"en/admin-en/installation-guides/kubernetes/wallarm-sidecar-container/#how-wallarm-sidecar-container-works","text":"Wallarm WAF node installs as a sidecar container to the same pod as the main application container. The WAF node filters incoming requests and forwards valid requests to the application container. Kubernetes runs the sidecar container alongside the main container image. The sidecar container also shares the same lifecycle as the main application container, being created and retired alongside it. #### Info:: See also: * [Types of containers in Kubernetes pod](https://kubernetes.io/docs/concepts/workloads/pods/pod-overview/)","title":"How Wallarm Sidecar Container Works"},{"location":"en/admin-en/installation-guides/kubernetes/wallarm-sidecar-container/#traffic-flow","text":"Normally Kubernetes uses a Service object with the ClusterIP or NodePort type to be exposed directly to the Internet or other Kubernetes applications. The following are examples of traffic flow for architecture with such Service object without Wallarm sidecar container and with it.","title":"Traffic Flow"},{"location":"en/admin-en/installation-guides/kubernetes/wallarm-sidecar-container/#scheme-of-the-traffic-flow-without-wallarm-sidecar-container","text":"An application container accepts incoming requests on port 8080/TCP and the Service object forwards incoming requests to the same port ( 8080/TCP ) on all healthy pods of the application (Kubernetes Deployment object).","title":"Scheme of the traffic flow without Wallarm sidecar container"},{"location":"en/admin-en/installation-guides/kubernetes/wallarm-sidecar-container/#scheme-of-the-traffic-flow-with-wallarm-sidecar-container","text":"An application container accepts incoming requests on port 8080/TCP and the Service object forwards incoming requests to another port (for example, 80/TCP ) on Wallarm sidecar container. Wallarm sidecar container filters requests and forwards the valid ones to the 8080/TCP port on all healthy pods of the application (Kubernetes Deployment object). When a Wallarm WAF node sidecar container is added to a Kubernetes pod it is necessary to change the flow of HTTP requests hitting the pod. The detailed description of changing is provided in the instructions.","title":"Scheme of the traffic flow with Wallarm sidecar container"},{"location":"en/admin-en/installation-guides/kubernetes/wallarm-sidecar-container/#wallarm-sidecar-congtainer-installation","text":"The way of sidecar container installation depends on Kubernetes application deployment options. Please select your option below and follow the instructions: Kubernetes deployment based on Helm Charts Kubernetes deployment based on manifests","title":"Wallarm Sidecar Congtainer Installation"},{"location":"en/admin-en/integration-guides/repo-mirroring/centos/how-to-mirror-repo-artifactory/","text":"How to Mirror the Wallarm Repository for CentOS \u00b6 You can create and use a local copy (also known as a mirror ) of the Wallarm repository to be sure that all filter nodes in your infrastructure are deployed from a single source and have the same version number. This document will guide you through the process of mirroring the Wallarm repository for a CentOS 6/7 server via the JFrog Artifactory repository manager. #### Info:: Prerequisites. Make sure that the following conditions are met prior to taking any further steps: * You have these components installed on your server: * CentOS 6 or CentOS 7 operating system * `yum-utils` and `epel-release` packages * JFrog Artifactory software capable of creating RPM repositories ([installation instructions][link-jfrog-installation]) Learn more about JFrog Artifactory editions and features [here][link-jfrog-comparison-matrix]. * JFrog Artifactory is up and running. * The server has internet access. Wallarm repository mirroring comprises Creating a local copy of the Wallarm repository Creating a local RPM repository in JFrog Artifactory Importing the local copy of the Wallarm repository into JFrog Artifactory 1. Creating a Local Copy of the Wallarm Repository \u00b6 To create a local copy of the Wallarm repository, do the following: Add the Wallarm repository by executing the following command: !include \"en/include-en/include/add-repo-for-mirroring-centos.md\" Navigate to a temporary directory (e.g., /tmp ) and synchronize the Wallarm repository to this directory by executing the following command: # reposync -r wallarm-node -p . If the reposync command finishes successfully, then the Wallarm packages will be placed in the wallarm-node/Packages subdirectory of your temporary directory (e.g., /tmp/wallarm-node/Packages ). 2. Creating a Local RPM Repository in JFrog Artifactory \u00b6 To create a local RPM repository in JFrog Artifactory, do the following: Navigate to the JFrog Artifactory web UI via either the domain name or IP address (e.g., http://jfrog.example.local:8081/artifactory ). Log in to the web UI with the administrator account. Click the Admin menu entry, then the Local link in the Repositories section. Click the New button to create a new local repository. Select the \u201cRPM\u201d package type. Fill the repository name in the Repository Key field. This name should be unique in JFrog Artifactory. We recommend choosing a name that complies with the Artifactory repositories naming best practices (e.g., wallarm-centos-upload-local ). Select the \u201cmaven-2-default\u201d layout from the Repository Layout drop-down list. You can leave other settings unchanged. Click the Save & Finish button to create the local Artifactory repository. Now, the newly created repository should be displayed in the local repository list. To finish mirroring the Wallarm repository, import synchronized packages into the local Artifactory repository. 3. Importing the Local Copy of the Wallarm Repository into JFrog Artifactory \u00b6 To import the Wallarm packages into the Artifactory local RPM repository, do the following: Log in to the JFrog Artifactory web UI with the administrator account. Click the Admin menu entry, then the Repositories link in the Import & Export section. In the Import Repository from Path section, select the local repository you created earlier from the Repository from Path drop-down list. Click the Browse button and select the directory with the Wallarm packages you created earlier . Click the Import button to import the Wallarm packages from the directory. Click the Artifacts menu entry, and make sure that the imported Wallarm packages are present in the desired local repository. Now you can deploy Wallarm filter nodes using the local mirror of the Wallarm repository.","title":"How to Mirror the Wallarm Repository for CentOS"},{"location":"en/admin-en/integration-guides/repo-mirroring/centos/how-to-mirror-repo-artifactory/#how-to-mirror-the-wallarm-repository-for-centos","text":"You can create and use a local copy (also known as a mirror ) of the Wallarm repository to be sure that all filter nodes in your infrastructure are deployed from a single source and have the same version number. This document will guide you through the process of mirroring the Wallarm repository for a CentOS 6/7 server via the JFrog Artifactory repository manager. #### Info:: Prerequisites. Make sure that the following conditions are met prior to taking any further steps: * You have these components installed on your server: * CentOS 6 or CentOS 7 operating system * `yum-utils` and `epel-release` packages * JFrog Artifactory software capable of creating RPM repositories ([installation instructions][link-jfrog-installation]) Learn more about JFrog Artifactory editions and features [here][link-jfrog-comparison-matrix]. * JFrog Artifactory is up and running. * The server has internet access. Wallarm repository mirroring comprises Creating a local copy of the Wallarm repository Creating a local RPM repository in JFrog Artifactory Importing the local copy of the Wallarm repository into JFrog Artifactory","title":"How to Mirror the Wallarm Repository for CentOS"},{"location":"en/admin-en/integration-guides/repo-mirroring/centos/how-to-mirror-repo-artifactory/#1-creating-a-local-copy-of-the-wallarm-repository","text":"To create a local copy of the Wallarm repository, do the following: Add the Wallarm repository by executing the following command: !include \"en/include-en/include/add-repo-for-mirroring-centos.md\" Navigate to a temporary directory (e.g., /tmp ) and synchronize the Wallarm repository to this directory by executing the following command: # reposync -r wallarm-node -p . If the reposync command finishes successfully, then the Wallarm packages will be placed in the wallarm-node/Packages subdirectory of your temporary directory (e.g., /tmp/wallarm-node/Packages ).","title":"1.  Creating a Local Copy of the Wallarm Repository"},{"location":"en/admin-en/integration-guides/repo-mirroring/centos/how-to-mirror-repo-artifactory/#2-creating-a-local-rpm-repository-in-jfrog-artifactory","text":"To create a local RPM repository in JFrog Artifactory, do the following: Navigate to the JFrog Artifactory web UI via either the domain name or IP address (e.g., http://jfrog.example.local:8081/artifactory ). Log in to the web UI with the administrator account. Click the Admin menu entry, then the Local link in the Repositories section. Click the New button to create a new local repository. Select the \u201cRPM\u201d package type. Fill the repository name in the Repository Key field. This name should be unique in JFrog Artifactory. We recommend choosing a name that complies with the Artifactory repositories naming best practices (e.g., wallarm-centos-upload-local ). Select the \u201cmaven-2-default\u201d layout from the Repository Layout drop-down list. You can leave other settings unchanged. Click the Save & Finish button to create the local Artifactory repository. Now, the newly created repository should be displayed in the local repository list. To finish mirroring the Wallarm repository, import synchronized packages into the local Artifactory repository.","title":"2.  Creating a Local RPM Repository in JFrog Artifactory"},{"location":"en/admin-en/integration-guides/repo-mirroring/centos/how-to-mirror-repo-artifactory/#3-importing-the-local-copy-of-the-wallarm-repository-into-jfrog-artifactory","text":"To import the Wallarm packages into the Artifactory local RPM repository, do the following: Log in to the JFrog Artifactory web UI with the administrator account. Click the Admin menu entry, then the Repositories link in the Import & Export section. In the Import Repository from Path section, select the local repository you created earlier from the Repository from Path drop-down list. Click the Browse button and select the directory with the Wallarm packages you created earlier . Click the Import button to import the Wallarm packages from the directory. Click the Artifacts menu entry, and make sure that the imported Wallarm packages are present in the desired local repository. Now you can deploy Wallarm filter nodes using the local mirror of the Wallarm repository.","title":"3.  Importing the Local Copy of the Wallarm Repository into JFrog Artifactory"},{"location":"en/admin-en/integration-guides/repo-mirroring/centos/how-to-use-mirrored-repo/","text":"How to Install Wallarm Packages from the Local JFrog Artifactory Repository for CentOS \u00b6 To install Wallarm packages from the JFrog Artifactory repository on a host dedicated to a filter node, perform the following actions on this host: Navigate to the JFrog Artifactory web UI via either the domain name or IP address (e.g., http://jfrog.example.local:8081/artifactory ). Log in to the web UI with a user account. Click the Artifacts menu entry and select a repository containing the Wallarm packages. Click the Set Me Up link. A pop-up window will appear. Type your user account\u2019s password in the Type Password field and press Enter . Now, the instructions in this window will contain your credentials. Scroll down to the yum configuration example and click the Copy Snippet to Clipboard button to copy this example to the clipboard. Create a yum configuration file (e.g., /etc/yum.repos.d/artifactory.repo ) and paste the copied snippet into it. #### Warning:: Important! Make sure to remove the <PATH_TO_REPODATA_FOLDER> fragment from the baseurl parameter so that the baseurl points to the root of the repository. An example of the /etc/yum.repos.d/artifactory.repo file for the wallarm-centos-upload-local sample repository: !include \"en/../include/artifactory-centos-code-snippet.md\" Install the epel-release package on the host: # yum install epel-release Now you can follow any installation instructions for CentOS. You will need to skip the step where the repository is added because you have set up a local repository instead. #### Info:: See also: * [Installing a filter node based on NGINX or NGINX Plus.][doc-install-nginx] * [Installing a filter node on the Kong platform.][doc-install-kong] * [Separate postanalytics installation.][doc-install-postanalytics]","title":"How to Install Wallarm Packages from the Local JFrog Artifactory Repository for CentOS"},{"location":"en/admin-en/integration-guides/repo-mirroring/centos/how-to-use-mirrored-repo/#how-to-install-wallarm-packages-from-the-local-jfrog-artifactory-repository-for-centos","text":"To install Wallarm packages from the JFrog Artifactory repository on a host dedicated to a filter node, perform the following actions on this host: Navigate to the JFrog Artifactory web UI via either the domain name or IP address (e.g., http://jfrog.example.local:8081/artifactory ). Log in to the web UI with a user account. Click the Artifacts menu entry and select a repository containing the Wallarm packages. Click the Set Me Up link. A pop-up window will appear. Type your user account\u2019s password in the Type Password field and press Enter . Now, the instructions in this window will contain your credentials. Scroll down to the yum configuration example and click the Copy Snippet to Clipboard button to copy this example to the clipboard. Create a yum configuration file (e.g., /etc/yum.repos.d/artifactory.repo ) and paste the copied snippet into it. #### Warning:: Important! Make sure to remove the <PATH_TO_REPODATA_FOLDER> fragment from the baseurl parameter so that the baseurl points to the root of the repository. An example of the /etc/yum.repos.d/artifactory.repo file for the wallarm-centos-upload-local sample repository: !include \"en/../include/artifactory-centos-code-snippet.md\" Install the epel-release package on the host: # yum install epel-release Now you can follow any installation instructions for CentOS. You will need to skip the step where the repository is added because you have set up a local repository instead. #### Info:: See also: * [Installing a filter node based on NGINX or NGINX Plus.][doc-install-nginx] * [Installing a filter node on the Kong platform.][doc-install-kong] * [Separate postanalytics installation.][doc-install-postanalytics]","title":"How to Install Wallarm Packages from the Local JFrog Artifactory Repository for CentOS"},{"location":"en/admin-en/monitoring/available-metrics/","text":"Available Metrics \u00b6 Metric Format Types of Wallarm Metrics NGINX Metrics and NGINX Wallarm Module Metrics Postanalytics Module Metrics Metric Format \u00b6 The collectd metrics have the following view: host/plugin[-plugin_instance]/type[-type_instance] Detailed description of metric format is available by the link . Note In the list of available metrics below, the host name (the host/ part) is omitted. When using the collectd_nagios utility, the host name must be omitted. It is set separately using the -H parameter ( more about using the utility ). Back to the table of contents \u25b2 Types of Wallarm Metrics \u00b6 Allowed types of Wallarm metrics are described below. The type is stored in the type metric parameter. gauge is a numerical representation of the measured value. The value can both increase and decrease. derive is the rate of change of the measured value since the previous measurement (derived value). The value can both increase and decrease. counter is similar to the gauge metric. The value can only increase. Back to the table of contents \u25b2 NGINX Metrics and NGINX Wallarm Module Metrics \u00b6 Number of Requests \u00b6 The number of requests processed by the filter node since installation. Metric: curl_json-wallarm_nginx/gauge-requests Metric value: 0 for the off mode >0 for the monitoring / block mode Rate of change: curl_json-wallarm_nginx/derive-requests Troubleshooting recommendations: 1. Check if the filter node settings are correct. 2. Check the filter node operation as described in the instruction . The value should increase by 1 after sending one test attack. Number of Attacks \u00b6 The number of attacks detected by the filter node since installation. Metric: curl_json-wallarm_nginx/gauge-attacks Metric value: 0 for the off mode >0 for the monitoring / block mode Rate of change: curl_json-wallarm_nginx/derive-attacks Troubleshooting recommendations: 1. Check if the filter node settings are correct. 2. Check the filter node operation as described in the instruction . The value should increase by 1 after sending one test attack. Number of Blocked Requests \u00b6 The number of requests blocked by the filter node since installation. This metric is collected if the filter node is in the block mode . Metric: curl_json-wallarm_nginx/gauge-blocked Metric value: 0 for the off / monitoring mode >0 for the block mode Rate of change: curl_json-wallarm_nginx/derive-blocked Troubleshooting recommendations: 1. Check if the filter node settings are correct and make sure the filter node is in the block mode. 2. Check the filter node operation as described in the instruction . The value should increase by 1 after sending one test attack. Number of Abnormal Requests \u00b6 The number of requests that were considered abnormal for the application. Temporarily, the metric collects all requests processed by the filter node. Metric: curl_json-wallarm_nginx/gauge-abnormal Metric value: temporarily equal to gauge-requests Rate of change: curl_json-wallarm_nginx/derive-abnormal Troubleshooting recommendations: temporarily does not matter Number of Lost Requests \u00b6 The number of requests not analyzed by the postanalytics module and not passed to Wallarm API. Blocking rules are applied to these requests, but requests are not visible in your Wallarm account and not taken into account when analyzing next requests. The number is the sum of tnt_errors and api_errors . Metric: curl_json-wallarm_nginx/gauge-requests_lost Metric value: 0 , the sum of tnt_errors and api_errors Rate of change: curl_json-wallarm_nginx/derive-requests_lost Troubleshooting recommendations: follow the instructions for tnt_errors and api_errors Number of Requests not Analyzed by the Postanalytics Module \u00b6 The number of requests not analyzed by the postanalytics module. The metric is collected if sending requests to the postanalytics module is configured ( wallarm_upstream_backend tarantool ). Blocking rules are applied to these requests, but requests are not visible in your Wallarm account and not taken into account when analyzing next requests. Metric: curl_json-wallarm_nginx/gauge-tnt_errors Metric value: 0 Rate of change: curl_json-wallarm_nginx/derive-tnt_errors Troubleshooting recommendations: Get the NGINX and Tarantool logs and analyze errors if any. Check if the Tarantool server address ( wallarm_tarantool_upstream ) is correct. Check that enough memory is allocated for Tarantool ( wallarm_ts_request_memory_limit ). Contact the Wallarm support team and provide the data above if the issue was not resolved. Number of Requests not Passed to the Wallarm API \u00b6 The number of requests not passed to Wallarm API. The metric is collected if passing requests to Wallarm API is configured ( wallarm_upstream_backend api ). Blocking rules are applied to these requests, but requests are not visible in your Wallarm account and not taken into account when analyzing next requests. Metric: curl_json-wallarm_nginx/gauge-api_errors Metric value: 0 Rate of change: curl_json-wallarm_nginx/derive-api_errors Troubleshooting recommendations: Get the NGINX and Tarantool logs and analyze errors if any. Check if Wallarm API settings ( wallarm_api_conf ) are correct. Check that enough memory is allocated for Tarantool ( wallarm_ts_request_memory_limit ). Contact the Wallarm support team and provide the data above if the issue was not resolved. Number of Issues Completed NGINX Worker Process Abnormally \u00b6 The number of issues led to abnormal completion of the NGINX worker process. The most common reason for abnormal completion is a critical error in NGINX. Metric: curl_json-wallarm_nginx/gauge-segfaults Metric value: 0 Rate of change: curl_json-wallarm_nginx/derive-segfaults Troubleshooting recommendations: 1. Collect the data about current state using the /usr/share/wallarm-common/collect-info.sh script. 2. Provide the generated file to the Wallarm support team for investigation. Number of Situations when the Virtual Memory Limit was Exceeded \u00b6 The number of situations when the virtual memory limit was exceeded. Metric: curl_json-wallarm_nginx/gauge-memfaults if the limit in your system was exceeded curl_json-wallarm_nginx/gauge-softmemfaults if the limit for proton.db +lom was exceeded ( wallarm_ts_request_memory_limit ) Metric value: 0 Rate of change: curl_json-wallarm_nginx/derive-memfaults for curl_json-wallarm_nginx/gauge-memfaults curl_json-wallarm_nginx/derive-softmemfaults for curl_json-wallarm_nginx/gauge-softmemfaults Troubleshooting recommendations: 1. Collect the data about current state using the /usr/share/wallarm-common/collect-info.sh script. 2. Provide the generated file to the Wallarm support team for investigation. Request Analysis Time (in Seconds) \u00b6 Time spent by the filter node analyzing requests since installation. Metric: curl_json-wallarm_nginx/gauge-time_detect Metric value: >0 Rate of change: curl_json-wallarm_nginx/derive-time_detect Troubleshooting recommendations: 1. Check if the filter node settings are correct. 2. Check the filter node operation as described in the instruction . The value should increase by 1 after sending one test attack. Version of proton.db \u00b6 The version of proton.db in use. Metric: curl_json-wallarm_nginx/gauge-db_id Metric value: no limits Version of LOM \u00b6 The version of LOM in use. Metric: curl_json-wallarm_nginx/gauge-lom_id Metric value: no limits proton.db and LOM Pairs \u00b6 Number of proton.db and LOM Pairs \u00b6 The number of proton.db and LOM pairs in use. Metric: curl_json-wallarm_nginx/gauge-proton_instances-total Metric value: >0 Troubleshooting recommendations: 1. Check if the filter node settings are correct. 2. Check if the path to the proton.db file is specified correctly ( wallarm_global_trainingset_path ). 3. Check if the path to the LOM file is specified correctly ( wallarm_local_trainingset_path ). Number of Successfully Downloaded proton.db and LOM Pairs \u00b6 The number of proton.db and LOM pairs that were successfully downloaded and read. Metric: curl_json-wallarm_nginx/gauge-proton_instances-success Metric value: is equal to proton_instances-total Troubleshooting recommendations: 1. Check if the filter node settings are correct. 2. Check if the path to the proton.db file is specified correctly ( wallarm_global_trainingset_path ). 3. Check if the path to the LOM file is specified correctly ( wallarm_local_trainingset_path ). Number of proton.db and LOM Pairs Downloaded from Last Saved Files \u00b6 The number of proton.db and LOM pairs downloaded from last saved files. These files store last successfully downloaded pairs. If pairs were updated but not downloaded, the data from last saved files used. Metric: curl_json-wallarm_nginx/gauge-proton_instances-fallback Metric value: >0 Troubleshooting recommendations: 1. Check if the filter node settings are correct. 2. Check if the path to the proton.db file is specified correctly ( wallarm_global_trainingset_path ). 3. Check if the path to the LOM file is specified correctly ( wallarm_local_trainingset_path ). Number of inactive proton.db and LOM Pairs \u00b6 The number of connected proton.db and LOM pairs that could not be read. Metric: curl_json-wallarm_nginx/gauge-proton_instances-failed Metric value: 0 Troubleshooting recommendations: 1. Check if the filter node settings are correct. 2. Check if the path to the proton.db file is specified correctly ( wallarm_global_trainingset_path ). 3. Check if the path to the LOM file is specified correctly ( wallarm_local_trainingset_path ). Back to the table of contents \u25b2 Postanalytics Module Metrics \u00b6 Identifier of the Last Processed Request \u00b6 ID of the last processed request. The value can both increase and decrease. Metric: wallarm-tarantool/counter-last_request_id if the value increased wallarm-tarantool/gauge-last_request_id if the value increased or decreased Metric value: no limits Troubleshooting recommendations: if there are incoming requests but the value is not changed, check if the filter node settings are correct Deleted Requests \u00b6 Indication of Deleted Requests \u00b6 The flag signaling that requests with attacks are deleted from the postanalytics module but not sent to the cloud . Metric: wallarm-tarantool/gauge-export_drops_flag Metric value: 0 if requests are not deleted 1 if requests are deleted (not enough memory, please follow the instructions below) Troubleshooting recommendations: Increase the wallarm_ts_request_memory_limit value. Install the postanalytics module in a separate server pool following the instructions . Number of Deleted Requests \u00b6 The number of requests with attacks that were deleted from the postanalytics module but were not sent to the cloud . The number of attacks in the request does not affect the value. The metric is collected if wallarm-tarantool/gauge-export_drops_flag: 1 . It is recommended to use the wallarm-tarantool/gauge-export_drops_flag metric when configuring monitoring notifications. Metric: wallarm-tarantool/gauge-export_drops Metric value: 0 Rate of change: wallarm-tarantool/derive-export_drops Troubleshooting recommendations: Increase the wallarm_ts_request_memory_limit value. Install the postanalytics module in a separate server pool following the instructions . Request Export Delay (in Seconds) \u00b6 The delay between the recording of a request by the postanalytics module and downloading of the information about detected attacks to the Wallarm cloud. Metric: wallarm-tarantool/gauge-export_delay Metric value: optimal if <60 warning if >60 critical if >300 Troubleshooting recommendations: Read logs from the /var/log/wallarm/export-attacks.log file and analyze errors. Increased value can be caused by low network throughput from the filter node to Wallarm\u2019s API service. Check that enough memory is allocated for Tarantool ( wallarm_ts_request_memory_limit ). The tnt_errors metric also increases if allocated memory is exceeded. Time of Storing Requests in the Postanalytics Module (in Seconds) \u00b6 Time that the postanalytics module stores requests. The value depends on the amount of memory allocated to the postanalytics module and on the size and properties of the processed HTTP requests. The shorter the interval, the worse the detection algorithms work\u2014because they rely on historical data. As a result, if intervals are too short, an attacker can perform brute force attacks faster, without being noticed. In this case, less data will be obtained on the attacker's behavior history. Metric: wallarm-tarantool/gauge-timeframe_size Metric value: optimal if >900 warning if <900 critical if <300 Troubleshooting recommendations: Increase the wallarm_ts_request_memory_limit value. Install the postanalytics module in a separate server pool following the instructions . Back to the table of contents \u25b2","title":"Available Metrics"},{"location":"en/admin-en/monitoring/available-metrics/#available-metrics","text":"Metric Format Types of Wallarm Metrics NGINX Metrics and NGINX Wallarm Module Metrics Postanalytics Module Metrics","title":"Available Metrics"},{"location":"en/admin-en/monitoring/available-metrics/#metric-format","text":"The collectd metrics have the following view: host/plugin[-plugin_instance]/type[-type_instance] Detailed description of metric format is available by the link . Note In the list of available metrics below, the host name (the host/ part) is omitted. When using the collectd_nagios utility, the host name must be omitted. It is set separately using the -H parameter ( more about using the utility ). Back to the table of contents \u25b2","title":"Metric Format"},{"location":"en/admin-en/monitoring/available-metrics/#types-of-wallarm-metrics","text":"Allowed types of Wallarm metrics are described below. The type is stored in the type metric parameter. gauge is a numerical representation of the measured value. The value can both increase and decrease. derive is the rate of change of the measured value since the previous measurement (derived value). The value can both increase and decrease. counter is similar to the gauge metric. The value can only increase. Back to the table of contents \u25b2","title":"Types of Wallarm Metrics"},{"location":"en/admin-en/monitoring/available-metrics/#nginx-metrics-and-nginx-wallarm-module-metrics","text":"","title":"NGINX Metrics and NGINX Wallarm Module Metrics"},{"location":"en/admin-en/monitoring/available-metrics/#number-of-requests","text":"The number of requests processed by the filter node since installation. Metric: curl_json-wallarm_nginx/gauge-requests Metric value: 0 for the off mode >0 for the monitoring / block mode Rate of change: curl_json-wallarm_nginx/derive-requests Troubleshooting recommendations: 1. Check if the filter node settings are correct. 2. Check the filter node operation as described in the instruction . The value should increase by 1 after sending one test attack.","title":"Number of Requests"},{"location":"en/admin-en/monitoring/available-metrics/#number-of-attacks","text":"The number of attacks detected by the filter node since installation. Metric: curl_json-wallarm_nginx/gauge-attacks Metric value: 0 for the off mode >0 for the monitoring / block mode Rate of change: curl_json-wallarm_nginx/derive-attacks Troubleshooting recommendations: 1. Check if the filter node settings are correct. 2. Check the filter node operation as described in the instruction . The value should increase by 1 after sending one test attack.","title":"Number of Attacks"},{"location":"en/admin-en/monitoring/available-metrics/#number-of-blocked-requests","text":"The number of requests blocked by the filter node since installation. This metric is collected if the filter node is in the block mode . Metric: curl_json-wallarm_nginx/gauge-blocked Metric value: 0 for the off / monitoring mode >0 for the block mode Rate of change: curl_json-wallarm_nginx/derive-blocked Troubleshooting recommendations: 1. Check if the filter node settings are correct and make sure the filter node is in the block mode. 2. Check the filter node operation as described in the instruction . The value should increase by 1 after sending one test attack.","title":"Number of Blocked Requests"},{"location":"en/admin-en/monitoring/available-metrics/#number-of-abnormal-requests","text":"The number of requests that were considered abnormal for the application. Temporarily, the metric collects all requests processed by the filter node. Metric: curl_json-wallarm_nginx/gauge-abnormal Metric value: temporarily equal to gauge-requests Rate of change: curl_json-wallarm_nginx/derive-abnormal Troubleshooting recommendations: temporarily does not matter","title":"Number of Abnormal Requests"},{"location":"en/admin-en/monitoring/available-metrics/#number-of-lost-requests","text":"The number of requests not analyzed by the postanalytics module and not passed to Wallarm API. Blocking rules are applied to these requests, but requests are not visible in your Wallarm account and not taken into account when analyzing next requests. The number is the sum of tnt_errors and api_errors . Metric: curl_json-wallarm_nginx/gauge-requests_lost Metric value: 0 , the sum of tnt_errors and api_errors Rate of change: curl_json-wallarm_nginx/derive-requests_lost Troubleshooting recommendations: follow the instructions for tnt_errors and api_errors","title":"Number of Lost Requests"},{"location":"en/admin-en/monitoring/available-metrics/#number-of-requests-not-analyzed-by-the-postanalytics-module","text":"The number of requests not analyzed by the postanalytics module. The metric is collected if sending requests to the postanalytics module is configured ( wallarm_upstream_backend tarantool ). Blocking rules are applied to these requests, but requests are not visible in your Wallarm account and not taken into account when analyzing next requests. Metric: curl_json-wallarm_nginx/gauge-tnt_errors Metric value: 0 Rate of change: curl_json-wallarm_nginx/derive-tnt_errors Troubleshooting recommendations: Get the NGINX and Tarantool logs and analyze errors if any. Check if the Tarantool server address ( wallarm_tarantool_upstream ) is correct. Check that enough memory is allocated for Tarantool ( wallarm_ts_request_memory_limit ). Contact the Wallarm support team and provide the data above if the issue was not resolved.","title":"Number of Requests not Analyzed by the Postanalytics Module"},{"location":"en/admin-en/monitoring/available-metrics/#number-of-requests-not-passed-to-the-wallarm-api","text":"The number of requests not passed to Wallarm API. The metric is collected if passing requests to Wallarm API is configured ( wallarm_upstream_backend api ). Blocking rules are applied to these requests, but requests are not visible in your Wallarm account and not taken into account when analyzing next requests. Metric: curl_json-wallarm_nginx/gauge-api_errors Metric value: 0 Rate of change: curl_json-wallarm_nginx/derive-api_errors Troubleshooting recommendations: Get the NGINX and Tarantool logs and analyze errors if any. Check if Wallarm API settings ( wallarm_api_conf ) are correct. Check that enough memory is allocated for Tarantool ( wallarm_ts_request_memory_limit ). Contact the Wallarm support team and provide the data above if the issue was not resolved.","title":"Number of Requests not Passed to the Wallarm API"},{"location":"en/admin-en/monitoring/available-metrics/#number-of-issues-completed-nginx-worker-process-abnormally","text":"The number of issues led to abnormal completion of the NGINX worker process. The most common reason for abnormal completion is a critical error in NGINX. Metric: curl_json-wallarm_nginx/gauge-segfaults Metric value: 0 Rate of change: curl_json-wallarm_nginx/derive-segfaults Troubleshooting recommendations: 1. Collect the data about current state using the /usr/share/wallarm-common/collect-info.sh script. 2. Provide the generated file to the Wallarm support team for investigation.","title":"Number of Issues Completed NGINX Worker Process Abnormally"},{"location":"en/admin-en/monitoring/available-metrics/#number-of-situations-when-the-virtual-memory-limit-was-exceeded","text":"The number of situations when the virtual memory limit was exceeded. Metric: curl_json-wallarm_nginx/gauge-memfaults if the limit in your system was exceeded curl_json-wallarm_nginx/gauge-softmemfaults if the limit for proton.db +lom was exceeded ( wallarm_ts_request_memory_limit ) Metric value: 0 Rate of change: curl_json-wallarm_nginx/derive-memfaults for curl_json-wallarm_nginx/gauge-memfaults curl_json-wallarm_nginx/derive-softmemfaults for curl_json-wallarm_nginx/gauge-softmemfaults Troubleshooting recommendations: 1. Collect the data about current state using the /usr/share/wallarm-common/collect-info.sh script. 2. Provide the generated file to the Wallarm support team for investigation.","title":"Number of Situations when the Virtual Memory Limit was Exceeded"},{"location":"en/admin-en/monitoring/available-metrics/#request-analysis-time-in-seconds","text":"Time spent by the filter node analyzing requests since installation. Metric: curl_json-wallarm_nginx/gauge-time_detect Metric value: >0 Rate of change: curl_json-wallarm_nginx/derive-time_detect Troubleshooting recommendations: 1. Check if the filter node settings are correct. 2. Check the filter node operation as described in the instruction . The value should increase by 1 after sending one test attack.","title":"Request Analysis Time (in Seconds)"},{"location":"en/admin-en/monitoring/available-metrics/#version-of-protondb","text":"The version of proton.db in use. Metric: curl_json-wallarm_nginx/gauge-db_id Metric value: no limits","title":"Version of proton.db"},{"location":"en/admin-en/monitoring/available-metrics/#version-of-lom","text":"The version of LOM in use. Metric: curl_json-wallarm_nginx/gauge-lom_id Metric value: no limits","title":"Version of LOM"},{"location":"en/admin-en/monitoring/available-metrics/#protondb-and-lom-pairs","text":"","title":"proton.db and LOM Pairs"},{"location":"en/admin-en/monitoring/available-metrics/#number-of-protondb-and-lom-pairs","text":"The number of proton.db and LOM pairs in use. Metric: curl_json-wallarm_nginx/gauge-proton_instances-total Metric value: >0 Troubleshooting recommendations: 1. Check if the filter node settings are correct. 2. Check if the path to the proton.db file is specified correctly ( wallarm_global_trainingset_path ). 3. Check if the path to the LOM file is specified correctly ( wallarm_local_trainingset_path ).","title":"Number of proton.db and LOM Pairs"},{"location":"en/admin-en/monitoring/available-metrics/#number-of-successfully-downloaded-protondb-and-lom-pairs","text":"The number of proton.db and LOM pairs that were successfully downloaded and read. Metric: curl_json-wallarm_nginx/gauge-proton_instances-success Metric value: is equal to proton_instances-total Troubleshooting recommendations: 1. Check if the filter node settings are correct. 2. Check if the path to the proton.db file is specified correctly ( wallarm_global_trainingset_path ). 3. Check if the path to the LOM file is specified correctly ( wallarm_local_trainingset_path ).","title":"Number of Successfully Downloaded proton.db and LOM Pairs"},{"location":"en/admin-en/monitoring/available-metrics/#number-of-protondb-and-lom-pairs-downloaded-from-last-saved-files","text":"The number of proton.db and LOM pairs downloaded from last saved files. These files store last successfully downloaded pairs. If pairs were updated but not downloaded, the data from last saved files used. Metric: curl_json-wallarm_nginx/gauge-proton_instances-fallback Metric value: >0 Troubleshooting recommendations: 1. Check if the filter node settings are correct. 2. Check if the path to the proton.db file is specified correctly ( wallarm_global_trainingset_path ). 3. Check if the path to the LOM file is specified correctly ( wallarm_local_trainingset_path ).","title":"Number of proton.db and LOM Pairs Downloaded from Last Saved Files"},{"location":"en/admin-en/monitoring/available-metrics/#number-of-inactive-protondb-and-lom-pairs","text":"The number of connected proton.db and LOM pairs that could not be read. Metric: curl_json-wallarm_nginx/gauge-proton_instances-failed Metric value: 0 Troubleshooting recommendations: 1. Check if the filter node settings are correct. 2. Check if the path to the proton.db file is specified correctly ( wallarm_global_trainingset_path ). 3. Check if the path to the LOM file is specified correctly ( wallarm_local_trainingset_path ). Back to the table of contents \u25b2","title":"Number of inactive proton.db and LOM Pairs"},{"location":"en/admin-en/monitoring/available-metrics/#postanalytics-module-metrics","text":"","title":"Postanalytics Module Metrics"},{"location":"en/admin-en/monitoring/available-metrics/#identifier-of-the-last-processed-request","text":"ID of the last processed request. The value can both increase and decrease. Metric: wallarm-tarantool/counter-last_request_id if the value increased wallarm-tarantool/gauge-last_request_id if the value increased or decreased Metric value: no limits Troubleshooting recommendations: if there are incoming requests but the value is not changed, check if the filter node settings are correct","title":"Identifier of the Last Processed Request"},{"location":"en/admin-en/monitoring/available-metrics/#deleted-requests","text":"","title":"Deleted Requests"},{"location":"en/admin-en/monitoring/available-metrics/#indication-of-deleted-requests","text":"The flag signaling that requests with attacks are deleted from the postanalytics module but not sent to the cloud . Metric: wallarm-tarantool/gauge-export_drops_flag Metric value: 0 if requests are not deleted 1 if requests are deleted (not enough memory, please follow the instructions below) Troubleshooting recommendations: Increase the wallarm_ts_request_memory_limit value. Install the postanalytics module in a separate server pool following the instructions .","title":"Indication of Deleted Requests"},{"location":"en/admin-en/monitoring/available-metrics/#number-of-deleted-requests","text":"The number of requests with attacks that were deleted from the postanalytics module but were not sent to the cloud . The number of attacks in the request does not affect the value. The metric is collected if wallarm-tarantool/gauge-export_drops_flag: 1 . It is recommended to use the wallarm-tarantool/gauge-export_drops_flag metric when configuring monitoring notifications. Metric: wallarm-tarantool/gauge-export_drops Metric value: 0 Rate of change: wallarm-tarantool/derive-export_drops Troubleshooting recommendations: Increase the wallarm_ts_request_memory_limit value. Install the postanalytics module in a separate server pool following the instructions .","title":"Number of Deleted Requests"},{"location":"en/admin-en/monitoring/available-metrics/#request-export-delay-in-seconds","text":"The delay between the recording of a request by the postanalytics module and downloading of the information about detected attacks to the Wallarm cloud. Metric: wallarm-tarantool/gauge-export_delay Metric value: optimal if <60 warning if >60 critical if >300 Troubleshooting recommendations: Read logs from the /var/log/wallarm/export-attacks.log file and analyze errors. Increased value can be caused by low network throughput from the filter node to Wallarm\u2019s API service. Check that enough memory is allocated for Tarantool ( wallarm_ts_request_memory_limit ). The tnt_errors metric also increases if allocated memory is exceeded.","title":"Request Export Delay (in Seconds)"},{"location":"en/admin-en/monitoring/available-metrics/#time-of-storing-requests-in-the-postanalytics-module-in-seconds","text":"Time that the postanalytics module stores requests. The value depends on the amount of memory allocated to the postanalytics module and on the size and properties of the processed HTTP requests. The shorter the interval, the worse the detection algorithms work\u2014because they rely on historical data. As a result, if intervals are too short, an attacker can perform brute force attacks faster, without being noticed. In this case, less data will be obtained on the attacker's behavior history. Metric: wallarm-tarantool/gauge-timeframe_size Metric value: optimal if >900 warning if <900 critical if <300 Troubleshooting recommendations: Increase the wallarm_ts_request_memory_limit value. Install the postanalytics module in a separate server pool following the instructions . Back to the table of contents \u25b2","title":"Time of Storing Requests in the Postanalytics Module (in Seconds)"},{"location":"en/admin-en/monitoring/collectd-nagios/","text":"Exporting Metrics to Nagios via the collectd-nagios Utility \u00b6 This document provides an example of exporting filter node metrics to the Nagios monitoring system (the Nagios Core edition is suggested; however, this document is suitable for any Nagios edition) using the collectd-nagios utility. #### Info:: Assumptions and requirements * The `collectd` service must be configured for working via a Unix domain socket (see [here][doc-unixsock] for details). * It is assumed that you already have the Nagios Core edition installed. If not, install Nagios Core (for example, follow these [instructions][link-nagios-core-install]). You can use another edition of Nagios if necessary (for example, Nagios XI). The \u201cNagios\u201d term will be used hereinafter to refer to any edition of Nagios, unless stated otherwise. * You must have the ability to connect to the filter node and the Nagios host (for example, via the SSH protocol), and work under the `root` account or another account with superuser rights. * The [Nagios Remote Plugin Executor][link-nrpe-docs] service (which will be referred to as *NRPE* throughout this example) must be installed on the filter node. Example Workflow \u00b6 #### Info:: Example of metric This example shows how to work with the single [`curl_json-wallarm_nginx/gauge-attacks`](../../admin-en/monitoring/available-metrics.md#number-of-attacks-reported) metric, which shows the number of attacks on an application that is protected by the filter node. The following deployment scheme is used in this document: The Wallarm filter node is deployed on a host accessible via the 10.0.30.5 IP address and the node.example.local fully qualified domain name. Nagios is installed on a separate host accessible via the 10.0.30.30 IP address. To execute commands on a remote host, the NRPE plugin is used. The plugin comprises The nrpe service that is installed on the monitored host alongside the filter node. It listens on the 5666/TCP standard NRPE port. The check_nrpe NRPE Nagios plugin that is installed on the Nagios host and allows Nagios to execute commands on the remote host where the nrpe service is installed. NRPE will be used to call the collectd_nagios utility that provides the collectd metrics in a Nagios-compatible format. Configuring Metrics Export to Nagios \u00b6 #### Info:: A note on this installation example This document describes how to install and configure the NRPE plugin when Nagios is already installed with default parameters (it is assumed that Nagios is installed in the `/usr/local/nagios` directory, and uses the `nagios` user to operate). If you are doing a non-default installation of the plugin or Nagios, adjust the corresponding commands and instructions from the document as needed. To configure metrics export from the filter node to Nagios, follow these steps: 1. Configure NRPE to Communicate with the Nagios Host \u00b6 To do this, on a filter node host: Open the NRPE configuration file (default: /usr/local/nagios/etc/nrpe.cfg ). Add the IP address or fully qualified domain name of the Nagios server to the allowed_hosts directive in this file. For example, if the Nagios host uses the 10.0.30.30 IP address: allowed_hosts=127.0.0.1,10.0.30.30 Restart the NRPE service by executing the appropriate command: {% termtabs name=\"CentOS 6 and Ubuntu 14.04\" -%} service nrpe restart \u00b6 {%- tab name=\"Other supported distributions\" -%} systemctl restart nrpe \u00b6 {%- endtermtabs %} 2. Install the Nagios NRPE Plugin on the Nagios Host \u00b6 To do this, on the Nagios host, take the following steps: Download and unzip the source files for the NRPE plugin, and install the necessary utilities to build and install the plugin (see the NRPE documentation for details). Go to the directory with the plugin source code, build from sources, then install the plugin. The minimal steps to take are: # ./configure # make all # make install-plugin 3. Make Sure the NRPE Nagios Plugin Successfully Interacts with the NRPE Service \u00b6 To do this, execute the following command on the Nagios host: # /usr/local/nagios/libexec/check_nrpe -H node.example.local If NRPE is operating normally, the command\u2019s output should contain an NRPE version (e.g., NRPE v3.2.1 ) 4. Define the check_nrpe Command to Run the NRPE Nagios Plugin with a Single Argument on the Nagios Host \u00b6 To do this, add to the /usr/local/nagios/etc/objects/commands.cfg file the following lines: define command{ command_name check_nrpe command_line $USER1$/check_nrpe -H $HOSTADDRESS$ -c $ARG1$ } 5. Install the collectd_nagios Utility on the Filter Node Host \u00b6 Execute one of the following commands: {% termtabs name=\"DEB-based distributions\" %} apt install --no-install-recommends collectd-utils \u00b6 {%- tab name=\"RPM-based distributions\" -%} yum install collectd-utils \u00b6 {% endtermtabs %} 6. Configure the collectd-nagios Utility to Run with Elevated Privileges on Behalf of the nagios User \u00b6 To do this, perform the following steps on the filter node host: Using the visudo utility, add the following line to the /etc/sudoers file: nagios ALL=(ALL:ALL) NOPASSWD:/usr/bin/collectd-nagios This allows the nagios user to run the collectd-nagios utility with superuser privileges using sudo without the need to provide any passwords. #### Info:: Running collectd-nagios with superuser privileges The utility must be run with superuser privileges because it uses the collectd Unix domain socket to receive data. Only a superuser can access this socket. Make sure that the nagios user can receive metric values from collectd by executing the following test command: # sudo -u nagios sudo /usr/bin/collectd-nagios -s /var/run/collectd-unixsock -n curl_json-wallarm_nginx/gauge-attacks -H node.example.local This command allows the nagios user to get the value of the curl_json-wallarm_nginx/gauge-attacks metric (the number of recorded attacks) for the node.example.local host. Example of command output: OKAY: 0 critical, 0 warning, 1 okay | value=0.000000;;;; Add a prefix to the NRPE service configuration file so that it will be able to execute commands using the sudo utility: command_prefix=/usr/bin/sudo 7. Add Commands to the NRPE Service Configuration File on the Filter Node to Get the Required Metrics \u00b6 For example, to create a command named check_wallarm_nginx_attacks that will receive the curl_json-wallarm_nginx/gauge-attacks metric for the filter node with the node.example.local fully qualified domain name, add the following line to the NRPE service\u2019s configuration file: command[check_wallarm_nginx_attacks]=/usr/bin/collectd-nagios -s /var/run/collectd-unixsock -n curl_json-wallarm_nginx/gauge-attacks -H node.example.local #### Info:: How to set threshold values for a metric If necessary, you can specify a range of values for which the `collectd-nagios` utility will return the `WARNING` or `CRITICAL` status by using the corresponding `-w` and `-c` options (detailed information is available in the utility [documentation][link-collectd-docs]). After you have added all necessary commands to the NRPE service configuration file, restart the service by executing the appropriate command: {% termtabs name=\"CentOS 6 and Ubuntu 14.04\" -%} service nrpe restart \u00b6 {%- tab name=\"Other supported distributions\" -%} systemctl restart nrpe \u00b6 {%- endtermtabs %} 8. On the Nagios Host, Use the Configuration Files to Specify the Filter Node Host and to Define the Services to Monitor \u00b6 #### Info:: Services and Metrics This document assumes that one Nagios service is equivalent to one metric. For example, this can be done as follows: Create a /usr/local/nagios/etc/objects/nodes.cfg file with the following contents: define host{ use linux-server host_name node.example.local address 10.0.30.5 } define service { use generic-service host_name node.example.local check_command check_nrpe!check_wallarm_nginx_attacks max_check_attempts 5 service_description wallarm_nginx_attacks } This file defines the node.example.local host with the 10.0.30.5 IP address and the command to check the status of the wallarm_nginx_attacks service, which means receiving the curl_json-wallarm_nginx/gauge-attacks metric from the filter node (see the description of the check_wallarm_nginx_attacks command). Add the following line to the Nagios configuration file (by default, /usr/local/nagios/etc/nagios.cfg ): cfg_file=/usr/local/nagios/etc/objects/nodes.cfg This is necessary for Nagios to start using the data from the nodes.cfg file on the next start. Restart the Nagios service by running the appropriate command: {% termtabs name=\"CentOS 6 and Ubuntu 14.04\" -%} service nagios restart \u00b6 {%- tab name=\"Other supported distributions\" -%} systemctl restart nagios \u00b6 {%- endtermtabs %} Setup is Complete \u00b6 Nagios is now monitoring the service associated with the specific metric of the filter node. If necessary, you can define other commands and services to check the metrics you are interested in. #### Info:: Information about NRPE Sources of additional information about NRPE: * [README][link-nrpe-readme] of the NRPE on GitHub; * NRPE documentation ([PDF][link-nrpe-pdf]).","title":"Exporting Metrics to Nagios via the `collectd-nagios` Utility"},{"location":"en/admin-en/monitoring/collectd-nagios/#exporting-metrics-to-nagios-via-the-collectd-nagios-utility","text":"This document provides an example of exporting filter node metrics to the Nagios monitoring system (the Nagios Core edition is suggested; however, this document is suitable for any Nagios edition) using the collectd-nagios utility. #### Info:: Assumptions and requirements * The `collectd` service must be configured for working via a Unix domain socket (see [here][doc-unixsock] for details). * It is assumed that you already have the Nagios Core edition installed. If not, install Nagios Core (for example, follow these [instructions][link-nagios-core-install]). You can use another edition of Nagios if necessary (for example, Nagios XI). The \u201cNagios\u201d term will be used hereinafter to refer to any edition of Nagios, unless stated otherwise. * You must have the ability to connect to the filter node and the Nagios host (for example, via the SSH protocol), and work under the `root` account or another account with superuser rights. * The [Nagios Remote Plugin Executor][link-nrpe-docs] service (which will be referred to as *NRPE* throughout this example) must be installed on the filter node.","title":"Exporting Metrics to Nagios via the collectd-nagios Utility"},{"location":"en/admin-en/monitoring/collectd-nagios/#example-workflow","text":"#### Info:: Example of metric This example shows how to work with the single [`curl_json-wallarm_nginx/gauge-attacks`](../../admin-en/monitoring/available-metrics.md#number-of-attacks-reported) metric, which shows the number of attacks on an application that is protected by the filter node. The following deployment scheme is used in this document: The Wallarm filter node is deployed on a host accessible via the 10.0.30.5 IP address and the node.example.local fully qualified domain name. Nagios is installed on a separate host accessible via the 10.0.30.30 IP address. To execute commands on a remote host, the NRPE plugin is used. The plugin comprises The nrpe service that is installed on the monitored host alongside the filter node. It listens on the 5666/TCP standard NRPE port. The check_nrpe NRPE Nagios plugin that is installed on the Nagios host and allows Nagios to execute commands on the remote host where the nrpe service is installed. NRPE will be used to call the collectd_nagios utility that provides the collectd metrics in a Nagios-compatible format.","title":"Example Workflow"},{"location":"en/admin-en/monitoring/collectd-nagios/#configuring-metrics-export-to-nagios","text":"#### Info:: A note on this installation example This document describes how to install and configure the NRPE plugin when Nagios is already installed with default parameters (it is assumed that Nagios is installed in the `/usr/local/nagios` directory, and uses the `nagios` user to operate). If you are doing a non-default installation of the plugin or Nagios, adjust the corresponding commands and instructions from the document as needed. To configure metrics export from the filter node to Nagios, follow these steps:","title":"Configuring Metrics Export to Nagios"},{"location":"en/admin-en/monitoring/collectd-nagios/#1-configure-nrpe-to-communicate-with-the-nagios-host","text":"To do this, on a filter node host: Open the NRPE configuration file (default: /usr/local/nagios/etc/nrpe.cfg ). Add the IP address or fully qualified domain name of the Nagios server to the allowed_hosts directive in this file. For example, if the Nagios host uses the 10.0.30.30 IP address: allowed_hosts=127.0.0.1,10.0.30.30 Restart the NRPE service by executing the appropriate command: {% termtabs name=\"CentOS 6 and Ubuntu 14.04\" -%}","title":"1.  Configure NRPE to Communicate with the Nagios Host"},{"location":"en/admin-en/monitoring/collectd-nagios/#service-nrpe-restart","text":"{%- tab name=\"Other supported distributions\" -%}","title":"service nrpe restart"},{"location":"en/admin-en/monitoring/collectd-nagios/#systemctl-restart-nrpe","text":"{%- endtermtabs %}","title":"systemctl restart nrpe"},{"location":"en/admin-en/monitoring/collectd-nagios/#2-install-the-nagios-nrpe-plugin-on-the-nagios-host","text":"To do this, on the Nagios host, take the following steps: Download and unzip the source files for the NRPE plugin, and install the necessary utilities to build and install the plugin (see the NRPE documentation for details). Go to the directory with the plugin source code, build from sources, then install the plugin. The minimal steps to take are: # ./configure # make all # make install-plugin","title":"2.  Install the Nagios NRPE Plugin on the Nagios Host"},{"location":"en/admin-en/monitoring/collectd-nagios/#3-make-sure-the-nrpe-nagios-plugin-successfully-interacts-with-the-nrpe-service","text":"To do this, execute the following command on the Nagios host: # /usr/local/nagios/libexec/check_nrpe -H node.example.local If NRPE is operating normally, the command\u2019s output should contain an NRPE version (e.g., NRPE v3.2.1 )","title":"3.  Make Sure the NRPE Nagios Plugin Successfully Interacts with the NRPE Service"},{"location":"en/admin-en/monitoring/collectd-nagios/#4-define-the-check_nrpe-command-to-run-the-nrpe-nagios-plugin-with-a-single-argument-on-the-nagios-host","text":"To do this, add to the /usr/local/nagios/etc/objects/commands.cfg file the following lines: define command{ command_name check_nrpe command_line $USER1$/check_nrpe -H $HOSTADDRESS$ -c $ARG1$ }","title":"4.  Define the check_nrpe Command to Run the NRPE Nagios Plugin with a Single Argument on the Nagios Host"},{"location":"en/admin-en/monitoring/collectd-nagios/#5-install-the-collectd_nagios-utility-on-the-filter-node-host","text":"Execute one of the following commands: {% termtabs name=\"DEB-based distributions\" %}","title":"5. Install the collectd_nagios Utility on the Filter Node Host"},{"location":"en/admin-en/monitoring/collectd-nagios/#apt-install-no-install-recommends-collectd-utils","text":"{%- tab name=\"RPM-based distributions\" -%}","title":"apt install --no-install-recommends collectd-utils"},{"location":"en/admin-en/monitoring/collectd-nagios/#yum-install-collectd-utils","text":"{% endtermtabs %}","title":"yum install collectd-utils"},{"location":"en/admin-en/monitoring/collectd-nagios/#6-configure-the-collectd-nagios-utility-to-run-with-elevated-privileges-on-behalf-of-the-nagios-user","text":"To do this, perform the following steps on the filter node host: Using the visudo utility, add the following line to the /etc/sudoers file: nagios ALL=(ALL:ALL) NOPASSWD:/usr/bin/collectd-nagios This allows the nagios user to run the collectd-nagios utility with superuser privileges using sudo without the need to provide any passwords. #### Info:: Running collectd-nagios with superuser privileges The utility must be run with superuser privileges because it uses the collectd Unix domain socket to receive data. Only a superuser can access this socket. Make sure that the nagios user can receive metric values from collectd by executing the following test command: # sudo -u nagios sudo /usr/bin/collectd-nagios -s /var/run/collectd-unixsock -n curl_json-wallarm_nginx/gauge-attacks -H node.example.local This command allows the nagios user to get the value of the curl_json-wallarm_nginx/gauge-attacks metric (the number of recorded attacks) for the node.example.local host. Example of command output: OKAY: 0 critical, 0 warning, 1 okay | value=0.000000;;;; Add a prefix to the NRPE service configuration file so that it will be able to execute commands using the sudo utility: command_prefix=/usr/bin/sudo","title":"6.  Configure the collectd-nagios Utility to Run with Elevated Privileges on Behalf of the nagios User"},{"location":"en/admin-en/monitoring/collectd-nagios/#7-add-commands-to-the-nrpe-service-configuration-file-on-the-filter-node-to-get-the-required-metrics","text":"For example, to create a command named check_wallarm_nginx_attacks that will receive the curl_json-wallarm_nginx/gauge-attacks metric for the filter node with the node.example.local fully qualified domain name, add the following line to the NRPE service\u2019s configuration file: command[check_wallarm_nginx_attacks]=/usr/bin/collectd-nagios -s /var/run/collectd-unixsock -n curl_json-wallarm_nginx/gauge-attacks -H node.example.local #### Info:: How to set threshold values for a metric If necessary, you can specify a range of values for which the `collectd-nagios` utility will return the `WARNING` or `CRITICAL` status by using the corresponding `-w` and `-c` options (detailed information is available in the utility [documentation][link-collectd-docs]). After you have added all necessary commands to the NRPE service configuration file, restart the service by executing the appropriate command: {% termtabs name=\"CentOS 6 and Ubuntu 14.04\" -%}","title":"7.  Add Commands to the NRPE Service Configuration File on the Filter Node to Get the Required Metrics"},{"location":"en/admin-en/monitoring/collectd-nagios/#service-nrpe-restart_1","text":"{%- tab name=\"Other supported distributions\" -%}","title":"service nrpe restart"},{"location":"en/admin-en/monitoring/collectd-nagios/#systemctl-restart-nrpe_1","text":"{%- endtermtabs %}","title":"systemctl restart nrpe"},{"location":"en/admin-en/monitoring/collectd-nagios/#8-on-the-nagios-host-use-the-configuration-files-to-specify-the-filter-node-host-and-to-define-the-services-to-monitor","text":"#### Info:: Services and Metrics This document assumes that one Nagios service is equivalent to one metric. For example, this can be done as follows: Create a /usr/local/nagios/etc/objects/nodes.cfg file with the following contents: define host{ use linux-server host_name node.example.local address 10.0.30.5 } define service { use generic-service host_name node.example.local check_command check_nrpe!check_wallarm_nginx_attacks max_check_attempts 5 service_description wallarm_nginx_attacks } This file defines the node.example.local host with the 10.0.30.5 IP address and the command to check the status of the wallarm_nginx_attacks service, which means receiving the curl_json-wallarm_nginx/gauge-attacks metric from the filter node (see the description of the check_wallarm_nginx_attacks command). Add the following line to the Nagios configuration file (by default, /usr/local/nagios/etc/nagios.cfg ): cfg_file=/usr/local/nagios/etc/objects/nodes.cfg This is necessary for Nagios to start using the data from the nodes.cfg file on the next start. Restart the Nagios service by running the appropriate command: {% termtabs name=\"CentOS 6 and Ubuntu 14.04\" -%}","title":"8.  On the Nagios Host, Use the Configuration Files to Specify the Filter Node Host and to Define the Services to Monitor"},{"location":"en/admin-en/monitoring/collectd-nagios/#service-nagios-restart","text":"{%- tab name=\"Other supported distributions\" -%}","title":"service nagios restart"},{"location":"en/admin-en/monitoring/collectd-nagios/#systemctl-restart-nagios","text":"{%- endtermtabs %}","title":"systemctl restart nagios"},{"location":"en/admin-en/monitoring/collectd-nagios/#setup-is-complete","text":"Nagios is now monitoring the service associated with the specific metric of the filter node. If necessary, you can define other commands and services to check the metrics you are interested in. #### Info:: Information about NRPE Sources of additional information about NRPE: * [README][link-nrpe-readme] of the NRPE on GitHub; * NRPE documentation ([PDF][link-nrpe-pdf]).","title":"Setup is Complete"},{"location":"en/admin-en/monitoring/collectd-zabbix/","text":"Exporting Metrics to Zabbix via the collectd-nagios Utility \u00b6 This document provides an example of exporting filter node metrics to the Zabbix monitoring system using the collectd-nagios utility. Example Workflow \u00b6 #### Info:: Example of metric This example shows how to work with the single [`curl_json-wallarm_nginx/gauge-attacks`](../../admin-en/monitoring/available-metrics.md#number-of-attacks-reported) metric, which shows the number of attacks on an application that is protected by the filter node. The following deployment scheme is used in this document: The Wallarm filter node is deployed on a host accessible via the 10.0.30.5 IP address and the node.example.local fully qualified domain name. The host has the Zabbix agent 4.0 LTS deployed that * Downloads the filter node metrics using the collectd-nagios utility. * Listens to incoming connections on the 10050/TCP port (thus passive checks will take place with the use of Zabbix Appliance). * Passes metric values to Zabbix Appliance. On a dedicated host with the 10.0.30.30 IP address (hereinafter referred to as the Docker host), the Zabbix Appliance 4.0 LTS is deployed in the form of a Docker container. The Zabbix Appliance includes * A Zabbix server that periodically polls the Zabbix agent installed on the filter node host to get information about changes to any monitored metrics). * The Zabbix server management web interface, available on the 80/TCP port. Configuring Metrics Export to Zabbix \u00b6 #### Info:: Prerequisites It is assumed that * The `collectd` service has been configured for working via a Unix domain socket (see [here][doc-unixsock] for details). * [Docker Community Edition][link-docker-ce] is already installed on the `10.0.30.30` Docker host. * The `node.example.local` filter node is already deployed, configured, available for further configuration (for example, via the SSH protocol), and working. Deploying Zabbix \u00b6 To deploy the Zabbix Appliance 4.0 LTS, execute the following command on the Docker host: # docker run --name zabbix-appliance -p 80:80 -d zabbix/zabbix-appliance:alpine-4.0-latest Now you have a working Zabbix monitoring system. Deploying the Zabbix Agent \u00b6 Install the Zabbix Agent 4.0 LTS on a host with the filter node: Connect to the filter node (for example, using the SSH protocol). Make sure you are running as root or another account with superuser privileges. Connect the Zabbix repositories (use the \u201cInstall Zabbix repository\u201d entry of the instructions for your operating system). Install the Zabbix agent by executing the appropriate command: {% termtabs name=\"DEB-based distributions\" %} apt install zabbix-agent \u00b6 {%- tab name=\"RPM-based distributions\" -%} yum install zabbix-agent \u00b6 {% endtermtabs %} Configure the Zabbix Agent to work with the Zabbix Appliance. To do this, make the following changes to the /etc/zabbix/zabbix_agentd.conf configuration file: Server=10.0.30.30 # Zabbix IP address Hostname=node.example.local # FQDN of the host with the filter node Configuring Metrics Collection Using the Zabbix Agent \u00b6 Connect to the filter node (for example, using the SSH protocol) and configure the collection of metrics using the Zabbix agent. To do this, perform the following steps on the host with the filter node: 1. Install the collectd_nagios utility \u00b6 Execute the appropriate command: {% termtabs name=\"DEB-based distributions\" %} apt install --no-install-recommends collectd-utils \u00b6 {%- tab name=\"RPM-based distributions\" -%} yum install collectd-utils \u00b6 {% endtermtabs %} 2. Configure the collectd-nagios utility to run with elevated privileges on behalf of the zabbix user \u00b6 Use the visudo utility to add the following line to the /etc/sudoers file: zabbix ALL=(ALL:ALL) NOPASSWD:/usr/bin/collectd-nagios This allows the zabbix user to run the collectd-nagios utility with superuser privileges using the sudo utility without the need to provide a password. #### Info:: Running `collectd-nagios` with superuser privileges The utility must be run with superuser privileges because it uses the `collectd` Unix domain socket to receive data. Only a superuser can access this socket. As an alternative to adding the `zabbix` user to the `sudoers` list, you can configure the Zabbix agent to run as `root` (this may pose a security risk, so this is not recommended). This can be achieved by enabling the [`AllowRoot`][link-allowroot] option in the agent configuration file. 3. Make sure that the zabbix user can receive metric values from collectd \u00b6 Run the following test command on the filter node: # sudo -u zabbix sudo /usr/bin/collectd-nagios -s /var/run/collectd-unixsock -n curl_json-wallarm_nginx/gauge-attacks -H node.example.local This command invokes the zabbix user to get the value of the curl_json-wallarm_nginx/gauge-attacks metric for the node.example.local host with the filter node. Example of the command output: OKAY: 0 critical, 0 warning, 1 okay | value=0.000000;;;; 4. Add custom parameters to the Zabbix agent configuration file on the filter node host to get the metrics you need \u00b6 For example, to create a custom parameter wallarm_nginx-gauge-attacks that corresponds to the curl_json-wallarm_nginx/gauge-attacks metric for a filter node with the fully qualified domain name node.example.local , add the following line to the configuration file: UserParameter=wallarm_nginx-gauge-attacks, sudo /usr/bin/collectd-nagios -s /var/run/collectd-unixsock -n curl_json-wallarm_nginx/gauge-attacks -H node.example.local | sed -n \"s/.*value\\=\\(.*\\);;;;.*/\\1/p\" #### Info:: Extracting a metric value To extract the value of a metric that goes after `value=` in the output of the `collectd-nagios` utility (e.g., `OKAY: 0 critical, 0 warning, 1 okay | value=0.000000;;;;`), this output is piped to the `sed` utility that executes the `sed` script to strip off unnecessary characters. See the [`sed` documentation][link-sed-docs] for more information on the syntax of its scripts. 5. After all the necessary commands have been added to the Zabbix agent configuration file, restart the agent \u00b6 {% termtabs name=\"CentOS 6 and Ubuntu 14.04\" -%} service zabbix-agent restart \u00b6 {%- tab name=\"Other supported distributions\" -%} systemctl restart zabbix-agent \u00b6 {%- endtermtabs %} Setup Complete \u00b6 Now you can monitor user parameters related to Wallarm-specific metrics with Zabbix.","title":"Exporting Metrics to Zabbix via the `collectd-nagios` Utility"},{"location":"en/admin-en/monitoring/collectd-zabbix/#exporting-metrics-to-zabbix-via-the-collectd-nagios-utility","text":"This document provides an example of exporting filter node metrics to the Zabbix monitoring system using the collectd-nagios utility.","title":"Exporting Metrics to Zabbix via the collectd-nagios Utility"},{"location":"en/admin-en/monitoring/collectd-zabbix/#example-workflow","text":"#### Info:: Example of metric This example shows how to work with the single [`curl_json-wallarm_nginx/gauge-attacks`](../../admin-en/monitoring/available-metrics.md#number-of-attacks-reported) metric, which shows the number of attacks on an application that is protected by the filter node. The following deployment scheme is used in this document: The Wallarm filter node is deployed on a host accessible via the 10.0.30.5 IP address and the node.example.local fully qualified domain name. The host has the Zabbix agent 4.0 LTS deployed that * Downloads the filter node metrics using the collectd-nagios utility. * Listens to incoming connections on the 10050/TCP port (thus passive checks will take place with the use of Zabbix Appliance). * Passes metric values to Zabbix Appliance. On a dedicated host with the 10.0.30.30 IP address (hereinafter referred to as the Docker host), the Zabbix Appliance 4.0 LTS is deployed in the form of a Docker container. The Zabbix Appliance includes * A Zabbix server that periodically polls the Zabbix agent installed on the filter node host to get information about changes to any monitored metrics). * The Zabbix server management web interface, available on the 80/TCP port.","title":"Example Workflow"},{"location":"en/admin-en/monitoring/collectd-zabbix/#configuring-metrics-export-to-zabbix","text":"#### Info:: Prerequisites It is assumed that * The `collectd` service has been configured for working via a Unix domain socket (see [here][doc-unixsock] for details). * [Docker Community Edition][link-docker-ce] is already installed on the `10.0.30.30` Docker host. * The `node.example.local` filter node is already deployed, configured, available for further configuration (for example, via the SSH protocol), and working.","title":"Configuring Metrics Export to Zabbix"},{"location":"en/admin-en/monitoring/collectd-zabbix/#deploying-zabbix","text":"To deploy the Zabbix Appliance 4.0 LTS, execute the following command on the Docker host: # docker run --name zabbix-appliance -p 80:80 -d zabbix/zabbix-appliance:alpine-4.0-latest Now you have a working Zabbix monitoring system.","title":"Deploying Zabbix"},{"location":"en/admin-en/monitoring/collectd-zabbix/#deploying-the-zabbix-agent","text":"Install the Zabbix Agent 4.0 LTS on a host with the filter node: Connect to the filter node (for example, using the SSH protocol). Make sure you are running as root or another account with superuser privileges. Connect the Zabbix repositories (use the \u201cInstall Zabbix repository\u201d entry of the instructions for your operating system). Install the Zabbix agent by executing the appropriate command: {% termtabs name=\"DEB-based distributions\" %}","title":"Deploying the Zabbix Agent"},{"location":"en/admin-en/monitoring/collectd-zabbix/#apt-install-zabbix-agent","text":"{%- tab name=\"RPM-based distributions\" -%}","title":"apt install zabbix-agent"},{"location":"en/admin-en/monitoring/collectd-zabbix/#yum-install-zabbix-agent","text":"{% endtermtabs %} Configure the Zabbix Agent to work with the Zabbix Appliance. To do this, make the following changes to the /etc/zabbix/zabbix_agentd.conf configuration file: Server=10.0.30.30 # Zabbix IP address Hostname=node.example.local # FQDN of the host with the filter node","title":"yum install zabbix-agent"},{"location":"en/admin-en/monitoring/collectd-zabbix/#configuring-metrics-collection-using-the-zabbix-agent","text":"Connect to the filter node (for example, using the SSH protocol) and configure the collection of metrics using the Zabbix agent. To do this, perform the following steps on the host with the filter node:","title":"Configuring Metrics Collection Using the Zabbix Agent"},{"location":"en/admin-en/monitoring/collectd-zabbix/#1-install-the-collectd_nagios-utility","text":"Execute the appropriate command: {% termtabs name=\"DEB-based distributions\" %}","title":"1.  Install the collectd_nagios utility"},{"location":"en/admin-en/monitoring/collectd-zabbix/#apt-install-no-install-recommends-collectd-utils","text":"{%- tab name=\"RPM-based distributions\" -%}","title":"apt install --no-install-recommends collectd-utils"},{"location":"en/admin-en/monitoring/collectd-zabbix/#yum-install-collectd-utils","text":"{% endtermtabs %}","title":"yum install collectd-utils"},{"location":"en/admin-en/monitoring/collectd-zabbix/#2-configure-the-collectd-nagios-utility-to-run-with-elevated-privileges-on-behalf-of-the-zabbix-user","text":"Use the visudo utility to add the following line to the /etc/sudoers file: zabbix ALL=(ALL:ALL) NOPASSWD:/usr/bin/collectd-nagios This allows the zabbix user to run the collectd-nagios utility with superuser privileges using the sudo utility without the need to provide a password. #### Info:: Running `collectd-nagios` with superuser privileges The utility must be run with superuser privileges because it uses the `collectd` Unix domain socket to receive data. Only a superuser can access this socket. As an alternative to adding the `zabbix` user to the `sudoers` list, you can configure the Zabbix agent to run as `root` (this may pose a security risk, so this is not recommended). This can be achieved by enabling the [`AllowRoot`][link-allowroot] option in the agent configuration file.","title":"2.  Configure the collectd-nagios utility to run with elevated privileges on behalf of the zabbix user"},{"location":"en/admin-en/monitoring/collectd-zabbix/#3-make-sure-that-the-zabbix-user-can-receive-metric-values-from-collectd","text":"Run the following test command on the filter node: # sudo -u zabbix sudo /usr/bin/collectd-nagios -s /var/run/collectd-unixsock -n curl_json-wallarm_nginx/gauge-attacks -H node.example.local This command invokes the zabbix user to get the value of the curl_json-wallarm_nginx/gauge-attacks metric for the node.example.local host with the filter node. Example of the command output: OKAY: 0 critical, 0 warning, 1 okay | value=0.000000;;;;","title":"3.  Make sure that the zabbix user can receive metric values from collectd"},{"location":"en/admin-en/monitoring/collectd-zabbix/#4-add-custom-parameters-to-the-zabbix-agent-configuration-file-on-the-filter-node-host-to-get-the-metrics-you-need","text":"For example, to create a custom parameter wallarm_nginx-gauge-attacks that corresponds to the curl_json-wallarm_nginx/gauge-attacks metric for a filter node with the fully qualified domain name node.example.local , add the following line to the configuration file: UserParameter=wallarm_nginx-gauge-attacks, sudo /usr/bin/collectd-nagios -s /var/run/collectd-unixsock -n curl_json-wallarm_nginx/gauge-attacks -H node.example.local | sed -n \"s/.*value\\=\\(.*\\);;;;.*/\\1/p\" #### Info:: Extracting a metric value To extract the value of a metric that goes after `value=` in the output of the `collectd-nagios` utility (e.g., `OKAY: 0 critical, 0 warning, 1 okay | value=0.000000;;;;`), this output is piped to the `sed` utility that executes the `sed` script to strip off unnecessary characters. See the [`sed` documentation][link-sed-docs] for more information on the syntax of its scripts.","title":"4.  Add custom parameters to the Zabbix agent configuration file on the filter node host to get the metrics you need"},{"location":"en/admin-en/monitoring/collectd-zabbix/#5-after-all-the-necessary-commands-have-been-added-to-the-zabbix-agent-configuration-file-restart-the-agent","text":"{% termtabs name=\"CentOS 6 and Ubuntu 14.04\" -%}","title":"5.  After all the necessary commands have been added to the Zabbix agent configuration file, restart the agent"},{"location":"en/admin-en/monitoring/collectd-zabbix/#service-zabbix-agent-restart","text":"{%- tab name=\"Other supported distributions\" -%}","title":"service zabbix-agent restart"},{"location":"en/admin-en/monitoring/collectd-zabbix/#systemctl-restart-zabbix-agent","text":"{%- endtermtabs %}","title":"systemctl restart zabbix-agent"},{"location":"en/admin-en/monitoring/collectd-zabbix/#setup-complete","text":"Now you can monitor user parameters related to Wallarm-specific metrics with Zabbix.","title":"Setup Complete"},{"location":"en/admin-en/monitoring/fetching-metrics/","text":"How to Fetch Metrics \u00b6 Exporting Metrics Directly From collectd \u00b6 You can export the metrics collected by collectd directly to the tools that support working with collectd data streams. #### Warning:: Prerequisites All further steps must be performed as a superuser (e.g., `root`). Exporting Metrics via the collectd Network Plugin \u00b6 Configure and connect the network plugin to collectd : In the /etc/collectd/collectd.conf.d/ directory, create a file with the .conf extension (e.g., export-via-network.conf ) and the following content: LoadPlugin network <Plugin \"network\"> Server \"Server IPv4/v6 address or FQDN\" \"Server port\" </Plugin> As stated in this file, the plugin will be loaded upon starting collectd , operate in the client mode, and send the filter node\u2019s metrics data to the specified server. Configure a server that will receive data from the collectd client. The necessary configuration steps depend on the selected server (see examples for collectd and InfluxDB ). #### Info:: Working with the Network Plugin The network plugin works over UDP (see the plugin documentation ). Make sure that the server allows communication over UDP for metrics collection to be operational. Restart the collectd service by executing the appropriate command: {%- termtabs name=\"CentOS 6.x or Ubuntu 14.04 LTS\" -%} service collectd restart \u00b6 {%- tab name=\"Other supported distributions\" -%} systemctl restart collectd \u00b6 {%- endtermtabs -%} #### Info:: Example Read an [example of exporting metrics][doc-network-plugin-example] to InfluxDB via the Network plugin with subsequent visualization of the metrics in Grafana. Exporting Metrics via the collectd Write Plugins \u00b6 To configure export of metrics via the collectd write plugins , refer to the documentation of the corresponding plugin. #### Info:: Example To get basic information about using write plugins, read an [example of exporting metrics][doc-write-plugin-example] to Graphite with subsequent visualization of the metrics in Grafana. Exporting Metrics Using the collectd-nagios Utility \u00b6 To export metrics using this method: Install the collectd-nagios utility on a host with a filter node by running the appropriate command (for a filter node installed on Linux): {% termtabs name=\"DEB-based distributions\" %} apt install --no-install-recommends collectd-utils \u00b6 {%- tab name=\"RPM-based distributions\" -%} yum install collectd-utils \u00b6 {% endtermtabs %} <!-- --> > #### Info:: Docker image > > The filter node Docker image ships with a preinstalled `collectd-nagios` utility. <!-- --> Make sure that you can run this utility with elevated privileges either on behalf of a superuser (for example, root ) or as a regular user. In the latter case, add the user to the sudoers file with the NOPASSWD directive, and use the sudo utility. #### Info:: Working with the Docker container When executing the collectd-nagios utility in a Docker container with the filter node, elevation of privileges is not required. Connect and configure the UnixSock plugin to transmit the collectd metrics via a Unix domain socket. To do this, create the file /etc/collectd/collectd.conf.d/unixsock.conf with the following content: LoadPlugin unixsock <Plugin unixsock> SocketFile \"/var/run/collectd-unixsock\" SocketGroup \"root\" SocketPerms \"0770\" DeleteSocket true </Plugin> Restart the collectd service by executing the appropriate command: {%- termtabs name=\"CentOS 6.x or Ubuntu 14.04 LTS\" -%} service collectd restart \u00b6 {%- tab name=\"Other supported distributions\" -%} systemctl restart collectd \u00b6 {%- endtermtabs -%} Get the value of the necessary metric by running the appropriate command: {%- codetabs name=\"Linux\", type=\"text\" -%} /usr/bin/collectd-nagios -s /var/run/collectd-unixsock -n -H \u00b6 {%- language name=\"Docker\", type=\"text\" -%} docker exec /usr/bin/collectd-nagios -s /var/run/collectd-unixsock -n -H \u00b6 {%- endcodetabs -%} <!-- --> > #### Info:: Getting the Docker container\u2019s ID > > You can find the value of the container identifier by running the `docker ps` command (see the \u201cCONTAINER ID\u201d column). #### Info:: Setting Thresholds for the `collectd-nagios` Utility If necessary, you can specify a range of values for which the `collectd-nagios` utility will return the `WARNING` or `CRITICAL` status by using the corresponding `-w` and `-c` options (detailed information is available in the utility [documentation][link-nagios-plugin-docs]). Examples of using the utility: To get the value of the curl_json-wallarm_nginx/gauge-attacks metric (at the time collectd-nagios was called) on the Linux host node.example.local with the filter node, run the following command: # /usr/bin/collectd-nagios -s /var/run/collectd-unixsock -n curl_json-wallarm_nginx/gauge-attacks -H node.example.local To get the value of the curl_json-wallarm_nginx/gauge-attacks metric (at the time collectd-nagios was called) for the filter node running in the Docker container with the wallarm-node name and the 95d278317794 identifier, run the following command: # docker exec wallarm-node /usr/bin/collectd-nagios -s /var/run/collectd-unixsock -n curl_json-wallarm_nginx/gauge-attacks -H 95d278317794 #### Info:: More examples To get basic information about using the `collectd-nagios` utility, read examples of exporting metrics * [to the Nagios monitoring system][doc-nagios-example] and * [to the Zabbix monitoring system][doc-zabbix-example]. Sending Notifications from collectd \u00b6 Notifications are configured in the file {%- codetabs name=\"DEB-based distributions\" -%} /etc/collectd/conf.d/traps.conf {%- language name=\"RPM-based distributions\" -%} /etc/collectd.d/traps.conf {%- endcodetabs -%} A general description of how notifications work is available here . More detailed information about how to set up notifications is available here . Possible methods of sending notifications: NSCA and NSCA-ng SNMP TRAP email messages custom scripts","title":"How to Fetch Metrics"},{"location":"en/admin-en/monitoring/fetching-metrics/#how-to-fetch-metrics","text":"","title":"How to Fetch Metrics"},{"location":"en/admin-en/monitoring/fetching-metrics/#exporting-metrics-directly-from-collectd","text":"You can export the metrics collected by collectd directly to the tools that support working with collectd data streams. #### Warning:: Prerequisites All further steps must be performed as a superuser (e.g., `root`).","title":"Exporting Metrics Directly From collectd"},{"location":"en/admin-en/monitoring/fetching-metrics/#exporting-metrics-via-the-collectd-network-plugin","text":"Configure and connect the network plugin to collectd : In the /etc/collectd/collectd.conf.d/ directory, create a file with the .conf extension (e.g., export-via-network.conf ) and the following content: LoadPlugin network <Plugin \"network\"> Server \"Server IPv4/v6 address or FQDN\" \"Server port\" </Plugin> As stated in this file, the plugin will be loaded upon starting collectd , operate in the client mode, and send the filter node\u2019s metrics data to the specified server. Configure a server that will receive data from the collectd client. The necessary configuration steps depend on the selected server (see examples for collectd and InfluxDB ). #### Info:: Working with the Network Plugin The network plugin works over UDP (see the plugin documentation ). Make sure that the server allows communication over UDP for metrics collection to be operational. Restart the collectd service by executing the appropriate command: {%- termtabs name=\"CentOS 6.x or Ubuntu 14.04 LTS\" -%}","title":"Exporting Metrics via the collectd Network Plugin"},{"location":"en/admin-en/monitoring/fetching-metrics/#service-collectd-restart","text":"{%- tab name=\"Other supported distributions\" -%}","title":"service collectd restart"},{"location":"en/admin-en/monitoring/fetching-metrics/#systemctl-restart-collectd","text":"{%- endtermtabs -%} #### Info:: Example Read an [example of exporting metrics][doc-network-plugin-example] to InfluxDB via the Network plugin with subsequent visualization of the metrics in Grafana.","title":"systemctl restart collectd"},{"location":"en/admin-en/monitoring/fetching-metrics/#exporting-metrics-via-the-collectd-write-plugins","text":"To configure export of metrics via the collectd write plugins , refer to the documentation of the corresponding plugin. #### Info:: Example To get basic information about using write plugins, read an [example of exporting metrics][doc-write-plugin-example] to Graphite with subsequent visualization of the metrics in Grafana.","title":"Exporting Metrics via the collectd Write Plugins"},{"location":"en/admin-en/monitoring/fetching-metrics/#exporting-metrics-using-the-collectd-nagios-utility","text":"To export metrics using this method: Install the collectd-nagios utility on a host with a filter node by running the appropriate command (for a filter node installed on Linux): {% termtabs name=\"DEB-based distributions\" %}","title":"Exporting Metrics Using the collectd-nagios Utility"},{"location":"en/admin-en/monitoring/fetching-metrics/#apt-install-no-install-recommends-collectd-utils","text":"{%- tab name=\"RPM-based distributions\" -%}","title":"apt install --no-install-recommends collectd-utils"},{"location":"en/admin-en/monitoring/fetching-metrics/#yum-install-collectd-utils","text":"{% endtermtabs %} <!-- --> > #### Info:: Docker image > > The filter node Docker image ships with a preinstalled `collectd-nagios` utility. <!-- --> Make sure that you can run this utility with elevated privileges either on behalf of a superuser (for example, root ) or as a regular user. In the latter case, add the user to the sudoers file with the NOPASSWD directive, and use the sudo utility. #### Info:: Working with the Docker container When executing the collectd-nagios utility in a Docker container with the filter node, elevation of privileges is not required. Connect and configure the UnixSock plugin to transmit the collectd metrics via a Unix domain socket. To do this, create the file /etc/collectd/collectd.conf.d/unixsock.conf with the following content: LoadPlugin unixsock <Plugin unixsock> SocketFile \"/var/run/collectd-unixsock\" SocketGroup \"root\" SocketPerms \"0770\" DeleteSocket true </Plugin> Restart the collectd service by executing the appropriate command: {%- termtabs name=\"CentOS 6.x or Ubuntu 14.04 LTS\" -%}","title":"yum install collectd-utils"},{"location":"en/admin-en/monitoring/fetching-metrics/#service-collectd-restart_1","text":"{%- tab name=\"Other supported distributions\" -%}","title":"service collectd restart"},{"location":"en/admin-en/monitoring/fetching-metrics/#systemctl-restart-collectd_1","text":"{%- endtermtabs -%} Get the value of the necessary metric by running the appropriate command: {%- codetabs name=\"Linux\", type=\"text\" -%}","title":"systemctl restart collectd"},{"location":"en/admin-en/monitoring/fetching-metrics/#usrbincollectd-nagios-s-varruncollectd-unixsock-n-h","text":"{%- language name=\"Docker\", type=\"text\" -%}","title":"/usr/bin/collectd-nagios -s /var/run/collectd-unixsock -n  -H "},{"location":"en/admin-en/monitoring/fetching-metrics/#docker-exec-usrbincollectd-nagios-s-varruncollectd-unixsock-n-h","text":"{%- endcodetabs -%} <!-- --> > #### Info:: Getting the Docker container\u2019s ID > > You can find the value of the container identifier by running the `docker ps` command (see the \u201cCONTAINER ID\u201d column). #### Info:: Setting Thresholds for the `collectd-nagios` Utility If necessary, you can specify a range of values for which the `collectd-nagios` utility will return the `WARNING` or `CRITICAL` status by using the corresponding `-w` and `-c` options (detailed information is available in the utility [documentation][link-nagios-plugin-docs]). Examples of using the utility: To get the value of the curl_json-wallarm_nginx/gauge-attacks metric (at the time collectd-nagios was called) on the Linux host node.example.local with the filter node, run the following command: # /usr/bin/collectd-nagios -s /var/run/collectd-unixsock -n curl_json-wallarm_nginx/gauge-attacks -H node.example.local To get the value of the curl_json-wallarm_nginx/gauge-attacks metric (at the time collectd-nagios was called) for the filter node running in the Docker container with the wallarm-node name and the 95d278317794 identifier, run the following command: # docker exec wallarm-node /usr/bin/collectd-nagios -s /var/run/collectd-unixsock -n curl_json-wallarm_nginx/gauge-attacks -H 95d278317794 #### Info:: More examples To get basic information about using the `collectd-nagios` utility, read examples of exporting metrics * [to the Nagios monitoring system][doc-nagios-example] and * [to the Zabbix monitoring system][doc-zabbix-example].","title":"docker exec  /usr/bin/collectd-nagios -s /var/run/collectd-unixsock -n  -H "},{"location":"en/admin-en/monitoring/fetching-metrics/#sending-notifications-from-collectd","text":"Notifications are configured in the file {%- codetabs name=\"DEB-based distributions\" -%} /etc/collectd/conf.d/traps.conf {%- language name=\"RPM-based distributions\" -%} /etc/collectd.d/traps.conf {%- endcodetabs -%} A general description of how notifications work is available here . More detailed information about how to set up notifications is available here . Possible methods of sending notifications: NSCA and NSCA-ng SNMP TRAP email messages custom scripts","title":"Sending Notifications from collectd"},{"location":"en/admin-en/monitoring/intro/","text":"Introduction \u00b6 You can monitor the state of a filter node using the node-provided metrics. These metrics are gathered by the collectd service that is installed on every Wallarm filter node. The collectd service provides several ways to transfer data and can serve as a source of metrics for many monitoring systems, offering you control over the state of the filter nodes. Need for Monitoring \u00b6 Failure or unstable work in the Wallarm module can lead to complete or partial denial of service for user requests to an application protected by a filter node. Failure of or unstable work in the postanalytics module can lead to inaccessibility of the following functionalities: Uploading attack data to the Wallarm cloud. As a result, the attacks will not be displayed on the Wallarm portal. Detecting behavioral attacks (see brute-force attacks ). Getting information about the structure of the protected application. You can monitor both the Wallarm module and the postanalytics module even if the latter is installed separately . #### Info:: Terminology agreement To monitor the Wallarm module and the postanalytics module, the same tools and methods are used; therefore both modules will be referred to as a \u201cfilter node\u201d throughout this guide, unless stated otherwise. All documents describing how to set up monitoring of a filter node are suitable for * separately deployed Wallarm modules, * separately deployed postanalytics modules, and * jointly deployed Wallarm and postanalytics modules. Prerequisites for Monitoring \u00b6 For monitoring to work, it is required that: NGINX returns the statistics to the filter node ( wallarm_status on ), the filter mode is in the monitoring / block mode . By default, this service is accessible at http://127.0.0.8/wallarm-status . If you configure the statistics service to be available at a non-standard address, you will need to correct the URL parameter accordingly in the collectd configuration file. The location of this file depends on the type of operating system distribution you have: {%- codetabs name=\"DEB-based distributions\", type=\"text\" -%} /etc/collectd/collectd.conf.d/nginx-wallarm.conf {%- language name=\"RPM-based distributions\", type=\"text\" -%} /etc/collectd.d/nginx-wallarm.conf {%- endcodetabs -%} If a non-standard IP address or port for Tarantool are used, you will need to correct the Tarantool configuration file accordingly. The location of this file depends on the type of operating system distribution you have: {%- codetabs name=\"DEB-based distributions\" -%} /etc/collectd/collectd.conf.d/wallarm-tarantool.conf {%- language name=\"RPM-based distributions\" -%} /etc/collectd.d/wallarm-tarantool.conf {%- endcodetabs -%} If SELinux is installed on the filter node host, make sure that SELinux is either configured or disabled . For simplicity, this document assumes that SELinux is disabled. How Metrics Look \u00b6 What the collectd Metrics Look Like \u00b6 A collectd metric identifier has the following format: host/plugin[-plugin_instance]/type[-type_instance] Where host : the host\u2019s Fully Qualified Domain Name (FQDN) for which the metric is obtained plugin : the name of the plugin with which the metric is obtained, -plugin_instance : the instance of the plugin, if one exists, type : the type of the metric value. Allowed types: counter derive gauge Detailed information about value types is available here . -type_instance : an instance of the type, if there is one. Instance type is equivalent to the value for which we want to get the metric. A full description of metric formats is available here . What Wallarm-Specific collectd Metrics Look Like \u00b6 The filter node uses collectd to collect Wallarm-specific metrics. Metrics of NGINX with the Wallarm module have the following format: host/curl_json-wallarm_nginx/type-type_instance Metrics of the postanalytics module have the following format: host/wallarm-tarantool/type-type_instance #### Info:: Metric Examples For a filter node on the `node.example.local` host: * `node.example.local/curl_json-wallarm_nginx/gauge-attacks` is the metric of the number of recorded attacks; * `node.example.local/wallarm-tarantool/gauge-export_delay` is the metric of the Tarantool export delay in seconds. A complete list of metrics that can be monitored is available [here][doc-available-metrics]. Methods of Fetching Metrics \u00b6 You can collect metrics from a filter node in several ways: By exporting data directly from the collectd service via the Network plugin for collectd . This plugin enables collectd to download metrics from a filter node to the collectd server or to the InfluxDB database. #### Info:: InfluxDB InfluxDB can be used for the aggregation of metrics from collectd and other data sources with subsequent visualization (for example, a Grafana monitoring system to visualize the metrics stored in the InfluxDB). via one of the write plugins for collectd . For example, you can export collected data to Graphite using the write_graphite plugin. #### Info:: Graphite Graphite can be used as a data source for monitoring and visualization systems (for example, Grafana ). This method is suitable for the following filter node deployment types: * in the clouds: Amazon AWS, Google Cloud; * on Linux for NGINX/NGINX Plus and Kong platforms. By exporting data via collectd-nagios . This utility receives the value of the given metric from collectd and presents it in a Nagios-compatible format . You can export metrics to Nagios or Zabbix monitoring systems by employing this utility. This method is supported by any Wallarm filter node, no matter how that node is deployed. By sending notifications from collectd when a metric has achieved a predetermined threshold value. This method is supported by any Wallarm filter node, no matter how that node is deployed.","title":"Introduction"},{"location":"en/admin-en/monitoring/intro/#introduction","text":"You can monitor the state of a filter node using the node-provided metrics. These metrics are gathered by the collectd service that is installed on every Wallarm filter node. The collectd service provides several ways to transfer data and can serve as a source of metrics for many monitoring systems, offering you control over the state of the filter nodes.","title":"Introduction"},{"location":"en/admin-en/monitoring/intro/#need-for-monitoring","text":"Failure or unstable work in the Wallarm module can lead to complete or partial denial of service for user requests to an application protected by a filter node. Failure of or unstable work in the postanalytics module can lead to inaccessibility of the following functionalities: Uploading attack data to the Wallarm cloud. As a result, the attacks will not be displayed on the Wallarm portal. Detecting behavioral attacks (see brute-force attacks ). Getting information about the structure of the protected application. You can monitor both the Wallarm module and the postanalytics module even if the latter is installed separately . #### Info:: Terminology agreement To monitor the Wallarm module and the postanalytics module, the same tools and methods are used; therefore both modules will be referred to as a \u201cfilter node\u201d throughout this guide, unless stated otherwise. All documents describing how to set up monitoring of a filter node are suitable for * separately deployed Wallarm modules, * separately deployed postanalytics modules, and * jointly deployed Wallarm and postanalytics modules.","title":"Need for Monitoring"},{"location":"en/admin-en/monitoring/intro/#prerequisites-for-monitoring","text":"For monitoring to work, it is required that: NGINX returns the statistics to the filter node ( wallarm_status on ), the filter mode is in the monitoring / block mode . By default, this service is accessible at http://127.0.0.8/wallarm-status . If you configure the statistics service to be available at a non-standard address, you will need to correct the URL parameter accordingly in the collectd configuration file. The location of this file depends on the type of operating system distribution you have: {%- codetabs name=\"DEB-based distributions\", type=\"text\" -%} /etc/collectd/collectd.conf.d/nginx-wallarm.conf {%- language name=\"RPM-based distributions\", type=\"text\" -%} /etc/collectd.d/nginx-wallarm.conf {%- endcodetabs -%} If a non-standard IP address or port for Tarantool are used, you will need to correct the Tarantool configuration file accordingly. The location of this file depends on the type of operating system distribution you have: {%- codetabs name=\"DEB-based distributions\" -%} /etc/collectd/collectd.conf.d/wallarm-tarantool.conf {%- language name=\"RPM-based distributions\" -%} /etc/collectd.d/wallarm-tarantool.conf {%- endcodetabs -%} If SELinux is installed on the filter node host, make sure that SELinux is either configured or disabled . For simplicity, this document assumes that SELinux is disabled.","title":"Prerequisites for Monitoring"},{"location":"en/admin-en/monitoring/intro/#how-metrics-look","text":"","title":"How Metrics Look"},{"location":"en/admin-en/monitoring/intro/#what-the-collectd-metrics-look-like","text":"A collectd metric identifier has the following format: host/plugin[-plugin_instance]/type[-type_instance] Where host : the host\u2019s Fully Qualified Domain Name (FQDN) for which the metric is obtained plugin : the name of the plugin with which the metric is obtained, -plugin_instance : the instance of the plugin, if one exists, type : the type of the metric value. Allowed types: counter derive gauge Detailed information about value types is available here . -type_instance : an instance of the type, if there is one. Instance type is equivalent to the value for which we want to get the metric. A full description of metric formats is available here .","title":"What the collectd Metrics Look Like"},{"location":"en/admin-en/monitoring/intro/#what-wallarm-specific-collectd-metrics-look-like","text":"The filter node uses collectd to collect Wallarm-specific metrics. Metrics of NGINX with the Wallarm module have the following format: host/curl_json-wallarm_nginx/type-type_instance Metrics of the postanalytics module have the following format: host/wallarm-tarantool/type-type_instance #### Info:: Metric Examples For a filter node on the `node.example.local` host: * `node.example.local/curl_json-wallarm_nginx/gauge-attacks` is the metric of the number of recorded attacks; * `node.example.local/wallarm-tarantool/gauge-export_delay` is the metric of the Tarantool export delay in seconds. A complete list of metrics that can be monitored is available [here][doc-available-metrics].","title":"What Wallarm-Specific collectd Metrics Look Like"},{"location":"en/admin-en/monitoring/intro/#methods-of-fetching-metrics","text":"You can collect metrics from a filter node in several ways: By exporting data directly from the collectd service via the Network plugin for collectd . This plugin enables collectd to download metrics from a filter node to the collectd server or to the InfluxDB database. #### Info:: InfluxDB InfluxDB can be used for the aggregation of metrics from collectd and other data sources with subsequent visualization (for example, a Grafana monitoring system to visualize the metrics stored in the InfluxDB). via one of the write plugins for collectd . For example, you can export collected data to Graphite using the write_graphite plugin. #### Info:: Graphite Graphite can be used as a data source for monitoring and visualization systems (for example, Grafana ). This method is suitable for the following filter node deployment types: * in the clouds: Amazon AWS, Google Cloud; * on Linux for NGINX/NGINX Plus and Kong platforms. By exporting data via collectd-nagios . This utility receives the value of the given metric from collectd and presents it in a Nagios-compatible format . You can export metrics to Nagios or Zabbix monitoring systems by employing this utility. This method is supported by any Wallarm filter node, no matter how that node is deployed. By sending notifications from collectd when a metric has achieved a predetermined threshold value. This method is supported by any Wallarm filter node, no matter how that node is deployed.","title":"Methods of Fetching Metrics"},{"location":"en/admin-en/monitoring/network-plugin-influxdb/","text":"Exporting Metrics to InfluxDB via the collectd Network Plugin \u00b6 This document provides an example of using the Network plugin to export metrics to the InfluxDB temporal database. It will also demonstrate how to visualize the metrics collected in InfluxDB using Grafana. Example Workflow \u00b6 #### Info:: Example of metric This example shows how to work with the single [`curl_json-wallarm_nginx/gauge-attacks`](../../admin-en/monitoring/available-metrics.md#number-of-attacks-reported) metric, which shows the number of attacks on an application that is protected by the filter node. The following deployment scheme is used in this document: The Wallarm filter node is deployed on a host accessible via the 10.0.30.5 IP address and the node.example.local fully qualified domain name. The network plugin for collectd on the filter node is configured in such a way that all metrics will be sent to the 10.0.30.30 InfluxDB server on port 25826/UDP . #### Info:: Network plugin features Please note that the plugin operates over UDP (see using examples and documentation of the network plugin). Both influxdb and grafana services are deployed as Docker containers on a separate host with the 10.0.30.30 IP address. The influxdb service with the InfluxDB database is configured as follows: * A collectd data source has been created (the collectd input according to InfluxDB terminology), which listens on the 25826/UDP port and writes incoming metrics to a database called collectd . * Communication with the InfluxDB API occurs via the 8086/TCP port. * The service shares a sample-net Docker network with the grafana service. The grafana service with Grafana is configured as follows: * The Grafana web console is available at http://10.0.30.30:3000 . * The service shares the sample-net Docker network with the influxdb service. Configuring Metrics Export to InfluxDB \u00b6 #### Info:: Prerequisites It is assumed that * [Docker Community Edition](https://docs.docker.com/install/) and [`docker-compose`](https://docs.docker.com/compose/install/) are already installed on the `10.0.30.30` Docker host. * The `node.example.local` filter node is already deployed, configured, available for further configuration (for example, via the SSH protocol), and working. Deploying InfluxDB and Grafana \u00b6 Deploy InfluxDB and Grafana on the Docker host: Create a working directory, for example, /tmp/influxdb-grafana , and navigate to it: # mkdir /tmp/influxdb-grafana # cd /tmp/influxdb-grafana For the InfluxDB data source to work, you will need a file named types.db that contains the collectd value types. This file describes the dataset specifications used by collectd . Such datasets include definitions of measurable types. Detailed information about this file is available here . Download the types.db file from the GitHub repository of the collectd project and put it in the working directory. Get the basic InfluxDB configuration file by running the following command: # docker run --rm influxdb influxd config > influxdb.conf Enable the collectd data source in the influxdb.conf InfluxDB configuration file by changing the value of the enabled parameter in the [[collectd]] section from false to true . Leave other parameters unchanged. The section should look like this: [[collectd]] enabled = true bind-address = \":25826\" database = \"collectd\" retention-policy = \"\" batch-size = 5000 batch-pending = 10 batch-timeout = \"10s\" read-buffer = 0 typesdb = \"/usr/share/collectd/types.db\" security-level = \"none\" auth-file = \"/etc/collectd/auth_file\" parse-multivalue-plugin = \"split\" Create a docker-compose.yaml file in the working directory with the following content: version: \"3\" services: influxdb: image: influxdb container_name: influxdb ports: - 8086:8086 - 25826:25826/udp networks: - sample-net volumes: - ./:/var/lib/influxdb - ./influxdb.conf:/etc/influxdb/influxdb.conf:ro - ./types.db:/usr/share/collectd/types.db:ro grafana: image: grafana/grafana container_name: grafana restart: always ports: - 3000:3000 networks: - sample-net networks: sample-net: According to the settings in volumes: , InfluxDB will use 1. The working directory as storage for the database. 2. The influxdb.conf configuration file that is located in the working directory. 3. The types.db file with the types of measurable values that is located in the working directory. Build the services by executing the docker-compose build command. Run the services by executing the docker-compose up -d influxdb grafana command. Create a database named collectd for the corresponding InfluxDB data source by executing the following command: # curl -i -X POST http://10.0.30.30:8086/query --data-urlencode \"q=CREATE DATABASE collectd\" The InfluxDB server should return a response similar to: HTTP/1.1 200 OK Content-Type: application/json Request-Id: 23604241-b086-11e9-8001-0242ac190002 X-Influxdb-Build: OSS X-Influxdb-Version: 1.7.7 X-Request-Id: 23604241-b086-11e9-8001-0242ac190002 Date: Sat, 27 Jul 2019 15:49:37 GMT Transfer-Encoding: chunked {\"results\":[{\"statement_id\":0}]} At this point, InfluxDB should be running, ready to receive metrics from collectd , and Grafana should be ready to monitor and visualize the data stored in InfluxDB. Configuring collectd \u00b6 Configure collectd to export metrics to InfluxDB: Connect to the filter node (for example, by using the SSH protocol). Make sure you are logged in as root or another account with superuser privileges. Create a file named /etc/collectd/collectd.conf.d/export-to-influxdb.conf with the following content: LoadPlugin network <Plugin \"network\"> Server \"10.0.30.30\" \"25826\" </Plugin> The following entities are configured here: 1. The server, to send metrics to ( 10.0.30.30 ) 2. The port that server listens on ( 25826/UDP ) Restart the collectd service by running the appropriate command: {%- termtabs name=\"CentOS 6.x or Ubuntu 14.04 LTS\" -%} service collectd restart \u00b6 {%- tab name=\"Other supported distributions\" -%} systemctl restart collectd \u00b6 {%- endtermtabs -%} Now InfluxDB receives all the metrics of the filter node. You can visualize the metrics you are interested in and monitor them with Grafana .","title":"Exporting Metrics to InfluxDB via the `collectd` Network Plugin"},{"location":"en/admin-en/monitoring/network-plugin-influxdb/#exporting-metrics-to-influxdb-via-the-collectd-network-plugin","text":"This document provides an example of using the Network plugin to export metrics to the InfluxDB temporal database. It will also demonstrate how to visualize the metrics collected in InfluxDB using Grafana.","title":"Exporting Metrics to InfluxDB via the collectd Network Plugin"},{"location":"en/admin-en/monitoring/network-plugin-influxdb/#example-workflow","text":"#### Info:: Example of metric This example shows how to work with the single [`curl_json-wallarm_nginx/gauge-attacks`](../../admin-en/monitoring/available-metrics.md#number-of-attacks-reported) metric, which shows the number of attacks on an application that is protected by the filter node. The following deployment scheme is used in this document: The Wallarm filter node is deployed on a host accessible via the 10.0.30.5 IP address and the node.example.local fully qualified domain name. The network plugin for collectd on the filter node is configured in such a way that all metrics will be sent to the 10.0.30.30 InfluxDB server on port 25826/UDP . #### Info:: Network plugin features Please note that the plugin operates over UDP (see using examples and documentation of the network plugin). Both influxdb and grafana services are deployed as Docker containers on a separate host with the 10.0.30.30 IP address. The influxdb service with the InfluxDB database is configured as follows: * A collectd data source has been created (the collectd input according to InfluxDB terminology), which listens on the 25826/UDP port and writes incoming metrics to a database called collectd . * Communication with the InfluxDB API occurs via the 8086/TCP port. * The service shares a sample-net Docker network with the grafana service. The grafana service with Grafana is configured as follows: * The Grafana web console is available at http://10.0.30.30:3000 . * The service shares the sample-net Docker network with the influxdb service.","title":"Example Workflow"},{"location":"en/admin-en/monitoring/network-plugin-influxdb/#configuring-metrics-export-to-influxdb","text":"#### Info:: Prerequisites It is assumed that * [Docker Community Edition](https://docs.docker.com/install/) and [`docker-compose`](https://docs.docker.com/compose/install/) are already installed on the `10.0.30.30` Docker host. * The `node.example.local` filter node is already deployed, configured, available for further configuration (for example, via the SSH protocol), and working.","title":"Configuring Metrics Export to InfluxDB"},{"location":"en/admin-en/monitoring/network-plugin-influxdb/#deploying-influxdb-and-grafana","text":"Deploy InfluxDB and Grafana on the Docker host: Create a working directory, for example, /tmp/influxdb-grafana , and navigate to it: # mkdir /tmp/influxdb-grafana # cd /tmp/influxdb-grafana For the InfluxDB data source to work, you will need a file named types.db that contains the collectd value types. This file describes the dataset specifications used by collectd . Such datasets include definitions of measurable types. Detailed information about this file is available here . Download the types.db file from the GitHub repository of the collectd project and put it in the working directory. Get the basic InfluxDB configuration file by running the following command: # docker run --rm influxdb influxd config > influxdb.conf Enable the collectd data source in the influxdb.conf InfluxDB configuration file by changing the value of the enabled parameter in the [[collectd]] section from false to true . Leave other parameters unchanged. The section should look like this: [[collectd]] enabled = true bind-address = \":25826\" database = \"collectd\" retention-policy = \"\" batch-size = 5000 batch-pending = 10 batch-timeout = \"10s\" read-buffer = 0 typesdb = \"/usr/share/collectd/types.db\" security-level = \"none\" auth-file = \"/etc/collectd/auth_file\" parse-multivalue-plugin = \"split\" Create a docker-compose.yaml file in the working directory with the following content: version: \"3\" services: influxdb: image: influxdb container_name: influxdb ports: - 8086:8086 - 25826:25826/udp networks: - sample-net volumes: - ./:/var/lib/influxdb - ./influxdb.conf:/etc/influxdb/influxdb.conf:ro - ./types.db:/usr/share/collectd/types.db:ro grafana: image: grafana/grafana container_name: grafana restart: always ports: - 3000:3000 networks: - sample-net networks: sample-net: According to the settings in volumes: , InfluxDB will use 1. The working directory as storage for the database. 2. The influxdb.conf configuration file that is located in the working directory. 3. The types.db file with the types of measurable values that is located in the working directory. Build the services by executing the docker-compose build command. Run the services by executing the docker-compose up -d influxdb grafana command. Create a database named collectd for the corresponding InfluxDB data source by executing the following command: # curl -i -X POST http://10.0.30.30:8086/query --data-urlencode \"q=CREATE DATABASE collectd\" The InfluxDB server should return a response similar to: HTTP/1.1 200 OK Content-Type: application/json Request-Id: 23604241-b086-11e9-8001-0242ac190002 X-Influxdb-Build: OSS X-Influxdb-Version: 1.7.7 X-Request-Id: 23604241-b086-11e9-8001-0242ac190002 Date: Sat, 27 Jul 2019 15:49:37 GMT Transfer-Encoding: chunked {\"results\":[{\"statement_id\":0}]} At this point, InfluxDB should be running, ready to receive metrics from collectd , and Grafana should be ready to monitor and visualize the data stored in InfluxDB.","title":"Deploying InfluxDB and Grafana"},{"location":"en/admin-en/monitoring/network-plugin-influxdb/#configuring-collectd","text":"Configure collectd to export metrics to InfluxDB: Connect to the filter node (for example, by using the SSH protocol). Make sure you are logged in as root or another account with superuser privileges. Create a file named /etc/collectd/collectd.conf.d/export-to-influxdb.conf with the following content: LoadPlugin network <Plugin \"network\"> Server \"10.0.30.30\" \"25826\" </Plugin> The following entities are configured here: 1. The server, to send metrics to ( 10.0.30.30 ) 2. The port that server listens on ( 25826/UDP ) Restart the collectd service by running the appropriate command: {%- termtabs name=\"CentOS 6.x or Ubuntu 14.04 LTS\" -%}","title":"Configuring collectd"},{"location":"en/admin-en/monitoring/network-plugin-influxdb/#service-collectd-restart","text":"{%- tab name=\"Other supported distributions\" -%}","title":"service collectd restart"},{"location":"en/admin-en/monitoring/network-plugin-influxdb/#systemctl-restart-collectd","text":"{%- endtermtabs -%} Now InfluxDB receives all the metrics of the filter node. You can visualize the metrics you are interested in and monitor them with Grafana .","title":"systemctl restart collectd"},{"location":"en/admin-en/monitoring/working-with-grafana/","text":"Working with the Filter Node Metrics in Grafana \u00b6 If you have configured the export of metrics in InfluxDB or Graphite, then you can visualize the metrics with Grafana . #### Info:: A few assumptions This document assumes that you have deployed Grafana alongside [InfluxDB][doc-network-plugin-influxdb] or [Graphite][doc-network-plugin-graphite]. The [`curl_json-wallarm_nginx/gauge-attacks`][doc-gauge-attacks] metric, which shows the number of attacks on an application that is protected by the `node.example.local` filter node, is used as an example. However, you can monitor any [supported metric][doc-available-metrics]. In your browser, go to http://10.0.30.30:3000 to open the Grafana web console, then log in to the console using the standard username ( admin ) and password ( admin ). In order to monitor a filter node using Grafana, you will need to Connect a data source. Fetch the required metrics from the data source. Set up metric visualization. It is assumed that you are using one of the following data sources: InfluxDB Graphite #### Info:: See also: [Verifying Monitoring.][anchor-verify-monitoring] Connecting a Data Source \u00b6 InfluxDB \u00b6 To connect an InfluxDB server as the data source take the following steps: On the main page of the Grafana console, click the Add data source button. Select \u201cInfluxDB\u201d as the data source type. Fill in the required parameters: Name: InfluxDB URL: http://influxdb:8086 Database: collectd User: root Password: root Click the Save & Test button. Graphite \u00b6 To connect a Graphite server as the data source take the following steps: On the main page of the Grafana console, click the Add data source button. Select \u201cGraphite\u201d as the data source type. Fill in the required parameters: Name: Graphite URL: http://graphite:8080 . Version: select the newest available version from the drop-down list. Click the Save & Test button. #### Info:: Checking a Data Source Status If a data source was connected successfully, the \u201cData source is working\u201d message should appear. Further Actions \u00b6 Perform the following actions to enable Grafana to monitor metrics: Click the Grafana icon in the upper left corner of the console to return to the main page. Create a new dashboard by clicking the New Dashboard button. Then add a query to fetch a metric to the dashboard by clicking the Add Query button. Fetching the Required Metrics from the Data Source \u00b6 InfluxDB \u00b6 To fetch a metric from the InfluxDB data source do the following: Select the newly created \u201cInfluxDB\u201d data source from the Query drop-down list. Design a query to the InfluxDB either by using the graphical query design tool, or by manually filling in a query in plain text (to do this, click the Toggle text edit button, which is highlighted in the screenshot below). The query to fetch the curl_json-wallarm_nginx/gauge-attacks metric is: SELECT value FROM curl_json_value WHERE (host = 'node.example.local' AND instance = 'wallarm_nginx' AND type = 'gauge' AND type_instance = 'attacks') Graphite \u00b6 To fetch a metric from the Graphite data source do the following: Select the newly created \u201cGraphite\u201d data source from the Query drop-down list. Select the elements of the required metric in a sequential manner by clicking the select metric button for the metric\u2019s element in the Series line. The elements of the curl_json-wallarm_nginx/gauge-attacks metric go as follows: 1. The hostname, as it was set in the write_graphite plugin configuration file. The `_` character serves as a delimiter by default in this plugin; therefore, the `node.example.local` domain name will be represented as `node_example_local` in the query. The name of the collectd plugin that provides a specific value. For this metric, the plugin is curl_json . The name of the plugin instance. For this metric, the name is wallarm_nginx . The type of value. For this metric, the type is gauge . The name of value. For this metric, the name is attacks . Further Actions \u00b6 After the creation of the query, set up a visualization for the corresponding metric. Setting Up Metric Visualization \u00b6 Switch from the Query tab to the Visualization tab, and select the desired visualization for the metric. For the curl_json-wallarm_nginx/gauge-attacks metric, we recommend using the \u201cGauge\u201d visualization: Select the Calc: Last option to display the current metric value. If necessary, you can configure thresholds and other parameters. Further Actions \u00b6 After configuring visualization take the following steps: Complete the query configuration by clicking on the \u201c\u2190\u201d button in the upper left corner of the console. Save any changes that were made to the dashboard. Verify and confirm that Grafana is successfully monitoring the metric. Verifying Monitoring \u00b6 After you have connected one of the data sources and configured the query and visualization for the curl_json-wallarm_nginx/gauge-attacks metric, check the monitoring operation: Enable automatic metric updates at five-second intervals (select a value from the drop-down list in the upper right corner of the Grafana console). Make sure that the current number of attacks on the Grafana dashboard matches the output from wallarm-status on the filter node: Execute the curl http://127.0.0.8/wallarm-status command if the default configuration of the statistics service is in use. Otherwise, see the /etc/nginx/conf.d/wallarm-status.conf configuration file to construct the correct command similar to the one above. {\"requests\":0,\"attacks\":0,\"blocked\":0,\"abnormal\":0,\"tnt_errors\":0,\"api_errors\":0,\"requests_lost\":0,\"segfaults\":0,\"memfaults\":0,\"softmemfaults\":0,\"time_detect\":0,\"db_id\":46,\"lom_id\":4,\"proton_instances\": { \"total\":2,\"success\":2,\"fallback\":0,\"failed\":0 },\"stalled_workers_count\":0,\"stalled_workers\":[] } Perform a test attack on an application protected by the filter node. To do this, you can send a malicious request to the application either with the curl utility or a browser. #### Info:: Example curl -I \u201chttp://node.example.local/?id='or+1=1--a-<script>prompt(1)</script>\u201d Make sure that the attack counter has increased both in the wallarm-status output and on the Grafana dashboard: {\"requests\":64,\"attacks\":16,\"blocked\":0,\"abnormal\":64,\"tnt_errors\":0,\"api_errors\":0,\"requests_lost\":0,\"segfaults\":0,\"memfaults\":0,\"softmemfaults\":0,\"time_detect\":0,\"db_id\":46,\"lom_id\":4,\"proton_instances\": { \"total\":2,\"success\":2,\"fallback\":0,\"failed\":0 },\"stalled_workers_count\":0,\"stalled_workers\":[] } The Grafana dashboard now displays the curl_json-wallarm_nginx/gauge-attacks metric values for the node.example.local filter node.","title":"Working with the Filter Node Metrics in Grafana"},{"location":"en/admin-en/monitoring/working-with-grafana/#working-with-the-filter-node-metrics-in-grafana","text":"If you have configured the export of metrics in InfluxDB or Graphite, then you can visualize the metrics with Grafana . #### Info:: A few assumptions This document assumes that you have deployed Grafana alongside [InfluxDB][doc-network-plugin-influxdb] or [Graphite][doc-network-plugin-graphite]. The [`curl_json-wallarm_nginx/gauge-attacks`][doc-gauge-attacks] metric, which shows the number of attacks on an application that is protected by the `node.example.local` filter node, is used as an example. However, you can monitor any [supported metric][doc-available-metrics]. In your browser, go to http://10.0.30.30:3000 to open the Grafana web console, then log in to the console using the standard username ( admin ) and password ( admin ). In order to monitor a filter node using Grafana, you will need to Connect a data source. Fetch the required metrics from the data source. Set up metric visualization. It is assumed that you are using one of the following data sources: InfluxDB Graphite #### Info:: See also: [Verifying Monitoring.][anchor-verify-monitoring]","title":"Working with the Filter Node Metrics in Grafana"},{"location":"en/admin-en/monitoring/working-with-grafana/#connecting-a-data-source","text":"","title":"Connecting a Data Source"},{"location":"en/admin-en/monitoring/working-with-grafana/#influxdb","text":"To connect an InfluxDB server as the data source take the following steps: On the main page of the Grafana console, click the Add data source button. Select \u201cInfluxDB\u201d as the data source type. Fill in the required parameters: Name: InfluxDB URL: http://influxdb:8086 Database: collectd User: root Password: root Click the Save & Test button.","title":"InfluxDB"},{"location":"en/admin-en/monitoring/working-with-grafana/#graphite","text":"To connect a Graphite server as the data source take the following steps: On the main page of the Grafana console, click the Add data source button. Select \u201cGraphite\u201d as the data source type. Fill in the required parameters: Name: Graphite URL: http://graphite:8080 . Version: select the newest available version from the drop-down list. Click the Save & Test button. #### Info:: Checking a Data Source Status If a data source was connected successfully, the \u201cData source is working\u201d message should appear.","title":"Graphite"},{"location":"en/admin-en/monitoring/working-with-grafana/#further-actions","text":"Perform the following actions to enable Grafana to monitor metrics: Click the Grafana icon in the upper left corner of the console to return to the main page. Create a new dashboard by clicking the New Dashboard button. Then add a query to fetch a metric to the dashboard by clicking the Add Query button.","title":"Further Actions"},{"location":"en/admin-en/monitoring/working-with-grafana/#fetching-the-required-metrics-from-the-data-source","text":"","title":"Fetching the Required Metrics from the Data Source"},{"location":"en/admin-en/monitoring/working-with-grafana/#influxdb_1","text":"To fetch a metric from the InfluxDB data source do the following: Select the newly created \u201cInfluxDB\u201d data source from the Query drop-down list. Design a query to the InfluxDB either by using the graphical query design tool, or by manually filling in a query in plain text (to do this, click the Toggle text edit button, which is highlighted in the screenshot below). The query to fetch the curl_json-wallarm_nginx/gauge-attacks metric is: SELECT value FROM curl_json_value WHERE (host = 'node.example.local' AND instance = 'wallarm_nginx' AND type = 'gauge' AND type_instance = 'attacks')","title":"InfluxDB"},{"location":"en/admin-en/monitoring/working-with-grafana/#graphite_1","text":"To fetch a metric from the Graphite data source do the following: Select the newly created \u201cGraphite\u201d data source from the Query drop-down list. Select the elements of the required metric in a sequential manner by clicking the select metric button for the metric\u2019s element in the Series line. The elements of the curl_json-wallarm_nginx/gauge-attacks metric go as follows: 1. The hostname, as it was set in the write_graphite plugin configuration file. The `_` character serves as a delimiter by default in this plugin; therefore, the `node.example.local` domain name will be represented as `node_example_local` in the query. The name of the collectd plugin that provides a specific value. For this metric, the plugin is curl_json . The name of the plugin instance. For this metric, the name is wallarm_nginx . The type of value. For this metric, the type is gauge . The name of value. For this metric, the name is attacks .","title":"Graphite"},{"location":"en/admin-en/monitoring/working-with-grafana/#further-actions_1","text":"After the creation of the query, set up a visualization for the corresponding metric.","title":"Further Actions"},{"location":"en/admin-en/monitoring/working-with-grafana/#setting-up-metric-visualization","text":"Switch from the Query tab to the Visualization tab, and select the desired visualization for the metric. For the curl_json-wallarm_nginx/gauge-attacks metric, we recommend using the \u201cGauge\u201d visualization: Select the Calc: Last option to display the current metric value. If necessary, you can configure thresholds and other parameters.","title":"Setting Up Metric Visualization"},{"location":"en/admin-en/monitoring/working-with-grafana/#further-actions_2","text":"After configuring visualization take the following steps: Complete the query configuration by clicking on the \u201c\u2190\u201d button in the upper left corner of the console. Save any changes that were made to the dashboard. Verify and confirm that Grafana is successfully monitoring the metric.","title":"Further Actions"},{"location":"en/admin-en/monitoring/working-with-grafana/#verifying-monitoring","text":"After you have connected one of the data sources and configured the query and visualization for the curl_json-wallarm_nginx/gauge-attacks metric, check the monitoring operation: Enable automatic metric updates at five-second intervals (select a value from the drop-down list in the upper right corner of the Grafana console). Make sure that the current number of attacks on the Grafana dashboard matches the output from wallarm-status on the filter node: Execute the curl http://127.0.0.8/wallarm-status command if the default configuration of the statistics service is in use. Otherwise, see the /etc/nginx/conf.d/wallarm-status.conf configuration file to construct the correct command similar to the one above. {\"requests\":0,\"attacks\":0,\"blocked\":0,\"abnormal\":0,\"tnt_errors\":0,\"api_errors\":0,\"requests_lost\":0,\"segfaults\":0,\"memfaults\":0,\"softmemfaults\":0,\"time_detect\":0,\"db_id\":46,\"lom_id\":4,\"proton_instances\": { \"total\":2,\"success\":2,\"fallback\":0,\"failed\":0 },\"stalled_workers_count\":0,\"stalled_workers\":[] } Perform a test attack on an application protected by the filter node. To do this, you can send a malicious request to the application either with the curl utility or a browser. #### Info:: Example curl -I \u201chttp://node.example.local/?id='or+1=1--a-<script>prompt(1)</script>\u201d Make sure that the attack counter has increased both in the wallarm-status output and on the Grafana dashboard: {\"requests\":64,\"attacks\":16,\"blocked\":0,\"abnormal\":64,\"tnt_errors\":0,\"api_errors\":0,\"requests_lost\":0,\"segfaults\":0,\"memfaults\":0,\"softmemfaults\":0,\"time_detect\":0,\"db_id\":46,\"lom_id\":4,\"proton_instances\": { \"total\":2,\"success\":2,\"fallback\":0,\"failed\":0 },\"stalled_workers_count\":0,\"stalled_workers\":[] } The Grafana dashboard now displays the curl_json-wallarm_nginx/gauge-attacks metric values for the node.example.local filter node.","title":"Verifying Monitoring"},{"location":"en/admin-en/monitoring/working-with-nagios/","text":"Working with the Filter Node Metrics in Nagios \u00b6 Verify that Nagios is successfully monitoring the status of the previously created service: Log in to the Nagios web interface. Go to the services page by clicking on the \u201cServices\u201d link. Make sure that the wallarm_nginx_attacks service is displayed and has the \u201cOK\u201d status: #### Info:: Forcing service check If the service does not have the \u201cOK\u201d status, you can force a check of the service to confirm its status. To do this, click on the service name in the \u201cService\u201d column, and then run the check by selecting \u201cReschedule the next check of this service\u201d in the \u201cService Commands\u201d list and entering the necessary parameters. View detailed information about the service by clicking on the link with its name in the \u201cStatus\u201d column: Make sure that the metric value displayed in Nagios (the \u201cPerformance Data\u201d row) matches the wallarm-status output on the filter node: 1. Execute the curl http://127.0.0.8/wallarm-status command if the default configuration of the statistics service is in use. 2. Otherwise, see the /etc/nginx/conf.d/wallarm-status.conf configuration file to construct the correct command similar to the one above. {\"requests\":0,\"attacks\":0,\"blocked\":0,\"abnormal\":0,\"tnt_errors\":0,\"api_errors\":0,\"requests_lost\":0,\"segfaults\":0,\"memfaults\":0,\"softmemfaults\":0,\"time_detect\":0,\"db_id\":46,\"lom_id\":4,\"proton_instances\": { \"total\":2,\"success\":2,\"fallback\":0,\"failed\":0 },\"stalled_workers_count\":0,\"stalled_workers\":[] } Perform a test attack on an application protected by the filter node. To do this, you can send a malicious request to the application either with the curl utility or a browser. #### Info:: Example curl -I \u201chttp://node.example.local/?id='or+1=1--a-<script>prompt(1)</script>\u201d Ensure that the \u201cPerformance Data\u201d value in Nagios has increased and matches the value displayed by wallarm-status on the filter node: {\"requests\":64,\"attacks\":16,\"blocked\":0,\"abnormal\":64,\"tnt_errors\":0,\"api_errors\":0,\"requests_lost\":0,\"segfaults\":0,\"memfaults\":0,\"softmemfaults\":0,\"time_detect\":0,\"db_id\":46,\"lom_id\":4,\"proton_instances\": { \"total\":2,\"success\":2,\"fallback\":0,\"failed\":0 },\"stalled_workers_count\":0,\"stalled_workers\":[] } Now the values of the curl_json-wallarm_nginx/gauge-attacks metric of the filter node are displayed in the service state information in Nagios. #### Info:: Nagios data visualization By default, Nagios Core only supports tracking service status (`OK`, `WARNING`, `CRITICAL`). To store and visualize metric values contained in \u201cPerformance Data,\u201d you can use third-party utilities, for example, [PHP4Nagios][link-php4nagios].","title":"Working with the Filter Node Metrics in Nagios"},{"location":"en/admin-en/monitoring/working-with-nagios/#working-with-the-filter-node-metrics-in-nagios","text":"Verify that Nagios is successfully monitoring the status of the previously created service: Log in to the Nagios web interface. Go to the services page by clicking on the \u201cServices\u201d link. Make sure that the wallarm_nginx_attacks service is displayed and has the \u201cOK\u201d status: #### Info:: Forcing service check If the service does not have the \u201cOK\u201d status, you can force a check of the service to confirm its status. To do this, click on the service name in the \u201cService\u201d column, and then run the check by selecting \u201cReschedule the next check of this service\u201d in the \u201cService Commands\u201d list and entering the necessary parameters. View detailed information about the service by clicking on the link with its name in the \u201cStatus\u201d column: Make sure that the metric value displayed in Nagios (the \u201cPerformance Data\u201d row) matches the wallarm-status output on the filter node: 1. Execute the curl http://127.0.0.8/wallarm-status command if the default configuration of the statistics service is in use. 2. Otherwise, see the /etc/nginx/conf.d/wallarm-status.conf configuration file to construct the correct command similar to the one above. {\"requests\":0,\"attacks\":0,\"blocked\":0,\"abnormal\":0,\"tnt_errors\":0,\"api_errors\":0,\"requests_lost\":0,\"segfaults\":0,\"memfaults\":0,\"softmemfaults\":0,\"time_detect\":0,\"db_id\":46,\"lom_id\":4,\"proton_instances\": { \"total\":2,\"success\":2,\"fallback\":0,\"failed\":0 },\"stalled_workers_count\":0,\"stalled_workers\":[] } Perform a test attack on an application protected by the filter node. To do this, you can send a malicious request to the application either with the curl utility or a browser. #### Info:: Example curl -I \u201chttp://node.example.local/?id='or+1=1--a-<script>prompt(1)</script>\u201d Ensure that the \u201cPerformance Data\u201d value in Nagios has increased and matches the value displayed by wallarm-status on the filter node: {\"requests\":64,\"attacks\":16,\"blocked\":0,\"abnormal\":64,\"tnt_errors\":0,\"api_errors\":0,\"requests_lost\":0,\"segfaults\":0,\"memfaults\":0,\"softmemfaults\":0,\"time_detect\":0,\"db_id\":46,\"lom_id\":4,\"proton_instances\": { \"total\":2,\"success\":2,\"fallback\":0,\"failed\":0 },\"stalled_workers_count\":0,\"stalled_workers\":[] } Now the values of the curl_json-wallarm_nginx/gauge-attacks metric of the filter node are displayed in the service state information in Nagios. #### Info:: Nagios data visualization By default, Nagios Core only supports tracking service status (`OK`, `WARNING`, `CRITICAL`). To store and visualize metric values contained in \u201cPerformance Data,\u201d you can use third-party utilities, for example, [PHP4Nagios][link-php4nagios].","title":"Working with the Filter Node Metrics in Nagios"},{"location":"en/admin-en/monitoring/working-with-zabbix/","text":"Working with the Filter Node Metrics in Zabbix \u00b6 Go to http://10.0.30.30 to access the Zabbix web interface login page. Log in to the web interface using the standard login ( Admin ) and password ( zabbix ). To monitor the metrics of the node.example.local filter node, perform the following actions: Create a new host by performing the following steps: Go to the Configuration \u2192 Hosts tab and click the Create host button. Fill the fully qualified domain name of the filter node host in the Host name field ( node.example.local ). Select the group you want to place the host into from the Groups field (for example, you can use the predefined \u201cLinux servers\u201d group, or create a dedicated group). Fill the IP address of the filter node host ( 10.0.30.5 ) in the Agent interfaces parameter group. Leave the default port value ( 10050 ) unchanged. #### Info:: Connecting using a domain name If necessary, you can set up a domain name to connect to the Zabbix agent. To do this, change the appropriate settings accordingly. Configure other settings, if necessary. Make sure that the Enabled checkbox is checked. Complete the host creation process by clicking the Add button. Add metrics that should be monitored for the filter node host. To add a single metric, follow the steps below: Click the name of the created host node.example.local in the list of hosts on the Configuration \u2192 Hosts tab. A page with the host data will open. Switch to the Items tab and click the Create item button. Fill a metric name in the Name field (for example, Wallarm NGINX Attacks ). Leave the Type , Host interface , and Type of information parameters unchanged. Enter the key name of the metric in the Key field (as specified in UserParameter= in the Zabbix agent configuration ; for example, wallarm_nginx-gauge-attacks ). If necessary, adjust the update frequency of the metric value and other parameters. Make sure that the Enabled checkbox is checked. Complete the process of adding a metric by clicking the Add button. Configure the visualization of the added metrics: Click the Zabbix logo in the upper left corner of the web interface to access the dashboard. Click the Edit dashboard button to make changes to the dashboard: Add a widget by clicking the Add widget button. Select the required widget type (for example, \u201cPlain Text\u201d) from the Type drop-down list. Fill any suitable name in the Name field. Add the required metric to the Items list (e.g., the newly created Wallarm NGINX Attacks ). Make sure that the Show text as HTML and Dynamic Items checkboxes are checked. Complete the Add widget wizard by clicking the Add button. Save the changes that you made to the dashboard by clicking the Save changes button. Check the monitoring operation: Make sure that the current number of attacks in the Zabbix widget matches the output of wallarm-status on the filter node: Execute the curl http://127.0.0.8/wallarm-status command if the default configuration of the statistics service is in use. Otherwise, see the /etc/nginx/conf.d/wallarm-status.conf configuration file to construct the correct command similar to the one above. {\"requests\":0,\"attacks\":0,\"blocked\":0,\"abnormal\":0,\"tnt_errors\":0,\"api_errors\":0,\"requests_lost\":0,\"segfaults\":0,\"memfaults\":0,\"softmemfaults\":0,\"time_detect\":0,\"db_id\":46,\"lom_id\":4,\"proton_instances\": { \"total\":2,\"success\":2,\"fallback\":0,\"failed\":0 },\"stalled_workers_count\":0,\"stalled_workers\":[] } Perform a test attack on an application protected by the filter node. To do this, you can send a malicious request to the application either with the curl utility or a browser. #### Info:: Example curl -I \u201chttp://node.example.local/?id='or+1=1--a-<script>prompt(1)</script>\u201d Make sure that the attack counter has increased in both the wallarm-status output and the Zabbix widget: {\"requests\":64,\"attacks\":16,\"blocked\":0,\"abnormal\":64,\"tnt_errors\":0,\"api_errors\":0,\"requests_lost\":0,\"segfaults\":0,\"memfaults\":0,\"softmemfaults\":0,\"time_detect\":0,\"db_id\":46,\"lom_id\":4,\"proton_instances\": { \"total\":2,\"success\":2,\"fallback\":0,\"failed\":0 },\"stalled_workers_count\":0,\"stalled_workers\":[] } The Zabbix dashboard now displays the curl_json-wallarm_nginx/gauge-attacks metric of the node.example.local filter node.","title":"Working with the Filter Node in Zabbix"},{"location":"en/admin-en/monitoring/working-with-zabbix/#working-with-the-filter-node-metrics-in-zabbix","text":"Go to http://10.0.30.30 to access the Zabbix web interface login page. Log in to the web interface using the standard login ( Admin ) and password ( zabbix ). To monitor the metrics of the node.example.local filter node, perform the following actions: Create a new host by performing the following steps: Go to the Configuration \u2192 Hosts tab and click the Create host button. Fill the fully qualified domain name of the filter node host in the Host name field ( node.example.local ). Select the group you want to place the host into from the Groups field (for example, you can use the predefined \u201cLinux servers\u201d group, or create a dedicated group). Fill the IP address of the filter node host ( 10.0.30.5 ) in the Agent interfaces parameter group. Leave the default port value ( 10050 ) unchanged. #### Info:: Connecting using a domain name If necessary, you can set up a domain name to connect to the Zabbix agent. To do this, change the appropriate settings accordingly. Configure other settings, if necessary. Make sure that the Enabled checkbox is checked. Complete the host creation process by clicking the Add button. Add metrics that should be monitored for the filter node host. To add a single metric, follow the steps below: Click the name of the created host node.example.local in the list of hosts on the Configuration \u2192 Hosts tab. A page with the host data will open. Switch to the Items tab and click the Create item button. Fill a metric name in the Name field (for example, Wallarm NGINX Attacks ). Leave the Type , Host interface , and Type of information parameters unchanged. Enter the key name of the metric in the Key field (as specified in UserParameter= in the Zabbix agent configuration ; for example, wallarm_nginx-gauge-attacks ). If necessary, adjust the update frequency of the metric value and other parameters. Make sure that the Enabled checkbox is checked. Complete the process of adding a metric by clicking the Add button. Configure the visualization of the added metrics: Click the Zabbix logo in the upper left corner of the web interface to access the dashboard. Click the Edit dashboard button to make changes to the dashboard: Add a widget by clicking the Add widget button. Select the required widget type (for example, \u201cPlain Text\u201d) from the Type drop-down list. Fill any suitable name in the Name field. Add the required metric to the Items list (e.g., the newly created Wallarm NGINX Attacks ). Make sure that the Show text as HTML and Dynamic Items checkboxes are checked. Complete the Add widget wizard by clicking the Add button. Save the changes that you made to the dashboard by clicking the Save changes button. Check the monitoring operation: Make sure that the current number of attacks in the Zabbix widget matches the output of wallarm-status on the filter node: Execute the curl http://127.0.0.8/wallarm-status command if the default configuration of the statistics service is in use. Otherwise, see the /etc/nginx/conf.d/wallarm-status.conf configuration file to construct the correct command similar to the one above. {\"requests\":0,\"attacks\":0,\"blocked\":0,\"abnormal\":0,\"tnt_errors\":0,\"api_errors\":0,\"requests_lost\":0,\"segfaults\":0,\"memfaults\":0,\"softmemfaults\":0,\"time_detect\":0,\"db_id\":46,\"lom_id\":4,\"proton_instances\": { \"total\":2,\"success\":2,\"fallback\":0,\"failed\":0 },\"stalled_workers_count\":0,\"stalled_workers\":[] } Perform a test attack on an application protected by the filter node. To do this, you can send a malicious request to the application either with the curl utility or a browser. #### Info:: Example curl -I \u201chttp://node.example.local/?id='or+1=1--a-<script>prompt(1)</script>\u201d Make sure that the attack counter has increased in both the wallarm-status output and the Zabbix widget: {\"requests\":64,\"attacks\":16,\"blocked\":0,\"abnormal\":64,\"tnt_errors\":0,\"api_errors\":0,\"requests_lost\":0,\"segfaults\":0,\"memfaults\":0,\"softmemfaults\":0,\"time_detect\":0,\"db_id\":46,\"lom_id\":4,\"proton_instances\": { \"total\":2,\"success\":2,\"fallback\":0,\"failed\":0 },\"stalled_workers_count\":0,\"stalled_workers\":[] } The Zabbix dashboard now displays the curl_json-wallarm_nginx/gauge-attacks metric of the node.example.local filter node.","title":"Working with the Filter Node Metrics in Zabbix"},{"location":"en/admin-en/monitoring/write-plugin-graphite/","text":"Exporting Metrics to Graphite via the collectd Write Plugin \u00b6 This document provides an example of using the write_graphite write plugin to export metrics to Graphite. Example Workflow \u00b6 #### Info:: Example of metric This example shows how to work with the single [`curl_json-wallarm_nginx/gauge-attacks`](../../admin-en/monitoring/available-metrics.md#number-of-attacks-reported) metric, which shows the number of attacks on an application that is protected by the filter node. The following deployment scheme is used in this document: Wallarm filter node is deployed on a host accessible via the 10.0.30.5 IP address and the node.example.local fully qualified domain name. The write_graphite plugin for collectd on the filter node is configured as follows: * All metrics are sent to the 10.0.30.30 server listening on the 2003/TCP port. * Some Wallarm-specific collectd plugins support multiple instances , so the write_graphite plugin contains the SeparateInstances parameter set to true . The true value means that the plugin can work with several instances. A complete list of plugin options is available here . Both graphite and grafana services are deployed as Docker containers on a separate host with the 10.0.30.30 IP address. The graphite service with Graphite is configured as follows: * It listens for incoming connections on the 2003/TCP port, to which collectd will send the filter node metrics. * It listens for incoming connections on the 8080/TCP port, through which communication with Grafana will occur. * The service shares the sample-net Docker network with the grafana service. The grafana service with Grafana is configured as follows: * The Grafana web console is available at http://10.0.30.30:3000 . * The service shares the sample-net Docker network with the graphite service. Configuring Metrics Export to Graphite \u00b6 #### Info:: Prerequisites It is assumed that * [Docker Community Edition](https://docs.docker.com/install/) and [`docker-compose`](https://docs.docker.com/compose/install/) are already installed on the `10.0.30.30` Docker host. * The `node.example.local` filter node is already deployed, configured, available for further configuration (for example, via the SSH protocol), and working. Deploying Graphite and Grafana \u00b6 Deploy Graphite and Grafana on the Docker host: Create a docker-compose.yaml file with the following content: version: \"3\" services: grafana: image: grafana/grafana container_name: grafana restart: always ports: - 3000:3000 networks: - sample-net graphite: image: graphiteapp/graphite-statsd container_name: graphite restart: always ports: - 8080:8080 - 2003:2003 networks: - sample-net networks: sample-net: Build the services by executing the docker-compose build command. Run the services by executing the docker-compose up -d graphite grafana command. At this point, you should have Graphite running and ready to receive metrics from collectd , and Grafana ready to monitor and visualize the data stored in Graphite. Configuring collectd \u00b6 Configure collectd to download metrics to Graphite: Connect to the filter node (for example, using the SSH protocol). Make sure you are logged in as root or another account with superuser privileges. Create a file named /etc/collectd/collectd.conf.d/export-to-graphite.conf with the following content: LoadPlugin write_graphite <Plugin write_graphite> <Node \"node.example.local\"> Host \"10.0.30.30\" Port \"2003\" Protocol \"tcp\" SeparateInstances true </Node> </Plugin> The following entities are configured here: 1. The host name from which metrics are collected ( node.example.local ). 2. The server to which metrics should be sent ( 10.0.30.30 ). 3. The server port ( 2003 ) and the protocol ( tcp ). 4. The data transfer logic: the data of one instance of the plugin is separated from the data of another instance ( SeparateInstances true ). Restart the collectd service by running the appropriate command: {%- termtabs name=\"CentOS 6.x or Ubuntu 14.04 LTS\" -%} service collectd restart \u00b6 {%- tab name=\"Other supported distributions\" -%} systemctl restart collectd \u00b6 {%- endtermtabs -%} Now Graphite will receive all metrics of the filter node. You can visualize the metrics you are interested in, and monitor them with Grafana .","title":"Exporting Metrics to Graphite via the `collectd` Write Plugin"},{"location":"en/admin-en/monitoring/write-plugin-graphite/#exporting-metrics-to-graphite-via-the-collectd-write-plugin","text":"This document provides an example of using the write_graphite write plugin to export metrics to Graphite.","title":"Exporting Metrics to Graphite via the collectd Write Plugin"},{"location":"en/admin-en/monitoring/write-plugin-graphite/#example-workflow","text":"#### Info:: Example of metric This example shows how to work with the single [`curl_json-wallarm_nginx/gauge-attacks`](../../admin-en/monitoring/available-metrics.md#number-of-attacks-reported) metric, which shows the number of attacks on an application that is protected by the filter node. The following deployment scheme is used in this document: Wallarm filter node is deployed on a host accessible via the 10.0.30.5 IP address and the node.example.local fully qualified domain name. The write_graphite plugin for collectd on the filter node is configured as follows: * All metrics are sent to the 10.0.30.30 server listening on the 2003/TCP port. * Some Wallarm-specific collectd plugins support multiple instances , so the write_graphite plugin contains the SeparateInstances parameter set to true . The true value means that the plugin can work with several instances. A complete list of plugin options is available here . Both graphite and grafana services are deployed as Docker containers on a separate host with the 10.0.30.30 IP address. The graphite service with Graphite is configured as follows: * It listens for incoming connections on the 2003/TCP port, to which collectd will send the filter node metrics. * It listens for incoming connections on the 8080/TCP port, through which communication with Grafana will occur. * The service shares the sample-net Docker network with the grafana service. The grafana service with Grafana is configured as follows: * The Grafana web console is available at http://10.0.30.30:3000 . * The service shares the sample-net Docker network with the graphite service.","title":"Example Workflow"},{"location":"en/admin-en/monitoring/write-plugin-graphite/#configuring-metrics-export-to-graphite","text":"#### Info:: Prerequisites It is assumed that * [Docker Community Edition](https://docs.docker.com/install/) and [`docker-compose`](https://docs.docker.com/compose/install/) are already installed on the `10.0.30.30` Docker host. * The `node.example.local` filter node is already deployed, configured, available for further configuration (for example, via the SSH protocol), and working.","title":"Configuring Metrics Export to Graphite"},{"location":"en/admin-en/monitoring/write-plugin-graphite/#deploying-graphite-and-grafana","text":"Deploy Graphite and Grafana on the Docker host: Create a docker-compose.yaml file with the following content: version: \"3\" services: grafana: image: grafana/grafana container_name: grafana restart: always ports: - 3000:3000 networks: - sample-net graphite: image: graphiteapp/graphite-statsd container_name: graphite restart: always ports: - 8080:8080 - 2003:2003 networks: - sample-net networks: sample-net: Build the services by executing the docker-compose build command. Run the services by executing the docker-compose up -d graphite grafana command. At this point, you should have Graphite running and ready to receive metrics from collectd , and Grafana ready to monitor and visualize the data stored in Graphite.","title":"Deploying Graphite and Grafana"},{"location":"en/admin-en/monitoring/write-plugin-graphite/#configuring-collectd","text":"Configure collectd to download metrics to Graphite: Connect to the filter node (for example, using the SSH protocol). Make sure you are logged in as root or another account with superuser privileges. Create a file named /etc/collectd/collectd.conf.d/export-to-graphite.conf with the following content: LoadPlugin write_graphite <Plugin write_graphite> <Node \"node.example.local\"> Host \"10.0.30.30\" Port \"2003\" Protocol \"tcp\" SeparateInstances true </Node> </Plugin> The following entities are configured here: 1. The host name from which metrics are collected ( node.example.local ). 2. The server to which metrics should be sent ( 10.0.30.30 ). 3. The server port ( 2003 ) and the protocol ( tcp ). 4. The data transfer logic: the data of one instance of the plugin is separated from the data of another instance ( SeparateInstances true ). Restart the collectd service by running the appropriate command: {%- termtabs name=\"CentOS 6.x or Ubuntu 14.04 LTS\" -%}","title":"Configuring collectd"},{"location":"en/admin-en/monitoring/write-plugin-graphite/#service-collectd-restart","text":"{%- tab name=\"Other supported distributions\" -%}","title":"service collectd restart"},{"location":"en/admin-en/monitoring/write-plugin-graphite/#systemctl-restart-collectd","text":"{%- endtermtabs -%} Now Graphite will receive all metrics of the filter node. You can visualize the metrics you are interested in, and monitor them with Grafana .","title":"systemctl restart collectd"},{"location":"en/cloud-include/addnode-script/","text":"{% codetabs name=\"EU Cloud\", type=\"sh\" -%} sudo /usr/share/wallarm-common/addnode {%- tab name=\"US Cloud\", type=\"sh\" -%} sudo /usr/share/wallarm-common/addnode -H us1.api.wallarm.com {%- endcodetabs %}","title":"Addnode script"},{"location":"en/cloud-include/api-access/","text":"API Access The API choice for your filter node depends on the cloud you are using. Please, select the API accordingly: * If you are using EU cloud, your node requires access to https://api.wallarm.com:444 . * If you are using US cloud, your node requires access to https://us1.api.wallarm.com:444 . Ensure the access is not blocked by a firewall.","title":"Api access"},{"location":"en/cloud-include/contacting-support/","text":"Contacting the support team \u00b6 You could contact Wallarm support team in the following ways: Log in to the Wallarm portal in the EU or US cloud with your Wallarm account. Press the book icon in the upper right corner of the portal. The \u201cQuick Help\u201d sidebar will appear. Select the \u201cSupport\u201d item in the sidebar then write and send a message to the support team. The support team is also reachable by e-mail .","title":"Contacting the Support Team"},{"location":"en/cloud-include/contacting-support/#contacting-the-support-team","text":"You could contact Wallarm support team in the following ways: Log in to the Wallarm portal in the EU or US cloud with your Wallarm account. Press the book icon in the upper right corner of the portal. The \u201cQuick Help\u201d sidebar will appear. Select the \u201cSupport\u201d item in the sidebar then write and send a message to the support team. The support team is also reachable by e-mail .","title":"Contacting the support team"},{"location":"en/cloud-include/docker-run-command-with-creds/","text":"{% codetabs name=\"EU Cloud\", type=\"sh\" -%} docker run -d -e \"NODE_UUID=00000000-0000-0000-0000-000000000000\" -e NODE_SECRET=\"0000000000000000000000000000000000000000000000000000000000000000\" -e NGINX_BACKEND=93.184.216.34 wallarm/node {%- language name=\"US Cloud\", type=\"sh\" -%} docker run -d -e WALLARM_API_HOST=us1.api.wallarm.com -e \"NODE_UUID=00000000-0000-0000-0000-000000000000\" -e NODE_SECRET=\"0000000000000000000000000000000000000000000000000000000000000000\" -e NGINX_BACKEND=93.184.216.34 wallarm/node {%- endcodetabs %}","title":"Docker run command with creds"},{"location":"en/cloud-include/docker-run-command/","text":"{% codetabs name=\"EU Cloud\", type=\"sh\" -%} docker run -d -e DEPLOY_USER=\" deploy@example.com \" -e DEPLOY_PASSWORD=\"very_secret\" -e NGINX_BACKEND=example.com -e TARANTOOL_MEMORY_GB=memvalue -p 80:80 wallarm/node {%- language name=\"US Cloud\", type=\"sh\" -%} docker run -d -e WALLARM_API_HOST=us1.api.wallarm.com -e DEPLOY_USER=\" deploy@example.com \" -e DEPLOY_PASSWORD=\"very_secret\" -e NGINX_BACKEND=example.com -e TARANTOOL_MEMORY_GB=memvalue -p 80:80 wallarm/node {%- endcodetabs %}","title":"Docker run command"},{"location":"en/cloud-include/heroku-connect-to-the-cloud/","text":"{% codetabs name=\"EU Cloud\", type=\"sh\" -%} heroku config:set WALLARM_USER= heroku config:set WALLARM_PASSWORD= {%- language name=\"US Cloud\", type=\"sh\" -%} heroku config:set WALLARM_API_HOST=us1.api.wallarm.com heroku config:set WALLARM_USER= heroku config:set WALLARM_PASSWORD= {%- endcodetabs %}","title":"Heroku connect to the cloud"},{"location":"en/cloud-include/heroku-deploy-app/","text":"{% codetabs name=\"EU Cloud\", type=\"sh\" -%} $ heroku create $ heroku buildpacks:add heroku/ruby $ heroku buildpacks:add https://github.com/wallarm/heroku-buildpack-wallarm-node.git $ heroku config:set WALLARM_USER= $ heroku config:set WALLARM_PASSWORD= $ git add . $ git commit -am \"init\" $ git push heroku master $ heroku logs -t {%- language name=\"US Cloud\", type=\"sh\" -%} $ heroku create $ heroku buildpacks:add heroku/ruby $ heroku buildpacks:add https://github.com/wallarm/heroku-buildpack-wallarm-node.git $ heroku config:set WALLARM_API_HOST=us1.api.wallarm.com $ heroku config:set WALLARM_USER= $ heroku config:set WALLARM_PASSWORD= $ git add . $ git commit -am \"init\" $ git push heroku master $ heroku logs -t {%- endcodetabs %}","title":"Heroku deploy app"},{"location":"en/cloud-include/k8s-install/","text":"{% codetabs name=\"EU Cloud\", type=\"sh\" -%} helm install wallarm/wallarm-ingress -n ingress-controller --set controller.wallarm.token= --set controller.wallarm.enabled=true {%- language name=\"US Cloud\", type=\"sh\" -%} helm install wallarm/wallarm-ingress -n ingress-controller --set controller.wallarm.apiHost=us1.api.wallarm.com --set controller.wallarm.token= --set controller.wallarm.enabled=true {%- endcodetabs %}","title":"K8s install"},{"location":"en/cloud-include/k8s-update/","text":"{% codetabs name=\"EU Cloud\", type=\"sh\" -%} helm upgrade wallarm/wallarm-ingress --reuse-values --set controller.wallarm.token= --set controller.wallarm.enabled=true {%- language name=\"US Cloud\", type=\"sh\" -%} helm upgrade wallarm/wallarm-ingress --reuse-values --set controller.wallarm.apiHost=us1.api.wallarm.com --set controller.wallarm.token= --set controller.wallarm.enabled=true {%- endcodetabs %}","title":"K8s update"},{"location":"en/cloud-include/postanalytics-installation-script/","text":"{% codetabs name=\"EU Cloud\", type=\"sh\" -%} /usr/share/wallarm-common/addnode --no-sync \u00b6 {%- language name=\"US Cloud\", type=\"sh\" -%} /usr/share/wallarm-common/addnode -H us1.api.wallarm.com --no-sync \u00b6 {%- endcodetabs %}","title":"Postanalytics installation script"},{"location":"en/cloud-include/postanalytics-installation-script/#usrsharewallarm-commonaddnode-no-sync","text":"{%- language name=\"US Cloud\", type=\"sh\" -%}","title":"/usr/share/wallarm-common/addnode --no-sync"},{"location":"en/cloud-include/postanalytics-installation-script/#usrsharewallarm-commonaddnode-h-us1apiwallarmcom-no-sync","text":"{%- endcodetabs %}","title":"/usr/share/wallarm-common/addnode -H us1.api.wallarm.com --no-sync"},{"location":"en/cloud-include/wallarm-clouds/","text":"EU or US","title":"Wallarm clouds"},{"location":"en/cloud-include/wallarm-portal-nodes/","text":"the Wallarm portal in the EU or US cloud","title":"Wallarm portal nodes"},{"location":"en/cloud-include/wallarm-portal-users/","text":"the Wallarm portal in the EU or US cloud","title":"Wallarm portal users"},{"location":"en/cloud-include/wallarm-portal/","text":"the Wallarm portal in the EU or US cloud","title":"Wallarm portal"},{"location":"en/cloud-include/wallarm-signup-uscloud-only/","text":"the US cloud to sign up","title":"Wallarm signup uscloud only"},{"location":"en/cloud-include/wallarm-signup/","text":"the EU or US cloud to sign up","title":"Wallarm signup"},{"location":"en/include-en/access-repo-en/","text":"Repository access Your system must have access to https://repo.wallarm.com to download the packages. Ensure the access is not blocked by a firewall.","title":"Access repo en"},{"location":"en/include-en/add-repo-distr-en/","text":"{% termtabs name=\"Debian 8.x (jessie-backports)\" -%} apt-get install dirmngr \u00b6 apt-key adv --keyserver keys.gnupg.net --recv-keys 72B865FD \u00b6 echo 'Acquire::Check-Valid-Until \"false\";' > /etc/apt/apt.conf.d/ignore-release-date \u00b6 echo 'deb http://archive.debian.org/debian jessie-backports main' > /etc/apt/sources.list.d/jessie-backports.list \u00b6 echo 'deb http://repo.wallarm.com/debian/wallarm-node jessie/2.14/' > /etc/apt/sources.list.d/wallarm.list \u00b6 echo 'deb http://repo.wallarm.com/debian/wallarm-node jessie-backports/2.14/' >> /etc/apt/sources.list.d/wallarm.list \u00b6 apt-get update \u00b6 {%- tab name=\"Debian 9.x (stretch)\" -%} apt-get install dirmngr \u00b6 apt-key adv --keyserver keys.gnupg.net --recv-keys 72B865FD \u00b6 sh -c \"echo 'deb http://repo.wallarm.com/debian/wallarm-node stretch/2.14/' >/etc/apt/sources.list.d/wallarm.list\" \u00b6 apt-get update \u00b6 {%- tab name=\"Debian 9.x (stretch-backports)\" -%} apt-get install dirmngr \u00b6 apt-key adv --keyserver keys.gnupg.net --recv-keys 72B865FD \u00b6 sh -c \"echo 'deb http://repo.wallarm.com/debian/wallarm-node stretch/2.14/' >/etc/apt/sources.list.d/wallarm.list\" \u00b6 sh -c \"echo 'deb http://repo.wallarm.com/debian/wallarm-node stretch-backports/2.14/' >> /etc/apt/sources.list.d/wallarm.list\" \u00b6 [warning][IMPORTANT]uncomment the following line in /etc/apt/sources.list: deb http://deb.debian.org/debian stretch-backports main contrib non-free apt-get update \u00b6 {%- tab name=\"Debian 10.x (buster)\" -%} apt-get install dirmngr \u00b6 apt-key adv --keyserver keys.gnupg.net --recv-keys 72B865FD \u00b6 sh -c \"echo 'deb http://repo.wallarm.com/debian/wallarm-node buster/2.14/' > /etc/apt/sources.list.d/wallarm.list\" \u00b6 apt-get update \u00b6 {%- tab name=\"CentOS 6.x\" -%} yum install --enablerepo=extras -y epel-release centos-release-SCL \u00b6 rpm -i https://repo.wallarm.com/centos/wallarm-node/6/2.14/x86_64/Packages/wallarm-node-repo-1-4.el6.noarch.rpm \u00b6 {%- tab name=\"CentOS 7.x\" -%} yum install -y epel-release \u00b6 rpm -i https://repo.wallarm.com/centos/wallarm-node/7/2.14/x86_64/Packages/wallarm-node-repo-1-4.el7.noarch.rpm \u00b6 {%- endtermtabs %}","title":"Add repo distr en"},{"location":"en/include-en/add-repo-distr-en/#apt-get-install-dirmngr","text":"","title":"apt-get install dirmngr"},{"location":"en/include-en/add-repo-distr-en/#apt-key-adv-keyserver-keysgnupgnet-recv-keys-72b865fd","text":"","title":"apt-key adv --keyserver keys.gnupg.net --recv-keys 72B865FD"},{"location":"en/include-en/add-repo-distr-en/#echo-acquirecheck-valid-until-false-etcaptaptconfdignore-release-date","text":"","title":"echo 'Acquire::Check-Valid-Until \"false\";' &gt; /etc/apt/apt.conf.d/ignore-release-date"},{"location":"en/include-en/add-repo-distr-en/#echo-deb-httparchivedebianorgdebian-jessie-backports-main-etcaptsourceslistdjessie-backportslist","text":"","title":"echo 'deb http://archive.debian.org/debian jessie-backports main' &gt; /etc/apt/sources.list.d/jessie-backports.list"},{"location":"en/include-en/add-repo-distr-en/#echo-deb-httprepowallarmcomdebianwallarm-node-jessie214-etcaptsourceslistdwallarmlist","text":"","title":"echo 'deb http://repo.wallarm.com/debian/wallarm-node jessie/2.14/' &gt; /etc/apt/sources.list.d/wallarm.list"},{"location":"en/include-en/add-repo-distr-en/#echo-deb-httprepowallarmcomdebianwallarm-node-jessie-backports214-etcaptsourceslistdwallarmlist","text":"","title":"echo 'deb http://repo.wallarm.com/debian/wallarm-node jessie-backports/2.14/' &gt;&gt; /etc/apt/sources.list.d/wallarm.list"},{"location":"en/include-en/add-repo-distr-en/#apt-get-update","text":"{%- tab name=\"Debian 9.x (stretch)\" -%}","title":"apt-get update"},{"location":"en/include-en/add-repo-distr-en/#apt-get-install-dirmngr_1","text":"","title":"apt-get install dirmngr"},{"location":"en/include-en/add-repo-distr-en/#apt-key-adv-keyserver-keysgnupgnet-recv-keys-72b865fd_1","text":"","title":"apt-key adv --keyserver keys.gnupg.net --recv-keys 72B865FD"},{"location":"en/include-en/add-repo-distr-en/#sh-c-echo-deb-httprepowallarmcomdebianwallarm-node-stretch214-etcaptsourceslistdwallarmlist","text":"","title":"sh -c \"echo 'deb http://repo.wallarm.com/debian/wallarm-node stretch/2.14/' &gt;/etc/apt/sources.list.d/wallarm.list\""},{"location":"en/include-en/add-repo-distr-en/#apt-get-update_1","text":"{%- tab name=\"Debian 9.x (stretch-backports)\" -%}","title":"apt-get update"},{"location":"en/include-en/add-repo-distr-en/#apt-get-install-dirmngr_2","text":"","title":"apt-get install dirmngr"},{"location":"en/include-en/add-repo-distr-en/#apt-key-adv-keyserver-keysgnupgnet-recv-keys-72b865fd_2","text":"","title":"apt-key adv --keyserver keys.gnupg.net --recv-keys 72B865FD"},{"location":"en/include-en/add-repo-distr-en/#sh-c-echo-deb-httprepowallarmcomdebianwallarm-node-stretch214-etcaptsourceslistdwallarmlist_1","text":"","title":"sh -c \"echo 'deb http://repo.wallarm.com/debian/wallarm-node stretch/2.14/' &gt;/etc/apt/sources.list.d/wallarm.list\""},{"location":"en/include-en/add-repo-distr-en/#sh-c-echo-deb-httprepowallarmcomdebianwallarm-node-stretch-backports214-etcaptsourceslistdwallarmlist","text":"[warning][IMPORTANT]uncomment the following line in /etc/apt/sources.list: deb http://deb.debian.org/debian stretch-backports main contrib non-free","title":"sh -c \"echo 'deb http://repo.wallarm.com/debian/wallarm-node stretch-backports/2.14/' &gt;&gt; /etc/apt/sources.list.d/wallarm.list\""},{"location":"en/include-en/add-repo-distr-en/#apt-get-update_2","text":"{%- tab name=\"Debian 10.x (buster)\" -%}","title":"apt-get update"},{"location":"en/include-en/add-repo-distr-en/#apt-get-install-dirmngr_3","text":"","title":"apt-get install dirmngr"},{"location":"en/include-en/add-repo-distr-en/#apt-key-adv-keyserver-keysgnupgnet-recv-keys-72b865fd_3","text":"","title":"apt-key adv --keyserver keys.gnupg.net --recv-keys 72B865FD"},{"location":"en/include-en/add-repo-distr-en/#sh-c-echo-deb-httprepowallarmcomdebianwallarm-node-buster214-etcaptsourceslistdwallarmlist","text":"","title":"sh -c \"echo 'deb http://repo.wallarm.com/debian/wallarm-node buster/2.14/' &gt; /etc/apt/sources.list.d/wallarm.list\""},{"location":"en/include-en/add-repo-distr-en/#apt-get-update_3","text":"{%- tab name=\"CentOS 6.x\" -%}","title":"apt-get update"},{"location":"en/include-en/add-repo-distr-en/#yum-install-enablerepoextras-y-epel-release-centos-release-scl","text":"","title":"yum install --enablerepo=extras -y epel-release centos-release-SCL"},{"location":"en/include-en/add-repo-distr-en/#rpm-i-httpsrepowallarmcomcentoswallarm-node6214x86_64packageswallarm-node-repo-1-4el6noarchrpm","text":"{%- tab name=\"CentOS 7.x\" -%}","title":"rpm -i https://repo.wallarm.com/centos/wallarm-node/6/2.14/x86_64/Packages/wallarm-node-repo-1-4.el6.noarch.rpm"},{"location":"en/include-en/add-repo-distr-en/#yum-install-y-epel-release","text":"","title":"yum install -y epel-release"},{"location":"en/include-en/add-repo-distr-en/#rpm-i-httpsrepowallarmcomcentoswallarm-node7214x86_64packageswallarm-node-repo-1-4el7noarchrpm","text":"{%- endtermtabs %}","title":"rpm -i https://repo.wallarm.com/centos/wallarm-node/7/2.14/x86_64/Packages/wallarm-node-repo-1-4.el7.noarch.rpm"},{"location":"en/include-en/add-repo-en/","text":"Debian 8.x (jessie) apt-get install dirmngr apt-key adv --keyserver keys.gnupg.net --recv-keys 72B865FD sh -c \"echo 'deb http://repo.wallarm.com/debian/wallarm-node jessie/2.14/' > /etc/apt/sources.list.d/wallarm.list\" apt-get update Debian 9.x (stretch) apt-get install dirmngr apt-key adv --keyserver keys.gnupg.net --recv-keys 72B865FD sh -c \"echo 'deb http://repo.wallarm.com/debian/wallarm-node stretch/2.14/' > /etc/apt/sources.list.d/wallarm.list\" apt-get update Debian 10.x (buster) apt-get install dirmngr apt-key adv --keyserver keys.gnupg.net --recv-keys 72B865FD sh -c \"echo 'deb http://repo.wallarm.com/debian/wallarm-node buster/2.14/' > /etc/apt/sources.list.d/wallarm.list\" apt-get update Ubuntu 14.04 LTS (trusty) apt-key adv --keyserver keys.gnupg.net --recv-keys 72B865FD sh -c \"echo 'deb http://repo.wallarm.com/ubuntu/wallarm-node trusty/2.14/' > /etc/apt/sources.list.d/wallarm.list\" apt-get update Ubuntu 16.04 LTS (xenial) apt-key adv --keyserver keys.gnupg.net --recv-keys 72B865FD sh -c \"echo 'deb http://repo.wallarm.com/ubuntu/wallarm-node xenial/2.14/' > /etc/apt/sources.list.d/wallarm.list\" apt-get update Ubuntu 18.04 LTS (bionic) apt-key adv --keyserver keys.gnupg.net --recv-keys 72B865FD sh -c \"echo 'deb http://repo.wallarm.com/ubuntu/wallarm-node bionic/2.14/' > /etc/apt/sources.list.d/wallarm.list\" apt-get update ``` CentOS 6.x yum install --enablerepo = extras -y epel-release centos-release-SCL rpm -i https://repo.wallarm.com/centos/wallarm-node/6/2.14/x86_64/Packages/wallarm-node-repo-1-4.el6.noarch.rpm CentOS 7.x yum install -y epel-release rpm -i https://repo.wallarm.com/centos/wallarm-node/7/2.14/x86_64/Packages/wallarm-node-repo-1-4.el7.noarch.rpm ``` Amazon Linux 2 yum install -y https://dl.fedoraproject.org/pub/epel/epel-release-latest-7.noarch.rpm rpm -i https://repo.wallarm.com/centos/wallarm-node/7/2.14/x86_64/Packages/wallarm-node-repo-1-4.el7.noarch.rpm","title":"Add repo en"},{"location":"en/include-en/add-repo-kong-en/","text":"{% termtabs name=\"Debian 8.x (jessie)\" -%} apt-key adv --keyserver keys.gnupg.net --recv-keys 72B865FD \u00b6 echo 'deb http://repo.wallarm.com/debian/wallarm-node jessie/2.14/' > /etc/apt/sources.list.d/wallarm.list \u00b6 apt-get update \u00b6 {%- tab name=\"Debian 9.x (stretch)\" -%} apt-get install dirmngr \u00b6 apt-key adv --keyserver keys.gnupg.net --recv-keys 72B865FD \u00b6 sh -c \"echo 'deb http://repo.wallarm.com/debian/wallarm-node stretch/2.14/' > /etc/apt/sources.list.d/wallarm.list\" \u00b6 apt-get update \u00b6 {%- tab name=\"Ubuntu 14.04 LTS (trusty)\" -%} apt-key adv --keyserver keys.gnupg.net --recv-keys 72B865FD \u00b6 echo 'deb http://repo.wallarm.com/ubuntu/wallarm-node trusty/2.14/' > /etc/apt/sources.list.d/wallarm.list \u00b6 apt-get update \u00b6 {%- tab name=\"Ubuntu 16.04 LTS (xenial)\" -%} apt-key adv --keyserver keys.gnupg.net --recv-keys 72B865FD \u00b6 echo 'deb http://repo.wallarm.com/ubuntu/wallarm-node xenial/2.14/' > /etc/apt/sources.list.d/wallarm.list \u00b6 apt-get update \u00b6 {%- tab name=\"Ubuntu 18.04 LTS (bionic)\" -%} apt-key adv --keyserver keys.gnupg.net --recv-keys 72B865FD \u00b6 sh -c \"echo 'deb http://repo.wallarm.com/ubuntu/wallarm-node bionic/2.14/' >/etc/apt/sources.list.d/wallarm.list\" \u00b6 apt-get update \u00b6 {%- tab name=\"CentOS 6.x\" -%} yum install --enablerepo=extras -y epel-release centos-release-SCL \u00b6 rpm -i https://repo.wallarm.com/centos/wallarm-node/6/2.14/x86_64/Packages/wallarm-node-repo-1-4.el6.noarch.rpm \u00b6 {%- tab name=\"CentOS 7.x\" -%} yum install -y epel-release \u00b6 rpm -i https://repo.wallarm.com/centos/wallarm-node/7/2.14/x86_64/Packages/wallarm-node-repo-1-4.el7.noarch.rpm \u00b6 {%- endtermtabs %}","title":"Add repo kong en"},{"location":"en/include-en/add-repo-kong-en/#apt-key-adv-keyserver-keysgnupgnet-recv-keys-72b865fd","text":"","title":"apt-key adv --keyserver keys.gnupg.net --recv-keys 72B865FD"},{"location":"en/include-en/add-repo-kong-en/#echo-deb-httprepowallarmcomdebianwallarm-node-jessie214-etcaptsourceslistdwallarmlist","text":"","title":"echo 'deb http://repo.wallarm.com/debian/wallarm-node jessie/2.14/' &gt; /etc/apt/sources.list.d/wallarm.list"},{"location":"en/include-en/add-repo-kong-en/#apt-get-update","text":"{%- tab name=\"Debian 9.x (stretch)\" -%}","title":"apt-get update"},{"location":"en/include-en/add-repo-kong-en/#apt-get-install-dirmngr","text":"","title":"apt-get install dirmngr"},{"location":"en/include-en/add-repo-kong-en/#apt-key-adv-keyserver-keysgnupgnet-recv-keys-72b865fd_1","text":"","title":"apt-key adv --keyserver keys.gnupg.net --recv-keys 72B865FD"},{"location":"en/include-en/add-repo-kong-en/#sh-c-echo-deb-httprepowallarmcomdebianwallarm-node-stretch214-etcaptsourceslistdwallarmlist","text":"","title":"sh -c \"echo 'deb http://repo.wallarm.com/debian/wallarm-node stretch/2.14/' &gt; /etc/apt/sources.list.d/wallarm.list\""},{"location":"en/include-en/add-repo-kong-en/#apt-get-update_1","text":"{%- tab name=\"Ubuntu 14.04 LTS (trusty)\" -%}","title":"apt-get update"},{"location":"en/include-en/add-repo-kong-en/#apt-key-adv-keyserver-keysgnupgnet-recv-keys-72b865fd_2","text":"","title":"apt-key adv --keyserver keys.gnupg.net --recv-keys 72B865FD"},{"location":"en/include-en/add-repo-kong-en/#echo-deb-httprepowallarmcomubuntuwallarm-node-trusty214-etcaptsourceslistdwallarmlist","text":"","title":"echo 'deb http://repo.wallarm.com/ubuntu/wallarm-node trusty/2.14/' &gt; /etc/apt/sources.list.d/wallarm.list"},{"location":"en/include-en/add-repo-kong-en/#apt-get-update_2","text":"{%- tab name=\"Ubuntu 16.04 LTS (xenial)\" -%}","title":"apt-get update"},{"location":"en/include-en/add-repo-kong-en/#apt-key-adv-keyserver-keysgnupgnet-recv-keys-72b865fd_3","text":"","title":"apt-key adv --keyserver keys.gnupg.net --recv-keys 72B865FD"},{"location":"en/include-en/add-repo-kong-en/#echo-deb-httprepowallarmcomubuntuwallarm-node-xenial214-etcaptsourceslistdwallarmlist","text":"","title":"echo 'deb http://repo.wallarm.com/ubuntu/wallarm-node xenial/2.14/' &gt; /etc/apt/sources.list.d/wallarm.list"},{"location":"en/include-en/add-repo-kong-en/#apt-get-update_3","text":"{%- tab name=\"Ubuntu 18.04 LTS (bionic)\" -%}","title":"apt-get update"},{"location":"en/include-en/add-repo-kong-en/#apt-key-adv-keyserver-keysgnupgnet-recv-keys-72b865fd_4","text":"","title":"apt-key adv --keyserver keys.gnupg.net --recv-keys 72B865FD"},{"location":"en/include-en/add-repo-kong-en/#sh-c-echo-deb-httprepowallarmcomubuntuwallarm-node-bionic214-etcaptsourceslistdwallarmlist","text":"","title":"sh -c \"echo 'deb http://repo.wallarm.com/ubuntu/wallarm-node bionic/2.14/' &gt;/etc/apt/sources.list.d/wallarm.list\""},{"location":"en/include-en/add-repo-kong-en/#apt-get-update_4","text":"{%- tab name=\"CentOS 6.x\" -%}","title":"apt-get update"},{"location":"en/include-en/add-repo-kong-en/#yum-install-enablerepoextras-y-epel-release-centos-release-scl","text":"","title":"yum install --enablerepo=extras -y epel-release centos-release-SCL"},{"location":"en/include-en/add-repo-kong-en/#rpm-i-httpsrepowallarmcomcentoswallarm-node6214x86_64packageswallarm-node-repo-1-4el6noarchrpm","text":"{%- tab name=\"CentOS 7.x\" -%}","title":"rpm -i https://repo.wallarm.com/centos/wallarm-node/6/2.14/x86_64/Packages/wallarm-node-repo-1-4.el6.noarch.rpm"},{"location":"en/include-en/add-repo-kong-en/#yum-install-y-epel-release","text":"","title":"yum install -y epel-release"},{"location":"en/include-en/add-repo-kong-en/#rpm-i-httpsrepowallarmcomcentoswallarm-node7214x86_64packageswallarm-node-repo-1-4el7noarchrpm","text":"{%- endtermtabs %}","title":"rpm -i https://repo.wallarm.com/centos/wallarm-node/7/2.14/x86_64/Packages/wallarm-node-repo-1-4.el7.noarch.rpm"},{"location":"en/include-en/add-repo-legacy-en/","text":"{% termtabs name=\"Debian 8.x (jessie)\" -%} apt-key adv --keyserver keys.gnupg.net --recv-keys 72B865FD \u00b6 echo 'deb http://repo.wallarm.com/debian/wallarm-node jessie/' >/etc/apt/sources.list.d/wallarm.list \u00b6 apt-get update \u00b6 {%- tab name=\"Debian 9.x (stretch)\" -%} apt-get install dirmngr \u00b6 apt-key adv --keyserver keys.gnupg.net --recv-keys 72B865FD \u00b6 sh -c \"echo 'deb http://repo.wallarm.com/debian/wallarm-node stretch/' >/etc/apt/sources.list.d/wallarm.list\" \u00b6 apt-get update \u00b6 {%- tab name=\"Ubuntu 14.04 LTS (trusty)\" -%} apt-key adv --keyserver keys.gnupg.net --recv-keys 72B865FD \u00b6 echo 'deb http://repo.wallarm.com/ubuntu/wallarm-node trusty/' >/etc/apt/sources.list.d/wallarm.list \u00b6 apt-get update \u00b6 {%- tab name=\"Ubuntu 16.04 LTS (xenial)\" -%} apt-key adv --keyserver keys.gnupg.net --recv-keys 72B865FD \u00b6 echo 'deb http://repo.wallarm.com/ubuntu/wallarm-node xenial/' >/etc/apt/sources.list.d/wallarm.list \u00b6 apt-get update \u00b6 {%- tab name=\"Ubuntu 18.04 LTS (bionic)\" -%} apt-key adv --keyserver keys.gnupg.net --recv-keys 72B865FD \u00b6 sh -c \"echo 'deb http://repo.wallarm.com/ubuntu/wallarm-node bionic/' >/etc/apt/sources.list.d/wallarm.list\" \u00b6 apt-get update \u00b6 {%- tab name=\"CentOS 7.x\" -%} yum install -y epel-release \u00b6 rpm -i https://repo.wallarm.com/centos/wallarm-node/7/x86_64/Packages/wallarm-node-repo-1-2.el7.centos.noarch.rpm \u00b6 {%- endtermtabs %}","title":"Add repo legacy en"},{"location":"en/include-en/add-repo-legacy-en/#apt-key-adv-keyserver-keysgnupgnet-recv-keys-72b865fd","text":"","title":"apt-key adv --keyserver keys.gnupg.net --recv-keys 72B865FD"},{"location":"en/include-en/add-repo-legacy-en/#echo-deb-httprepowallarmcomdebianwallarm-node-jessie-etcaptsourceslistdwallarmlist","text":"","title":"echo 'deb http://repo.wallarm.com/debian/wallarm-node jessie/' &gt;/etc/apt/sources.list.d/wallarm.list"},{"location":"en/include-en/add-repo-legacy-en/#apt-get-update","text":"{%- tab name=\"Debian 9.x (stretch)\" -%}","title":"apt-get update"},{"location":"en/include-en/add-repo-legacy-en/#apt-get-install-dirmngr","text":"","title":"apt-get install dirmngr"},{"location":"en/include-en/add-repo-legacy-en/#apt-key-adv-keyserver-keysgnupgnet-recv-keys-72b865fd_1","text":"","title":"apt-key adv --keyserver keys.gnupg.net --recv-keys 72B865FD"},{"location":"en/include-en/add-repo-legacy-en/#sh-c-echo-deb-httprepowallarmcomdebianwallarm-node-stretch-etcaptsourceslistdwallarmlist","text":"","title":"sh -c \"echo 'deb http://repo.wallarm.com/debian/wallarm-node stretch/' &gt;/etc/apt/sources.list.d/wallarm.list\""},{"location":"en/include-en/add-repo-legacy-en/#apt-get-update_1","text":"{%- tab name=\"Ubuntu 14.04 LTS (trusty)\" -%}","title":"apt-get update"},{"location":"en/include-en/add-repo-legacy-en/#apt-key-adv-keyserver-keysgnupgnet-recv-keys-72b865fd_2","text":"","title":"apt-key adv --keyserver keys.gnupg.net --recv-keys 72B865FD"},{"location":"en/include-en/add-repo-legacy-en/#echo-deb-httprepowallarmcomubuntuwallarm-node-trusty-etcaptsourceslistdwallarmlist","text":"","title":"echo 'deb http://repo.wallarm.com/ubuntu/wallarm-node trusty/' &gt;/etc/apt/sources.list.d/wallarm.list"},{"location":"en/include-en/add-repo-legacy-en/#apt-get-update_2","text":"{%- tab name=\"Ubuntu 16.04 LTS (xenial)\" -%}","title":"apt-get update"},{"location":"en/include-en/add-repo-legacy-en/#apt-key-adv-keyserver-keysgnupgnet-recv-keys-72b865fd_3","text":"","title":"apt-key adv --keyserver keys.gnupg.net --recv-keys 72B865FD"},{"location":"en/include-en/add-repo-legacy-en/#echo-deb-httprepowallarmcomubuntuwallarm-node-xenial-etcaptsourceslistdwallarmlist","text":"","title":"echo 'deb http://repo.wallarm.com/ubuntu/wallarm-node xenial/' &gt;/etc/apt/sources.list.d/wallarm.list"},{"location":"en/include-en/add-repo-legacy-en/#apt-get-update_3","text":"{%- tab name=\"Ubuntu 18.04 LTS (bionic)\" -%}","title":"apt-get update"},{"location":"en/include-en/add-repo-legacy-en/#apt-key-adv-keyserver-keysgnupgnet-recv-keys-72b865fd_4","text":"","title":"apt-key adv --keyserver keys.gnupg.net --recv-keys 72B865FD"},{"location":"en/include-en/add-repo-legacy-en/#sh-c-echo-deb-httprepowallarmcomubuntuwallarm-node-bionic-etcaptsourceslistdwallarmlist","text":"","title":"sh -c \"echo 'deb http://repo.wallarm.com/ubuntu/wallarm-node bionic/' &gt;/etc/apt/sources.list.d/wallarm.list\""},{"location":"en/include-en/add-repo-legacy-en/#apt-get-update_4","text":"{%- tab name=\"CentOS 7.x\" -%}","title":"apt-get update"},{"location":"en/include-en/add-repo-legacy-en/#yum-install-y-epel-release","text":"","title":"yum install -y epel-release"},{"location":"en/include-en/add-repo-legacy-en/#rpm-i-httpsrepowallarmcomcentoswallarm-node7x86_64packageswallarm-node-repo-1-2el7centosnoarchrpm","text":"{%- endtermtabs %}","title":"rpm -i https://repo.wallarm.com/centos/wallarm-node/7/x86_64/Packages/wallarm-node-repo-1-2.el7.centos.noarch.rpm"},{"location":"en/include-en/check-operation-en/","text":"If everything is configured correctly, Wallarm filters the requests and proxies the filtered requests in accordance with the configuration file settings. To check the correct operation, you must: Execute the wallarm-status request. Run a test attack. 1. Execute the wallarm-status Request \u00b6 You can get filter node operation statistics by requesting the /wallarm-status URL. Run the command: curl http://127.0.0.8/wallarm-status The output will be like: { \"requests\" : 0 , \"attacks\" : 0 , \"blocked\" : 0 , \"abnormal\" : 0 , \"tnt_errors\" : 0 , \"api_errors\" : 0 , \"requests_lost\" : 0 , \"segfaults\" : 0 , \"memfaults\" : 0 , \"softmemfaults\" : 0 , \"time_detect\" : 0 , \"db_id\" : 46 , \"lom_id\" : 16767 , \"proton_instances\" :{ \"total\" : 1 , \"success\" : 1 , \"fallback\" : 0 , \"failed\" : 0 }, \"stalled_workers_count\" : 0 , \"stalled_workers\" :[] } This means that the filter node statistics service is running and working properly. The Statistics Service You can read more about the statistics service and how to configure it here . 2. Run a Test Attack \u00b6 To check if Wallarm correctly detects attacks, send an invalid request to the protected resource. For example: http://<resource_URL>/?id='or+1=1--a-<script>prompt(1)</script> Wallarm must detect in the request the following: SQLI XSS Now the counter of the number of attacks will increase when a request for wallarm-status is executed, which means that the filter node is operating normally.","title":"Check operation en"},{"location":"en/include-en/check-operation-en/#1-execute-the-wallarm-status-request","text":"You can get filter node operation statistics by requesting the /wallarm-status URL. Run the command: curl http://127.0.0.8/wallarm-status The output will be like: { \"requests\" : 0 , \"attacks\" : 0 , \"blocked\" : 0 , \"abnormal\" : 0 , \"tnt_errors\" : 0 , \"api_errors\" : 0 , \"requests_lost\" : 0 , \"segfaults\" : 0 , \"memfaults\" : 0 , \"softmemfaults\" : 0 , \"time_detect\" : 0 , \"db_id\" : 46 , \"lom_id\" : 16767 , \"proton_instances\" :{ \"total\" : 1 , \"success\" : 1 , \"fallback\" : 0 , \"failed\" : 0 }, \"stalled_workers_count\" : 0 , \"stalled_workers\" :[] } This means that the filter node statistics service is running and working properly. The Statistics Service You can read more about the statistics service and how to configure it here .","title":"1. Execute the wallarm-status Request"},{"location":"en/include-en/check-operation-en/#2-run-a-test-attack","text":"To check if Wallarm correctly detects attacks, send an invalid request to the protected resource. For example: http://<resource_URL>/?id='or+1=1--a-<script>prompt(1)</script> Wallarm must detect in the request the following: SQLI XSS Now the counter of the number of attacks will increase when a request for wallarm-status is executed, which means that the filter node is operating normally.","title":"2. Run a Test Attack"},{"location":"en/include-en/check-postanalytics-status/","text":"{% termtabs name=\"Debian 8.x (jessie)\" -%} systemctl status wallarm-tarantool \u00b6 {%- tab name=\"Debian 9.x (stretch)\" -%} systemctl status wallarm-tarantool \u00b6 {%- tab name=\"Debian 10.x (buster)\" -%} systemctl status wallarm-tarantool \u00b6 {%- tab name=\"Ubuntu 14.04 LTS (trusty)\" -%} service wallarm-tarantool status \u00b6 {%- tab name=\"Ubuntu 16.04 LTS (xenial)\" -%} systemctl status wallarm-tarantool \u00b6 {%- tab name=\"Ubuntu 18.04 LTS (bionic)\" -%} systemctl status wallarm-tarantool \u00b6 {%- tab name=\"CentOS 6.x\" -%} service wallarm-tarantool status \u00b6 {%- tab name=\"CentOS 7.x\" -%} systemctl status wallarm-tarantool \u00b6 {%- tab name=\"Amazon Linux 2\" -%} systemctl status wallarm-tarantool \u00b6 {%- endtermtabs %}","title":"Check postanalytics status"},{"location":"en/include-en/check-postanalytics-status/#systemctl-status-wallarm-tarantool","text":"{%- tab name=\"Debian 9.x (stretch)\" -%}","title":"systemctl status wallarm-tarantool"},{"location":"en/include-en/check-postanalytics-status/#systemctl-status-wallarm-tarantool_1","text":"{%- tab name=\"Debian 10.x (buster)\" -%}","title":"systemctl status wallarm-tarantool"},{"location":"en/include-en/check-postanalytics-status/#systemctl-status-wallarm-tarantool_2","text":"{%- tab name=\"Ubuntu 14.04 LTS (trusty)\" -%}","title":"systemctl status wallarm-tarantool"},{"location":"en/include-en/check-postanalytics-status/#service-wallarm-tarantool-status","text":"{%- tab name=\"Ubuntu 16.04 LTS (xenial)\" -%}","title":"service wallarm-tarantool status"},{"location":"en/include-en/check-postanalytics-status/#systemctl-status-wallarm-tarantool_3","text":"{%- tab name=\"Ubuntu 18.04 LTS (bionic)\" -%}","title":"systemctl status wallarm-tarantool"},{"location":"en/include-en/check-postanalytics-status/#systemctl-status-wallarm-tarantool_4","text":"{%- tab name=\"CentOS 6.x\" -%}","title":"systemctl status wallarm-tarantool"},{"location":"en/include-en/check-postanalytics-status/#service-wallarm-tarantool-status_1","text":"{%- tab name=\"CentOS 7.x\" -%}","title":"service wallarm-tarantool status"},{"location":"en/include-en/check-postanalytics-status/#systemctl-status-wallarm-tarantool_5","text":"{%- tab name=\"Amazon Linux 2\" -%}","title":"systemctl status wallarm-tarantool"},{"location":"en/include-en/check-postanalytics-status/#systemctl-status-wallarm-tarantool_6","text":"{%- endtermtabs %}","title":"systemctl status wallarm-tarantool"},{"location":"en/include-en/check-setup-installation-en/","text":"Check that the filter node runs and filters the traffic. See Check the filter node operation .","title":"Check setup installation en"},{"location":"en/include-en/configure-postanalytics-address-en/","text":"Add the server address of postanalytics to /etc/nginx-wallarm/conf.d/wallarm.conf : upstream wallarm_tarantool { server <ip1>:3313 max_fails=0 fail_timeout=0 max_conns=1; server <ip2>:3313 max_fails=0 fail_timeout=0 max_conns=1; keepalive 2; } ... wallarm_tarantool_upstream wallarm_tarantool; #### Warning:: Required conditions It is required that the following conditions are satisfied for the `max_conns` and the `keepalive` parameters: * The value of the `keepalive` parameter must not be lower than the number of the tarantool servers. * The value of the `max_conns` parameter must be specified for each of the upstream Tarantool servers to prevent the creation of excessive connections.","title":"Configure postanalytics address en"},{"location":"en/include-en/configure-postanalytics-address-kong-en/","text":"Add the server address of postanalytics to /etc/kong/nginx-wallarm.template : upstream wallarm_tarantool { server <ip1>:3313 max_fails=0 fail_timeout=0 max_conns=1; server <ip2>:3313 max_fails=0 fail_timeout=0 max_conns=1; keepalive 2; } ... wallarm_tarantool_upstream wallarm_tarantool; #### Warning:: Required conditions It is required that the following conditions are satisfied for the `max_conns` and the `keepalive` parameters: * The value of the `keepalive` parameter must not be lower than the number of the tarantool servers. * The value of the `max_conns` parameter must be specified for each of the upstream Tarantool servers to prevent the creation of excessive connections.","title":"Configure postanalytics address kong en"},{"location":"en/include-en/configure-postanalytics-address-nginx-en/","text":"Add the server address of postanalytics to /etc/nginx/conf.d/wallarm.conf : upstream wallarm_tarantool { server <ip1>:3313 max_fails=0 fail_timeout=0 max_conns=1; server <ip2>:3313 max_fails=0 fail_timeout=0 max_conns=1; keepalive 2; } ... wallarm_tarantool_upstream wallarm_tarantool; #### Warning:: Required conditions It is required that the following conditions are satisfied for the `max_conns` and the `keepalive` parameters: * The value of the `keepalive` parameter must not be lower than the number of the tarantool servers. * The value of the `max_conns` parameter must be specified for each of the upstream Tarantool servers to prevent the creation of excessive connections.","title":"Configure postanalytics address nginx en"},{"location":"en/include-en/configure-postanalytics-distr-en/","text":"The amount of memory determines the quality of work of the statistical algorithms. The recommended value is 75% of the total server memory. For example, if the server has 32 GB of memory, the recommended allocation size is 24 GB. Allocate the operating memory size for Tarantool: Open for editing the configuration file of Tarantool: {% termtabs name=\"Debian 8.x (jessie)\" -%} vi /etc/default/wallarm-tarantool \u00b6 {%- tab name=\"Debian 9.x (stretch)\" -%} vi /etc/default/wallarm-tarantool \u00b6 {%- tab name=\"Debian 10.x (buster)\" -%} vi /etc/default/wallarm-tarantool \u00b6 {%- tab name=\"CentOS 6.x\" -%} vi /etc/sysconfig/wallarm-tarantool \u00b6 {%- tab name=\"CentOS 7.x\" -%} vi /etc/sysconfig/wallarm-tarantool \u00b6 {%- endtermtabs %} Set the allocated memory size in the configuration file of Tarantool via the SLAB_ALLOC_ARENA directive. For example: SLAB_ALLOC_ARENA=24 Restart Tarantool: {% termtabs name=\"Debian 8.x (jessie)\" -%} systemctl restart wallarm-tarantool \u00b6 {%- tab name=\"Debian 9.x (stretch)\" -%} systemctl restart wallarm-tarantool \u00b6 {%- tab name=\"Debian 10.x (buster)\" -%} systemctl restart wallarm-tarantool \u00b6 {%- tab name=\"CentOS 6.x\" -%} service wallarm-tarantool restart \u00b6 {%- tab name=\"CentOS 7.x\" -%} systemctl restart wallarm-tarantool \u00b6 {%- endtermtabs %}","title":"Configure postanalytics distr en"},{"location":"en/include-en/configure-postanalytics-distr-en/#vi-etcdefaultwallarm-tarantool","text":"{%- tab name=\"Debian 9.x (stretch)\" -%}","title":"vi /etc/default/wallarm-tarantool"},{"location":"en/include-en/configure-postanalytics-distr-en/#vi-etcdefaultwallarm-tarantool_1","text":"{%- tab name=\"Debian 10.x (buster)\" -%}","title":"vi /etc/default/wallarm-tarantool"},{"location":"en/include-en/configure-postanalytics-distr-en/#vi-etcdefaultwallarm-tarantool_2","text":"{%- tab name=\"CentOS 6.x\" -%}","title":"vi /etc/default/wallarm-tarantool"},{"location":"en/include-en/configure-postanalytics-distr-en/#vi-etcsysconfigwallarm-tarantool","text":"{%- tab name=\"CentOS 7.x\" -%}","title":"vi /etc/sysconfig/wallarm-tarantool"},{"location":"en/include-en/configure-postanalytics-distr-en/#vi-etcsysconfigwallarm-tarantool_1","text":"{%- endtermtabs %} Set the allocated memory size in the configuration file of Tarantool via the SLAB_ALLOC_ARENA directive. For example: SLAB_ALLOC_ARENA=24 Restart Tarantool: {% termtabs name=\"Debian 8.x (jessie)\" -%}","title":"vi /etc/sysconfig/wallarm-tarantool"},{"location":"en/include-en/configure-postanalytics-distr-en/#systemctl-restart-wallarm-tarantool","text":"{%- tab name=\"Debian 9.x (stretch)\" -%}","title":"systemctl restart wallarm-tarantool"},{"location":"en/include-en/configure-postanalytics-distr-en/#systemctl-restart-wallarm-tarantool_1","text":"{%- tab name=\"Debian 10.x (buster)\" -%}","title":"systemctl restart wallarm-tarantool"},{"location":"en/include-en/configure-postanalytics-distr-en/#systemctl-restart-wallarm-tarantool_2","text":"{%- tab name=\"CentOS 6.x\" -%}","title":"systemctl restart wallarm-tarantool"},{"location":"en/include-en/configure-postanalytics-distr-en/#service-wallarm-tarantool-restart","text":"{%- tab name=\"CentOS 7.x\" -%}","title":"service wallarm-tarantool restart"},{"location":"en/include-en/configure-postanalytics-distr-en/#systemctl-restart-wallarm-tarantool_3","text":"{%- endtermtabs %}","title":"systemctl restart wallarm-tarantool"},{"location":"en/include-en/configure-postanalytics-en/","text":"The amount of memory determines the quality of work of the statistical algorithms. The recommended value is 75% of the total server memory. For example, if the server has 32 GB of memory, the recommended allocation size is 24 GB. Allocate the operating memory size for Tarantool: Open for editing the configuration file of Tarantool: Debian 8.x (jessie) vi /etc/default/wallarm-tarantool Debian 9.x (stretch) vi /etc/default/wallarm-tarantool Debian 10.x (buster) vi /etc/default/wallarm-tarantool Ubuntu 14.04 LTS (trusty) vi /etc/default/wallarm-tarantool Ubuntu 16.04 LTS (xenial) vi /etc/default/wallarm-tarantool Ubuntu 18.04 LTS (bionic) vi /etc/default/wallarm-tarantool CentOS 6.x vi /etc/sysconfig/wallarm-tarantool CentOS 7.x vi /etc/sysconfig/wallarm-tarantool Amazon Linux 2 vi /etc/sysconfig/wallarm-tarantool Set the allocated memory size in the configuration file of Tarantool via the SLAB_ALLOC_ARENA directive. For example: SLAB_ALLOC_ARENA=24 Restart Tarantool: Debian 8.x (jessie) systemctl restart wallarm-tarantool Debian 9.x (stretch) systemctl restart wallarm-tarantool Debian 10.x (buster) systemctl restart wallarm-tarantool Ubuntu 14.04 LTS (trusty) service wallarm-tarantool restart Ubuntu 16.04 LTS (xenial) service wallarm-tarantool restart Ubuntu 18.04 LTS (bionic) service wallarm-tarantool restart CentOS 6.x service wallarm-tarantool restart CentOS 7.x systemctl restart wallarm-tarantool Amazon Linux 2 systemctl restart wallarm-tarantool","title":"Configure postanalytics en"},{"location":"en/include-en/configure-postanalytics-kong-en/","text":"The amount of memory determines the quality of work of the statistical algorithms. The recommended value is 75% of the total server memory. For example, if the server has 32 GB of memory, the recommended allocation size is 24 GB. Allocate the operating memory size for Tarantool: Open for editing the configuration file of Tarantool: {% termtabs name=\"Debian 8.x (jessie)\" -%} vi /etc/default/wallarm-tarantool \u00b6 {%- tab name=\"Debian 9.x (stretch)\" -%} vi /etc/default/wallarm-tarantool \u00b6 {%- tab name=\"Ubuntu 14.04 LTS (trusty)\" -%} vi /etc/default/wallarm-tarantool \u00b6 {%- tab name=\"Ubuntu 16.04 LTS (xenial)\" -%} vi /etc/default/wallarm-tarantool \u00b6 {%- tab name=\"Ubuntu 18.04 LTS (bionic)\" -%} vi /etc/default/wallarm-tarantool \u00b6 {%- tab name=\"CentOS 6.x\" -%} vi /etc/sysconfig/wallarm-tarantool \u00b6 {%- tab name=\"CentOS 7.x\" -%} vi /etc/sysconfig/wallarm-tarantool \u00b6 {%- endtermtabs %} Set the allocated memory size in the configuration file of Tarantool via the SLAB_ALLOC_ARENA directive. For example: SLAB_ALLOC_ARENA=24 Restart Tarantool: {% termtabs name=\"Debian 8.x (jessie)\" -%} systemctl restart wallarm-tarantool \u00b6 {%- tab name=\"Debian 9.x (stretch)\" -%} systemctl restart wallarm-tarantool \u00b6 {%- tab name=\"Ubuntu 14.04 LTS (trusty)\" -%} service wallarm-tarantool restart \u00b6 {%- tab name=\"Ubuntu 16.04 LTS (xenial)\" -%} service wallarm-tarantool restart \u00b6 {%- tab name=\"Ubuntu 18.04 LTS (bionic)\" -%} service wallarm-tarantool restart \u00b6 {%- tab name=\"CentOS 6.x\" -%} service wallarm-tarantool restart \u00b6 {%- tab name=\"CentOS 7.x\" -%} systemctl restart wallarm-tarantool \u00b6 {%- endtermtabs %}","title":"Configure postanalytics kong en"},{"location":"en/include-en/configure-postanalytics-kong-en/#vi-etcdefaultwallarm-tarantool","text":"{%- tab name=\"Debian 9.x (stretch)\" -%}","title":"vi /etc/default/wallarm-tarantool"},{"location":"en/include-en/configure-postanalytics-kong-en/#vi-etcdefaultwallarm-tarantool_1","text":"{%- tab name=\"Ubuntu 14.04 LTS (trusty)\" -%}","title":"vi /etc/default/wallarm-tarantool"},{"location":"en/include-en/configure-postanalytics-kong-en/#vi-etcdefaultwallarm-tarantool_2","text":"{%- tab name=\"Ubuntu 16.04 LTS (xenial)\" -%}","title":"vi /etc/default/wallarm-tarantool"},{"location":"en/include-en/configure-postanalytics-kong-en/#vi-etcdefaultwallarm-tarantool_3","text":"{%- tab name=\"Ubuntu 18.04 LTS (bionic)\" -%}","title":"vi /etc/default/wallarm-tarantool"},{"location":"en/include-en/configure-postanalytics-kong-en/#vi-etcdefaultwallarm-tarantool_4","text":"{%- tab name=\"CentOS 6.x\" -%}","title":"vi /etc/default/wallarm-tarantool"},{"location":"en/include-en/configure-postanalytics-kong-en/#vi-etcsysconfigwallarm-tarantool","text":"{%- tab name=\"CentOS 7.x\" -%}","title":"vi /etc/sysconfig/wallarm-tarantool"},{"location":"en/include-en/configure-postanalytics-kong-en/#vi-etcsysconfigwallarm-tarantool_1","text":"{%- endtermtabs %} Set the allocated memory size in the configuration file of Tarantool via the SLAB_ALLOC_ARENA directive. For example: SLAB_ALLOC_ARENA=24 Restart Tarantool: {% termtabs name=\"Debian 8.x (jessie)\" -%}","title":"vi /etc/sysconfig/wallarm-tarantool"},{"location":"en/include-en/configure-postanalytics-kong-en/#systemctl-restart-wallarm-tarantool","text":"{%- tab name=\"Debian 9.x (stretch)\" -%}","title":"systemctl restart wallarm-tarantool"},{"location":"en/include-en/configure-postanalytics-kong-en/#systemctl-restart-wallarm-tarantool_1","text":"{%- tab name=\"Ubuntu 14.04 LTS (trusty)\" -%}","title":"systemctl restart wallarm-tarantool"},{"location":"en/include-en/configure-postanalytics-kong-en/#service-wallarm-tarantool-restart","text":"{%- tab name=\"Ubuntu 16.04 LTS (xenial)\" -%}","title":"service wallarm-tarantool restart"},{"location":"en/include-en/configure-postanalytics-kong-en/#service-wallarm-tarantool-restart_1","text":"{%- tab name=\"Ubuntu 18.04 LTS (bionic)\" -%}","title":"service wallarm-tarantool restart"},{"location":"en/include-en/configure-postanalytics-kong-en/#service-wallarm-tarantool-restart_2","text":"{%- tab name=\"CentOS 6.x\" -%}","title":"service wallarm-tarantool restart"},{"location":"en/include-en/configure-postanalytics-kong-en/#service-wallarm-tarantool-restart_3","text":"{%- tab name=\"CentOS 7.x\" -%}","title":"service wallarm-tarantool restart"},{"location":"en/include-en/configure-postanalytics-kong-en/#systemctl-restart-wallarm-tarantool_2","text":"{%- endtermtabs %}","title":"systemctl restart wallarm-tarantool"},{"location":"en/include-en/configure-postanalytics-legacy-en/","text":"The amount of memory determines the quality of work of the statistical algorithms. The recommended value is 75% of the total server memory. For example, if the server has 32 GB of memory, the recommended allocation size is 24 GB. Allocate the operating memory size for Tarantool: Open for editing the configuration file of Tarantool: {% termtabs name=\"Debian 8.x (jessie)\" -%} vi /etc/default/wallarm-tarantool \u00b6 {%- tab name=\"Debian 9.x (stretch)\" -%} vi /etc/default/wallarm-tarantool \u00b6 {%- tab name=\"Ubuntu 14.04 LTS (trusty)\" -%} vi /etc/default/wallarm-tarantool \u00b6 {%- tab name=\"Ubuntu 16.04 LTS (xenial)\" -%} vi /etc/default/wallarm-tarantool \u00b6 {%- tab name=\"Ubuntu 18.04 LTS (bionic)\" -%} vi /etc/default/wallarm-tarantool \u00b6 {%- tab name=\"CentOS 7.x\" -%} vi /etc/sysconfig/wallarm-tarantool \u00b6 {%- endtermtabs %} Set the allocated memory size in the configuration file of Tarantool via the SLAB_ALLOC_ARENA directive. For example: SLAB_ALLOC_ARENA=24 Restart Tarantool: {% termtabs name=\"Debian 8.x (jessie)\" -%} systemctl restart wallarm-tarantool \u00b6 {%- tab name=\"Debian 9.x (stretch)\" -%} systemctl restart wallarm-tarantool \u00b6 {%- tab name=\"Ubuntu 14.04 LTS (trusty)\" -%} service wallarm-tarantool restart \u00b6 {%- tab name=\"Ubuntu 16.04 LTS (xenial)\" -%} service wallarm-tarantool restart \u00b6 {%- tab name=\"Ubuntu 18.04 LTS (bionic)\" -%} service wallarm-tarantool restart \u00b6 {%- tab name=\"CentOS 7.x\" -%} systemctl restart wallarm-tarantool \u00b6 {%- endtermtabs %}","title":"Configure postanalytics legacy en"},{"location":"en/include-en/configure-postanalytics-legacy-en/#vi-etcdefaultwallarm-tarantool","text":"{%- tab name=\"Debian 9.x (stretch)\" -%}","title":"vi /etc/default/wallarm-tarantool"},{"location":"en/include-en/configure-postanalytics-legacy-en/#vi-etcdefaultwallarm-tarantool_1","text":"{%- tab name=\"Ubuntu 14.04 LTS (trusty)\" -%}","title":"vi /etc/default/wallarm-tarantool"},{"location":"en/include-en/configure-postanalytics-legacy-en/#vi-etcdefaultwallarm-tarantool_2","text":"{%- tab name=\"Ubuntu 16.04 LTS (xenial)\" -%}","title":"vi /etc/default/wallarm-tarantool"},{"location":"en/include-en/configure-postanalytics-legacy-en/#vi-etcdefaultwallarm-tarantool_3","text":"{%- tab name=\"Ubuntu 18.04 LTS (bionic)\" -%}","title":"vi /etc/default/wallarm-tarantool"},{"location":"en/include-en/configure-postanalytics-legacy-en/#vi-etcdefaultwallarm-tarantool_4","text":"{%- tab name=\"CentOS 7.x\" -%}","title":"vi /etc/default/wallarm-tarantool"},{"location":"en/include-en/configure-postanalytics-legacy-en/#vi-etcsysconfigwallarm-tarantool","text":"{%- endtermtabs %} Set the allocated memory size in the configuration file of Tarantool via the SLAB_ALLOC_ARENA directive. For example: SLAB_ALLOC_ARENA=24 Restart Tarantool: {% termtabs name=\"Debian 8.x (jessie)\" -%}","title":"vi /etc/sysconfig/wallarm-tarantool"},{"location":"en/include-en/configure-postanalytics-legacy-en/#systemctl-restart-wallarm-tarantool","text":"{%- tab name=\"Debian 9.x (stretch)\" -%}","title":"systemctl restart wallarm-tarantool"},{"location":"en/include-en/configure-postanalytics-legacy-en/#systemctl-restart-wallarm-tarantool_1","text":"{%- tab name=\"Ubuntu 14.04 LTS (trusty)\" -%}","title":"systemctl restart wallarm-tarantool"},{"location":"en/include-en/configure-postanalytics-legacy-en/#service-wallarm-tarantool-restart","text":"{%- tab name=\"Ubuntu 16.04 LTS (xenial)\" -%}","title":"service wallarm-tarantool restart"},{"location":"en/include-en/configure-postanalytics-legacy-en/#service-wallarm-tarantool-restart_1","text":"{%- tab name=\"Ubuntu 18.04 LTS (bionic)\" -%}","title":"service wallarm-tarantool restart"},{"location":"en/include-en/configure-postanalytics-legacy-en/#service-wallarm-tarantool-restart_2","text":"{%- tab name=\"CentOS 7.x\" -%}","title":"service wallarm-tarantool restart"},{"location":"en/include-en/configure-postanalytics-legacy-en/#systemctl-restart-wallarm-tarantool_2","text":"{%- endtermtabs %}","title":"systemctl restart wallarm-tarantool"},{"location":"en/include-en/configure-postanalytics-separate-en/","text":"Allocate the operating memory size for Tarantool The amount of memory determines the quality of work of the statistical algorithms. The recommended value is 75% of the total server memory. For example, if the server has 32 GB of memory, the recommended allocation size is 24 GB. Open for editing the configuration file of Tarantool: {% termtabs name=\"Debian 8.x (jessie)\" -%} vi /etc/default/wallarm-tarantool \u00b6 {%- tab name=\"Debian 9.x (stretch)\" -%} vi /etc/default/wallarm-tarantool \u00b6 {%- tab name=\"Debian 10.x (buster)\" -%} vi /etc/default/wallarm-tarantool \u00b6 {%- tab name=\"Ubuntu 14.04 LTS (trusty)\" -%} vi /etc/default/wallarm-tarantool \u00b6 {%- tab name=\"Ubuntu 16.04 LTS (xenial)\" -%} vi /etc/default/wallarm-tarantool \u00b6 {%- tab name=\"Ubuntu 18.04 LTS (bionic)\" -%} vi /etc/default/wallarm-tarantool \u00b6 {%- tab name=\"CentOS 6.x\" -%} vi /etc/sysconfig/wallarm-tarantool \u00b6 {%- tab name=\"CentOS 7.x\" -%} vi /etc/sysconfig/wallarm-tarantool \u00b6 {%- tab name=\"Amazon Linux 2\" -%} vi /etc/sysconfig/wallarm-tarantool \u00b6 {%- endtermtabs %} Set the allocated memory size in the configuration file of Tarantool via the SLAB_ALLOC_ARENA directive. For example: SLAB_ALLOC_ARENA=24 Configure the server addresses of postanalytics Uncomment HOST and PORT variables and set them the following values: # address and port for bind HOST='0.0.0.0' PORT=3313 Restart Tarantool {% termtabs name=\"Debian 8.x (jessie)\" -%} service wallarm-tarantool restart \u00b6 {%- tab name=\"Debian 9.x (stretch)\" -%} systemctl restart wallarm-tarantool \u00b6 {%- tab name=\"Debian 10.x (buster)\" -%} systemctl restart wallarm-tarantool \u00b6 {%- tab name=\"Ubuntu 14.04 LTS (trusty)\" -%} service wallarm-tarantool restart \u00b6 {%- tab name=\"Ubuntu 16.04 LTS (xenial)\" -%} systemctl restart wallarm-tarantool \u00b6 {%- tab name=\"Ubuntu 18.04 LTS (bionic)\" -%} systemctl restart wallarm-tarantool \u00b6 {%- tab name=\"CentOS 6.x\" -%} service wallarm-tarantool restart \u00b6 {%- tab name=\"CentOS 7.x\" -%} systemctl restart wallarm-tarantool \u00b6 {%- tab name=\"Amazon Linux 2\" -%} systemctl restart wallarm-tarantool \u00b6 {%- endtermtabs %}","title":"Configure postanalytics separate en"},{"location":"en/include-en/configure-postanalytics-separate-en/#vi-etcdefaultwallarm-tarantool","text":"{%- tab name=\"Debian 9.x (stretch)\" -%}","title":"vi /etc/default/wallarm-tarantool"},{"location":"en/include-en/configure-postanalytics-separate-en/#vi-etcdefaultwallarm-tarantool_1","text":"{%- tab name=\"Debian 10.x (buster)\" -%}","title":"vi /etc/default/wallarm-tarantool"},{"location":"en/include-en/configure-postanalytics-separate-en/#vi-etcdefaultwallarm-tarantool_2","text":"{%- tab name=\"Ubuntu 14.04 LTS (trusty)\" -%}","title":"vi /etc/default/wallarm-tarantool"},{"location":"en/include-en/configure-postanalytics-separate-en/#vi-etcdefaultwallarm-tarantool_3","text":"{%- tab name=\"Ubuntu 16.04 LTS (xenial)\" -%}","title":"vi /etc/default/wallarm-tarantool"},{"location":"en/include-en/configure-postanalytics-separate-en/#vi-etcdefaultwallarm-tarantool_4","text":"{%- tab name=\"Ubuntu 18.04 LTS (bionic)\" -%}","title":"vi /etc/default/wallarm-tarantool"},{"location":"en/include-en/configure-postanalytics-separate-en/#vi-etcdefaultwallarm-tarantool_5","text":"{%- tab name=\"CentOS 6.x\" -%}","title":"vi /etc/default/wallarm-tarantool"},{"location":"en/include-en/configure-postanalytics-separate-en/#vi-etcsysconfigwallarm-tarantool","text":"{%- tab name=\"CentOS 7.x\" -%}","title":"vi /etc/sysconfig/wallarm-tarantool"},{"location":"en/include-en/configure-postanalytics-separate-en/#vi-etcsysconfigwallarm-tarantool_1","text":"{%- tab name=\"Amazon Linux 2\" -%}","title":"vi /etc/sysconfig/wallarm-tarantool"},{"location":"en/include-en/configure-postanalytics-separate-en/#vi-etcsysconfigwallarm-tarantool_2","text":"{%- endtermtabs %} Set the allocated memory size in the configuration file of Tarantool via the SLAB_ALLOC_ARENA directive. For example: SLAB_ALLOC_ARENA=24 Configure the server addresses of postanalytics Uncomment HOST and PORT variables and set them the following values: # address and port for bind HOST='0.0.0.0' PORT=3313 Restart Tarantool {% termtabs name=\"Debian 8.x (jessie)\" -%}","title":"vi /etc/sysconfig/wallarm-tarantool"},{"location":"en/include-en/configure-postanalytics-separate-en/#service-wallarm-tarantool-restart","text":"{%- tab name=\"Debian 9.x (stretch)\" -%}","title":"service wallarm-tarantool restart"},{"location":"en/include-en/configure-postanalytics-separate-en/#systemctl-restart-wallarm-tarantool","text":"{%- tab name=\"Debian 10.x (buster)\" -%}","title":"systemctl restart wallarm-tarantool"},{"location":"en/include-en/configure-postanalytics-separate-en/#systemctl-restart-wallarm-tarantool_1","text":"{%- tab name=\"Ubuntu 14.04 LTS (trusty)\" -%}","title":"systemctl restart wallarm-tarantool"},{"location":"en/include-en/configure-postanalytics-separate-en/#service-wallarm-tarantool-restart_1","text":"{%- tab name=\"Ubuntu 16.04 LTS (xenial)\" -%}","title":"service wallarm-tarantool restart"},{"location":"en/include-en/configure-postanalytics-separate-en/#systemctl-restart-wallarm-tarantool_2","text":"{%- tab name=\"Ubuntu 18.04 LTS (bionic)\" -%}","title":"systemctl restart wallarm-tarantool"},{"location":"en/include-en/configure-postanalytics-separate-en/#systemctl-restart-wallarm-tarantool_3","text":"{%- tab name=\"CentOS 6.x\" -%}","title":"systemctl restart wallarm-tarantool"},{"location":"en/include-en/configure-postanalytics-separate-en/#service-wallarm-tarantool-restart_2","text":"{%- tab name=\"CentOS 7.x\" -%}","title":"service wallarm-tarantool restart"},{"location":"en/include-en/configure-postanalytics-separate-en/#systemctl-restart-wallarm-tarantool_4","text":"{%- tab name=\"Amazon Linux 2\" -%}","title":"systemctl restart wallarm-tarantool"},{"location":"en/include-en/configure-postanalytics-separate-en/#systemctl-restart-wallarm-tarantool_5","text":"{%- endtermtabs %}","title":"systemctl restart wallarm-tarantool"},{"location":"en/include-en/connect-cloud-en/","text":"API Access The API choice for your filter node depends on the Cloud you are using. Please, select the API accordingly: * If you are using https://my.wallarm.com/ , your node requires access to https://api.wallarm.com:444 . * If you are using https://us1.my.wallarm.com/ , your node requires access to https://us1.api.wallarm.com:444 . Ensure the access is not blocked by a firewall. The filter node interacts with the Wallarm cloud. To connect the node to the cloud using your cloud account requisites, proceed with the following steps: Make sure that your Wallarm account has the Administrator role enabled and two-factor authentication disabled, therefore allowing you to connect a filter node to the cloud. You can check the aforementioned parameters by navigating to the user account list in the Wallarm console. * If you are using <https://my.wallarm.com/>, proceed to the [following link][link-wl-console-users-eu] to check your user settings. * If you are using <https://us1.my.wallarm.com/>, proceed to the [following link][link-wl-console-users-us] to check your user settings. Run the addnode script in a system with the filter node: Info You have to pick the script to run depending on the Cloud you are using. * If you are using https://my.wallarm.com/ , run the script from the \u00abEU Cloud\u00bb tab below. * If you are using https://us1.my.wallarm.com/ , run the script from the \u00abUS Cloud\u00bb tab below. EU Cloud /usr/share/wallarm-common/addnode US Cloud /usr/share/wallarm-common/addnode -H us1.api.wallarm.com To specify the name of the created node, use the -n <node name> option. Provide your Wallarm account\u2019s login and password when prompted.","title":"Connect cloud en"},{"location":"en/include-en/connect-cloud-node-cloud-en/","text":"The filter node interacts with the Wallarm cloud. There are two ways of connecting the node to the cloud: Using the filter node token Using your cloud account login and password Required access rights Make sure that your Wallarm account has the Administrator role enabled and two-factor authentication disabled, therefore allowing you to connect a filter node to the cloud. You can check the aforementioned parameters by navigating to the user account list in the Wallarm console. * If you are using https://my.wallarm.com/ , proceed to the following link to check your user settings. * If you are using https://us1.my.wallarm.com/ , proceed to the following link to check your user settings. Connecting Using the Filter Node Token \u00b6 To connect the node to the cloud using the token, proceed with the following steps: Create a new node on the Nodes tab of Wallarm web interface. Click the Create new node button. In the form that appears, enter the node name into the corresponding field and select the \u201cCloud\u201d type of installation from the drop-down list. Click the Create button. In the window that appears, click the Copy button next to the field with the token to add the token of the newly created filter node to your clipboard. On the virtual machine run the addcloudnode script: Info:: \u00b6 You have to pick which script to run depending on the Cloud you are using. * If you are using https://my.wallarm.com/ , run the script from the EU Cloud tab below. * If you are using https://us1.my.wallarm.com/ , run the script from the US Cloud tab below. {% termtabs name=\"EU Cloud\" -%} /usr/share/wallarm-common/addcloudnode \u00b6 {%- tab name=\"US Cloud\" -%} /usr/share/wallarm-common/addcloudnode -H us1.api.wallarm.com \u00b6 {%- endtermtabs %} Paste the filter node token from your clipboard. Your filter node will now synchronize with the cloud every 5 seconds according to the default synchronization configuration. Node and cloud synchronization configuration After running the addcloudnode script, the /etc/wallarm/syncnode file containing the node and cloud synchronization settings will be created. To learn more about synchronization configuration file content, proceed to the link . Connecting Using Your Cloud Account Login and Password \u00b6 To connect the node to the cloud using your cloud account requisites, proceed with the following steps: On the virtual machine run the addnode script: Info:: \u00b6 You have to pick which script to run depending on the Cloud you are using. * If you are using https://my.wallarm.com/ , run the script from the \u00ab EU Cloud tab below. * If you are using https://us1.my.wallarm.com/ , run the script from the US Cloud tab below. {% termtabs name=\"EU Cloud\" -%} /usr/share/wallarm-common/addnode \u00b6 {%- tab name=\"US Cloud\" -%} /usr/share/wallarm-common/addnode -H us1.api.wallarm.com \u00b6 {%- endtermtabs %} Provide your Wallarm account\u2019s login and password when prompted. API Access The API choice for your filter node depends on the Cloud you are using. Please, select the API accordingly: * If you are using https://my.wallarm.com/ , your node requires access to https://api.wallarm.com:444 . * If you are using https://us1.my.wallarm.com/ , your node requires access to https://us1.api.wallarm.com:444 . Ensure the access is not blocked by a firewall.","title":"Connect cloud node cloud en"},{"location":"en/include-en/connect-cloud-node-cloud-en/#connecting-using-the-filter-node-token","text":"To connect the node to the cloud using the token, proceed with the following steps: Create a new node on the Nodes tab of Wallarm web interface. Click the Create new node button. In the form that appears, enter the node name into the corresponding field and select the \u201cCloud\u201d type of installation from the drop-down list. Click the Create button. In the window that appears, click the Copy button next to the field with the token to add the token of the newly created filter node to your clipboard. On the virtual machine run the addcloudnode script:","title":"Connecting Using the Filter Node Token"},{"location":"en/include-en/connect-cloud-node-cloud-en/#info","text":"You have to pick which script to run depending on the Cloud you are using. * If you are using https://my.wallarm.com/ , run the script from the EU Cloud tab below. * If you are using https://us1.my.wallarm.com/ , run the script from the US Cloud tab below. {% termtabs name=\"EU Cloud\" -%}","title":"Info::"},{"location":"en/include-en/connect-cloud-node-cloud-en/#usrsharewallarm-commonaddcloudnode","text":"{%- tab name=\"US Cloud\" -%}","title":"/usr/share/wallarm-common/addcloudnode"},{"location":"en/include-en/connect-cloud-node-cloud-en/#usrsharewallarm-commonaddcloudnode-h-us1apiwallarmcom","text":"{%- endtermtabs %} Paste the filter node token from your clipboard. Your filter node will now synchronize with the cloud every 5 seconds according to the default synchronization configuration. Node and cloud synchronization configuration After running the addcloudnode script, the /etc/wallarm/syncnode file containing the node and cloud synchronization settings will be created. To learn more about synchronization configuration file content, proceed to the link .","title":"/usr/share/wallarm-common/addcloudnode -H us1.api.wallarm.com"},{"location":"en/include-en/connect-cloud-node-cloud-en/#connecting-using-your-cloud-account-login-and-password","text":"To connect the node to the cloud using your cloud account requisites, proceed with the following steps: On the virtual machine run the addnode script:","title":"Connecting Using Your Cloud Account Login and Password"},{"location":"en/include-en/connect-cloud-node-cloud-en/#info_1","text":"You have to pick which script to run depending on the Cloud you are using. * If you are using https://my.wallarm.com/ , run the script from the \u00ab EU Cloud tab below. * If you are using https://us1.my.wallarm.com/ , run the script from the US Cloud tab below. {% termtabs name=\"EU Cloud\" -%}","title":"Info::"},{"location":"en/include-en/connect-cloud-node-cloud-en/#usrsharewallarm-commonaddnode","text":"{%- tab name=\"US Cloud\" -%}","title":"/usr/share/wallarm-common/addnode"},{"location":"en/include-en/connect-cloud-node-cloud-en/#usrsharewallarm-commonaddnode-h-us1apiwallarmcom","text":"{%- endtermtabs %} Provide your Wallarm account\u2019s login and password when prompted. API Access The API choice for your filter node depends on the Cloud you are using. Please, select the API accordingly: * If you are using https://my.wallarm.com/ , your node requires access to https://api.wallarm.com:444 . * If you are using https://us1.my.wallarm.com/ , your node requires access to https://us1.api.wallarm.com:444 . Ensure the access is not blocked by a firewall.","title":"/usr/share/wallarm-common/addnode -H us1.api.wallarm.com"},{"location":"en/include-en/elevated-priveleges/","text":"Prerequisites Prior to taking any steps listed below, either disable or configure SELinux if it is installed on the operating system. Make sure that you execute all commands below as superuser (e.g. root ).","title":"Elevated priveleges"},{"location":"en/include-en/filter-node-defaults/","text":"#### Info:: Default Settings A freshly installed filter node operates in blocking mode (see the [`wallarm_mode`](../admin-en/configure-parameters-en.html#wallarmmode) directive description) by default. This may result in the inoperable [Wallarm scanner](../user-guides/cloud-ui/scanner/intro.md). If you plan to use the scanner, then you [need to perform additional actions](#adding-wallarm-scanner-addresses-to-the-whitelist) to render scanner operational.","title":"Filter node defaults"},{"location":"en/include-en/gcp-autoscaling-connect-ssh/","text":"Connecting to the instance via a custom private key If during base instance creation process you have enabled connection to the instance via a custom SSH key pair, make sure you have access to the private key from this key pair.","title":"Gcp autoscaling connect ssh"},{"location":"en/include-en/ingress-k8s-limitations-padding/","text":"> #### Warning:: Supported Kubernetes Platform > > Please note, that the Wallarm NGINX or NGINX Plus Ingress controllers run only on the Kubernetes platform version 1.15 and lower.","title":"Ingress k8s limitations padding"},{"location":"en/include-en/ingress-k8s-limitations/","text":"#### Warning:: Supported Kubernetes Platform Please note, that the Wallarm NGINX or NGINX Plus Ingress controllers run only on the Kubernetes platform version 1.15 and lower.","title":"Ingress k8s limitations"},{"location":"en/include-en/install-nginx-distr-en/","text":"{% termtabs name=\"Debian 8.x (jessie-backports)\" -%} apt-get install --no-install-recommends nginx wallarm-node-nginx libnginx-mod-http-wallarm -t jessie-backports \u00b6 {%- tab name=\"Debian 9.x (stretch)\" -%} apt-get install --no-install-recommends nginx wallarm-node-nginx libnginx-mod-http-wallarm \u00b6 {%- tab name=\"Debian 9.x (stretch-backports)\" -%} apt-get install --no-install-recommends nginx wallarm-node-nginx libnginx-mod-http-wallarm -t stretch-backports \u00b6 {%- tab name=\"Debian 10.x (buster)\" -%} apt-get install --no-install-recommends nginx wallarm-node-nginx libnginx-mod-http-wallarm \u00b6 {%- tab name=\"CentOS 6.x\" -%} yum install nginx wallarm-node-nginx nginx-mod-http-wallarm \u00b6 {%- tab name=\"CentOS 7.x\" -%} yum install nginx wallarm-node-nginx nginx-mod-http-wallarm \u00b6 {%- endtermtabs %}","title":"Install nginx distr en"},{"location":"en/include-en/install-nginx-distr-en/#apt-get-install-no-install-recommends-nginx-wallarm-node-nginx-libnginx-mod-http-wallarm-t-jessie-backports","text":"{%- tab name=\"Debian 9.x (stretch)\" -%}","title":"apt-get install --no-install-recommends nginx wallarm-node-nginx libnginx-mod-http-wallarm -t jessie-backports"},{"location":"en/include-en/install-nginx-distr-en/#apt-get-install-no-install-recommends-nginx-wallarm-node-nginx-libnginx-mod-http-wallarm","text":"{%- tab name=\"Debian 9.x (stretch-backports)\" -%}","title":"apt-get install --no-install-recommends nginx wallarm-node-nginx libnginx-mod-http-wallarm"},{"location":"en/include-en/install-nginx-distr-en/#apt-get-install-no-install-recommends-nginx-wallarm-node-nginx-libnginx-mod-http-wallarm-t-stretch-backports","text":"{%- tab name=\"Debian 10.x (buster)\" -%}","title":"apt-get install --no-install-recommends nginx wallarm-node-nginx libnginx-mod-http-wallarm -t stretch-backports"},{"location":"en/include-en/install-nginx-distr-en/#apt-get-install-no-install-recommends-nginx-wallarm-node-nginx-libnginx-mod-http-wallarm_1","text":"{%- tab name=\"CentOS 6.x\" -%}","title":"apt-get install --no-install-recommends nginx wallarm-node-nginx libnginx-mod-http-wallarm"},{"location":"en/include-en/install-nginx-distr-en/#yum-install-nginx-wallarm-node-nginx-nginx-mod-http-wallarm","text":"{%- tab name=\"CentOS 7.x\" -%}","title":"yum install nginx wallarm-node-nginx nginx-mod-http-wallarm"},{"location":"en/include-en/install-nginx-distr-en/#yum-install-nginx-wallarm-node-nginx-nginx-mod-http-wallarm_1","text":"{%- endtermtabs %}","title":"yum install nginx wallarm-node-nginx nginx-mod-http-wallarm"},{"location":"en/include-en/install-nginx-en/","text":"Debian 8.x (jessie) apt-get install --no-install-recommends wallarm-node-nginx nginx-module-wallarm Debian 9.x (stretch) apt-get install --no-install-recommends wallarm-node-nginx nginx-module-wallarm Debian 10.x (buster) apt-get install --no-install-recommends wallarm-node-nginx nginx-module-wallarm Ubuntu 14.04 LTS (trusty) apt-get install --no-install-recommends wallarm-node-nginx nginx-module-wallarm Ubuntu 16.04 LTS (xenial) apt-get install --no-install-recommends wallarm-node-nginx nginx-module-wallarm Ubuntu 18.04 LTS (bionic) apt-get install --no-install-recommends wallarm-node-nginx nginx-module-wallarm CentOS 6.x yum install wallarm-node-nginx nginx-module-wallarm CentOS 7.x yum install wallarm-node-nginx nginx-module-wallarm Amazon Linux 2 yum install wallarm-node-nginx nginx-module-wallarm","title":"Install nginx en"},{"location":"en/include-en/install-nginx-plus-en/","text":"{% termtabs name=\"Debian 8.x (jessie)\" -%} apt-get install --no-install-recommends wallarm-node-nginx nginx-plus-module-wallarm \u00b6 {%- tab name=\"Debian 9.x (stretch)\" -%} apt-get install --no-install-recommends wallarm-node-nginx nginx-plus-module-wallarm \u00b6 {%- tab name=\"Debian 10.x (buster)\" -%} apt-get install --no-install-recommends wallarm-node-nginx nginx-plus-module-wallarm \u00b6 {%- tab name=\"Ubuntu 14.04 LTS (trusty)\" -%} apt-get install --no-install-recommends wallarm-node-nginx nginx-plus-module-wallarm \u00b6 {%- tab name=\"Ubuntu 16.04 LTS (xenial)\" -%} apt-get install --no-install-recommends wallarm-node-nginx nginx-plus-module-wallarm \u00b6 {%- tab name=\"Ubuntu 18.04 LTS (bionic)\" -%} apt-get install --no-install-recommends wallarm-node-nginx nginx-plus-module-wallarm \u00b6 {%- tab name=\"CentOS 6.x\" -%} yum install wallarm-node-nginx nginx-plus-module-wallarm \u00b6 {%- tab name=\"CentOS 7.x\" -%} yum install wallarm-node-nginx nginx-plus-module-wallarm \u00b6 {%- tab name=\"Amazon Linux 2\" -%} yum install wallarm-node-nginx nginx-plus-module-wallarm \u00b6 {%- endtermtabs %}","title":"Install nginx plus en"},{"location":"en/include-en/install-nginx-plus-en/#apt-get-install-no-install-recommends-wallarm-node-nginx-nginx-plus-module-wallarm","text":"{%- tab name=\"Debian 9.x (stretch)\" -%}","title":"apt-get install --no-install-recommends wallarm-node-nginx nginx-plus-module-wallarm"},{"location":"en/include-en/install-nginx-plus-en/#apt-get-install-no-install-recommends-wallarm-node-nginx-nginx-plus-module-wallarm_1","text":"{%- tab name=\"Debian 10.x (buster)\" -%}","title":"apt-get install --no-install-recommends wallarm-node-nginx nginx-plus-module-wallarm"},{"location":"en/include-en/install-nginx-plus-en/#apt-get-install-no-install-recommends-wallarm-node-nginx-nginx-plus-module-wallarm_2","text":"{%- tab name=\"Ubuntu 14.04 LTS (trusty)\" -%}","title":"apt-get install --no-install-recommends wallarm-node-nginx nginx-plus-module-wallarm"},{"location":"en/include-en/install-nginx-plus-en/#apt-get-install-no-install-recommends-wallarm-node-nginx-nginx-plus-module-wallarm_3","text":"{%- tab name=\"Ubuntu 16.04 LTS (xenial)\" -%}","title":"apt-get install --no-install-recommends wallarm-node-nginx nginx-plus-module-wallarm"},{"location":"en/include-en/install-nginx-plus-en/#apt-get-install-no-install-recommends-wallarm-node-nginx-nginx-plus-module-wallarm_4","text":"{%- tab name=\"Ubuntu 18.04 LTS (bionic)\" -%}","title":"apt-get install --no-install-recommends wallarm-node-nginx nginx-plus-module-wallarm"},{"location":"en/include-en/install-nginx-plus-en/#apt-get-install-no-install-recommends-wallarm-node-nginx-nginx-plus-module-wallarm_5","text":"{%- tab name=\"CentOS 6.x\" -%}","title":"apt-get install --no-install-recommends wallarm-node-nginx nginx-plus-module-wallarm"},{"location":"en/include-en/install-nginx-plus-en/#yum-install-wallarm-node-nginx-nginx-plus-module-wallarm","text":"{%- tab name=\"CentOS 7.x\" -%}","title":"yum install wallarm-node-nginx nginx-plus-module-wallarm"},{"location":"en/include-en/install-nginx-plus-en/#yum-install-wallarm-node-nginx-nginx-plus-module-wallarm_1","text":"{%- tab name=\"Amazon Linux 2\" -%}","title":"yum install wallarm-node-nginx nginx-plus-module-wallarm"},{"location":"en/include-en/install-nginx-plus-en/#yum-install-wallarm-node-nginx-nginx-plus-module-wallarm_2","text":"{%- endtermtabs %}","title":"yum install wallarm-node-nginx nginx-plus-module-wallarm"},{"location":"en/include-en/install-nginx-plus-postanalytics-en/","text":"{% termtabs name=\"Debian 8.x (jessie)\" -%} apt-get install --no-install-recommends wallarm-node nginx-plus-module-wallarm \u00b6 {%- tab name=\"Debian 9.x (stretch)\" -%} apt-get install --no-install-recommends wallarm-node nginx-plus-module-wallarm \u00b6 {%- tab name=\"Debian 10.x (buster)\" -%} apt-get install --no-install-recommends wallarm-node nginx-plus-module-wallarm \u00b6 {%- tab name=\"Ubuntu 14.04 LTS (trusty)\" -%} apt-get install --no-install-recommends wallarm-node nginx-plus-module-wallarm \u00b6 {%- tab name=\"Ubuntu 16.04 LTS (xenial)\" -%} apt-get install --no-install-recommends wallarm-node nginx-plus-module-wallarm \u00b6 {%- tab name=\"Ubuntu 18.04 LTS (bionic)\" -%} apt-get install --no-install-recommends wallarm-node nginx-plus-module-wallarm \u00b6 {%- tab name=\"CentOS 6.x\" -%} yum install wallarm-node nginx-plus-module-wallarm \u00b6 {%- tab name=\"CentOS 7.x\" -%} yum install wallarm-node nginx-plus-module-wallarm \u00b6 {%- tab name=\"Amazon Linux 2\" -%} yum install wallarm-node nginx-plus-module-wallarm \u00b6 {%- endtermtabs %}","title":"Install nginx plus postanalytics en"},{"location":"en/include-en/install-nginx-plus-postanalytics-en/#apt-get-install-no-install-recommends-wallarm-node-nginx-plus-module-wallarm","text":"{%- tab name=\"Debian 9.x (stretch)\" -%}","title":"apt-get install --no-install-recommends wallarm-node nginx-plus-module-wallarm"},{"location":"en/include-en/install-nginx-plus-postanalytics-en/#apt-get-install-no-install-recommends-wallarm-node-nginx-plus-module-wallarm_1","text":"{%- tab name=\"Debian 10.x (buster)\" -%}","title":"apt-get install --no-install-recommends wallarm-node nginx-plus-module-wallarm"},{"location":"en/include-en/install-nginx-plus-postanalytics-en/#apt-get-install-no-install-recommends-wallarm-node-nginx-plus-module-wallarm_2","text":"{%- tab name=\"Ubuntu 14.04 LTS (trusty)\" -%}","title":"apt-get install --no-install-recommends wallarm-node nginx-plus-module-wallarm"},{"location":"en/include-en/install-nginx-plus-postanalytics-en/#apt-get-install-no-install-recommends-wallarm-node-nginx-plus-module-wallarm_3","text":"{%- tab name=\"Ubuntu 16.04 LTS (xenial)\" -%}","title":"apt-get install --no-install-recommends wallarm-node nginx-plus-module-wallarm"},{"location":"en/include-en/install-nginx-plus-postanalytics-en/#apt-get-install-no-install-recommends-wallarm-node-nginx-plus-module-wallarm_4","text":"{%- tab name=\"Ubuntu 18.04 LTS (bionic)\" -%}","title":"apt-get install --no-install-recommends wallarm-node nginx-plus-module-wallarm"},{"location":"en/include-en/install-nginx-plus-postanalytics-en/#apt-get-install-no-install-recommends-wallarm-node-nginx-plus-module-wallarm_5","text":"{%- tab name=\"CentOS 6.x\" -%}","title":"apt-get install --no-install-recommends wallarm-node nginx-plus-module-wallarm"},{"location":"en/include-en/install-nginx-plus-postanalytics-en/#yum-install-wallarm-node-nginx-plus-module-wallarm","text":"{%- tab name=\"CentOS 7.x\" -%}","title":"yum install wallarm-node nginx-plus-module-wallarm"},{"location":"en/include-en/install-nginx-plus-postanalytics-en/#yum-install-wallarm-node-nginx-plus-module-wallarm_1","text":"{%- tab name=\"Amazon Linux 2\" -%}","title":"yum install wallarm-node nginx-plus-module-wallarm"},{"location":"en/include-en/install-nginx-plus-postanalytics-en/#yum-install-wallarm-node-nginx-plus-module-wallarm_2","text":"{%- endtermtabs %}","title":"yum install wallarm-node nginx-plus-module-wallarm"},{"location":"en/include-en/install-nginx-postanalytics-distr-en/","text":"{% termtabs name=\"Debian 8.x (jessie-backports)\" -%} apt-get install --no-install-recommends nginx wallarm-node libnginx-mod-http-wallarm -t jessie-backports \u00b6 {%- tab name=\"Debian 9.x (stretch)\" -%} apt-get install --no-install-recommends nginx wallarm-node libnginx-mod-http-wallarm \u00b6 {%- tab name=\"Debian 9.x (stretch-backports)\" -%} apt-get install --no-install-recommends nginx wallarm-node libnginx-mod-http-wallarm -t stretch-backports \u00b6 {%- tab name=\"Debian 10.x (buster)\" -%} apt-get install --no-install-recommends nginx wallarm-node libnginx-mod-http-wallarm \u00b6 {%- tab name=\"CentOS 6.x\" -%} yum install nginx wallarm-node nginx-mod-http-wallarm \u00b6 {%- tab name=\"CentOS 7.x\" -%} yum install nginx wallarm-node nginx-mod-http-wallarm \u00b6 {%- endtermtabs %}","title":"Install nginx postanalytics distr en"},{"location":"en/include-en/install-nginx-postanalytics-distr-en/#apt-get-install-no-install-recommends-nginx-wallarm-node-libnginx-mod-http-wallarm-t-jessie-backports","text":"{%- tab name=\"Debian 9.x (stretch)\" -%}","title":"apt-get install --no-install-recommends nginx wallarm-node libnginx-mod-http-wallarm -t jessie-backports"},{"location":"en/include-en/install-nginx-postanalytics-distr-en/#apt-get-install-no-install-recommends-nginx-wallarm-node-libnginx-mod-http-wallarm","text":"{%- tab name=\"Debian 9.x (stretch-backports)\" -%}","title":"apt-get install --no-install-recommends nginx wallarm-node libnginx-mod-http-wallarm"},{"location":"en/include-en/install-nginx-postanalytics-distr-en/#apt-get-install-no-install-recommends-nginx-wallarm-node-libnginx-mod-http-wallarm-t-stretch-backports","text":"{%- tab name=\"Debian 10.x (buster)\" -%}","title":"apt-get install --no-install-recommends nginx wallarm-node libnginx-mod-http-wallarm -t stretch-backports"},{"location":"en/include-en/install-nginx-postanalytics-distr-en/#apt-get-install-no-install-recommends-nginx-wallarm-node-libnginx-mod-http-wallarm_1","text":"{%- tab name=\"CentOS 6.x\" -%}","title":"apt-get install --no-install-recommends nginx wallarm-node libnginx-mod-http-wallarm"},{"location":"en/include-en/install-nginx-postanalytics-distr-en/#yum-install-nginx-wallarm-node-nginx-mod-http-wallarm","text":"{%- tab name=\"CentOS 7.x\" -%}","title":"yum install nginx wallarm-node nginx-mod-http-wallarm"},{"location":"en/include-en/install-nginx-postanalytics-distr-en/#yum-install-nginx-wallarm-node-nginx-mod-http-wallarm_1","text":"{%- endtermtabs %}","title":"yum install nginx wallarm-node nginx-mod-http-wallarm"},{"location":"en/include-en/install-nginx-postanalytics-en/","text":"Debian 8.x (jessie) apt-get install --no-install-recommends wallarm-node nginx-module-wallarm Debian 9.x (stretch) apt-get install --no-install-recommends wallarm-node nginx-module-wallarm Debian 10.x (buster) apt-get install --no-install-recommends wallarm-node nginx-module-wallarm Ubuntu 14.04 LTS (trusty) apt-get install --no-install-recommends wallarm-node nginx-module-wallarm Ubuntu 16.04 LTS (xenial) apt-get install --no-install-recommends wallarm-node nginx-module-wallarm Ubuntu 18.04 LTS (bionic) apt-get install --no-install-recommends wallarm-node nginx-module-wallarm CentOS 6.x yum install wallarm-node nginx-module-wallarm CentOS 7.x yum install wallarm-node nginx-module-wallarm Amazon Linux 2 yum install wallarm-node nginx-module-wallarm","title":"Install nginx postanalytics en"},{"location":"en/include-en/install-package-en/","text":"{% termtabs name=\"Debian 8.x (jessie)\" -%} apt-get install --no-install-recommends wallarm-node=2.10.4 nginx-wallarm wallarm-node-nginx=2.10.4 wallarm-node-tarantool=2.10.4 wallarm-common=2.10.4 wallarm-monitoring=2.10.4 ruby-proton=2.10.13 ruby-wallarm-api=2.10.4 \u00b6 {%- tab name=\"Debian 9.x (stretch)\" -%} apt-get install --no-install-recommends wallarm-node=2.10.4 nginx-wallarm wallarm-node-nginx=2.10.4 wallarm-node-tarantool=2.10.4 wallarm-common=2.10.4 wallarm-monitoring=2.10.4 ruby-proton=2.10.13 ruby-wallarm-api=2.10.4 \u00b6 {%- tab name=\"Ubuntu 14.04 LTS (trusty)\" -%} apt-get install --no-install-recommends wallarm-node=2.10.4 nginx-wallarm wallarm-node-nginx=2.10.4 wallarm-node-tarantool=2.10.4 wallarm-common=2.10.4 wallarm-monitoring=2.10.4 ruby-proton=2.10.13 ruby-wallarm-api=2.10.4 \u00b6 {%- tab name=\"Ubuntu 16.04 LTS (xenial)\" -%} apt-get install --no-install-recommends wallarm-node=2.10.4 nginx-wallarm wallarm-node-nginx=2.10.4 wallarm-node-tarantool=2.10.4 wallarm-common=2.10.4 wallarm-monitoring=2.10.4 ruby-proton=2.10.13 ruby-wallarm-api=2.10.4 \u00b6 {%- tab name=\"Ubuntu 18.04 LTS (bionic)\" -%} apt-get install --no-install-recommends wallarm-node=2.10.4 nginx-wallarm wallarm-node-nginx=2.10.4 wallarm-node-tarantool=2.10.4 wallarm-common=2.10.4 wallarm-monitoring=2.10.4 ruby-proton=2.10.13 ruby-wallarm-api=2.10.4 \u00b6 {%- tab name=\"CentOS 7.x\" -%} yum install libproton210-2.10.4 ruby-proton-2.10.4 nginx-wallarm-2.10.4 wallarm-node-2.10.4 \u00b6 {%- endtermtabs %}","title":"Install package en"},{"location":"en/include-en/install-package-en/#apt-get-install-no-install-recommends-wallarm-node2104-nginx-wallarm-wallarm-node-nginx2104-wallarm-node-tarantool2104-wallarm-common2104-wallarm-monitoring2104-ruby-proton21013-ruby-wallarm-api2104","text":"{%- tab name=\"Debian 9.x (stretch)\" -%}","title":"apt-get install --no-install-recommends wallarm-node=2.10.4 nginx-wallarm wallarm-node-nginx=2.10.4 wallarm-node-tarantool=2.10.4  wallarm-common=2.10.4 wallarm-monitoring=2.10.4 ruby-proton=2.10.13 ruby-wallarm-api=2.10.4"},{"location":"en/include-en/install-package-en/#apt-get-install-no-install-recommends-wallarm-node2104-nginx-wallarm-wallarm-node-nginx2104-wallarm-node-tarantool2104-wallarm-common2104-wallarm-monitoring2104-ruby-proton21013-ruby-wallarm-api2104_1","text":"{%- tab name=\"Ubuntu 14.04 LTS (trusty)\" -%}","title":"apt-get install --no-install-recommends wallarm-node=2.10.4 nginx-wallarm wallarm-node-nginx=2.10.4 wallarm-node-tarantool=2.10.4  wallarm-common=2.10.4 wallarm-monitoring=2.10.4 ruby-proton=2.10.13 ruby-wallarm-api=2.10.4"},{"location":"en/include-en/install-package-en/#apt-get-install-no-install-recommends-wallarm-node2104-nginx-wallarm-wallarm-node-nginx2104-wallarm-node-tarantool2104-wallarm-common2104-wallarm-monitoring2104-ruby-proton21013-ruby-wallarm-api2104_2","text":"{%- tab name=\"Ubuntu 16.04 LTS (xenial)\" -%}","title":"apt-get install --no-install-recommends wallarm-node=2.10.4 nginx-wallarm wallarm-node-nginx=2.10.4 wallarm-node-tarantool=2.10.4  wallarm-common=2.10.4 wallarm-monitoring=2.10.4 ruby-proton=2.10.13 ruby-wallarm-api=2.10.4"},{"location":"en/include-en/install-package-en/#apt-get-install-no-install-recommends-wallarm-node2104-nginx-wallarm-wallarm-node-nginx2104-wallarm-node-tarantool2104-wallarm-common2104-wallarm-monitoring2104-ruby-proton21013-ruby-wallarm-api2104_3","text":"{%- tab name=\"Ubuntu 18.04 LTS (bionic)\" -%}","title":"apt-get install --no-install-recommends wallarm-node=2.10.4 nginx-wallarm wallarm-node-nginx=2.10.4 wallarm-node-tarantool=2.10.4  wallarm-common=2.10.4 wallarm-monitoring=2.10.4 ruby-proton=2.10.13 ruby-wallarm-api=2.10.4"},{"location":"en/include-en/install-package-en/#apt-get-install-no-install-recommends-wallarm-node2104-nginx-wallarm-wallarm-node-nginx2104-wallarm-node-tarantool2104-wallarm-common2104-wallarm-monitoring2104-ruby-proton21013-ruby-wallarm-api2104_4","text":"{%- tab name=\"CentOS 7.x\" -%}","title":"apt-get install --no-install-recommends wallarm-node=2.10.4 nginx-wallarm wallarm-node-nginx=2.10.4 wallarm-node-tarantool=2.10.4  wallarm-common=2.10.4 wallarm-monitoring=2.10.4 ruby-proton=2.10.13 ruby-wallarm-api=2.10.4"},{"location":"en/include-en/install-package-en/#yum-install-libproton210-2104-ruby-proton-2104-nginx-wallarm-2104-wallarm-node-2104","text":"{%- endtermtabs %}","title":"yum install libproton210-2.10.4 ruby-proton-2.10.4 nginx-wallarm-2.10.4 wallarm-node-2.10.4"},{"location":"en/include-en/install-package-kong-en/","text":"{% termtabs name=\"Debian 8.x (jessie)\" -%} apt-get install --no-install-recommends wallarm-node kong-module-wallarm \u00b6 {%- tab name=\"Debian 9.x (stretch)\" -%} apt-get install --no-install-recommends wallarm-node kong-module-wallarm \u00b6 {%- tab name=\"Ubuntu 14.04 LTS (trusty)\" -%} apt-get install --no-install-recommends wallarm-node kong-module-wallarm \u00b6 {%- tab name=\"Ubuntu 16.04 LTS (xenial)\" -%} apt-get install --no-install-recommends wallarm-node kong-module-wallarm \u00b6 {%- tab name=\"Ubuntu 18.04 LTS (bionic)\" -%} apt-get install --no-install-recommends wallarm-node kong-module-wallarm \u00b6 {%- tab name=\"CentOS 6.x\" -%} yum install wallarm-node kong-module-wallarm \u00b6 {%- tab name=\"CentOS 7.x\" -%} yum install wallarm-node kong-module-wallarm \u00b6 {%- endtermtabs %}","title":"Install package kong en"},{"location":"en/include-en/install-package-kong-en/#apt-get-install-no-install-recommends-wallarm-node-kong-module-wallarm","text":"{%- tab name=\"Debian 9.x (stretch)\" -%}","title":"apt-get install --no-install-recommends wallarm-node kong-module-wallarm"},{"location":"en/include-en/install-package-kong-en/#apt-get-install-no-install-recommends-wallarm-node-kong-module-wallarm_1","text":"{%- tab name=\"Ubuntu 14.04 LTS (trusty)\" -%}","title":"apt-get install --no-install-recommends wallarm-node kong-module-wallarm"},{"location":"en/include-en/install-package-kong-en/#apt-get-install-no-install-recommends-wallarm-node-kong-module-wallarm_2","text":"{%- tab name=\"Ubuntu 16.04 LTS (xenial)\" -%}","title":"apt-get install --no-install-recommends wallarm-node kong-module-wallarm"},{"location":"en/include-en/install-package-kong-en/#apt-get-install-no-install-recommends-wallarm-node-kong-module-wallarm_3","text":"{%- tab name=\"Ubuntu 18.04 LTS (bionic)\" -%}","title":"apt-get install --no-install-recommends wallarm-node kong-module-wallarm"},{"location":"en/include-en/install-package-kong-en/#apt-get-install-no-install-recommends-wallarm-node-kong-module-wallarm_4","text":"{%- tab name=\"CentOS 6.x\" -%}","title":"apt-get install --no-install-recommends wallarm-node kong-module-wallarm"},{"location":"en/include-en/install-package-kong-en/#yum-install-wallarm-node-kong-module-wallarm","text":"{%- tab name=\"CentOS 7.x\" -%}","title":"yum install wallarm-node kong-module-wallarm"},{"location":"en/include-en/install-package-kong-en/#yum-install-wallarm-node-kong-module-wallarm_1","text":"{%- endtermtabs %}","title":"yum install wallarm-node kong-module-wallarm"},{"location":"en/include-en/install-package-postanalytics-en/","text":"{% termtabs name=\"Debian 8.x (jessie)\" -%} apt-get install --no-install-recommends wallarm-node-tarantool \u00b6 {%- tab name=\"Debian 9.x (stretch)\" -%} apt-get install --no-install-recommends wallarm-node-tarantool \u00b6 {%- tab name=\"Debian 10.x (buster)\" -%} apt-get install --no-install-recommends wallarm-node-tarantool \u00b6 {%- tab name=\"Ubuntu 14.04 LTS (trusty)\" -%} apt-get install --no-install-recommends wallarm-node-tarantool \u00b6 {%- tab name=\"Ubuntu 16.04 LTS (xenial)\" -%} apt-get install --no-install-recommends wallarm-node-tarantool \u00b6 {%- tab name=\"Ubuntu 18.04 LTS (bionic)\" -%} apt-get install --no-install-recommends wallarm-node-tarantool \u00b6 {%- tab name=\"CentOS 6.x\" -%} yum install wallarm-node-tarantool \u00b6 {%- tab name=\"CentOS 7.x\" -%} yum install wallarm-node-tarantool \u00b6 {%- tab name=\"Amazon Linux 2\" -%} yum install wallarm-node-tarantool \u00b6 {%- endtermtabs %}","title":"Install package postanalytics en"},{"location":"en/include-en/install-package-postanalytics-en/#apt-get-install-no-install-recommends-wallarm-node-tarantool","text":"{%- tab name=\"Debian 9.x (stretch)\" -%}","title":"apt-get install --no-install-recommends wallarm-node-tarantool"},{"location":"en/include-en/install-package-postanalytics-en/#apt-get-install-no-install-recommends-wallarm-node-tarantool_1","text":"{%- tab name=\"Debian 10.x (buster)\" -%}","title":"apt-get install --no-install-recommends wallarm-node-tarantool"},{"location":"en/include-en/install-package-postanalytics-en/#apt-get-install-no-install-recommends-wallarm-node-tarantool_2","text":"{%- tab name=\"Ubuntu 14.04 LTS (trusty)\" -%}","title":"apt-get install --no-install-recommends wallarm-node-tarantool"},{"location":"en/include-en/install-package-postanalytics-en/#apt-get-install-no-install-recommends-wallarm-node-tarantool_3","text":"{%- tab name=\"Ubuntu 16.04 LTS (xenial)\" -%}","title":"apt-get install --no-install-recommends wallarm-node-tarantool"},{"location":"en/include-en/install-package-postanalytics-en/#apt-get-install-no-install-recommends-wallarm-node-tarantool_4","text":"{%- tab name=\"Ubuntu 18.04 LTS (bionic)\" -%}","title":"apt-get install --no-install-recommends wallarm-node-tarantool"},{"location":"en/include-en/install-package-postanalytics-en/#apt-get-install-no-install-recommends-wallarm-node-tarantool_5","text":"{%- tab name=\"CentOS 6.x\" -%}","title":"apt-get install --no-install-recommends wallarm-node-tarantool"},{"location":"en/include-en/install-package-postanalytics-en/#yum-install-wallarm-node-tarantool","text":"{%- tab name=\"CentOS 7.x\" -%}","title":"yum install wallarm-node-tarantool"},{"location":"en/include-en/install-package-postanalytics-en/#yum-install-wallarm-node-tarantool_1","text":"{%- tab name=\"Amazon Linux 2\" -%}","title":"yum install wallarm-node-tarantool"},{"location":"en/include-en/install-package-postanalytics-en/#yum-install-wallarm-node-tarantool_2","text":"{%- endtermtabs %}","title":"yum install wallarm-node-tarantool"},{"location":"en/include-en/install-package-primary-en/","text":"{% termtabs name=\"Debian 8.x (jessie)\" -%} apt-get install --no-install-recommends wallarm-node-nginx nginx-wallarm \u00b6 {%- tab name=\"Debian 9.x (stretch)\" -%} apt-get install --no-install-recommends wallarm-node-nginx nginx-wallarm \u00b6 {%- tab name=\"Ubuntu 14.04 LTS (trusty)\" -%} apt-get install --no-install-recommends wallarm-node-nginx nginx-wallarm \u00b6 {%- tab name=\"Ubuntu 16.04 LTS (xenial)\" -%} apt-get install --no-install-recommends wallarm-node-nginx nginx-wallarm \u00b6 {%- tab name=\"Ubuntu 18.04 LTS (bionic)\" -%} apt-get install --no-install-recommends wallarm-node-nginx nginx-wallarm \u00b6 {%- tab name=\"CentOS 6.x\" -%} yum install wallarm-node-nginx nginx-wallarm \u00b6 {%- tab name=\"CentOS 7.x\" -%} yum install wallarm-node-nginx nginx-wallarm \u00b6 {%- endtermtabs %}","title":"Install package primary en"},{"location":"en/include-en/install-package-primary-en/#apt-get-install-no-install-recommends-wallarm-node-nginx-nginx-wallarm","text":"{%- tab name=\"Debian 9.x (stretch)\" -%}","title":"apt-get install --no-install-recommends wallarm-node-nginx nginx-wallarm"},{"location":"en/include-en/install-package-primary-en/#apt-get-install-no-install-recommends-wallarm-node-nginx-nginx-wallarm_1","text":"{%- tab name=\"Ubuntu 14.04 LTS (trusty)\" -%}","title":"apt-get install --no-install-recommends wallarm-node-nginx nginx-wallarm"},{"location":"en/include-en/install-package-primary-en/#apt-get-install-no-install-recommends-wallarm-node-nginx-nginx-wallarm_2","text":"{%- tab name=\"Ubuntu 16.04 LTS (xenial)\" -%}","title":"apt-get install --no-install-recommends wallarm-node-nginx nginx-wallarm"},{"location":"en/include-en/install-package-primary-en/#apt-get-install-no-install-recommends-wallarm-node-nginx-nginx-wallarm_3","text":"{%- tab name=\"Ubuntu 18.04 LTS (bionic)\" -%}","title":"apt-get install --no-install-recommends wallarm-node-nginx nginx-wallarm"},{"location":"en/include-en/install-package-primary-en/#apt-get-install-no-install-recommends-wallarm-node-nginx-nginx-wallarm_4","text":"{%- tab name=\"CentOS 6.x\" -%}","title":"apt-get install --no-install-recommends wallarm-node-nginx nginx-wallarm"},{"location":"en/include-en/install-package-primary-en/#yum-install-wallarm-node-nginx-nginx-wallarm","text":"{%- tab name=\"CentOS 7.x\" -%}","title":"yum install wallarm-node-nginx nginx-wallarm"},{"location":"en/include-en/install-package-primary-en/#yum-install-wallarm-node-nginx-nginx-wallarm_1","text":"{%- endtermtabs %}","title":"yum install wallarm-node-nginx nginx-wallarm"},{"location":"en/include-en/install-package-primary-kong-en/","text":"{% termtabs name=\"Debian 8.x (jessie)\" -%} apt-get install --no-install-recommends wallarm-node-nginx kong-module-wallarm \u00b6 {%- tab name=\"Debian 9.x (stretch)\" -%} apt-get install --no-install-recommends wallarm-node-nginx kong-module-wallarm \u00b6 {%- tab name=\"Ubuntu 14.04 LTS (trusty)\" -%} apt-get install --no-install-recommends wallarm-node-nginx kong-module-wallarm \u00b6 {%- tab name=\"Ubuntu 16.04 LTS (xenial)\" -%} apt-get install --no-install-recommends wallarm-node-nginx kong-module-wallarm \u00b6 {%- tab name=\"Ubuntu 18.04 LTS (bionic)\" -%} apt-get install --no-install-recommends wallarm-node-nginx kong-module-wallarm \u00b6 {%- tab name=\"CentOS 6.x\" -%} yum install wallarm-node-nginx kong-module-wallarm \u00b6 {%- tab name=\"CentOS 7.x\" -%} yum install wallarm-node-nginx kong-module-wallarm \u00b6 {%- endtermtabs %}","title":"Install package primary kong en"},{"location":"en/include-en/install-package-primary-kong-en/#apt-get-install-no-install-recommends-wallarm-node-nginx-kong-module-wallarm","text":"{%- tab name=\"Debian 9.x (stretch)\" -%}","title":"apt-get install --no-install-recommends wallarm-node-nginx kong-module-wallarm"},{"location":"en/include-en/install-package-primary-kong-en/#apt-get-install-no-install-recommends-wallarm-node-nginx-kong-module-wallarm_1","text":"{%- tab name=\"Ubuntu 14.04 LTS (trusty)\" -%}","title":"apt-get install --no-install-recommends wallarm-node-nginx kong-module-wallarm"},{"location":"en/include-en/install-package-primary-kong-en/#apt-get-install-no-install-recommends-wallarm-node-nginx-kong-module-wallarm_2","text":"{%- tab name=\"Ubuntu 16.04 LTS (xenial)\" -%}","title":"apt-get install --no-install-recommends wallarm-node-nginx kong-module-wallarm"},{"location":"en/include-en/install-package-primary-kong-en/#apt-get-install-no-install-recommends-wallarm-node-nginx-kong-module-wallarm_3","text":"{%- tab name=\"Ubuntu 18.04 LTS (bionic)\" -%}","title":"apt-get install --no-install-recommends wallarm-node-nginx kong-module-wallarm"},{"location":"en/include-en/install-package-primary-kong-en/#apt-get-install-no-install-recommends-wallarm-node-nginx-kong-module-wallarm_4","text":"{%- tab name=\"CentOS 6.x\" -%}","title":"apt-get install --no-install-recommends wallarm-node-nginx kong-module-wallarm"},{"location":"en/include-en/install-package-primary-kong-en/#yum-install-wallarm-node-nginx-kong-module-wallarm","text":"{%- tab name=\"CentOS 7.x\" -%}","title":"yum install wallarm-node-nginx kong-module-wallarm"},{"location":"en/include-en/install-package-primary-kong-en/#yum-install-wallarm-node-nginx-kong-module-wallarm_1","text":"{%- endtermtabs %}","title":"yum install wallarm-node-nginx kong-module-wallarm"},{"location":"en/include-en/installation-extra-steps/","text":"Additional Settings \u00b6 The filter node may require some additional configuration after installation. The document below lists a few of the typical setups that you can apply if needed. To get more information about other available settings, proceed to the \u201cConfiguration\u201d section of the Administrator\u2019s Guide . Configuring the Display of the Client's Real IP \u00b6 If the filter node is deployed behind a proxy server or load balancer without any additional configuration, the request source address may not be equal to the actual IP address of the client. Instead, it may be equal to one of the IP addresses of the proxy server or the load balancer. In this case, if you want the filter node to receive the client's IP address as a request source address, you need to perform an additional configuration of the proxy server or the load balancer. Adding Wallarm Scanner Addresses to the Whitelist \u00b6 The Wallarm scanner checks the resources of your company for vulnerabilities. Scanning is conducted using IP addresses from one of the following lists (depending on the type of Wallarm Cloud you are using): EU scanner addresses for EU Cloud users US scanner addresses for US Cloud users If you are using the Wallarm scanner, you need to configure the whitelists on your network scope security software (such as firewalls, intrusion detection systems, etc.) to contain Wallarm scanner IP addresses. For example, a Wallarm filter node with default settings is placed in the blocking mode, thus rendering the Wallarm scanner unable to scan the resources behind the filter node. To make the scanner operational again, whitelist the scanner's IP addresses on this filter node. Limiting the Single Request Processing Time \u00b6 Use the wallarm_process_time_limit Wallarm directive to specify the limit of the duration for processing a single request by the filter node. If processing the request consumes more time than specified in the directive, then the information on the error is entered into the log file and the request is marked as an overlimit_res attack. Limiting the Server Reply Waiting Time \u00b6 Use the proxy_read_timeout NGINX directive to specify the timeout for reading the proxy server reply. If the server sends nothing during this time, the connection is closed. Limiting the Maximum Request Size \u00b6 Use the client_max_body_size NGINX directive to specify the limit for the maximum size of the body of the client's request. If this limit is exceeded, NGINX replies to the client with the 413 ( Payload Too Large ) code, also known as the Request Entity Too Large message.","title":"Installation extra steps"},{"location":"en/include-en/installation-extra-steps/#additional-settings","text":"The filter node may require some additional configuration after installation. The document below lists a few of the typical setups that you can apply if needed. To get more information about other available settings, proceed to the \u201cConfiguration\u201d section of the Administrator\u2019s Guide .","title":"Additional Settings"},{"location":"en/include-en/installation-extra-steps/#configuring-the-display-of-the-clients-real-ip","text":"If the filter node is deployed behind a proxy server or load balancer without any additional configuration, the request source address may not be equal to the actual IP address of the client. Instead, it may be equal to one of the IP addresses of the proxy server or the load balancer. In this case, if you want the filter node to receive the client's IP address as a request source address, you need to perform an additional configuration of the proxy server or the load balancer.","title":"Configuring the Display of the Client's Real IP"},{"location":"en/include-en/installation-extra-steps/#adding-wallarm-scanner-addresses-to-the-whitelist","text":"The Wallarm scanner checks the resources of your company for vulnerabilities. Scanning is conducted using IP addresses from one of the following lists (depending on the type of Wallarm Cloud you are using): EU scanner addresses for EU Cloud users US scanner addresses for US Cloud users If you are using the Wallarm scanner, you need to configure the whitelists on your network scope security software (such as firewalls, intrusion detection systems, etc.) to contain Wallarm scanner IP addresses. For example, a Wallarm filter node with default settings is placed in the blocking mode, thus rendering the Wallarm scanner unable to scan the resources behind the filter node. To make the scanner operational again, whitelist the scanner's IP addresses on this filter node.","title":"Adding Wallarm Scanner Addresses to the Whitelist"},{"location":"en/include-en/installation-extra-steps/#limiting-the-single-request-processing-time","text":"Use the wallarm_process_time_limit Wallarm directive to specify the limit of the duration for processing a single request by the filter node. If processing the request consumes more time than specified in the directive, then the information on the error is entered into the log file and the request is marked as an overlimit_res attack.","title":"Limiting the Single Request Processing Time"},{"location":"en/include-en/installation-extra-steps/#limiting-the-server-reply-waiting-time","text":"Use the proxy_read_timeout NGINX directive to specify the timeout for reading the proxy server reply. If the server sends nothing during this time, the connection is closed.","title":"Limiting the Server Reply Waiting Time"},{"location":"en/include-en/installation-extra-steps/#limiting-the-maximum-request-size","text":"Use the client_max_body_size NGINX directive to specify the limit for the maximum size of the body of the client's request. If this limit is exceeded, NGINX replies to the client with the 413 ( Payload Too Large ) code, also known as the Request Entity Too Large message.","title":"Limiting the Maximum Request Size"},{"location":"en/include-en/installation-options-en/","text":"The processing of requests in the filter node is done in two stages: Processing in NGINX-Wallarm. Postanalytics \u2013 statistical analysis of the processed requests. The processing is not memory demanding and can be put on front end servers without changing the server requirements. Postanalytics is memory demanding, which may require changes in the server configuration or installation of postanalytics on a separate server. Wallarm also has the option of installing postanalytics in a separate server pool.","title":"Installation options en"},{"location":"en/include-en/installation-options-nginx-en/","text":"The processing of requests in the filter node is done in two stages: Processing in NGINX-Module-Wallarm. Postanalytics \u2013 statistical analysis of the processed requests. The processing is not memory demanding and can be put on front end servers without changing the server requirements. Postanalytics is memory demanding, which may require changes in the server configuration or installation of postanalytics on a separate server. Wallarm also has the option of installing postanalytics in a separate server pool.","title":"Installation options nginx en"},{"location":"en/include-en/installation-step-logging/","text":"Configure the filter node variables logging using NGINX. This will allow to perform a quick filter node diagnostics with the help of the NGINX log file.","title":"Installation step logging"},{"location":"en/include-en/intro-en/","text":"Wallarm is a DevOps-friendly Web Application Firewall (WAF) uniquely suited to protect your cloud applications and APIs. Wallarm's hybrid architecture safeguards your resources by offering: Protection from hacker attacks. Automatic detection of vulnerabilities . Wallarm analyzes all incoming HTTP requests and instantly blocks the malicious ones. Wallarm continuously collects metrics from the entire network traffic and processes the metrics by applying machine learning in the Wallarm cloud. Based on the processed requests, Wallarm creates an individual profile of the protected resources and applies the finely tuned security rules. The Wallarm scanner checks your company's network resources in several modes to detect vulnerabilities. Wallarm consists of the following components: The Wallarm filter node The Wallarm cloud Filter Node \u00b6 The network traffic check is done through the Wallarm filter node installed in the company's network infrastructure. The Wallarm filter node does the following: Blocks malicious requests and filters the valid ones Analyzes the company's entire network traffic Collects the network traffic metrics and uploads the metrics to the Wallarm cloud Downloads fine-tuned resource-specific rules from the Wallarm cloud Cloud \u00b6 The Wallarm cloud does the following: Processes the metrics that the filter node uploads Creates fine-tuned resource-specific rules Scans the company's protected resources to detect vulnerabilities Wallarm manages European and American cloud instances with each cloud being completely separate in terms of databases, API endpoints, client accounts, etc. A client registered in one Wallarm cloud cannot use other Wallarm cloud to manage or get access to their data stored in the first cloud. At the same time you may use both Wallarm clouds. In this case you will need to use different accounts in the Wallarm system and API endpoints to access and manage your information in individual clouds. Endpoints for the clouds are provided below. EU Cloud \u00b6 Physically located in France. https://my.wallarm.com/ to create Wallarm account https://api.wallarm.com/ to call API methods US Cloud \u00b6 Physically located in the USA. https://us1.my.wallarm.com/ to create Wallarm account https://us1.api.wallarm.com/ to call API methods","title":"Intro en"},{"location":"en/include-en/intro-en/#filter-node","text":"The network traffic check is done through the Wallarm filter node installed in the company's network infrastructure. The Wallarm filter node does the following: Blocks malicious requests and filters the valid ones Analyzes the company's entire network traffic Collects the network traffic metrics and uploads the metrics to the Wallarm cloud Downloads fine-tuned resource-specific rules from the Wallarm cloud","title":"Filter Node"},{"location":"en/include-en/intro-en/#cloud","text":"The Wallarm cloud does the following: Processes the metrics that the filter node uploads Creates fine-tuned resource-specific rules Scans the company's protected resources to detect vulnerabilities Wallarm manages European and American cloud instances with each cloud being completely separate in terms of databases, API endpoints, client accounts, etc. A client registered in one Wallarm cloud cannot use other Wallarm cloud to manage or get access to their data stored in the first cloud. At the same time you may use both Wallarm clouds. In this case you will need to use different accounts in the Wallarm system and API endpoints to access and manage your information in individual clouds. Endpoints for the clouds are provided below.","title":"Cloud"},{"location":"en/include-en/intro-en/#eu-cloud","text":"Physically located in France. https://my.wallarm.com/ to create Wallarm account https://api.wallarm.com/ to call API methods","title":"EU Cloud"},{"location":"en/include-en/intro-en/#us-cloud","text":"Physically located in the USA. https://us1.my.wallarm.com/ to create Wallarm account https://us1.api.wallarm.com/ to call API methods","title":"US Cloud"},{"location":"en/include-en/os-support-en/","text":"The filter node supports installation from packages on the following operating systems: #### Warning:: Supported OS types Only x64 operating systems are supported. Debian 8.x (jessie) Debian 9.x (stretch) Debian 10.x (buster) Ubuntu 14.04 LTS (trusty) Ubuntu 16.04 LTS (xenial) Ubuntu 18.04 LTS (bionic) CentOS 6.x CentOS 7.x Amazon Linux 2","title":"Os support en"},{"location":"en/include-en/prereq-en/","text":"Wallarm installation prerequisites: Supported operating system. Root access. Wallarm account on the Wallarm portal in the EU or US cloud.","title":"Prereq en"},{"location":"en/include-en/rechecker-ip-us/","text":"35.236.51.79 35.236.75.97 35.236.111.124 35.236.108.88 35.236.16.246 35.236.61.185 35.236.110.91 35.236.14.198 35.235.124.137 35.236.48.47 35.236.100.176 35.236.18.117 35.235.112.188 35.236.55.214 35.236.126.84 35.236.3.158 35.236.127.211 35.236.118.146 35.236.20.89 35.236.1.4","title":"Rechecker ip us"},{"location":"en/include-en/restart-nginx-distr-en/","text":"{% termtabs name=\"Debian 8.x (jessie)\" -%} systemctl restart nginx \u00b6 {%- tab name=\"Debian 9.x (stretch)\" -%} systemctl restart nginx \u00b6 {%- tab name=\"Debian 10.x (buster)\" -%} systemctl restart nginx \u00b6 {%- tab name=\"CentOS 6.x\" -%} service nginx restart \u00b6 {%- tab name=\"CentOS 7.x\" -%} systemctl restart nginx \u00b6 {%- endtermtabs %}","title":"Restart nginx distr en"},{"location":"en/include-en/restart-nginx-distr-en/#systemctl-restart-nginx","text":"{%- tab name=\"Debian 9.x (stretch)\" -%}","title":"systemctl restart nginx"},{"location":"en/include-en/restart-nginx-distr-en/#systemctl-restart-nginx_1","text":"{%- tab name=\"Debian 10.x (buster)\" -%}","title":"systemctl restart nginx"},{"location":"en/include-en/restart-nginx-distr-en/#systemctl-restart-nginx_2","text":"{%- tab name=\"CentOS 6.x\" -%}","title":"systemctl restart nginx"},{"location":"en/include-en/restart-nginx-distr-en/#service-nginx-restart","text":"{%- tab name=\"CentOS 7.x\" -%}","title":"service nginx restart"},{"location":"en/include-en/restart-nginx-distr-en/#systemctl-restart-nginx_3","text":"{%- endtermtabs %}","title":"systemctl restart nginx"},{"location":"en/include-en/restart-nginx-en/","text":"Debian 8.x (jessie) systemctl restart nginx Debian 9.x (stretch) systemctl restart nginx Debian 10.x (buster) systemctl restart nginx Ubuntu 14.04 LTS (trusty) service nginx restart Ubuntu 16.04 LTS (xenial) service nginx restart Ubuntu 18.04 LTS (bionic) service nginx restart CentOS 6.x service nginx restart CentOS 7.x systemctl restart nginx Amazon Linux 2 systemctl restart nginx","title":"Restart nginx en"},{"location":"en/include-en/restart-nginx-wallarm-en/","text":"{% termtabs name=\"Debian 8.x (jessie)\" -%} systemctl restart nginx-wallarm \u00b6 {%- tab name=\"Debian 9.x (stretch)\" -%} systemctl restart nginx-wallarm \u00b6 {%- tab name=\"Ubuntu 14.04 LTS (trusty)\" -%} service nginx-wallarm restart \u00b6 {%- tab name=\"Ubuntu 16.04 LTS (xenial)\" -%} service nginx-wallarm restart \u00b6 {%- tab name=\"Ubuntu 18.04 LTS (bionic)\" -%} service nginx-wallarm restart \u00b6 {%- tab name=\"CentOS 6.x\" -%} service nginx-wallarm restart \u00b6 {%- tab name=\"CentOS 7.x\" -%} systemctl restart nginx-wallarm \u00b6 {%- tab name=\"Amazon Linux 2\" -%} systemctl restart nginx-wallarm \u00b6 {%- endtermtabs %}","title":"Restart nginx wallarm en"},{"location":"en/include-en/restart-nginx-wallarm-en/#systemctl-restart-nginx-wallarm","text":"{%- tab name=\"Debian 9.x (stretch)\" -%}","title":"systemctl restart nginx-wallarm"},{"location":"en/include-en/restart-nginx-wallarm-en/#systemctl-restart-nginx-wallarm_1","text":"{%- tab name=\"Ubuntu 14.04 LTS (trusty)\" -%}","title":"systemctl restart nginx-wallarm"},{"location":"en/include-en/restart-nginx-wallarm-en/#service-nginx-wallarm-restart","text":"{%- tab name=\"Ubuntu 16.04 LTS (xenial)\" -%}","title":"service nginx-wallarm restart"},{"location":"en/include-en/restart-nginx-wallarm-en/#service-nginx-wallarm-restart_1","text":"{%- tab name=\"Ubuntu 18.04 LTS (bionic)\" -%}","title":"service nginx-wallarm restart"},{"location":"en/include-en/restart-nginx-wallarm-en/#service-nginx-wallarm-restart_2","text":"{%- tab name=\"CentOS 6.x\" -%}","title":"service nginx-wallarm restart"},{"location":"en/include-en/restart-nginx-wallarm-en/#service-nginx-wallarm-restart_3","text":"{%- tab name=\"CentOS 7.x\" -%}","title":"service nginx-wallarm restart"},{"location":"en/include-en/restart-nginx-wallarm-en/#systemctl-restart-nginx-wallarm_2","text":"{%- tab name=\"Amazon Linux 2\" -%}","title":"systemctl restart nginx-wallarm"},{"location":"en/include-en/restart-nginx-wallarm-en/#systemctl-restart-nginx-wallarm_3","text":"{%- endtermtabs %}","title":"systemctl restart nginx-wallarm"},{"location":"en/include-en/restart-nginx-wallarm-legacy-en/","text":"{% termtabs name=\"Debian 8.x (jessie)\" -%} systemctl restart nginx-wallarm \u00b6 {%- tab name=\"Debian 9.x (stretch)\" -%} systemctl restart nginx-wallarm \u00b6 {%- tab name=\"Ubuntu 14.04 LTS (trusty)\" -%} service nginx-wallarm restart \u00b6 {%- tab name=\"Ubuntu 16.04 LTS (xenial)\" -%} service nginx-wallarm restart \u00b6 {%- tab name=\"Ubuntu 18.04 LTS (bionic)\" -%} service nginx-wallarm restart \u00b6 {%- tab name=\"CentOS 7.x\" -%} systemctl restart nginx-wallarm \u00b6 {%- endtermtabs %}","title":"Restart nginx wallarm legacy en"},{"location":"en/include-en/restart-nginx-wallarm-legacy-en/#systemctl-restart-nginx-wallarm","text":"{%- tab name=\"Debian 9.x (stretch)\" -%}","title":"systemctl restart nginx-wallarm"},{"location":"en/include-en/restart-nginx-wallarm-legacy-en/#systemctl-restart-nginx-wallarm_1","text":"{%- tab name=\"Ubuntu 14.04 LTS (trusty)\" -%}","title":"systemctl restart nginx-wallarm"},{"location":"en/include-en/restart-nginx-wallarm-legacy-en/#service-nginx-wallarm-restart","text":"{%- tab name=\"Ubuntu 16.04 LTS (xenial)\" -%}","title":"service nginx-wallarm restart"},{"location":"en/include-en/restart-nginx-wallarm-legacy-en/#service-nginx-wallarm-restart_1","text":"{%- tab name=\"Ubuntu 18.04 LTS (bionic)\" -%}","title":"service nginx-wallarm restart"},{"location":"en/include-en/restart-nginx-wallarm-legacy-en/#service-nginx-wallarm-restart_2","text":"{%- tab name=\"CentOS 7.x\" -%}","title":"service nginx-wallarm restart"},{"location":"en/include-en/restart-nginx-wallarm-legacy-en/#systemctl-restart-nginx-wallarm_2","text":"{%- endtermtabs %}","title":"systemctl restart nginx-wallarm"},{"location":"en/include-en/root_perm_info/","text":"Providing user with root permission If you are running NGINX as a user that does not have root permission, add this user to the wallarm group using the following command: # usermod -aG wallarm &lt;user_name&gt; where <user_name> is the name of the user without root permission.","title":"Root perm info"},{"location":"en/include-en/scanner-ip-request-us/","text":"23.239.18.250 104.237.155.105 45.56.71.221 45.79.194.128 104.237.151.202 45.33.15.249 45.33.43.225 45.79.10.15 45.33.79.18 45.79.75.59 23.239.30.236 50.116.11.251 45.56.123.144 45.79.143.18 172.104.21.210 74.207.237.202 45.79.186.159 45.79.216.187 45.33.16.32 96.126.127.23 172.104.208.113 192.81.135.28","title":"Scanner ip request us"},{"location":"en/include-en/scanner-ip-request/","text":"139.162.130.66 139.162.144.202 139.162.151.10 139.162.151.155 139.162.156.102 139.162.157.131 139.162.158.79 139.162.159.137 139.162.159.244 139.162.163.61 139.162.164.41 139.162.166.202 139.162.167.19 139.162.167.51 139.162.168.17 139.162.170.84 139.162.171.141 139.162.172.35 139.162.174.220 139.162.174.26 139.162.175.71 139.162.176.169 139.162.178.148 139.162.179.214 139.162.180.37 139.162.182.156 139.162.182.20 139.162.184.225 139.162.185.243 139.162.186.136 139.162.187.138 139.162.188.246 139.162.190.22 139.162.190.86 139.162.191.89 85.90.246.120 104.200.29.36 104.237.151.23 173.230.130.253 173.230.138.206 173.230.156.200 173.230.158.207 173.255.192.83 173.255.193.92 173.255.200.80 173.255.214.180 192.155.82.205 23.239.11.21 23.92.18.13 23.92.30.204 45.33.105.35 45.33.33.19 45.33.41.31 45.33.64.71 45.33.65.37 45.33.72.81 45.33.73.43 45.33.80.65 45.33.81.109 45.33.88.42 45.33.97.86 45.33.98.89 45.56.102.9 45.56.104.7 45.56.113.41 45.56.114.24 45.56.119.39 50.116.35.43 50.116.42.181 50.116.43.110 66.175.222.237 66.228.58.101 69.164.202.55 72.14.181.105 72.14.184.100 72.14.191.76 172.104.150.243 139.162.190.165 139.162.130.123 139.162.132.87 139.162.145.238 139.162.146.245 139.162.162.71 139.162.171.208 139.162.184.33 139.162.186.129 172.104.128.103 172.104.128.67 172.104.139.37 172.104.146.90 172.104.151.59 172.104.152.244 172.104.152.96 172.104.154.128 172.104.229.59 172.104.250.27 172.104.252.112 45.33.115.7 45.56.69.211 45.79.16.240 50.116.23.110 85.90.246.49 172.104.139.18 172.104.152.28 139.162.177.83 172.104.240.115 172.105.64.135 139.162.153.16 172.104.241.162 139.162.167.48 172.104.233.100 172.104.157.26 172.105.65.182","title":"Scanner ip request"},{"location":"en/include-en/scanner-ip-validate/","text":"178.32.42.221 46.105.75.84 51.254.85.145 188.165.30.182 188.165.136.41 188.165.137.10 54.36.135.252 54.36.135.253 54.36.135.254 54.36.135.255 54.36.131.128 54.36.131.129","title":"Scanner ip validate"},{"location":"en/include-en/scanner-whitelist-warning/","text":"#### Warning:: Disable Blocking of the Wallarm Scanner IP Addresses Note that if you use the blocking mode by default (`default block;`) when detecting malicious requests, you must explicitly specify for the Wallarm scanner a list of IP addresses from which requests should not be blocked. You can read more about disabling the blocking mode for scanner IP addresses [here](scanner-ips-whitelisting.md).","title":"Scanner whitelist warning"},{"location":"en/include-en/setup-filter-en/","text":"The filtering and proxying rules are configured in the /etc/nginx-wallarm/conf.d/wallarm.conf file. You can create your own configuration files to define the operation of NGINX-Wallarm. It is recommended to create a separate configuration file with the server block for each group of the domains that should be processed in the same way. To see detailed information about configuring NGINX-Wallarm, proceed to the official NGINX documentation . Wallarm directives define the operation logic of the Wallarm filter node. To see the list of Wallarm directives available, proceed to the Wallarm configuration options page. A Configuration File Example \u00b6 Let us suppose that you need to configure the server to work in the following conditions: Only HTTP traffic is processed. There are no HTTPS requests processed. The following domains receive the requests: example.com and www.example.com . All requests must be passed to the server 10.80.0.5 . All incoming requests are considered less than 1MB in size (default setting). The processing of a request takes no more than 60 seconds (default setting). Wallarm must operate in the monitor mode. Clients access the filter node directly, without an intermediate HTTP load balancer. Creating a configuration file You can create a custom NGINX-Wallarm configuration file (e.g. example.com.conf ) or modify the default NGINX-Wallarm configuration file ( default.conf ). When creating a custom configuration file, make sure that NGINX-Wallarm listens to the incoming connections on the free port. To meet the listed conditions, the contents of the configuration file must be the following: server { listen 80; listen [::]:80 ipv6only=on; # the domains for which traffic is processed server_name example.com; server_name www.example.com; # turn on the monitoring mode of traffic processing wallarm_mode monitoring; # wallarm_instance 1; location / { # setting the address for request forwarding proxy_pass http://10.80.0.5; proxy_set_header Host $host; proxy_set_header X-Real-IP $remote_addr; proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for; } }","title":"Setup filter en"},{"location":"en/include-en/setup-filter-en/#a-configuration-file-example","text":"Let us suppose that you need to configure the server to work in the following conditions: Only HTTP traffic is processed. There are no HTTPS requests processed. The following domains receive the requests: example.com and www.example.com . All requests must be passed to the server 10.80.0.5 . All incoming requests are considered less than 1MB in size (default setting). The processing of a request takes no more than 60 seconds (default setting). Wallarm must operate in the monitor mode. Clients access the filter node directly, without an intermediate HTTP load balancer. Creating a configuration file You can create a custom NGINX-Wallarm configuration file (e.g. example.com.conf ) or modify the default NGINX-Wallarm configuration file ( default.conf ). When creating a custom configuration file, make sure that NGINX-Wallarm listens to the incoming connections on the free port. To meet the listed conditions, the contents of the configuration file must be the following: server { listen 80; listen [::]:80 ipv6only=on; # the domains for which traffic is processed server_name example.com; server_name www.example.com; # turn on the monitoring mode of traffic processing wallarm_mode monitoring; # wallarm_instance 1; location / { # setting the address for request forwarding proxy_pass http://10.80.0.5; proxy_set_header Host $host; proxy_set_header X-Real-IP $remote_addr; proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for; } }","title":"A Configuration File Example"},{"location":"en/include-en/setup-filter-kong-en/","text":"The filtering and proxying rules are configured in the /etc/kong/nginx-wallarm.template file. To see detailed information about working with NGINX configuration files, proceed to the official NGINX documentation . Wallarm directives define the operation logic of the Wallarm filter node. To see the list of Wallarm directives available, proceed to the Wallarm configuration options page. A Configuration File Example \u00b6 Let us suppose that you need to configure the server to work in the following conditions: Only HTTP traffic is processed. There are no HTTPS requests processed. The following domains receive the requests: example.com and www.example.com . All requests must be passed to the server 10.80.0.5 . All incoming requests are considered less than 1MB in size (default setting). The processing of a request takes no more than 60 seconds (default setting). Wallarm must operate in the monitor mode. Clients access the filter node directly, without an intermediate HTTP load balancer. To meet the listed conditions, the contents of the configuration file must be the following: server { listen 80; listen [::]:80 ipv6only=on; # the domains for which traffic is processed server_name example.com; server_name www.example.com; # turn on the monitoring mode of traffic processing wallarm_mode monitoring; # wallarm_instance 1; location / { # setting the address for request forwarding proxy_pass http://10.80.0.5; proxy_set_header Host $host; proxy_set_header X-Real-IP $remote_addr; proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for; } }","title":"Setup filter kong en"},{"location":"en/include-en/setup-filter-kong-en/#a-configuration-file-example","text":"Let us suppose that you need to configure the server to work in the following conditions: Only HTTP traffic is processed. There are no HTTPS requests processed. The following domains receive the requests: example.com and www.example.com . All requests must be passed to the server 10.80.0.5 . All incoming requests are considered less than 1MB in size (default setting). The processing of a request takes no more than 60 seconds (default setting). Wallarm must operate in the monitor mode. Clients access the filter node directly, without an intermediate HTTP load balancer. To meet the listed conditions, the contents of the configuration file must be the following: server { listen 80; listen [::]:80 ipv6only=on; # the domains for which traffic is processed server_name example.com; server_name www.example.com; # turn on the monitoring mode of traffic processing wallarm_mode monitoring; # wallarm_instance 1; location / { # setting the address for request forwarding proxy_pass http://10.80.0.5; proxy_set_header Host $host; proxy_set_header X-Real-IP $remote_addr; proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for; } }","title":"A Configuration File Example"},{"location":"en/include-en/setup-filter-nginx-en/","text":"The etc/nginx/conf.d directory contains NGINX and Wallarm filter node configuration files. By default, this directory contains the following configuration files: The default.conf file defines the configuration of NGINX. The wallarm.conf file defines the global configuration of Wallarm filter node. The wallarm-status.conf file defines the Wallarm monitoring configuration. You can create your own configuration files to define the operation of NGINX and Wallarm. It is recommended to create a separate configuration file with the server block for each group of the domains that should be processed in the same way. To see detailed information about working with NGINX configuration files, proceed to the official NGINX documentation . Wallarm directives define the operation logic of the Wallarm filter node. To see the list of Wallarm directives available, proceed to the Wallarm configuration options page. A Configuration File Example \u00b6 Let us suppose that you need to configure the server to work in the following conditions: Only HTTP traffic is processed. There are no HTTPS requests processed. The following domains receive the requests: example.com and www.example.com . All requests must be passed to the server 10.80.0.5 . All incoming requests are considered less than 1MB in size (default setting). The processing of a request takes no more than 60 seconds (default setting). Wallarm must operate in the monitor mode. Clients access the filter node directly, without an intermediate HTTP load balancer. Creating a configuration file You can create a custom NGINX configuration file (e.g. example.com.conf ) or modify the default NGINX configuration file ( default.conf ). When creating a custom configuration file, make sure that NGINX listens to the incoming connections on the free port. To meet the listed conditions, the contents of the configuration file must be the following: server { listen 80; listen [::]:80 ipv6only=on; # the domains for which traffic is processed server_name example.com; server_name www.example.com; # turn on the monitoring mode of traffic processing wallarm_mode monitoring; # wallarm_instance 1; location / { # setting the address for request forwarding proxy_pass http://10.80.0.5; proxy_set_header Host $host; proxy_set_header X-Real-IP $remote_addr; proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for; } }","title":"Setup filter nginx en"},{"location":"en/include-en/setup-filter-nginx-en/#a-configuration-file-example","text":"Let us suppose that you need to configure the server to work in the following conditions: Only HTTP traffic is processed. There are no HTTPS requests processed. The following domains receive the requests: example.com and www.example.com . All requests must be passed to the server 10.80.0.5 . All incoming requests are considered less than 1MB in size (default setting). The processing of a request takes no more than 60 seconds (default setting). Wallarm must operate in the monitor mode. Clients access the filter node directly, without an intermediate HTTP load balancer. Creating a configuration file You can create a custom NGINX configuration file (e.g. example.com.conf ) or modify the default NGINX configuration file ( default.conf ). When creating a custom configuration file, make sure that NGINX listens to the incoming connections on the free port. To meet the listed conditions, the contents of the configuration file must be the following: server { listen 80; listen [::]:80 ipv6only=on; # the domains for which traffic is processed server_name example.com; server_name www.example.com; # turn on the monitoring mode of traffic processing wallarm_mode monitoring; # wallarm_instance 1; location / { # setting the address for request forwarding proxy_pass http://10.80.0.5; proxy_set_header Host $host; proxy_set_header X-Real-IP $remote_addr; proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for; } }","title":"A Configuration File Example"},{"location":"en/include-en/setup-proxy/","text":"Info This setup step is intended for users who use their own proxy server for the operation of the protected web applications. If you do not use a proxy server, skip this step of the setup. You need to assign new values to the environment variables, which define the proxy server used, to configure Wallarm node for using your proxy server. Add new values of the environment variables to the /etc/environment file: Add https_proxy to define a proxy for the https protocol. Add http_proxy to define a proxy for the http protocol. Add no_proxy to define the list of the resources proxy should not be used for. Assign the <scheme>://<proxy_user>:<proxy_pass>@<host>:<port> string values to the https_proxy and http_proxy variables. <scheme> defines the protocol used. It should match the protocol that the current environment variable sets up proxy for. <proxy_user> defines the username for proxy authorization. <proxy_pass> defines the password for proxy authorization. <host> defines a host of the proxy server. <port> defines a port of the proxy server. Assign a \"<res_1>, <res_2>, <res_3>, <res_4>, ...\" array value, where <res_1> , <res_2> , <res_3> , and <res_4> are the IP addresses and/or domains, to the no_proxy variable to define a list of the resources which proxy should not be used for. This array should consist of IP addresses and/or domains. Resources that need to be addressed without a proxy Add the following IP addresses and domain to the list of the resources that have to be addressed without a proxy for the system to operate correctly: 127.0.0.1 , 127.0.0.8 , 127.0.0.9 , and localhost . The 127.0.0.8 and 127.0.0.9 IP addresses are used for the operation of the Wallarm filter node. The example of the correct /etc/environment file contents below demonstrates the following configuration: HTTPS and HTTP requests are proxied to the 1.2.3.4 host with the 1234 port, using the admin username and the 01234 password for authorization on the proxy server. Proxying is disabled for the requests sent to 127.0.0.1 , 127.0.0.8 , 127.0.0.9 , and localhost . https_proxy=http://admin:01234@1.2.3.4:1234 http_proxy=http://admin:01234@1.2.3.4:1234 no_proxy=\"127.0.0.1, 127.0.0.8, 127.0.0.9, localhost\"","title":"Setup proxy"},{"location":"en/include-en/update-package-en/","text":"{% termtabs name=\"Debian 8.x (jessie)\" -%} apt-get update \u00b6 apt-get install wallarm-node \u00b6 {%- tab name=\"Debian 9.x (stretch)\" -%} apt-get update \u00b6 apt-get install wallarm-node \u00b6 {%- tab name=\"Debian 10.x (buster)\" -%} apt-get update \u00b6 apt-get install wallarm-node \u00b6 {%- tab name=\"Ubuntu 14.04 LTS (trusty)\" -%} apt-get update \u00b6 apt-get install wallarm-node \u00b6 {%- tab name=\"Ubuntu 16.04 LTS (xenial)\" -%} apt-get update \u00b6 apt-get install wallarm-node \u00b6 {%- tab name=\"Ubuntu 18.04 LTS (bionic)\" -%} apt-get update \u00b6 apt-get install wallarm-node \u00b6 {%- tab name=\"CentOS 6.x\" -%} yum update wallarm-node \u00b6 {%- tab name=\"CentOS 7.x\" -%} yum update wallarm-node \u00b6 {%- tab name=\"Amazon Linux 2\" -%} yum update wallarm-node \u00b6 {%- endtermtabs %}","title":"Update package en"},{"location":"en/include-en/update-package-en/#apt-get-update","text":"","title":"apt-get update"},{"location":"en/include-en/update-package-en/#apt-get-install-wallarm-node","text":"{%- tab name=\"Debian 9.x (stretch)\" -%}","title":"apt-get install wallarm-node"},{"location":"en/include-en/update-package-en/#apt-get-update_1","text":"","title":"apt-get update"},{"location":"en/include-en/update-package-en/#apt-get-install-wallarm-node_1","text":"{%- tab name=\"Debian 10.x (buster)\" -%}","title":"apt-get install wallarm-node"},{"location":"en/include-en/update-package-en/#apt-get-update_2","text":"","title":"apt-get update"},{"location":"en/include-en/update-package-en/#apt-get-install-wallarm-node_2","text":"{%- tab name=\"Ubuntu 14.04 LTS (trusty)\" -%}","title":"apt-get install wallarm-node"},{"location":"en/include-en/update-package-en/#apt-get-update_3","text":"","title":"apt-get update"},{"location":"en/include-en/update-package-en/#apt-get-install-wallarm-node_3","text":"{%- tab name=\"Ubuntu 16.04 LTS (xenial)\" -%}","title":"apt-get install wallarm-node"},{"location":"en/include-en/update-package-en/#apt-get-update_4","text":"","title":"apt-get update"},{"location":"en/include-en/update-package-en/#apt-get-install-wallarm-node_4","text":"{%- tab name=\"Ubuntu 18.04 LTS (bionic)\" -%}","title":"apt-get install wallarm-node"},{"location":"en/include-en/update-package-en/#apt-get-update_5","text":"","title":"apt-get update"},{"location":"en/include-en/update-package-en/#apt-get-install-wallarm-node_5","text":"{%- tab name=\"CentOS 6.x\" -%}","title":"apt-get install wallarm-node"},{"location":"en/include-en/update-package-en/#yum-update-wallarm-node","text":"{%- tab name=\"CentOS 7.x\" -%}","title":"yum update wallarm-node"},{"location":"en/include-en/update-package-en/#yum-update-wallarm-node_1","text":"{%- tab name=\"Amazon Linux 2\" -%}","title":"yum update wallarm-node"},{"location":"en/include-en/update-package-en/#yum-update-wallarm-node_2","text":"{%- endtermtabs %}","title":"yum update wallarm-node"},{"location":"en/include-en/update-package-nginx-en/","text":"{% termtabs name=\"Debian 8.x (jessie)\" -%} apt-get update \u00b6 apt-get install wallarm-node-nginx \u00b6 {%- tab name=\"Debian 9.x (stretch)\" -%} apt-get update \u00b6 apt-get install wallarm-node-nginx \u00b6 {%- tab name=\"Debian 10.x (buster)\" -%} apt-get update \u00b6 apt-get install wallarm-node-nginx \u00b6 {%- tab name=\"Ubuntu 14.04 LTS (trusty)\" -%} apt-get update \u00b6 apt-get install wallarm-node-nginx \u00b6 {%- tab name=\"Ubuntu 16.04 LTS (xenial)\" -%} apt-get update \u00b6 apt-get install wallarm-node-nginx \u00b6 {%- tab name=\"Ubuntu 18.04 LTS (bionic)\" -%} apt-get update \u00b6 apt-get install wallarm-node-nginx \u00b6 {%- tab name=\"CentOS 6.x\" -%} yum update wallarm-node-nginx \u00b6 {%- tab name=\"CentOS 7.x\" -%} yum update wallarm-node-nginx \u00b6 {%- tab name=\"Amazon Linux 2\" -%} yum update wallarm-node-nginx \u00b6 {%- endtermtabs %}","title":"Update package nginx en"},{"location":"en/include-en/update-package-nginx-en/#apt-get-update","text":"","title":"apt-get update"},{"location":"en/include-en/update-package-nginx-en/#apt-get-install-wallarm-node-nginx","text":"{%- tab name=\"Debian 9.x (stretch)\" -%}","title":"apt-get install wallarm-node-nginx"},{"location":"en/include-en/update-package-nginx-en/#apt-get-update_1","text":"","title":"apt-get update"},{"location":"en/include-en/update-package-nginx-en/#apt-get-install-wallarm-node-nginx_1","text":"{%- tab name=\"Debian 10.x (buster)\" -%}","title":"apt-get install wallarm-node-nginx"},{"location":"en/include-en/update-package-nginx-en/#apt-get-update_2","text":"","title":"apt-get update"},{"location":"en/include-en/update-package-nginx-en/#apt-get-install-wallarm-node-nginx_2","text":"{%- tab name=\"Ubuntu 14.04 LTS (trusty)\" -%}","title":"apt-get install wallarm-node-nginx"},{"location":"en/include-en/update-package-nginx-en/#apt-get-update_3","text":"","title":"apt-get update"},{"location":"en/include-en/update-package-nginx-en/#apt-get-install-wallarm-node-nginx_3","text":"{%- tab name=\"Ubuntu 16.04 LTS (xenial)\" -%}","title":"apt-get install wallarm-node-nginx"},{"location":"en/include-en/update-package-nginx-en/#apt-get-update_4","text":"","title":"apt-get update"},{"location":"en/include-en/update-package-nginx-en/#apt-get-install-wallarm-node-nginx_4","text":"{%- tab name=\"Ubuntu 18.04 LTS (bionic)\" -%}","title":"apt-get install wallarm-node-nginx"},{"location":"en/include-en/update-package-nginx-en/#apt-get-update_5","text":"","title":"apt-get update"},{"location":"en/include-en/update-package-nginx-en/#apt-get-install-wallarm-node-nginx_5","text":"{%- tab name=\"CentOS 6.x\" -%}","title":"apt-get install wallarm-node-nginx"},{"location":"en/include-en/update-package-nginx-en/#yum-update-wallarm-node-nginx","text":"{%- tab name=\"CentOS 7.x\" -%}","title":"yum update wallarm-node-nginx"},{"location":"en/include-en/update-package-nginx-en/#yum-update-wallarm-node-nginx_1","text":"{%- tab name=\"Amazon Linux 2\" -%}","title":"yum update wallarm-node-nginx"},{"location":"en/include-en/update-package-nginx-en/#yum-update-wallarm-node-nginx_2","text":"{%- endtermtabs %}","title":"yum update wallarm-node-nginx"},{"location":"en/include-en/update-postanalytics-restart-service/","text":"{% termtabs name=\"Debian 8.x (jessie)\" -%} systemctl restart wallarm-tarantool \u00b6 {%- tab name=\"Debian 9.x (stretch)\" -%} systemctl restart wallarm-tarantool \u00b6 {%- tab name=\"Debian 10.x (buster)\" -%} systemctl restart wallarm-tarantool \u00b6 {%- tab name=\"Ubuntu 14.04 LTS (trusty)\" -%} service wallarm-tarantool restart \u00b6 {%- tab name=\"Ubuntu 16.04 LTS (xenial)\" -%} systemctl restart wallarm-tarantool \u00b6 {%- tab name=\"Ubuntu 18.04 LTS (bionic)\" -%} systemctl restart wallarm-tarantool \u00b6 {%- tab name=\"CentOS 6.x\" -%} service wallarm-tarantool restart \u00b6 {%- tab name=\"CentOS 7.x\" -%} systemctl restart wallarm-tarantool \u00b6 {%- endtermtabs %}","title":"Update postanalytics restart service"},{"location":"en/include-en/update-postanalytics-restart-service/#systemctl-restart-wallarm-tarantool","text":"{%- tab name=\"Debian 9.x (stretch)\" -%}","title":"systemctl restart wallarm-tarantool"},{"location":"en/include-en/update-postanalytics-restart-service/#systemctl-restart-wallarm-tarantool_1","text":"{%- tab name=\"Debian 10.x (buster)\" -%}","title":"systemctl restart wallarm-tarantool"},{"location":"en/include-en/update-postanalytics-restart-service/#systemctl-restart-wallarm-tarantool_2","text":"{%- tab name=\"Ubuntu 14.04 LTS (trusty)\" -%}","title":"systemctl restart wallarm-tarantool"},{"location":"en/include-en/update-postanalytics-restart-service/#service-wallarm-tarantool-restart","text":"{%- tab name=\"Ubuntu 16.04 LTS (xenial)\" -%}","title":"service wallarm-tarantool restart"},{"location":"en/include-en/update-postanalytics-restart-service/#systemctl-restart-wallarm-tarantool_3","text":"{%- tab name=\"Ubuntu 18.04 LTS (bionic)\" -%}","title":"systemctl restart wallarm-tarantool"},{"location":"en/include-en/update-postanalytics-restart-service/#systemctl-restart-wallarm-tarantool_4","text":"{%- tab name=\"CentOS 6.x\" -%}","title":"systemctl restart wallarm-tarantool"},{"location":"en/include-en/update-postanalytics-restart-service/#service-wallarm-tarantool-restart_1","text":"{%- tab name=\"CentOS 7.x\" -%}","title":"service wallarm-tarantool restart"},{"location":"en/include-en/update-postanalytics-restart-service/#systemctl-restart-wallarm-tarantool_5","text":"{%- endtermtabs %}","title":"systemctl restart wallarm-tarantool"},{"location":"en/include-en/update-postanalytics/","text":"{% termtabs name=\"Debian 8.x (jessie)\" -%} apt-get update \u00b6 apt-get install wallarm-node-tarantool \u00b6 {%- tab name=\"Debian 9.x (stretch)\" -%} apt-get update \u00b6 apt-get install wallarm-node-tarantool \u00b6 {%- tab name=\"Debian 10.x (buster)\" -%} apt-get update \u00b6 apt-get install wallarm-node-tarantool \u00b6 {%- tab name=\"Ubuntu 14.04 LTS (trusty)\" -%} apt-get update \u00b6 apt-get install wallarm-node-tarantool \u00b6 {%- tab name=\"Ubuntu 16.04 LTS (xenial)\" -%} apt-get update \u00b6 apt-get install wallarm-node-tarantool \u00b6 {%- tab name=\"Ubuntu 18.04 LTS (bionic)\" -%} apt-get update \u00b6 apt-get install wallarm-node-tarantool \u00b6 {%- tab name=\"CentOS 6.x\" -%} yum update wallarm-node-tarantool \u00b6 {%- tab name=\"CentOS 7.x\" -%} yum update wallarm-node-tarantool \u00b6 {%- endtermtabs %}","title":"Update postanalytics"},{"location":"en/include-en/update-postanalytics/#apt-get-update","text":"","title":"apt-get update"},{"location":"en/include-en/update-postanalytics/#apt-get-install-wallarm-node-tarantool","text":"{%- tab name=\"Debian 9.x (stretch)\" -%}","title":"apt-get install wallarm-node-tarantool"},{"location":"en/include-en/update-postanalytics/#apt-get-update_1","text":"","title":"apt-get update"},{"location":"en/include-en/update-postanalytics/#apt-get-install-wallarm-node-tarantool_1","text":"{%- tab name=\"Debian 10.x (buster)\" -%}","title":"apt-get install wallarm-node-tarantool"},{"location":"en/include-en/update-postanalytics/#apt-get-update_2","text":"","title":"apt-get update"},{"location":"en/include-en/update-postanalytics/#apt-get-install-wallarm-node-tarantool_2","text":"{%- tab name=\"Ubuntu 14.04 LTS (trusty)\" -%}","title":"apt-get install wallarm-node-tarantool"},{"location":"en/include-en/update-postanalytics/#apt-get-update_3","text":"","title":"apt-get update"},{"location":"en/include-en/update-postanalytics/#apt-get-install-wallarm-node-tarantool_3","text":"{%- tab name=\"Ubuntu 16.04 LTS (xenial)\" -%}","title":"apt-get install wallarm-node-tarantool"},{"location":"en/include-en/update-postanalytics/#apt-get-update_4","text":"","title":"apt-get update"},{"location":"en/include-en/update-postanalytics/#apt-get-install-wallarm-node-tarantool_4","text":"{%- tab name=\"Ubuntu 18.04 LTS (bionic)\" -%}","title":"apt-get install wallarm-node-tarantool"},{"location":"en/include-en/update-postanalytics/#apt-get-update_5","text":"","title":"apt-get update"},{"location":"en/include-en/update-postanalytics/#apt-get-install-wallarm-node-tarantool_5","text":"{%- tab name=\"CentOS 6.x\" -%}","title":"apt-get install wallarm-node-tarantool"},{"location":"en/include-en/update-postanalytics/#yum-update-wallarm-node-tarantool","text":"{%- tab name=\"CentOS 7.x\" -%}","title":"yum update wallarm-node-tarantool"},{"location":"en/include-en/update-postanalytics/#yum-update-wallarm-node-tarantool_1","text":"{%- endtermtabs %}","title":"yum update wallarm-node-tarantool"},{"location":"en/include-en/api-request-examples/create-rule-en/","text":"{% termtabs name=\"EU cloud\" -%} curl -v -X POST \" https://api.wallarm.com/v1/objects/hint/create \" -H \"X-WallarmAPI-UUID: YOUR_UUID\" -H \"X-WallarmAPI-Secret: YOUR_SECRET_KEY\" -H \"accept: application/json\" -H \"Content-Type: application/json\" -d \"{ \\\"clientid\\\": YOUR_CLIENT_ID, \\\"type\\\": \\\"vpatch\\\", \\\"action\\\": [ {\\\"type\\\":\\\"equal\\\",\\\"value\\\":\\\"my\\\",\\\"point\\\":[\\\"path\\\",0]}, {\\\"type\\\":\\\"equal\\\",\\\"value\\\":\\\"api\\\",\\\"point\\\":[\\\"path\\\",1]}, {\\\"type\\\":\\\"equal\\\",\\\"value\\\":\\\"endpoint\\\",\\\"point\\\":[\\\"header\\\",\\\"2\\\"]}], \\\"validated\\\": false, \\\"point\\\": [ [ \\\"header\\\", \\\"HOST\\\" ] ], \\\"attack_type\\\": \\\"any\\\"}\" \u00b6 {%- tab name=\"US cloud\" -%} curl -v -X POST \" https://us1.api.wallarm.com/v1/objects/hint/create \" -H \"X-WallarmAPI-UUID: YOUR_UUID\" -H \"X-WallarmAPI-Secret: YOUR_SECRET_KEY\" -H \"accept: application/json\" -H \"Content-Type: application/json\" -d \"{ \\\"clientid\\\": YOUR_CLIENT_ID, \\\"type\\\": \\\"vpatch\\\", \\\"action\\\": [ {\\\"type\\\":\\\"equal\\\",\\\"value\\\":\\\"my\\\",\\\"point\\\":[\\\"path\\\",0]}, {\\\"type\\\":\\\"equal\\\",\\\"value\\\":\\\"api\\\",\\\"point\\\":[\\\"path\\\",1]}, {\\\"type\\\":\\\"equal\\\",\\\"value\\\":\\\"endpoint\\\",\\\"point\\\":[\\\"header\\\",\\\"2\\\"]}], \\\"validated\\\": false, \\\"point\\\": [ [ \\\"header\\\", \\\"HOST\\\" ] ], \\\"attack_type\\\": \\\"any\\\"}\" \u00b6 {%- endtermtabs %}","title":"Create rule en"},{"location":"en/include-en/api-request-examples/create-rule-en/#curl-v-x-post-httpsapiwallarmcomv1objectshintcreate-h-x-wallarmapi-uuid-your_uuid-h-x-wallarmapi-secret-your_secret_key-h-accept-applicationjson-h-content-type-applicationjson-d-clientid-your_client_id-type-vpatch-action-typeequalvaluemypointpath0-typeequalvalueapipointpath1-typeequalvalueendpointpointheader2-validated-false-point-header-host-attack_type-any","text":"{%- tab name=\"US cloud\" -%}","title":"curl -v -X POST \"https://api.wallarm.com/v1/objects/hint/create\" -H \"X-WallarmAPI-UUID: YOUR_UUID\" -H \"X-WallarmAPI-Secret: YOUR_SECRET_KEY\" -H \"accept: application/json\" -H \"Content-Type: application/json\" -d \"{ \\\"clientid\\\": YOUR_CLIENT_ID, \\\"type\\\": \\\"vpatch\\\", \\\"action\\\": [ {\\\"type\\\":\\\"equal\\\",\\\"value\\\":\\\"my\\\",\\\"point\\\":[\\\"path\\\",0]}, {\\\"type\\\":\\\"equal\\\",\\\"value\\\":\\\"api\\\",\\\"point\\\":[\\\"path\\\",1]}, {\\\"type\\\":\\\"equal\\\",\\\"value\\\":\\\"endpoint\\\",\\\"point\\\":[\\\"header\\\",\\\"2\\\"]}], \\\"validated\\\": false, \\\"point\\\": [ [ \\\"header\\\", \\\"HOST\\\" ] ], \\\"attack_type\\\": \\\"any\\\"}\""},{"location":"en/include-en/api-request-examples/create-rule-en/#curl-v-x-post-httpsus1apiwallarmcomv1objectshintcreate-h-x-wallarmapi-uuid-your_uuid-h-x-wallarmapi-secret-your_secret_key-h-accept-applicationjson-h-content-type-applicationjson-d-clientid-your_client_id-type-vpatch-action-typeequalvaluemypointpath0-typeequalvalueapipointpath1-typeequalvalueendpointpointheader2-validated-false-point-header-host-attack_type-any","text":"{%- endtermtabs %}","title":"curl -v -X POST \"https://us1.api.wallarm.com/v1/objects/hint/create\" -H \"X-WallarmAPI-UUID: YOUR_UUID\" -H \"X-WallarmAPI-Secret: YOUR_SECRET_KEY\" -H \"accept: application/json\" -H \"Content-Type: application/json\" -d \"{ \\\"clientid\\\": YOUR_CLIENT_ID, \\\"type\\\": \\\"vpatch\\\", \\\"action\\\": [ {\\\"type\\\":\\\"equal\\\",\\\"value\\\":\\\"my\\\",\\\"point\\\":[\\\"path\\\",0]}, {\\\"type\\\":\\\"equal\\\",\\\"value\\\":\\\"api\\\",\\\"point\\\":[\\\"path\\\",1]}, {\\\"type\\\":\\\"equal\\\",\\\"value\\\":\\\"endpoint\\\",\\\"point\\\":[\\\"header\\\",\\\"2\\\"]}], \\\"validated\\\": false, \\\"point\\\": [ [ \\\"header\\\", \\\"HOST\\\" ] ], \\\"attack_type\\\": \\\"any\\\"}\""},{"location":"en/include-en/api-request-examples/get-attacks-en/","text":"{% termtabs name=\"EU cloud\" -%} curl -v -X POST \" https://api.wallarm.com/v1/objects/attack \" -H \"X-WallarmAPI-UUID: YOUR_UUID\" -H \"X-WallarmAPI-Secret: YOUR_SECRET_KEY\" -H \"accept: application/json\" -H \"Content-Type: application/json\" -d \"{ \\\"filter\\\": { \\\"clientid\\\": [YOUR_CLIENT_ID], \\\"time\\\": [CURRENT_TIMESTAMP] }, \\\"offset\\\": 0, \\\"limit\\\": 50, \\\"order_by\\\": \\\"last_time\\\", \\\"order_desc\\\": true}\" \u00b6 {%- tab name=\"US cloud\" -%} curl -v -X POST \" https://us1.api.wallarm.com/v1/objects/attack \" -H \"X-WallarmAPI-UUID: YOUR_UUID\" -H \"X-WallarmAPI-Secret: YOUR_SECRET_KEY\" -H \"accept: application/json\" -H \"Content-Type: application/json\" -d \"{ \\\"filter\\\": { \\\"clientid\\\": [YOUR_CLIENT_ID], \\\"time\\\": [CURRENT_TIMESTAMP] }, \\\"offset\\\": 0, \\\"limit\\\": 50, \\\"order_by\\\": \\\"last_time\\\", \\\"order_desc\\\": true}\" \u00b6 {%- endtermtabs %}","title":"Get attacks en"},{"location":"en/include-en/api-request-examples/get-attacks-en/#curl-v-x-post-httpsapiwallarmcomv1objectsattack-h-x-wallarmapi-uuid-your_uuid-h-x-wallarmapi-secret-your_secret_key-h-accept-applicationjson-h-content-type-applicationjson-d-filter-clientid-your_client_id-time-current_timestamp-offset-0-limit-50-order_by-last_time-order_desc-true","text":"{%- tab name=\"US cloud\" -%}","title":"curl -v -X POST \"https://api.wallarm.com/v1/objects/attack\" -H \"X-WallarmAPI-UUID: YOUR_UUID\" -H \"X-WallarmAPI-Secret: YOUR_SECRET_KEY\" -H \"accept: application/json\" -H \"Content-Type: application/json\" -d \"{ \\\"filter\\\": { \\\"clientid\\\": [YOUR_CLIENT_ID], \\\"time\\\": [CURRENT_TIMESTAMP] }, \\\"offset\\\": 0, \\\"limit\\\": 50, \\\"order_by\\\": \\\"last_time\\\", \\\"order_desc\\\": true}\""},{"location":"en/include-en/api-request-examples/get-attacks-en/#curl-v-x-post-httpsus1apiwallarmcomv1objectsattack-h-x-wallarmapi-uuid-your_uuid-h-x-wallarmapi-secret-your_secret_key-h-accept-applicationjson-h-content-type-applicationjson-d-filter-clientid-your_client_id-time-current_timestamp-offset-0-limit-50-order_by-last_time-order_desc-true","text":"{%- endtermtabs %}","title":"curl -v -X POST \"https://us1.api.wallarm.com/v1/objects/attack\" -H \"X-WallarmAPI-UUID: YOUR_UUID\" -H \"X-WallarmAPI-Secret: YOUR_SECRET_KEY\" -H \"accept: application/json\"  -H \"Content-Type: application/json\" -d \"{ \\\"filter\\\": { \\\"clientid\\\": [YOUR_CLIENT_ID], \\\"time\\\": [CURRENT_TIMESTAMP] }, \\\"offset\\\": 0, \\\"limit\\\": 50, \\\"order_by\\\": \\\"last_time\\\", \\\"order_desc\\\": true}\""},{"location":"en/include-en/api-request-examples/get-incidents-en/","text":"{% termtabs name=\"EU cloud\" -%} curl -v -X POST \" https://api.wallarm.com/v1/objects/attack \" -H \"X-WallarmAPI-UUID: YOUR_UUID\" -H \"X-WallarmAPI-Secret: YOUR_SECRET_KEY\" -H \"accept: application/json\" -H \"Content-Type: application/json\" -d \"{ \\\"filter\\\": { \\\"clientid\\\": [YOUR_CLIENT_ID], \\\"!vulnid\\\": null, \\\"time\\\": [CURRENT_TIMESTAMP] }, \\\"offset\\\": 0, \\\"limit\\\": 50, \\\"order_by\\\": \\\"last_time\\\", \\\"order_desc\\\": true}\" \u00b6 {%- tab name=\"US cloud\" -%} curl -v -X POST \" https://us1.api.wallarm.com/v1/objects/attack \" -H \"X-WallarmAPI-UUID: YOUR_UUID\" -H \"X-WallarmAPI-Secret: YOUR_SECRET_KEY\" -H \"accept: application/json\" -H \"Content-Type: application/json\" -d \"{ \\\"filter\\\": { \\\"clientid\\\": [YOUR_CLIENT_ID], \\\"!vulnid\\\": null, \\\"time\\\": [CURRENT_TIMESTAMP] }, \\\"offset\\\": 0, \\\"limit\\\": 50, \\\"order_by\\\": \\\"last_time\\\", \\\"order_desc\\\": true}\" \u00b6 {%- endtermtabs %}","title":"Get incidents en"},{"location":"en/include-en/api-request-examples/get-incidents-en/#curl-v-x-post-httpsapiwallarmcomv1objectsattack-h-x-wallarmapi-uuid-your_uuid-h-x-wallarmapi-secret-your_secret_key-h-accept-applicationjson-h-content-type-applicationjson-d-filter-clientid-your_client_id-vulnid-null-time-current_timestamp-offset-0-limit-50-order_by-last_time-order_desc-true","text":"{%- tab name=\"US cloud\" -%}","title":"curl -v -X POST \"https://api.wallarm.com/v1/objects/attack\" -H \"X-WallarmAPI-UUID: YOUR_UUID\" -H \"X-WallarmAPI-Secret: YOUR_SECRET_KEY\" -H \"accept: application/json\" -H \"Content-Type: application/json\" -d \"{ \\\"filter\\\": { \\\"clientid\\\": [YOUR_CLIENT_ID], \\\"!vulnid\\\": null, \\\"time\\\": [CURRENT_TIMESTAMP] }, \\\"offset\\\": 0, \\\"limit\\\": 50, \\\"order_by\\\": \\\"last_time\\\", \\\"order_desc\\\": true}\""},{"location":"en/include-en/api-request-examples/get-incidents-en/#curl-v-x-post-httpsus1apiwallarmcomv1objectsattack-h-x-wallarmapi-uuid-your_uuid-h-x-wallarmapi-secret-your_secret_key-h-accept-applicationjson-h-content-type-applicationjson-d-filter-clientid-your_client_id-vulnid-null-time-current_timestamp-offset-0-limit-50-order_by-last_time-order_desc-true","text":"{%- endtermtabs %}","title":"curl -v -X POST \"https://us1.api.wallarm.com/v1/objects/attack\" -H \"X-WallarmAPI-UUID: YOUR_UUID\" -H \"X-WallarmAPI-Secret: YOUR_SECRET_KEY\" -H \"accept: application/json\"  -H \"Content-Type: application/json\" -d \"{ \\\"filter\\\": { \\\"clientid\\\": [YOUR_CLIENT_ID], \\\"!vulnid\\\": null, \\\"time\\\": [CURRENT_TIMESTAMP] }, \\\"offset\\\": 0, \\\"limit\\\": 50, \\\"order_by\\\": \\\"last_time\\\", \\\"order_desc\\\": true}\""},{"location":"en/include-en/kubernetes-sidecar-container/deployment-template/","text":"apiVersion: apps/v1 kind: Deployment metadata: name: myapp spec: selector: matchLabels: app: myapp template: metadata: labels: app: myapp spec: containers: - name: myapp # definition of your main app container image: <Image> resources: limits: memory: \"128Mi\" cpu: \"500m\" ports: - containerPort: 8080 # port on which the application container accepts incoming requests","title":"Deployment template"},{"location":"en/include-en/kubernetes-sidecar-container/deployment-with-wallarm-example-helm/","text":"apiVersion: apps/v1 kind: Deployment metadata: annotations: checksum/config: {{ include (print $.Template.BasePath \"/wallarm-sidecar-configmap.yaml\") . | sha256sum }} # Wallarm element: annotation to update running pods after changing Wallarm ConfigMap name: myapp spec: selector: matchLabels: app: myapp template: metadata: labels: app: myapp spec: containers: - name: wallarm # Wallarm element: definition of Wallarm sidecar container image: {{ .Values.wallarm.image.repository }}:{{ .Values.wallarm.image.tag }} imagePullPolicy: {{ .Values.wallarm.image.pullPolicy | quote }} env: - name: WALLARM_API_HOST value: {{ .Values.wallarm.wallarm_host_api | quote }} - name: DEPLOY_USER value: {{ .Values.wallarm.deploy_username | quote }} - name: DEPLOY_PASSWORD value: {{ .Values.wallarm.deploy_password | quote }} - name: DEPLOY_FORCE value: \"true\" - name: TARANTOOL_MEMORY_GB value: {{ .Values.wallarm.tarantool_memory_gb | quote }} ports: - name: http containerPort: 80 # port on which the Wallarm sidecar container accepts requests from the Service object volumeMounts: - mountPath: /etc/nginx/sites-enabled readOnly: true name: wallarm-nginx-conf - name: myapp # definition of your main app container image: <Image> resources: limits: memory: \"128Mi\" cpu: \"500m\" ports: - containerPort: 8080 # port on which the application container accepts incoming requests volumes: - name: wallarm-nginx-conf # Wallarm element: definition of the wallarm-nginx-conf volume configMap: name: wallarm-sidecar-nginx-conf items: - key: default path: default","title":"Deployment with wallarm example helm"},{"location":"en/include-en/kubernetes-sidecar-container/deployment-with-wallarm-example-manifest/","text":"apiVersion: apps/v1 kind: Deployment metadata: name: myapp spec: selector: matchLabels: app: myapp template: metadata: labels: app: myapp spec: containers: - name: wallarm # Wallarm element: definition of Wallarm sidecar container image: wallarm/node:2.14 imagePullPolicy: Always env: - name: WALLARM_API_HOST # Wallarm API endpoint: \"api.wallarm.com\" for the EU cloud, \"us1.api.wallarm.com\" for the US cloud value: \"api.wallarm.com\" - name: DEPLOY_USER # username of the user with the Deploy role value: \"username\" - name: DEPLOY_PASSWORD # password of the user with the Deploy role value: \"password\" - name: DEPLOY_FORCE value: \"true\" - name: WALLARM_ACL_ENABLE value: \"true\" - name: TARANTOOL_MEMORY_GB # amount of memory in GB for request analytics data, recommended value is 75% of the total server memory value: 2 ports: - name: http containerPort: 80 # port on which the Wallarm sidecar container accepts requests from the Service object volumeMounts: - mountPath: /etc/nginx/sites-enabled readOnly: true name: wallarm-nginx-conf - name: myapp # definition of your main app container image: <Image> resources: limits: memory: \"128Mi\" cpu: \"500m\" ports: - containerPort: 8080 # port on which the application container accepts incoming requests volumes: # - name: wallarm-nginx-conf # Wallarm element: definition of the wallarm-nginx-conf volume configMap: name: wallarm-sidecar-nginx-conf items: - key: default path: default","title":"Deployment with wallarm example manifest"},{"location":"en/include-en/kubernetes-sidecar-container/service-template/","text":"apiVersion: v1 kind: Service metadata: name: myapp spec: selector: app: myapp ports: - port: {{ .Values.service.port }} targetPort: 8080 # Wallarm sidecar container port; the value must be identical to ports.containerPort in definition of Wallarm sidecar container","title":"Service template"},{"location":"en/include-en/kubernetes-sidecar-container/test-sidecar-container-in-kubernetes/","text":"Get the list of pods using the following command: # kubectl get pods The number of containers in the pod should increase and the status of the pod should be \"Running\". NAME READY STATUS RESTARTS AGE mychart-856f957bbd-cr4kt 2/2 Running 0 3m48s Go to your Wallarm account > Nodes by the link below and make sure that a new node is displayed. The created node is used to filter requests to your application. * https://my.wallarm.com/nodes/ for the EU cloud * https://us1.my.wallarm.com/nodes/ for the US cloud Send a malicious test attack request to the application as described in this instruction . Go to your Wallarm account > Events by the link below and make sure that an attack is displayed in the list: * https://my.wallarm.com/events/ for the EU cloud * https://us1.my.wallarm.com/events/ for the US cloud","title":"Test sidecar container in kubernetes"},{"location":"en/include-en/kubernetes-sidecar-container/values-wallarm-description/","text":"wallarm: image: repository: wallarm/node tag: 2.14 pullPolicy: Always wallarm_host_api: \"api.wallarm.com\" # Wallarm API endpoint: \"api.wallarm.com\" for the EU cloud, \"us1.api.wallarm.com\" for the US cloud deploy_username: \"username\" # username of the user with the Deploy role deploy_password: \"password\" # password of the user with the Deploy role app_container_port: 80 # port on which the container accepts incoming requests, the value must be identical to ports.containerPort in definition of your main app container mode: \"block\" # request filtering modes: \"off\" to disable request processing, \"monitoring\" to process but not block requests, \"block\" to process all requests and block the malicious ones tarantool_memory_gb: 2 # amount of memory in GB for request analytics data, recommended value is 75% of the total server memory","title":"Values wallarm description"},{"location":"en/include-en/kubernetes-sidecar-container/wallarm-sidecar-configmap-helm-template/","text":"apiVersion: v1 kind: ConfigMap metadata: name: wallarm-sidecar-nginx-conf data: default: | map $remote_addr $wallarm_mode_real { default {{ .Values.wallarm.mode | quote }}; # please leave the block with IP addresses and rules for your cloud below # IP addresses and rules for US cloud scanners 23.239.18.250 off;104.237.155.105 off;45.56.71.221 off;45.79.194.128 off;104.237.151.202 off;45.33.15.249 off;45.33.43.225 off;45.79.10.15 off;45.33.79.18 off;45.79.75.59 off;23.239.30.236 off;50.116.11.251 off;45.56.123.144 off;45.79.143.18 off;172.104.21.210 off;74.207.237.202 off;45.79.186.159 off;45.79.216.187 off;45.33.16.32 off;96.126.127.23 off;172.104.208.113 off;192.81.135.28 off;35.236.51.79 off;35.236.75.97 off;35.236.111.124 off;35.236.108.88 off;35.236.16.246 off;35.236.61.185 off;35.236.110.91 off;35.236.14.198 off;35.235.124.137 off;35.236.48.47 off;35.236.100.176 off;35.236.18.117 off;35.235.112.188 off;35.236.55.214 off;35.236.126.84 off;35.236.3.158 off;35.236.127.211 off;35.236.118.146 off;35.236.20.89 off;35.236.1.4 off; # IP addresses and rules for European cloud scanners 139.162.130.66 off;139.162.144.202 off;139.162.151.10 off;139.162.151.155 off;139.162.156.102 off;139.162.157.131 off;139.162.158.79 off;139.162.159.137 off;139.162.159.244 off;139.162.163.61 off;139.162.164.41 off;139.162.166.202 off;139.162.167.19 off;139.162.167.51 off;139.162.168.17 off;139.162.170.84 off;139.162.171.141 off;139.162.172.35 off;139.162.174.220 off;139.162.174.26 off;139.162.175.71 off;139.162.176.169 off;139.162.178.148 off;139.162.179.214 off;139.162.180.37 off;139.162.182.156 off;139.162.182.20 off;139.162.184.225 off;139.162.185.243 off;139.162.186.136 off;139.162.187.138 off;139.162.188.246 off;139.162.190.22 off;139.162.190.86 off;139.162.191.89 off;85.90.246.120 off;104.200.29.36 off;104.237.151.23 off;173.230.130.253 off;173.230.138.206 off;173.230.156.200 off;173.230.158.207 off;173.255.192.83 off;173.255.193.92 off;173.255.200.80 off;173.255.214.180 off;192.155.82.205 off;23.239.11.21 off;23.92.18.13 off;23.92.30.204 off;45.33.105.35 off;45.33.33.19 off;45.33.41.31 off;45.33.64.71 off;45.33.65.37 off;45.33.72.81 off;45.33.73.43 off;45.33.80.65 off;45.33.81.109 off;45.33.88.42 off;45.33.97.86 off;45.33.98.89 off;45.56.102.9 off;45.56.104.7 off;45.56.113.41 off;45.56.114.24 off;45.56.119.39 off;50.116.35.43 off;50.116.42.181 off;50.116.43.110 off;66.175.222.237 off;66.228.58.101 off;69.164.202.55 off;72.14.181.105 off;72.14.184.100 off;72.14.191.76 off;172.104.150.243 off;139.162.190.165 off;139.162.130.123 off;139.162.132.87 off;139.162.145.238 off;139.162.146.245 off;139.162.162.71 off;139.162.171.208 off;139.162.184.33 off;139.162.186.129 off;172.104.128.103 off;172.104.128.67 off;172.104.139.37 off;172.104.146.90 off;172.104.151.59 off;172.104.152.244 off;172.104.152.96 off;172.104.154.128 off;172.104.229.59 off;172.104.250.27 off;172.104.252.112 off;45.33.115.7 off;45.56.69.211 off;45.79.16.240 off;50.116.23.110 off;85.90.246.49 off;172.104.139.18 off;172.104.152.28 off;139.162.177.83 off;172.104.240.115 off;172.105.64.135 off;139.162.153.16 off;172.104.241.162 off;139.162.167.48 off;172.104.233.100 off;172.104.157.26 off;172.105.65.182 off;178.32.42.221 off;46.105.75.84 off;51.254.85.145 off;188.165.30.182 off;188.165.136.41 off;188.165.137.10 off;54.36.135.252 off;54.36.135.253 off;54.36.135.254 off;54.36.135.255 off;54.36.131.128 off;54.36.131.129 off; } server { listen 80 default_server; listen [::]:80 default_server ipv6only=on; server_name localhost; root /usr/share/nginx/html; index index.html index.htm; wallarm_mode $wallarm_mode_real; # wallarm_instance 1; {{ if eq .Values.wallarm.enable_ip_blocking \"true\" }} wallarm_acl default; {{ end }} set_real_ip_from 0.0.0.0/0; real_ip_header X-Forwarded-For; location / { proxy_pass http://localhost:{{ .Values.wallarm.app_container_port }}; include proxy_params; } }","title":"Wallarm sidecar configmap helm template"},{"location":"en/include-en/kubernetes-sidecar-container/wallarm-sidecar-configmap-manifest/","text":"apiVersion: v1 kind: ConfigMap metadata: name: wallarm-sidecar-nginx-conf data: default: | map $remote_addr $wallarm_mode_real { default <WALLARM_MODE>; # please replace <WALLARM_MODE> by the request filtering mode: off to disable request processing, monitoring to process but not block requests, block to process all requests and block the malicious ones # please leave the block with IP addresses and rules for your cloud below # IP addresses and rules for US cloud scanners 23.239.18.250 off;104.237.155.105 off;45.56.71.221 off;45.79.194.128 off;104.237.151.202 off;45.33.15.249 off;45.33.43.225 off;45.79.10.15 off;45.33.79.18 off;45.79.75.59 off;23.239.30.236 off;50.116.11.251 off;45.56.123.144 off;45.79.143.18 off;172.104.21.210 off;74.207.237.202 off;45.79.186.159 off;45.79.216.187 off;45.33.16.32 off;96.126.127.23 off;172.104.208.113 off;192.81.135.28 off;35.236.51.79 off;35.236.75.97 off;35.236.111.124 off;35.236.108.88 off;35.236.16.246 off;35.236.61.185 off;35.236.110.91 off;35.236.14.198 off;35.235.124.137 off;35.236.48.47 off;35.236.100.176 off;35.236.18.117 off;35.235.112.188 off;35.236.55.214 off;35.236.126.84 off;35.236.3.158 off;35.236.127.211 off;35.236.118.146 off;35.236.20.89 off;35.236.1.4 off; # IP addresses and rules for European cloud scanners 139.162.130.66 off;139.162.144.202 off;139.162.151.10 off;139.162.151.155 off;139.162.156.102 off;139.162.157.131 off;139.162.158.79 off;139.162.159.137 off;139.162.159.244 off;139.162.163.61 off;139.162.164.41 off;139.162.166.202 off;139.162.167.19 off;139.162.167.51 off;139.162.168.17 off;139.162.170.84 off;139.162.171.141 off;139.162.172.35 off;139.162.174.220 off;139.162.174.26 off;139.162.175.71 off;139.162.176.169 off;139.162.178.148 off;139.162.179.214 off;139.162.180.37 off;139.162.182.156 off;139.162.182.20 off;139.162.184.225 off;139.162.185.243 off;139.162.186.136 off;139.162.187.138 off;139.162.188.246 off;139.162.190.22 off;139.162.190.86 off;139.162.191.89 off;85.90.246.120 off;104.200.29.36 off;104.237.151.23 off;173.230.130.253 off;173.230.138.206 off;173.230.156.200 off;173.230.158.207 off;173.255.192.83 off;173.255.193.92 off;173.255.200.80 off;173.255.214.180 off;192.155.82.205 off;23.239.11.21 off;23.92.18.13 off;23.92.30.204 off;45.33.105.35 off;45.33.33.19 off;45.33.41.31 off;45.33.64.71 off;45.33.65.37 off;45.33.72.81 off;45.33.73.43 off;45.33.80.65 off;45.33.81.109 off;45.33.88.42 off;45.33.97.86 off;45.33.98.89 off;45.56.102.9 off;45.56.104.7 off;45.56.113.41 off;45.56.114.24 off;45.56.119.39 off;50.116.35.43 off;50.116.42.181 off;50.116.43.110 off;66.175.222.237 off;66.228.58.101 off;69.164.202.55 off;72.14.181.105 off;72.14.184.100 off;72.14.191.76 off;172.104.150.243 off;139.162.190.165 off;139.162.130.123 off;139.162.132.87 off;139.162.145.238 off;139.162.146.245 off;139.162.162.71 off;139.162.171.208 off;139.162.184.33 off;139.162.186.129 off;172.104.128.103 off;172.104.128.67 off;172.104.139.37 off;172.104.146.90 off;172.104.151.59 off;172.104.152.244 off;172.104.152.96 off;172.104.154.128 off;172.104.229.59 off;172.104.250.27 off;172.104.252.112 off;45.33.115.7 off;45.56.69.211 off;45.79.16.240 off;50.116.23.110 off;85.90.246.49 off;172.104.139.18 off;172.104.152.28 off;139.162.177.83 off;172.104.240.115 off;172.105.64.135 off;139.162.153.16 off;172.104.241.162 off;139.162.167.48 off;172.104.233.100 off;172.104.157.26 off;172.105.65.182 off;178.32.42.221 off;46.105.75.84 off;51.254.85.145 off;188.165.30.182 off;188.165.136.41 off;188.165.137.10 off;54.36.135.252 off;54.36.135.253 off;54.36.135.254 off;54.36.135.255 off;54.36.131.128 off;54.36.131.129 off; } server { listen 80 default_server; listen [::]:80 default_server ipv6only=on; server_name localhost; root /usr/share/nginx/html; index index.html index.htm; wallarm_mode $wallarm_mode_real; # wallarm_instance 1; set_real_ip_from 0.0.0.0/0; real_ip_header X-Forwarded-For; location / { proxy_pass http://localhost:<APP_CONTAINER_PORT>; # please replace <APP_CONTAINER_PORT> by the port number on which the container accepts incoming requests, the value must be identical to ports.containerPort in definition of your main app container include proxy_params; } }","title":"Wallarm sidecar configmap manifest"},{"location":"en/include-en/migration-212-214/add-repos-deb/","text":"{% codetabs name=\"Debian 8.x (jessie)\", type=\"sh\" %} deb http://repo.wallarm.com/debian/wallarm-node jessie/ \u00b6 deb http://repo.wallarm.com/debian/wallarm-node jessie/2.14/ {% language name=\"Debian 8.x (jessie-backports)\", type=\"sh\" %} deb http://repo.wallarm.com/debian/wallarm-node jessie/ \u00b6 deb http://repo.wallarm.com/debian/wallarm-node jessie-backports/ \u00b6 deb http://repo.wallarm.com/debian/wallarm-node jessie/2.14/ deb http://repo.wallarm.com/debian/wallarm-node jessie-backports/2.14/ {% language name=\"Debian 9.x (stretch)\", type=\"sh\" %} deb http://repo.wallarm.com/debian/wallarm-node stretch/ \u00b6 deb http://repo.wallarm.com/debian/wallarm-node stretch/2.14/ {% language name=\"Debian 9.x (stretch-backports)\", type=\"sh\" %} deb http://repo.wallarm.com/debian/wallarm-node stretch/ \u00b6 deb http://repo.wallarm.com/debian/wallarm-node stretch-backports/ \u00b6 deb http://repo.wallarm.com/debian/wallarm-node stretch/2.14/ deb http://repo.wallarm.com/debian/wallarm-node stretch-backports/2.14/ {% language name=\"Debian 10.x (buster)\", type=\"sh\" %} deb http://repo.wallarm.com/debian/wallarm-node buster/ \u00b6 deb http://repo.wallarm.com/debian/wallarm-node buster/2.14/ {% language name=\"Ubuntu 14.04 LTS (trusty)\", type=\"sh\" %} deb http://repo.wallarm.com/ubuntu/wallarm-node trusty/ \u00b6 deb http://repo.wallarm.com/ubuntu/wallarm-node trusty/2.14/ {% language name=\"Ubuntu 16.04 LTS (xenial)\", type=\"sh\" %} deb http://repo.wallarm.com/ubuntu/wallarm-node xenial/ \u00b6 deb http://repo.wallarm.com/ubuntu/wallarm-node xenial/2.14/ {% language name=\"Ubuntu 18.04 LTS (bionic)\", type=\"sh\" %} deb http://repo.wallarm.com/ubuntu/wallarm-node bionic/ \u00b6 deb http://repo.wallarm.com/ubuntu/wallarm-node bionic/2.14/ {% endcodetabs %}","title":"Add repos deb"},{"location":"en/include-en/migration-212-214/add-repos-deb/#deb-httprepowallarmcomdebianwallarm-node-jessie","text":"deb http://repo.wallarm.com/debian/wallarm-node jessie/2.14/ {% language name=\"Debian 8.x (jessie-backports)\", type=\"sh\" %}","title":"deb http://repo.wallarm.com/debian/wallarm-node jessie/"},{"location":"en/include-en/migration-212-214/add-repos-deb/#deb-httprepowallarmcomdebianwallarm-node-jessie_1","text":"","title":"deb http://repo.wallarm.com/debian/wallarm-node jessie/"},{"location":"en/include-en/migration-212-214/add-repos-deb/#deb-httprepowallarmcomdebianwallarm-node-jessie-backports","text":"deb http://repo.wallarm.com/debian/wallarm-node jessie/2.14/ deb http://repo.wallarm.com/debian/wallarm-node jessie-backports/2.14/ {% language name=\"Debian 9.x (stretch)\", type=\"sh\" %}","title":"deb http://repo.wallarm.com/debian/wallarm-node jessie-backports/"},{"location":"en/include-en/migration-212-214/add-repos-deb/#deb-httprepowallarmcomdebianwallarm-node-stretch","text":"deb http://repo.wallarm.com/debian/wallarm-node stretch/2.14/ {% language name=\"Debian 9.x (stretch-backports)\", type=\"sh\" %}","title":"deb http://repo.wallarm.com/debian/wallarm-node stretch/"},{"location":"en/include-en/migration-212-214/add-repos-deb/#deb-httprepowallarmcomdebianwallarm-node-stretch_1","text":"","title":"deb http://repo.wallarm.com/debian/wallarm-node stretch/"},{"location":"en/include-en/migration-212-214/add-repos-deb/#deb-httprepowallarmcomdebianwallarm-node-stretch-backports","text":"deb http://repo.wallarm.com/debian/wallarm-node stretch/2.14/ deb http://repo.wallarm.com/debian/wallarm-node stretch-backports/2.14/ {% language name=\"Debian 10.x (buster)\", type=\"sh\" %}","title":"deb http://repo.wallarm.com/debian/wallarm-node stretch-backports/"},{"location":"en/include-en/migration-212-214/add-repos-deb/#deb-httprepowallarmcomdebianwallarm-node-buster","text":"deb http://repo.wallarm.com/debian/wallarm-node buster/2.14/ {% language name=\"Ubuntu 14.04 LTS (trusty)\", type=\"sh\" %}","title":"deb http://repo.wallarm.com/debian/wallarm-node buster/"},{"location":"en/include-en/migration-212-214/add-repos-deb/#deb-httprepowallarmcomubuntuwallarm-node-trusty","text":"deb http://repo.wallarm.com/ubuntu/wallarm-node trusty/2.14/ {% language name=\"Ubuntu 16.04 LTS (xenial)\", type=\"sh\" %}","title":"deb http://repo.wallarm.com/ubuntu/wallarm-node trusty/"},{"location":"en/include-en/migration-212-214/add-repos-deb/#deb-httprepowallarmcomubuntuwallarm-node-xenial","text":"deb http://repo.wallarm.com/ubuntu/wallarm-node xenial/2.14/ {% language name=\"Ubuntu 18.04 LTS (bionic)\", type=\"sh\" %}","title":"deb http://repo.wallarm.com/ubuntu/wallarm-node xenial/"},{"location":"en/include-en/migration-212-214/add-repos-deb/#deb-httprepowallarmcomubuntuwallarm-node-bionic","text":"deb http://repo.wallarm.com/ubuntu/wallarm-node bionic/2.14/ {% endcodetabs %}","title":"deb http://repo.wallarm.com/ubuntu/wallarm-node bionic/"},{"location":"en/include-en/migration-212-214/add-repos-rpm/","text":"{% codetabs name=\"CentOS 6.x\", type=\"sh\" %} [wallarm-node] baseurl= http://repo.wallarm.com/centos/wallarm-node/6/$basearch \u00b6 baseurl= http://repo.wallarm.com/centos/wallarm-node/6/2.14/$basearch {% language name=\"CentOS 7.x or Amazon Linux 2\", type=\"sh\" %} [wallarm-node] baseurl= http://repo.wallarm.com/centos/wallarm-node/7/$basearch \u00b6 baseurl= http://repo.wallarm.com/centos/wallarm-node/7/2.14/$basearch {% endcodetabs %}","title":"Add repos rpm"},{"location":"en/include-en/migration-212-214/add-repos-rpm/#baseurlhttprepowallarmcomcentoswallarm-node6basearch","text":"baseurl= http://repo.wallarm.com/centos/wallarm-node/6/2.14/$basearch {% language name=\"CentOS 7.x or Amazon Linux 2\", type=\"sh\" %} [wallarm-node]","title":"baseurl=http://repo.wallarm.com/centos/wallarm-node/6/$basearch"},{"location":"en/include-en/migration-212-214/add-repos-rpm/#baseurlhttprepowallarmcomcentoswallarm-node7basearch","text":"baseurl= http://repo.wallarm.com/centos/wallarm-node/7/2.14/$basearch {% endcodetabs %}","title":"baseurl=http://repo.wallarm.com/centos/wallarm-node/7/$basearch"},{"location":"en/include-en/migration-212-214/install-module-addon/","text":"{% termtabs name=\"Debian or Ubuntu\" %} apt-get install wallarm-node-nginx --no-install-recommends \u00b6 {% tab name=\"CentOS or Amazon Linux 2\" %} yum upgrade wallarm-node-nginx \u00b6 {% endtermtabs %}","title":"Install module addon"},{"location":"en/include-en/migration-212-214/install-module-addon/#apt-get-install-wallarm-node-nginx-no-install-recommends","text":"{% tab name=\"CentOS or Amazon Linux 2\" %}","title":"apt-get install wallarm-node-nginx --no-install-recommends"},{"location":"en/include-en/migration-212-214/install-module-addon/#yum-upgrade-wallarm-node-nginx","text":"{% endtermtabs %}","title":"yum upgrade wallarm-node-nginx"},{"location":"en/include-en/migration-212-214/install-module-postanalytics/","text":"{% termtabs name=\"Debian or Ubuntu\" %} apt-get install wallarm-node-tarantool --no-install-recommends \u00b6 {% tab name=\"CentOS or Amazon Linux 2\" %} yum upgrade wallarm-node-tarantool \u00b6 {% endtermtabs %}","title":"Install module postanalytics"},{"location":"en/include-en/migration-212-214/install-module-postanalytics/#apt-get-install-wallarm-node-tarantool-no-install-recommends","text":"{% tab name=\"CentOS or Amazon Linux 2\" %}","title":"apt-get install wallarm-node-tarantool --no-install-recommends"},{"location":"en/include-en/migration-212-214/install-module-postanalytics/#yum-upgrade-wallarm-node-tarantool","text":"{% endtermtabs %}","title":"yum upgrade wallarm-node-tarantool"},{"location":"en/include-en/migration-212-214/install-modules-all/","text":"{% termtabs name=\"Debian or Ubuntu\" %} apt-get install wallarm-node --no-install-recommends \u00b6 {% tab name=\"CentOS or Amazon Linux 2\" %} yum upgrade wallarm-node \u00b6 {% endtermtabs %}","title":"Install modules all"},{"location":"en/include-en/migration-212-214/install-modules-all/#apt-get-install-wallarm-node-no-install-recommends","text":"{% tab name=\"CentOS or Amazon Linux 2\" %}","title":"apt-get install wallarm-node --no-install-recommends"},{"location":"en/include-en/migration-212-214/install-modules-all/#yum-upgrade-wallarm-node","text":"{% endtermtabs %}","title":"yum upgrade wallarm-node"},{"location":"en/include-en/migration-212-214/restart-services/","text":"{% termtabs name=\"CentOS 6.x or Ubuntu 14.04\" %} service nginx restart \u00b6 {% tab name=\"Other supported OS distributive\" %} systemctl restart nginx \u00b6 {% endtermtabs %}","title":"Restart services"},{"location":"en/include-en/migration-212-214/restart-services/#service-nginx-restart","text":"{% tab name=\"Other supported OS distributive\" %}","title":"service nginx restart"},{"location":"en/include-en/migration-212-214/restart-services/#systemctl-restart-nginx","text":"{% endtermtabs %}","title":"systemctl restart nginx"},{"location":"en/include-en/monitoring/collectd-config-location/","text":"{%- codetabs name=\"DEB-based distributions\", type=\"text\" -%} /etc/collectd/collectd.conf.d/nginx-wallarm.conf {%- language name=\"RPM-based distributions\", type=\"text\" -%} /etc/collectd.d/nginx-wallarm.conf {%- endcodetabs -%}","title":"Collectd config location"},{"location":"en/include-en/monitoring/collectd-nagios-fetch-metric/","text":"{%- codetabs name=\"Linux\", type=\"text\" -%} /usr/bin/collectd-nagios -s /var/run/collectd-unixsock -n -H \u00b6 {%- language name=\"Docker\", type=\"text\" -%} docker exec /usr/bin/collectd-nagios -s /var/run/collectd-unixsock -n -H \u00b6 {%- endcodetabs -%}","title":"Collectd nagios fetch metric"},{"location":"en/include-en/monitoring/collectd-nagios-fetch-metric/#usrbincollectd-nagios-s-varruncollectd-unixsock-n-h","text":"{%- language name=\"Docker\", type=\"text\" -%}","title":"/usr/bin/collectd-nagios -s /var/run/collectd-unixsock -n  -H "},{"location":"en/include-en/monitoring/collectd-nagios-fetch-metric/#docker-exec-usrbincollectd-nagios-s-varruncollectd-unixsock-n-h","text":"{%- endcodetabs -%}","title":"docker exec  /usr/bin/collectd-nagios -s /var/run/collectd-unixsock -n  -H "},{"location":"en/include-en/monitoring/collectd-restart/","text":"{%- termtabs name=\"CentOS 6.x or Ubuntu 14.04 LTS\" -%} service collectd restart \u00b6 {%- tab name=\"Other supported distributions\" -%} systemctl restart collectd \u00b6 {%- endtermtabs -%}","title":"Collectd restart"},{"location":"en/include-en/monitoring/collectd-restart/#service-collectd-restart","text":"{%- tab name=\"Other supported distributions\" -%}","title":"service collectd restart"},{"location":"en/include-en/monitoring/collectd-restart/#systemctl-restart-collectd","text":"{%- endtermtabs -%}","title":"systemctl restart collectd"},{"location":"en/include-en/monitoring/docker-prerequisites/","text":"#### Info:: Prerequisites It is assumed that * [Docker Community Edition](https://docs.docker.com/install/) and [`docker-compose`](https://docs.docker.com/compose/install/) are already installed on the `10.0.30.30` Docker host. * The `node.example.local` filter node is already deployed, configured, available for further configuration (for example, via the SSH protocol), and working.","title":"Docker prerequisites"},{"location":"en/include-en/monitoring/install-collectd-utils/","text":"{% termtabs name=\"DEB-based distributions\" %} apt install --no-install-recommends collectd-utils \u00b6 {%- tab name=\"RPM-based distributions\" -%} yum install collectd-utils \u00b6 {% endtermtabs %}","title":"Install collectd utils"},{"location":"en/include-en/monitoring/install-collectd-utils/#apt-install-no-install-recommends-collectd-utils","text":"{%- tab name=\"RPM-based distributions\" -%}","title":"apt install --no-install-recommends collectd-utils"},{"location":"en/include-en/monitoring/install-collectd-utils/#yum-install-collectd-utils","text":"{% endtermtabs %}","title":"yum install collectd-utils"},{"location":"en/include-en/monitoring/install-zabbix-agent/","text":"{% termtabs name=\"DEB-based distributions\" %} apt install zabbix-agent \u00b6 {%- tab name=\"RPM-based distributions\" -%} yum install zabbix-agent \u00b6 {% endtermtabs %}","title":"Install zabbix agent"},{"location":"en/include-en/monitoring/install-zabbix-agent/#apt-install-zabbix-agent","text":"{%- tab name=\"RPM-based distributions\" -%}","title":"apt install zabbix-agent"},{"location":"en/include-en/monitoring/install-zabbix-agent/#yum-install-zabbix-agent","text":"{% endtermtabs %}","title":"yum install zabbix-agent"},{"location":"en/include-en/monitoring/metric-example/","text":"#### Info:: Example of metric This example shows how to work with the single [`curl_json-wallarm_nginx/gauge-attacks`](../../admin-en/monitoring/available-metrics.md#number-of-attacks-reported) metric, which shows the number of attacks on an application that is protected by the filter node.","title":"Metric example"},{"location":"en/include-en/monitoring/nagios-restart/","text":"{% termtabs name=\"CentOS 6 and Ubuntu 14.04\" -%} service nagios restart \u00b6 {%- tab name=\"Other supported distributions\" -%} systemctl restart nagios \u00b6 {%- endtermtabs %}","title":"Nagios restart"},{"location":"en/include-en/monitoring/nagios-restart/#service-nagios-restart","text":"{%- tab name=\"Other supported distributions\" -%}","title":"service nagios restart"},{"location":"en/include-en/monitoring/nagios-restart/#systemctl-restart-nagios","text":"{%- endtermtabs %}","title":"systemctl restart nagios"},{"location":"en/include-en/monitoring/notification-config-location/","text":"{%- codetabs name=\"DEB-based distributions\" -%} /etc/collectd/conf.d/traps.conf {%- language name=\"RPM-based distributions\" -%} /etc/collectd.d/traps.conf {%- endcodetabs -%}","title":"Notification config location"},{"location":"en/include-en/monitoring/nrpe-restart/","text":"{% termtabs name=\"CentOS 6 and Ubuntu 14.04\" -%} service nrpe restart \u00b6 {%- tab name=\"Other supported distributions\" -%} systemctl restart nrpe \u00b6 {%- endtermtabs %}","title":"Nrpe restart"},{"location":"en/include-en/monitoring/nrpe-restart/#service-nrpe-restart","text":"{%- tab name=\"Other supported distributions\" -%}","title":"service nrpe restart"},{"location":"en/include-en/monitoring/nrpe-restart/#systemctl-restart-nrpe","text":"{%- endtermtabs %}","title":"systemctl restart nrpe"},{"location":"en/include-en/monitoring/sample-malicious-request/","text":"#### Info:: Example ``` curl -I \u201chttp://node.example.local/?id='or+1=1--a-<script>prompt(1)</script>\u201d ```","title":"Sample malicious request"},{"location":"en/include-en/monitoring/tarantool-config-location/","text":"{%- codetabs name=\"DEB-based distributions\" -%} /etc/collectd/collectd.conf.d/wallarm-tarantool.conf {%- language name=\"RPM-based distributions\" -%} /etc/collectd.d/wallarm-tarantool.conf {%- endcodetabs -%}","title":"Tarantool config location"},{"location":"en/include-en/monitoring/wallarm-status-check-padded/","text":"<br> 1. Execute the `curl http://127.0.0.8/wallarm-status` command if the default configuration of the statistics service is in use. 2. Otherwise, see the `/etc/nginx/conf.d/wallarm-status.conf` configuration file to construct the correct command similar to the one above. ``` {\"requests\":0,\"attacks\":0,\"blocked\":0,\"abnormal\":0,\"tnt_errors\":0,\"api_errors\":0,\"requests_lost\":0,\"segfaults\":0,\"memfaults\":0,\"softmemfaults\":0,\"time_detect\":0,\"db_id\":46,\"lom_id\":4,\"proton_instances\": { \"total\":2,\"success\":2,\"fallback\":0,\"failed\":0 },\"stalled_workers_count\":0,\"stalled_workers\":[] } ```","title":"Wallarm status check padded"},{"location":"en/include-en/monitoring/wallarm-status-check/","text":"<br> 1. Execute the `curl http://127.0.0.8/wallarm-status` command if the default configuration of the statistics service is in use. 2. Otherwise, see the `/etc/nginx/conf.d/wallarm-status.conf` configuration file to construct the correct command similar to the one above. ``` {\"requests\":0,\"attacks\":0,\"blocked\":0,\"abnormal\":0,\"tnt_errors\":0,\"api_errors\":0,\"requests_lost\":0,\"segfaults\":0,\"memfaults\":0,\"softmemfaults\":0,\"time_detect\":0,\"db_id\":46,\"lom_id\":4,\"proton_instances\": { \"total\":2,\"success\":2,\"fallback\":0,\"failed\":0 },\"stalled_workers_count\":0,\"stalled_workers\":[] } ```","title":"Wallarm status check"},{"location":"en/include-en/monitoring/wallarm-status-output-padded/","text":"``` {\"requests\":64,\"attacks\":16,\"blocked\":0,\"abnormal\":64,\"tnt_errors\":0,\"api_errors\":0,\"requests_lost\":0,\"segfaults\":0,\"memfaults\":0,\"softmemfaults\":0,\"time_detect\":0,\"db_id\":46,\"lom_id\":4,\"proton_instances\": { \"total\":2,\"success\":2,\"fallback\":0,\"failed\":0 },\"stalled_workers_count\":0,\"stalled_workers\":[] } ```","title":"Wallarm status output padded"},{"location":"en/include-en/monitoring/wallarm-status-output/","text":"``` {\"requests\":64,\"attacks\":16,\"blocked\":0,\"abnormal\":64,\"tnt_errors\":0,\"api_errors\":0,\"requests_lost\":0,\"segfaults\":0,\"memfaults\":0,\"softmemfaults\":0,\"time_detect\":0,\"db_id\":46,\"lom_id\":4,\"proton_instances\": { \"total\":2,\"success\":2,\"fallback\":0,\"failed\":0 },\"stalled_workers_count\":0,\"stalled_workers\":[] } ```","title":"Wallarm status output"},{"location":"en/include-en/monitoring/zabbix-agent-restart/","text":"{% termtabs name=\"CentOS 6 and Ubuntu 14.04\" -%} service zabbix-agent restart \u00b6 {%- tab name=\"Other supported distributions\" -%} systemctl restart zabbix-agent \u00b6 {%- endtermtabs %}","title":"Zabbix agent restart"},{"location":"en/include-en/monitoring/zabbix-agent-restart/#service-zabbix-agent-restart","text":"{%- tab name=\"Other supported distributions\" -%}","title":"service zabbix-agent restart"},{"location":"en/include-en/monitoring/zabbix-agent-restart/#systemctl-restart-zabbix-agent","text":"{%- endtermtabs %}","title":"systemctl restart zabbix-agent"},{"location":"en/partner-en/partner-create-tenant-en/","text":"Creating a Tenant \u00b6 Prerequisites \u00b6 Ensure the following: You have a vendor account with Wallarm. You have your user UUID and secret key. You have your vendor UUID. To create a tenant, you must: Create a tenant through Wallarm API. Tie the created tenant to you vendor account. 1. Create a Tenant \u00b6 Issue the following cURL-request: Info Run the command appropriate to the cloud you are using. * If you are using https://my.wallarm.com/ , run the command from the \u00abEU Cloud\u00bb tab below. * If you are using https://us1.my.wallarm.com , run the command from the \u00abUS Cloud\u00bb tab below. {% termtabs name=\"EU Cloud\" -%} curl -X POST --header \"Content-Type: application/json\" --header \"Accept: application/json\" --header \"X-WallarmAPI-UUID: YOUR-USER-UUID\" --header \"X-WallarmAPI-Secret: YOUR-SECRET-KEY\" -d \"{ \u00b6 \\\"name\\\": \\\"TENANT-NAME\\\", \\\"vuln_prefix\\\": \\\"VULNERABILITY-PREFIX\\\", \\\"language\\\": \\\"en\\\", \\\"enabled\\\": true, \\\"notifications\\\": {}, \\\"mode\\\": \\\"monitoring\\\", \\\"blocking_type\\\": \\\"incidents\\\", \\\"qrator_blacklists\\\": false, \\\"scanner_mode\\\": \\\"off\\\", \\\"partner_uuid\\\": \\\"YOUR-VENDOR-UUID\\\", \\\"qrator_mode\\\": \\\"async\\\", \\\"scanner_state\\\": {} }\" \" https://api.wallarm.com/v1/objects/client/create \" {%- tab name=\"US Cloud\" -%} curl -X POST --header \"Content-Type: application/json\" --header \"Accept: application/json\" --header \"X-WallarmAPI-UUID: YOUR-USER-UUID\" --header \"X-WallarmAPI-Secret: YOUR-SECRET-KEY\" -d \"{ \u00b6 \\\"name\\\": \\\"TENANT-NAME\\\", \\\"vuln_prefix\\\": \\\"VULNERABILITY-PREFIX\\\", \\\"language\\\": \\\"en\\\", \\\"enabled\\\": true, \\\"notifications\\\": {}, \\\"mode\\\": \\\"monitoring\\\", \\\"blocking_type\\\": \\\"incidents\\\", \\\"qrator_blacklists\\\": false, \\\"scanner_mode\\\": \\\"off\\\", \\\"partner_uuid\\\": \\\"YOUR-VENDOR-UUID\\\", \\\"qrator_mode\\\": \\\"async\\\", \\\"scanner_state\\\": {} }\" \" https://us1.api.wallarm.com/v1/objects/client/create \" {%- endtermtabs %} where: X-WallarmAPI-UUID: is your user UUID. X-WallarmAPI-Secret: is your secret key. \"name\": is the name of the tenant. \"vuln_prefix\": is the vulnerability prefix that Wallarm will use for vulnerability tracking and association. This field must contain four letters and/or numbers. Base the prefix on the tenant name for easier identification. For example, if the tenant name is \"Tenant\", name the prefix \"TNNT\". \"language\": is language if your Wallarm web-interface. Set this to en . \"partner_uuid\": is your vendor UUID. See also POST /v1/objects/client/create in the Wallarm API . Check the output: 200 \u2013 The operation is successful. 403 \u2013 The authorization operation failed. Ensure you have provided the correct user UUID, secret key, and vendor UUID. 400 \u2013 The operation failed. The most likely cause is that one of the parameters is missing, or your JSON syntax is incorrect. Ensure that all parameters are set correctly. Copy the following values from the output: \"id\": \"partnerid\": You will need these values to tie the tenant to your vendor account. You have now created your tenant. 2. Tie the Tenant to Your Vendor Account \u00b6 Issue the following cURL-request: Info Run the command appropriate to the cloud you are using. * If you are using https://my.wallarm.com/ , run the command from the \u00abEU Cloud\u00bb tab below. * If you are using https://us1.my.wallarm.com , run the command from the \u00abUS Cloud\u00bb tab below. {% termtabs name=\"EU Cloud\" -%} curl -X POST --header \"Content-Type: application/json\" --header \"Accept: application/json\" --header \"X-WallarmAPI-UUID: YOUR-USER-UUID\" --header \"X-WallarmAPI-Secret: YOUR-SECRET-KEY\" -d \"{ \u00b6 \\\"clientid\\\": CLIENT-ID, \\\"id\\\": NUMBER, \\\"params\\\": {} }\" \" https://api.wallarm.com/v2/partner/{PARTNER-ID}/partner_client \" {%- tab name=\"US Cloud\" -%} curl -X POST --header \"Content-Type: application/json\" --header \"Accept: application/json\" --header \"X-WallarmAPI-UUID: YOUR-USER-UUID\" --header \"X-WallarmAPI-Secret: YOUR-SECRET-KEY\" -d \"{ \u00b6 \\\"clientid\\\": CLIENT-ID, \\\"id\\\": NUMBER, \\\"params\\\": {} }\" \" https://us1.api.wallarm.com/v2/partner/{PARTNER-ID}/partner_client \" {%- endtermtabs %} where: X-WallarmAPI-UUID: is your user UUID. X-WallarmAPI-Secret: is your secret key. \"clientid\": is the \"id\": value that you copied at the end of tenant creation in Step 2. \"id\": is any number that you will use to identify and configure your tenant. Set any number make sure you and copy it for later use. {PARTNER-ID} is the partner ID value that you copied from \"partnerid\": in Step 3. See also POST/v2/partner/{partnerid}/partner_client in the Wallarm API . Check the Response Code field: 200 \u2013 The operation is successful. 403 \u2013 The autorization operation failed. Ensure you have provided the correct user UUID, secret key, and vendor UUID. 400 \u2013 The operation failed. The most likely cause is that one of the parameters is missing or your JSON syntax is incorrect. Ensure you have all the parameters set correctly. You have now tied the tenant to your vendor account. See next Setting up the tenant","title":"Creating a Tenant"},{"location":"en/partner-en/partner-create-tenant-en/#creating-a-tenant","text":"","title":"Creating a Tenant"},{"location":"en/partner-en/partner-create-tenant-en/#prerequisites","text":"Ensure the following: You have a vendor account with Wallarm. You have your user UUID and secret key. You have your vendor UUID. To create a tenant, you must: Create a tenant through Wallarm API. Tie the created tenant to you vendor account.","title":"Prerequisites"},{"location":"en/partner-en/partner-create-tenant-en/#1-create-a-tenant","text":"Issue the following cURL-request: Info Run the command appropriate to the cloud you are using. * If you are using https://my.wallarm.com/ , run the command from the \u00abEU Cloud\u00bb tab below. * If you are using https://us1.my.wallarm.com , run the command from the \u00abUS Cloud\u00bb tab below. {% termtabs name=\"EU Cloud\" -%}","title":"1. Create a Tenant"},{"location":"en/partner-en/partner-create-tenant-en/#curl-x-post-header-content-type-applicationjson-header-accept-applicationjson-header-x-wallarmapi-uuid-your-user-uuid-header-x-wallarmapi-secret-your-secret-key-d","text":"\\\"name\\\": \\\"TENANT-NAME\\\", \\\"vuln_prefix\\\": \\\"VULNERABILITY-PREFIX\\\", \\\"language\\\": \\\"en\\\", \\\"enabled\\\": true, \\\"notifications\\\": {}, \\\"mode\\\": \\\"monitoring\\\", \\\"blocking_type\\\": \\\"incidents\\\", \\\"qrator_blacklists\\\": false, \\\"scanner_mode\\\": \\\"off\\\", \\\"partner_uuid\\\": \\\"YOUR-VENDOR-UUID\\\", \\\"qrator_mode\\\": \\\"async\\\", \\\"scanner_state\\\": {} }\" \" https://api.wallarm.com/v1/objects/client/create \" {%- tab name=\"US Cloud\" -%}","title":"curl -X POST --header \"Content-Type: application/json\" --header \"Accept: application/json\" --header \"X-WallarmAPI-UUID: YOUR-USER-UUID\" --header \"X-WallarmAPI-Secret: YOUR-SECRET-KEY\" -d \"{"},{"location":"en/partner-en/partner-create-tenant-en/#curl-x-post-header-content-type-applicationjson-header-accept-applicationjson-header-x-wallarmapi-uuid-your-user-uuid-header-x-wallarmapi-secret-your-secret-key-d_1","text":"\\\"name\\\": \\\"TENANT-NAME\\\", \\\"vuln_prefix\\\": \\\"VULNERABILITY-PREFIX\\\", \\\"language\\\": \\\"en\\\", \\\"enabled\\\": true, \\\"notifications\\\": {}, \\\"mode\\\": \\\"monitoring\\\", \\\"blocking_type\\\": \\\"incidents\\\", \\\"qrator_blacklists\\\": false, \\\"scanner_mode\\\": \\\"off\\\", \\\"partner_uuid\\\": \\\"YOUR-VENDOR-UUID\\\", \\\"qrator_mode\\\": \\\"async\\\", \\\"scanner_state\\\": {} }\" \" https://us1.api.wallarm.com/v1/objects/client/create \" {%- endtermtabs %} where: X-WallarmAPI-UUID: is your user UUID. X-WallarmAPI-Secret: is your secret key. \"name\": is the name of the tenant. \"vuln_prefix\": is the vulnerability prefix that Wallarm will use for vulnerability tracking and association. This field must contain four letters and/or numbers. Base the prefix on the tenant name for easier identification. For example, if the tenant name is \"Tenant\", name the prefix \"TNNT\". \"language\": is language if your Wallarm web-interface. Set this to en . \"partner_uuid\": is your vendor UUID. See also POST /v1/objects/client/create in the Wallarm API . Check the output: 200 \u2013 The operation is successful. 403 \u2013 The authorization operation failed. Ensure you have provided the correct user UUID, secret key, and vendor UUID. 400 \u2013 The operation failed. The most likely cause is that one of the parameters is missing, or your JSON syntax is incorrect. Ensure that all parameters are set correctly. Copy the following values from the output: \"id\": \"partnerid\": You will need these values to tie the tenant to your vendor account. You have now created your tenant.","title":"curl -X POST --header \"Content-Type: application/json\" --header \"Accept: application/json\" --header \"X-WallarmAPI-UUID: YOUR-USER-UUID\" --header \"X-WallarmAPI-Secret: YOUR-SECRET-KEY\" -d \"{"},{"location":"en/partner-en/partner-create-tenant-en/#2-tie-the-tenant-to-your-vendor-account","text":"Issue the following cURL-request: Info Run the command appropriate to the cloud you are using. * If you are using https://my.wallarm.com/ , run the command from the \u00abEU Cloud\u00bb tab below. * If you are using https://us1.my.wallarm.com , run the command from the \u00abUS Cloud\u00bb tab below. {% termtabs name=\"EU Cloud\" -%}","title":"2. Tie the Tenant to Your Vendor Account"},{"location":"en/partner-en/partner-create-tenant-en/#curl-x-post-header-content-type-applicationjson-header-accept-applicationjson-header-x-wallarmapi-uuid-your-user-uuid-header-x-wallarmapi-secret-your-secret-key-d_2","text":"\\\"clientid\\\": CLIENT-ID, \\\"id\\\": NUMBER, \\\"params\\\": {} }\" \" https://api.wallarm.com/v2/partner/{PARTNER-ID}/partner_client \" {%- tab name=\"US Cloud\" -%}","title":"curl -X POST --header \"Content-Type: application/json\" --header \"Accept: application/json\" --header \"X-WallarmAPI-UUID: YOUR-USER-UUID\" --header \"X-WallarmAPI-Secret: YOUR-SECRET-KEY\" -d \"{"},{"location":"en/partner-en/partner-create-tenant-en/#curl-x-post-header-content-type-applicationjson-header-accept-applicationjson-header-x-wallarmapi-uuid-your-user-uuid-header-x-wallarmapi-secret-your-secret-key-d_3","text":"\\\"clientid\\\": CLIENT-ID, \\\"id\\\": NUMBER, \\\"params\\\": {} }\" \" https://us1.api.wallarm.com/v2/partner/{PARTNER-ID}/partner_client \" {%- endtermtabs %} where: X-WallarmAPI-UUID: is your user UUID. X-WallarmAPI-Secret: is your secret key. \"clientid\": is the \"id\": value that you copied at the end of tenant creation in Step 2. \"id\": is any number that you will use to identify and configure your tenant. Set any number make sure you and copy it for later use. {PARTNER-ID} is the partner ID value that you copied from \"partnerid\": in Step 3. See also POST/v2/partner/{partnerid}/partner_client in the Wallarm API . Check the Response Code field: 200 \u2013 The operation is successful. 403 \u2013 The autorization operation failed. Ensure you have provided the correct user UUID, secret key, and vendor UUID. 400 \u2013 The operation failed. The most likely cause is that one of the parameters is missing or your JSON syntax is incorrect. Ensure you have all the parameters set correctly. You have now tied the tenant to your vendor account. See next Setting up the tenant","title":"curl -X POST --header \"Content-Type: application/json\" --header \"Accept: application/json\" --header \"X-WallarmAPI-UUID: YOUR-USER-UUID\" --header \"X-WallarmAPI-Secret: YOUR-SECRET-KEY\" -d \"{"},{"location":"en/partner-en/partner-install-en/","text":"Installing the Filter Node \u00b6 Depending on your system, see one of the following sections: Installing as a dynamic module for NGINX Installing on Linux Deploying with Docker Installing with NGINX Plus Installing with Kong Deploying as an Amazon Machine Image Warning:: Switch the filter node to the vendor status \u00b6 After installing the filter node, contact Wallarm support to switch the filter node to the status \"vendor\". See next Creating a tenant","title":"Installing the Filter Node"},{"location":"en/partner-en/partner-install-en/#installing-the-filter-node","text":"Depending on your system, see one of the following sections: Installing as a dynamic module for NGINX Installing on Linux Deploying with Docker Installing with NGINX Plus Installing with Kong Deploying as an Amazon Machine Image","title":"Installing the Filter Node"},{"location":"en/partner-en/partner-install-en/#warning-switch-the-filter-node-to-the-vendor-status","text":"After installing the filter node, contact Wallarm support to switch the filter node to the status \"vendor\". See next Creating a tenant","title":"Warning:: Switch the filter node to the vendor status"},{"location":"en/partner-en/partner-intro-en/","text":"Introduction \u00b6 Wallarm is a multi-tenant system that lets vendors provide their tenants with the Wallarm solution. With the vendor account you can create independent accounts for your tenants and control them. This guide walks you through the process of creating a vendor account within the Wallarm system and setting up your tenants through cURL. The process consists of the following steps: Sign up with Wallarm and get your license key. See Signing up with Wallarm . Get your user UUID, secret key, and vendor UUID from Wallarm. See Getting your UUID and secret key . Install the filter node. See Installing the filter node . Create your tenant. See Creating a tenant . Set up your tenant. See Setting up the tenant . See next Signing up with Wallarm","title":"Introduction"},{"location":"en/partner-en/partner-intro-en/#introduction","text":"Wallarm is a multi-tenant system that lets vendors provide their tenants with the Wallarm solution. With the vendor account you can create independent accounts for your tenants and control them. This guide walks you through the process of creating a vendor account within the Wallarm system and setting up your tenants through cURL. The process consists of the following steps: Sign up with Wallarm and get your license key. See Signing up with Wallarm . Get your user UUID, secret key, and vendor UUID from Wallarm. See Getting your UUID and secret key . Install the filter node. See Installing the filter node . Create your tenant. See Creating a tenant . Set up your tenant. See Setting up the tenant . See next Signing up with Wallarm","title":"Introduction"},{"location":"en/partner-en/partner-set-tenant-en/","text":"Configuring Traffic Processing \u00b6 Prerequisites \u00b6 Ensure the following: You have created and tied the tenant as described in Creating a tenant . You have the tenant ID that you copied at the very end of Creating a tenant . Wallarm support has switched your filter node status to \"vendor\". To set up the tenant, you must: Put the tenant ID in the tenant's configuration file. Configure traffic processing in the tenant's configuration file. 1. Put the Tenant ID in the Tenant's Configuration File \u00b6 Open for editing the tenant's NGINX configuration file that processes the tenant's traffic. Add the wallarm_instance string and set the tenant ID. An edited configuration file sample with the tenant ID set to 78: Wallarm module specific parameters ... wallarm_fallback on; wallarm_cache_path /var/cache/nginx/wallarm wallarm_instance 78; You have now set the tenant ID in the configuration file. 2. Configure Traffic Processing in the Tenant's Configuration File \u00b6 Open for editing the tenant's NGINX configuration file that processes the tenant's traffic and has the wallarm_instance string. Configure traffic processing as described in the NGINX official documentation . An edited configuration file sample: location / { proxy_pass http://78.78.78.78; proxy_set_header Host $host; proxy_set_header X-Real-IP $remote_addr; proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for; proxy_set_header X-Forwarded-Proto https; include proxy_params; wallarm_instance 78; } You have now completed the tenant setup.","title":"Configuring Traffic Processing"},{"location":"en/partner-en/partner-set-tenant-en/#configuring-traffic-processing","text":"","title":"Configuring Traffic Processing"},{"location":"en/partner-en/partner-set-tenant-en/#prerequisites","text":"Ensure the following: You have created and tied the tenant as described in Creating a tenant . You have the tenant ID that you copied at the very end of Creating a tenant . Wallarm support has switched your filter node status to \"vendor\". To set up the tenant, you must: Put the tenant ID in the tenant's configuration file. Configure traffic processing in the tenant's configuration file.","title":"Prerequisites"},{"location":"en/partner-en/partner-set-tenant-en/#1-put-the-tenant-id-in-the-tenants-configuration-file","text":"Open for editing the tenant's NGINX configuration file that processes the tenant's traffic. Add the wallarm_instance string and set the tenant ID. An edited configuration file sample with the tenant ID set to 78: Wallarm module specific parameters ... wallarm_fallback on; wallarm_cache_path /var/cache/nginx/wallarm wallarm_instance 78; You have now set the tenant ID in the configuration file.","title":"1. Put the Tenant ID in the Tenant's Configuration File"},{"location":"en/partner-en/partner-set-tenant-en/#2-configure-traffic-processing-in-the-tenants-configuration-file","text":"Open for editing the tenant's NGINX configuration file that processes the tenant's traffic and has the wallarm_instance string. Configure traffic processing as described in the NGINX official documentation . An edited configuration file sample: location / { proxy_pass http://78.78.78.78; proxy_set_header Host $host; proxy_set_header X-Real-IP $remote_addr; proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for; proxy_set_header X-Forwarded-Proto https; include proxy_params; wallarm_instance 78; } You have now completed the tenant setup.","title":"2. Configure Traffic Processing in the Tenant's Configuration File"},{"location":"en/partner-en/partner-signup-en/","text":"Signing up with Wallarm \u00b6 1. Create Your Wallarm Account \u00b6 Go to the EU or US cloud to sign up . Enter the required data. !!! info \"Business email You can only sign up with a business email. Click Sign up . 2. Confirm Your Email \u00b6 After the successful registration, you will receive and automatic email with a confirmation link. 3. Get the License Key \u00b6 After clicking the confirmation link, click Deploy node . You will receive an automatic email with your license key attached to the message. See next Getting your UUID and secret key","title":"Signing up with Wallarm"},{"location":"en/partner-en/partner-signup-en/#signing-up-with-wallarm","text":"","title":"Signing up with Wallarm"},{"location":"en/partner-en/partner-signup-en/#1-create-your-wallarm-account","text":"Go to the EU or US cloud to sign up . Enter the required data. !!! info \"Business email You can only sign up with a business email. Click Sign up .","title":"1. Create Your Wallarm Account"},{"location":"en/partner-en/partner-signup-en/#2-confirm-your-email","text":"After the successful registration, you will receive and automatic email with a confirmation link.","title":"2. Confirm Your Email"},{"location":"en/partner-en/partner-signup-en/#3-get-the-license-key","text":"After clicking the confirmation link, click Deploy node . You will receive an automatic email with your license key attached to the message. See next Getting your UUID and secret key","title":"3. Get the License Key"},{"location":"en/partner-en/partner-uuid-en/","text":"Getting your UUID and Secret Key \u00b6 After you sign up, contact Wallarm Support and request to switch your regular account to the vendor account. Once switched, Wallarm Support will provide you with the following: Your user UUID and secret key that you need to create tenants. Your vendor UUID that you need to tie tenants to you vendor account. See next Installing the filter node","title":"Getting your UUID and Secret Key"},{"location":"en/partner-en/partner-uuid-en/#getting-your-uuid-and-secret-key","text":"After you sign up, contact Wallarm Support and request to switch your regular account to the vendor account. Once switched, Wallarm Support will provide you with the following: Your user UUID and secret key that you need to create tenants. Your vendor UUID that you need to tie tenants to you vendor account. See next Installing the filter node","title":"Getting your UUID and Secret Key"},{"location":"en/quickstart-en/qs-check-operation-en/","text":"Checking the Filter Node Operation \u00b6 If everything is configured correctly, Wallarm filters the requests and proxies the filtered requests in accordance with the configuration file settings. To check the correct operation, you must: Execute the wallarm-status request. Run a test attack. 1. Execute the wallarm-status Request \u00b6 You can get filter node operation statistics by requesting the /wallarm-status URL. Run the command: curl http://127.0.0.8/wallarm-status The output will be like: { \"requests\" : 0 , \"attacks\" : 0 , \"blocked\" : 0 , \"abnormal\" : 0 , \"tnt_errors\" : 0 , \"api_errors\" : 0 , \"requests_lost\" : 0 , \"segfaults\" : 0 , \"memfaults\" : 0 , \"softmemfaults\" : 0 , \"time_detect\" : 0 , \"db_id\" : 46 , \"lom_id\" : 16767 , \"proton_instances\" :{ \"total\" : 1 , \"success\" : 1 , \"fallback\" : 0 , \"failed\" : 0 }, \"stalled_workers_count\" : 0 , \"stalled_workers\" :[] } This means that the filter node statistics service is running and working properly. The Statistics Service You can read more about the statistics service and how to configure it here . 2. Run a Test Attack \u00b6 To check if Wallarm correctly detects attacks, send an invalid request to the protected resource. For example: http://<resource_URL>/?id='or+1=1--a-<script>prompt(1)</script> Wallarm must detect in the request the following: SQLI XSS Now the counter of the number of attacks will increase when a request for wallarm-status is executed, which means that the filter node is operating normally. If the operation check is successful, the initial installation and setup is complete. See User guide .","title":"Check the Filter Node Operation"},{"location":"en/quickstart-en/qs-check-operation-en/#checking-the-filter-node-operation","text":"If everything is configured correctly, Wallarm filters the requests and proxies the filtered requests in accordance with the configuration file settings. To check the correct operation, you must: Execute the wallarm-status request. Run a test attack.","title":"Checking the Filter Node Operation"},{"location":"en/quickstart-en/qs-check-operation-en/#1-execute-the-wallarm-status-request","text":"You can get filter node operation statistics by requesting the /wallarm-status URL. Run the command: curl http://127.0.0.8/wallarm-status The output will be like: { \"requests\" : 0 , \"attacks\" : 0 , \"blocked\" : 0 , \"abnormal\" : 0 , \"tnt_errors\" : 0 , \"api_errors\" : 0 , \"requests_lost\" : 0 , \"segfaults\" : 0 , \"memfaults\" : 0 , \"softmemfaults\" : 0 , \"time_detect\" : 0 , \"db_id\" : 46 , \"lom_id\" : 16767 , \"proton_instances\" :{ \"total\" : 1 , \"success\" : 1 , \"fallback\" : 0 , \"failed\" : 0 }, \"stalled_workers_count\" : 0 , \"stalled_workers\" :[] } This means that the filter node statistics service is running and working properly. The Statistics Service You can read more about the statistics service and how to configure it here .","title":"1. Execute the wallarm-status Request"},{"location":"en/quickstart-en/qs-check-operation-en/#2-run-a-test-attack","text":"To check if Wallarm correctly detects attacks, send an invalid request to the protected resource. For example: http://<resource_URL>/?id='or+1=1--a-<script>prompt(1)</script> Wallarm must detect in the request the following: SQLI XSS Now the counter of the number of attacks will increase when a request for wallarm-status is executed, which means that the filter node is operating normally. If the operation check is successful, the initial installation and setup is complete. See User guide .","title":"2. Run a Test Attack"},{"location":"en/quickstart-en/qs-install-node-en/","text":"Installing the Filter Node \u00b6 Request processing Request processing by a filter node consists of the following phases: * Initial processing by the NGINX-Module-Wallarm * Postanalytics and the statistical analysis of the processed requests. This instruction describes the installation of the Wallarm filter node as a dynamic module for NGINX on the same server with postanalytics. To install the filter node, do the following: Install NGINX. Add the Wallarm repositories, from which you will download packages. Install the Wallarm packages. Configure postanalytics. Connect the Wallarm module. Connect the filter node to the Wallarm cloud. Prerequisites Prior to taking any steps listed below, either disable or configure SELinux if it is installed on the operating system. Make sure that you execute all commands below as superuser (e.g. root ). 1. Install NGINX \u00b6 Install NGINX from the official NGINX repositoriy by following the instruction that corresponds with your operating system from the list below. Ubuntu Debian CentOS Amazon Linux 2 : use the CentOS 7 instruction Stable NGINX version Make sure you are installing the stable version of NGINX. The mainline part of the path must be omitted from the NGINX repository link. 2. Add the Wallarm Repositories \u00b6 The filter node is installed and updated from the Wallarm repositories. Depending on your operating system, run one of the commands: Debian 8.x (jessie) apt-get install dirmngr apt-key adv --keyserver keys.gnupg.net --recv-keys 72B865FD sh -c \"echo 'deb http://repo.wallarm.com/debian/wallarm-node jessie/2.14/' > /etc/apt/sources.list.d/wallarm.list\" apt-get update Debian 9.x (stretch) apt-get install dirmngr apt-key adv --keyserver keys.gnupg.net --recv-keys 72B865FD sh -c \"echo 'deb http://repo.wallarm.com/debian/wallarm-node stretch/2.14/' > /etc/apt/sources.list.d/wallarm.list\" apt-get update Debian 10.x (buster) apt-get install dirmngr apt-key adv --keyserver keys.gnupg.net --recv-keys 72B865FD sh -c \"echo 'deb http://repo.wallarm.com/debian/wallarm-node buster/2.14/' > /etc/apt/sources.list.d/wallarm.list\" apt-get update Ubuntu 14.04 LTS (trusty) apt-key adv --keyserver keys.gnupg.net --recv-keys 72B865FD sh -c \"echo 'deb http://repo.wallarm.com/ubuntu/wallarm-node trusty/2.14/' > /etc/apt/sources.list.d/wallarm.list\" apt-get update Ubuntu 16.04 LTS (xenial) apt-key adv --keyserver keys.gnupg.net --recv-keys 72B865FD sh -c \"echo 'deb http://repo.wallarm.com/ubuntu/wallarm-node xenial/2.14/' > /etc/apt/sources.list.d/wallarm.list\" apt-get update Ubuntu 18.04 LTS (bionic) apt-key adv --keyserver keys.gnupg.net --recv-keys 72B865FD sh -c \"echo 'deb http://repo.wallarm.com/ubuntu/wallarm-node bionic/2.14/' > /etc/apt/sources.list.d/wallarm.list\" apt-get update ``` CentOS 6.x yum install --enablerepo = extras -y epel-release centos-release-SCL rpm -i https://repo.wallarm.com/centos/wallarm-node/6/2.14/x86_64/Packages/wallarm-node-repo-1-4.el6.noarch.rpm CentOS 7.x yum install -y epel-release rpm -i https://repo.wallarm.com/centos/wallarm-node/7/2.14/x86_64/Packages/wallarm-node-repo-1-4.el7.noarch.rpm ``` Amazon Linux 2 yum install -y https://dl.fedoraproject.org/pub/epel/epel-release-latest-7.noarch.rpm rpm -i https://repo.wallarm.com/centos/wallarm-node/7/2.14/x86_64/Packages/wallarm-node-repo-1-4.el7.noarch.rpm Repository access Your system must have access to https://repo.wallarm.com to download the packages. Ensure the access is not blocked by a firewall. 3. Install the Wallarm Packages \u00b6 Depending on your operating system, run one of the commands: Debian 8.x (jessie) apt-get install --no-install-recommends wallarm-node nginx-module-wallarm Debian 9.x (stretch) apt-get install --no-install-recommends wallarm-node nginx-module-wallarm Debian 10.x (buster) apt-get install --no-install-recommends wallarm-node nginx-module-wallarm Ubuntu 14.04 LTS (trusty) apt-get install --no-install-recommends wallarm-node nginx-module-wallarm Ubuntu 16.04 LTS (xenial) apt-get install --no-install-recommends wallarm-node nginx-module-wallarm Ubuntu 18.04 LTS (bionic) apt-get install --no-install-recommends wallarm-node nginx-module-wallarm CentOS 6.x yum install wallarm-node nginx-module-wallarm CentOS 7.x yum install wallarm-node nginx-module-wallarm Amazon Linux 2 yum install wallarm-node nginx-module-wallarm 4. Configure Postanalytics \u00b6 Postanalytics uses the Tarantool in-memory storage. You must set the amount of server RAM allocated to Tarantool. The amount of memory determines the quality of work of the statistical algorithms. The recommended value is 75% of the total server memory. For example, if the server has 32 GB of memory, the recommended allocation size is 24 GB. Allocate the operating memory size for Tarantool: Open for editing the configuration file of Tarantool: Debian 8.x (jessie) vi /etc/default/wallarm-tarantool Debian 9.x (stretch) vi /etc/default/wallarm-tarantool Debian 10.x (buster) vi /etc/default/wallarm-tarantool Ubuntu 14.04 LTS (trusty) vi /etc/default/wallarm-tarantool Ubuntu 16.04 LTS (xenial) vi /etc/default/wallarm-tarantool Ubuntu 18.04 LTS (bionic) vi /etc/default/wallarm-tarantool CentOS 6.x vi /etc/sysconfig/wallarm-tarantool CentOS 7.x vi /etc/sysconfig/wallarm-tarantool Amazon Linux 2 vi /etc/sysconfig/wallarm-tarantool Set the allocated memory size in the configuration file of Tarantool via the SLAB_ALLOC_ARENA directive. For example: SLAB_ALLOC_ARENA=24 Restart Tarantool: Debian 8.x (jessie) systemctl restart wallarm-tarantool Debian 9.x (stretch) systemctl restart wallarm-tarantool Debian 10.x (buster) systemctl restart wallarm-tarantool Ubuntu 14.04 LTS (trusty) service wallarm-tarantool restart Ubuntu 16.04 LTS (xenial) service wallarm-tarantool restart Ubuntu 18.04 LTS (bionic) service wallarm-tarantool restart CentOS 6.x service wallarm-tarantool restart CentOS 7.x systemctl restart wallarm-tarantool Amazon Linux 2 systemctl restart wallarm-tarantool 5. Connect the Wallarm Module \u00b6 Open the /etc/nginx/nginx.conf file. Ensure that you have the include /etc/nginx/conf.d/* line in the file. If you do not, add it. Add the following directive right after the worker_processes directive: load_module modules/ngx_http_wallarm_module.so; Configuration example with the added directive: user nginx; worker_processes auto; load_module modules/ngx_http_wallarm_module.so; error_log /var/log/nginx/error.log notice; pid /var/run/nginx.pid; Copy the configuration files for the system setup: cp /usr/share/doc/nginx-module-wallarm/examples/*.conf /etc/nginx/conf.d/ 6. Connect the Filter Node to the Wallarm Cloud \u00b6 API Access The API choice for your filter node depends on the Cloud you are using. Please, select the API accordingly: * If you are using https://my.wallarm.com/ , your node requires access to https://api.wallarm.com:444 . * If you are using https://us1.my.wallarm.com/ , your node requires access to https://us1.api.wallarm.com:444 . Ensure the access is not blocked by a firewall. The filter node interacts with the Wallarm cloud. To connect the node to the cloud using your cloud account requisites, proceed with the following steps: Make sure that your Wallarm account has the Administrator role enabled and two-factor authentication disabled, therefore allowing you to connect a filter node to the cloud. You can check the aforementioned parameters by navigating to the user account list in the Wallarm console. * If you are using <https://my.wallarm.com/>, proceed to the [following link][link-wl-console-users-eu] to check your user settings. * If you are using <https://us1.my.wallarm.com/>, proceed to the [following link][link-wl-console-users-us] to check your user settings. Run the addnode script in a system with the filter node: Info You have to pick the script to run depending on the Cloud you are using. * If you are using https://my.wallarm.com/ , run the script from the \u00abEU Cloud\u00bb tab below. * If you are using https://us1.my.wallarm.com/ , run the script from the \u00abUS Cloud\u00bb tab below. EU Cloud /usr/share/wallarm-common/addnode US Cloud /usr/share/wallarm-common/addnode -H us1.api.wallarm.com To specify the name of the created node, use the -n <node name> option. Provide your Wallarm account\u2019s login and password when prompted. Installation Completed \u00b6 The installation is completed. Now you need to configure the filter node to filter traffic. See Configure the Proxying and Filtering Rules .","title":"Install the Filter Node (NGINX)"},{"location":"en/quickstart-en/qs-install-node-en/#installing-the-filter-node","text":"Request processing Request processing by a filter node consists of the following phases: * Initial processing by the NGINX-Module-Wallarm * Postanalytics and the statistical analysis of the processed requests. This instruction describes the installation of the Wallarm filter node as a dynamic module for NGINX on the same server with postanalytics. To install the filter node, do the following: Install NGINX. Add the Wallarm repositories, from which you will download packages. Install the Wallarm packages. Configure postanalytics. Connect the Wallarm module. Connect the filter node to the Wallarm cloud. Prerequisites Prior to taking any steps listed below, either disable or configure SELinux if it is installed on the operating system. Make sure that you execute all commands below as superuser (e.g. root ).","title":"Installing the Filter Node"},{"location":"en/quickstart-en/qs-install-node-en/#1-install-nginx","text":"Install NGINX from the official NGINX repositoriy by following the instruction that corresponds with your operating system from the list below. Ubuntu Debian CentOS Amazon Linux 2 : use the CentOS 7 instruction Stable NGINX version Make sure you are installing the stable version of NGINX. The mainline part of the path must be omitted from the NGINX repository link.","title":"1. Install NGINX"},{"location":"en/quickstart-en/qs-install-node-en/#2-add-the-wallarm-repositories","text":"The filter node is installed and updated from the Wallarm repositories. Depending on your operating system, run one of the commands: Debian 8.x (jessie) apt-get install dirmngr apt-key adv --keyserver keys.gnupg.net --recv-keys 72B865FD sh -c \"echo 'deb http://repo.wallarm.com/debian/wallarm-node jessie/2.14/' > /etc/apt/sources.list.d/wallarm.list\" apt-get update Debian 9.x (stretch) apt-get install dirmngr apt-key adv --keyserver keys.gnupg.net --recv-keys 72B865FD sh -c \"echo 'deb http://repo.wallarm.com/debian/wallarm-node stretch/2.14/' > /etc/apt/sources.list.d/wallarm.list\" apt-get update Debian 10.x (buster) apt-get install dirmngr apt-key adv --keyserver keys.gnupg.net --recv-keys 72B865FD sh -c \"echo 'deb http://repo.wallarm.com/debian/wallarm-node buster/2.14/' > /etc/apt/sources.list.d/wallarm.list\" apt-get update Ubuntu 14.04 LTS (trusty) apt-key adv --keyserver keys.gnupg.net --recv-keys 72B865FD sh -c \"echo 'deb http://repo.wallarm.com/ubuntu/wallarm-node trusty/2.14/' > /etc/apt/sources.list.d/wallarm.list\" apt-get update Ubuntu 16.04 LTS (xenial) apt-key adv --keyserver keys.gnupg.net --recv-keys 72B865FD sh -c \"echo 'deb http://repo.wallarm.com/ubuntu/wallarm-node xenial/2.14/' > /etc/apt/sources.list.d/wallarm.list\" apt-get update Ubuntu 18.04 LTS (bionic) apt-key adv --keyserver keys.gnupg.net --recv-keys 72B865FD sh -c \"echo 'deb http://repo.wallarm.com/ubuntu/wallarm-node bionic/2.14/' > /etc/apt/sources.list.d/wallarm.list\" apt-get update ``` CentOS 6.x yum install --enablerepo = extras -y epel-release centos-release-SCL rpm -i https://repo.wallarm.com/centos/wallarm-node/6/2.14/x86_64/Packages/wallarm-node-repo-1-4.el6.noarch.rpm CentOS 7.x yum install -y epel-release rpm -i https://repo.wallarm.com/centos/wallarm-node/7/2.14/x86_64/Packages/wallarm-node-repo-1-4.el7.noarch.rpm ``` Amazon Linux 2 yum install -y https://dl.fedoraproject.org/pub/epel/epel-release-latest-7.noarch.rpm rpm -i https://repo.wallarm.com/centos/wallarm-node/7/2.14/x86_64/Packages/wallarm-node-repo-1-4.el7.noarch.rpm Repository access Your system must have access to https://repo.wallarm.com to download the packages. Ensure the access is not blocked by a firewall.","title":"2. Add the Wallarm Repositories"},{"location":"en/quickstart-en/qs-install-node-en/#3-install-the-wallarm-packages","text":"Depending on your operating system, run one of the commands: Debian 8.x (jessie) apt-get install --no-install-recommends wallarm-node nginx-module-wallarm Debian 9.x (stretch) apt-get install --no-install-recommends wallarm-node nginx-module-wallarm Debian 10.x (buster) apt-get install --no-install-recommends wallarm-node nginx-module-wallarm Ubuntu 14.04 LTS (trusty) apt-get install --no-install-recommends wallarm-node nginx-module-wallarm Ubuntu 16.04 LTS (xenial) apt-get install --no-install-recommends wallarm-node nginx-module-wallarm Ubuntu 18.04 LTS (bionic) apt-get install --no-install-recommends wallarm-node nginx-module-wallarm CentOS 6.x yum install wallarm-node nginx-module-wallarm CentOS 7.x yum install wallarm-node nginx-module-wallarm Amazon Linux 2 yum install wallarm-node nginx-module-wallarm","title":"3. Install the Wallarm Packages"},{"location":"en/quickstart-en/qs-install-node-en/#4-configure-postanalytics","text":"Postanalytics uses the Tarantool in-memory storage. You must set the amount of server RAM allocated to Tarantool. The amount of memory determines the quality of work of the statistical algorithms. The recommended value is 75% of the total server memory. For example, if the server has 32 GB of memory, the recommended allocation size is 24 GB. Allocate the operating memory size for Tarantool: Open for editing the configuration file of Tarantool: Debian 8.x (jessie) vi /etc/default/wallarm-tarantool Debian 9.x (stretch) vi /etc/default/wallarm-tarantool Debian 10.x (buster) vi /etc/default/wallarm-tarantool Ubuntu 14.04 LTS (trusty) vi /etc/default/wallarm-tarantool Ubuntu 16.04 LTS (xenial) vi /etc/default/wallarm-tarantool Ubuntu 18.04 LTS (bionic) vi /etc/default/wallarm-tarantool CentOS 6.x vi /etc/sysconfig/wallarm-tarantool CentOS 7.x vi /etc/sysconfig/wallarm-tarantool Amazon Linux 2 vi /etc/sysconfig/wallarm-tarantool Set the allocated memory size in the configuration file of Tarantool via the SLAB_ALLOC_ARENA directive. For example: SLAB_ALLOC_ARENA=24 Restart Tarantool: Debian 8.x (jessie) systemctl restart wallarm-tarantool Debian 9.x (stretch) systemctl restart wallarm-tarantool Debian 10.x (buster) systemctl restart wallarm-tarantool Ubuntu 14.04 LTS (trusty) service wallarm-tarantool restart Ubuntu 16.04 LTS (xenial) service wallarm-tarantool restart Ubuntu 18.04 LTS (bionic) service wallarm-tarantool restart CentOS 6.x service wallarm-tarantool restart CentOS 7.x systemctl restart wallarm-tarantool Amazon Linux 2 systemctl restart wallarm-tarantool","title":"4. Configure Postanalytics"},{"location":"en/quickstart-en/qs-install-node-en/#5-connect-the-wallarm-module","text":"Open the /etc/nginx/nginx.conf file. Ensure that you have the include /etc/nginx/conf.d/* line in the file. If you do not, add it. Add the following directive right after the worker_processes directive: load_module modules/ngx_http_wallarm_module.so; Configuration example with the added directive: user nginx; worker_processes auto; load_module modules/ngx_http_wallarm_module.so; error_log /var/log/nginx/error.log notice; pid /var/run/nginx.pid; Copy the configuration files for the system setup: cp /usr/share/doc/nginx-module-wallarm/examples/*.conf /etc/nginx/conf.d/","title":"5. Connect the Wallarm Module"},{"location":"en/quickstart-en/qs-install-node-en/#6-connect-the-filter-node-to-the-wallarm-cloud","text":"API Access The API choice for your filter node depends on the Cloud you are using. Please, select the API accordingly: * If you are using https://my.wallarm.com/ , your node requires access to https://api.wallarm.com:444 . * If you are using https://us1.my.wallarm.com/ , your node requires access to https://us1.api.wallarm.com:444 . Ensure the access is not blocked by a firewall. The filter node interacts with the Wallarm cloud. To connect the node to the cloud using your cloud account requisites, proceed with the following steps: Make sure that your Wallarm account has the Administrator role enabled and two-factor authentication disabled, therefore allowing you to connect a filter node to the cloud. You can check the aforementioned parameters by navigating to the user account list in the Wallarm console. * If you are using <https://my.wallarm.com/>, proceed to the [following link][link-wl-console-users-eu] to check your user settings. * If you are using <https://us1.my.wallarm.com/>, proceed to the [following link][link-wl-console-users-us] to check your user settings. Run the addnode script in a system with the filter node: Info You have to pick the script to run depending on the Cloud you are using. * If you are using https://my.wallarm.com/ , run the script from the \u00abEU Cloud\u00bb tab below. * If you are using https://us1.my.wallarm.com/ , run the script from the \u00abUS Cloud\u00bb tab below. EU Cloud /usr/share/wallarm-common/addnode US Cloud /usr/share/wallarm-common/addnode -H us1.api.wallarm.com To specify the name of the created node, use the -n <node name> option. Provide your Wallarm account\u2019s login and password when prompted.","title":"6. Connect the Filter Node to the Wallarm Cloud"},{"location":"en/quickstart-en/qs-install-node-en/#installation-completed","text":"The installation is completed. Now you need to configure the filter node to filter traffic. See Configure the Proxying and Filtering Rules .","title":"Installation Completed"},{"location":"en/quickstart-en/qs-intro-en/","text":"How Wallarm Works \u00b6 Wallarm is a DevOps-friendly Web Application Firewall (WAF) uniquely suited to protect your cloud applications and APIs. Wallarm's hybrid architecture safeguards your resources by offering: Protection from hacker attacks. Automatic detection of vulnerabilities . Wallarm analyzes all incoming HTTP requests and instantly blocks the malicious ones. Wallarm continuously collects metrics from the entire network traffic and processes the metrics by applying machine learning in the Wallarm cloud. Based on the processed requests, Wallarm creates an individual profile of the protected resources and applies the finely tuned security rules. The Wallarm scanner checks your company's network resources in several modes to detect vulnerabilities. Wallarm consists of the following components: The Wallarm filter node The Wallarm cloud Filter Node \u00b6 The network traffic check is done through the Wallarm filter node installed in the company's network infrastructure. The Wallarm filter node does the following: Blocks malicious requests and filters the valid ones Analyzes the company's entire network traffic Collects the network traffic metrics and uploads the metrics to the Wallarm cloud Downloads fine-tuned resource-specific rules from the Wallarm cloud Cloud \u00b6 The Wallarm cloud does the following: Processes the metrics that the filter node uploads Creates fine-tuned resource-specific rules Scans the company's protected resources to detect vulnerabilities Wallarm manages European and American cloud instances with each cloud being completely separate in terms of databases, API endpoints, client accounts, etc. A client registered in one Wallarm cloud cannot use other Wallarm cloud to manage or get access to their data stored in the first cloud. At the same time you may use both Wallarm clouds. In this case you will need to use different accounts in the Wallarm system and API endpoints to access and manage your information in individual clouds. Endpoints for the clouds are provided below. EU Cloud \u00b6 Physically located in France. https://my.wallarm.com/ to create Wallarm account https://api.wallarm.com/ to call API methods US Cloud \u00b6 Physically located in the USA. https://us1.my.wallarm.com/ to create Wallarm account https://us1.api.wallarm.com/ to call API methods End of file.","title":"How Wallarm Works"},{"location":"en/quickstart-en/qs-intro-en/#how-wallarm-works","text":"Wallarm is a DevOps-friendly Web Application Firewall (WAF) uniquely suited to protect your cloud applications and APIs. Wallarm's hybrid architecture safeguards your resources by offering: Protection from hacker attacks. Automatic detection of vulnerabilities . Wallarm analyzes all incoming HTTP requests and instantly blocks the malicious ones. Wallarm continuously collects metrics from the entire network traffic and processes the metrics by applying machine learning in the Wallarm cloud. Based on the processed requests, Wallarm creates an individual profile of the protected resources and applies the finely tuned security rules. The Wallarm scanner checks your company's network resources in several modes to detect vulnerabilities. Wallarm consists of the following components: The Wallarm filter node The Wallarm cloud","title":"How Wallarm Works"},{"location":"en/quickstart-en/qs-intro-en/#filter-node","text":"The network traffic check is done through the Wallarm filter node installed in the company's network infrastructure. The Wallarm filter node does the following: Blocks malicious requests and filters the valid ones Analyzes the company's entire network traffic Collects the network traffic metrics and uploads the metrics to the Wallarm cloud Downloads fine-tuned resource-specific rules from the Wallarm cloud","title":"Filter Node"},{"location":"en/quickstart-en/qs-intro-en/#cloud","text":"The Wallarm cloud does the following: Processes the metrics that the filter node uploads Creates fine-tuned resource-specific rules Scans the company's protected resources to detect vulnerabilities Wallarm manages European and American cloud instances with each cloud being completely separate in terms of databases, API endpoints, client accounts, etc. A client registered in one Wallarm cloud cannot use other Wallarm cloud to manage or get access to their data stored in the first cloud. At the same time you may use both Wallarm clouds. In this case you will need to use different accounts in the Wallarm system and API endpoints to access and manage your information in individual clouds. Endpoints for the clouds are provided below.","title":"Cloud"},{"location":"en/quickstart-en/qs-intro-en/#eu-cloud","text":"Physically located in France. https://my.wallarm.com/ to create Wallarm account https://api.wallarm.com/ to call API methods","title":"EU Cloud"},{"location":"en/quickstart-en/qs-intro-en/#us-cloud","text":"Physically located in the USA. https://us1.my.wallarm.com/ to create Wallarm account https://us1.api.wallarm.com/ to call API methods End of file.","title":"US Cloud"},{"location":"en/quickstart-en/qs-license-en/","text":"Creating the Wallarm Account \u00b6 To create the Wallarm account, proceed with the following steps: Fill in the registration form. Confirm your email address. 1. Fill in the Registration Form \u00b6 Choose one of the following versions of the Wallarm Cloud and proceed to the corresponding link: If you want to use the European version of the Wallarm Cloud, proceed to this link . If you want to use the US version of the Wallarm Cloud, proceed to this link . Enter the required data. Business email You can only sign up using a business email. Click Create account . You can also check the option Observe network perimeter . With the option selected, Wallarm will do the following: Automatically scan and discover all network resources of your company. Display the discovered resources in Wallarm console. Check the discovered resources for vulnerabilities . 2. Confirm Your Email Address \u00b6 After the successful registration, you will receive and automatic email with a link for your email address confirmation. After clicking the confirmation link, click Deploy node to start working with Wallarm.","title":"Creating the Wallarm Account"},{"location":"en/quickstart-en/qs-license-en/#creating-the-wallarm-account","text":"To create the Wallarm account, proceed with the following steps: Fill in the registration form. Confirm your email address.","title":"Creating the Wallarm Account"},{"location":"en/quickstart-en/qs-license-en/#1-fill-in-the-registration-form","text":"Choose one of the following versions of the Wallarm Cloud and proceed to the corresponding link: If you want to use the European version of the Wallarm Cloud, proceed to this link . If you want to use the US version of the Wallarm Cloud, proceed to this link . Enter the required data. Business email You can only sign up using a business email. Click Create account . You can also check the option Observe network perimeter . With the option selected, Wallarm will do the following: Automatically scan and discover all network resources of your company. Display the discovered resources in Wallarm console. Check the discovered resources for vulnerabilities .","title":"1. Fill in the Registration Form"},{"location":"en/quickstart-en/qs-license-en/#2-confirm-your-email-address","text":"After the successful registration, you will receive and automatic email with a link for your email address confirmation. After clicking the confirmation link, click Deploy node to start working with Wallarm.","title":"2. Confirm Your Email Address"},{"location":"en/quickstart-en/qs-prereq-en/","text":"Prerequisites \u00b6 Wallarm installation prerequisites: Supported operating system. Root access. Wallarm account on the Wallarm portal in the EU or US cloud. Supported Operating Systems \u00b6 The filter node supports installation from packages on the following operating systems: #### Warning:: Supported OS types Only x64 operating systems are supported. Debian 8.x (jessie) Debian 9.x (stretch) Debian 10.x (buster) Ubuntu 14.04 LTS (trusty) Ubuntu 16.04 LTS (xenial) Ubuntu 18.04 LTS (bionic) CentOS 6.x CentOS 7.x Amazon Linux 2","title":"Prerequisites"},{"location":"en/quickstart-en/qs-prereq-en/#prerequisites","text":"Wallarm installation prerequisites: Supported operating system. Root access. Wallarm account on the Wallarm portal in the EU or US cloud.","title":"Prerequisites"},{"location":"en/quickstart-en/qs-prereq-en/#supported-operating-systems","text":"The filter node supports installation from packages on the following operating systems: #### Warning:: Supported OS types Only x64 operating systems are supported. Debian 8.x (jessie) Debian 9.x (stretch) Debian 10.x (buster) Ubuntu 14.04 LTS (trusty) Ubuntu 16.04 LTS (xenial) Ubuntu 18.04 LTS (bionic) CentOS 6.x CentOS 7.x Amazon Linux 2","title":"Supported Operating Systems"},{"location":"en/quickstart-en/qs-setup-proxy-en/","text":"Configure Traffic Proxying \u00b6 To process the HTTP requests, Wallarm uses the web and proxy server NGINX with additional modules to analyze the traffic. To configure the proxying and filtering rules, you must: Edit the NGINX configuration files. Set up the filter node for using a proxy server. Restart NGINX. 1. Edit the NGINX Configuration Files \u00b6 The etc/nginx/conf.d directory contains NGINX and Wallarm filter node configuration files. By default, this directory contains the following configuration files: The default.conf file defines the configuration of NGINX. The wallarm.conf file defines the global configuration of Wallarm filter node. The wallarm-status.conf file defines the Wallarm monitoring configuration. You can create your own configuration files to define the operation of NGINX and Wallarm. It is recommended to create a separate configuration file with the server block for each group of the domains that should be processed in the same way. To see detailed information about working with NGINX configuration files, proceed to the official NGINX documentation . Wallarm directives define the operation logic of the Wallarm filter node. To see the list of Wallarm directives available, proceed to the Wallarm configuration options page. A Configuration File Example \u00b6 Let us suppose that you need to configure the server to work in the following conditions: Only HTTP traffic is processed. There are no HTTPS requests processed. The following domains receive the requests: example.com and www.example.com . All requests must be passed to the server 10.80.0.5 . All incoming requests are considered less than 1MB in size (default setting). The processing of a request takes no more than 60 seconds (default setting). Wallarm must operate in the monitor mode. Clients access the filter node directly, without an intermediate HTTP load balancer. Creating a configuration file You can create a custom NGINX configuration file (e.g. example.com.conf ) or modify the default NGINX configuration file ( default.conf ). When creating a custom configuration file, make sure that NGINX listens to the incoming connections on the free port. To meet the listed conditions, the contents of the configuration file must be the following: server { listen 80; listen [::]:80 ipv6only=on; # the domains for which traffic is processed server_name example.com; server_name www.example.com; # turn on the monitoring mode of traffic processing wallarm_mode monitoring; # wallarm_instance 1; location / { # setting the address for request forwarding proxy_pass http://10.80.0.5; proxy_set_header Host $host; proxy_set_header X-Real-IP $remote_addr; proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for; } } 2. Set up the Filter Node for Using a Proxy Server \u00b6 Info This setup step is intended for users who use their own proxy server for the operation of the protected web applications. If you do not use a proxy server, skip this step of the setup. You need to assign new values to the environment variables, which define the proxy server used, to configure Wallarm node for using your proxy server. Add new values of the environment variables to the /etc/environment file: Add https_proxy to define a proxy for the https protocol. Add http_proxy to define a proxy for the http protocol. Add no_proxy to define the list of the resources proxy should not be used for. Assign the <scheme>://<proxy_user>:<proxy_pass>@<host>:<port> string values to the https_proxy and http_proxy variables. <scheme> defines the protocol used. It should match the protocol that the current environment variable sets up proxy for. <proxy_user> defines the username for proxy authorization. <proxy_pass> defines the password for proxy authorization. <host> defines a host of the proxy server. <port> defines a port of the proxy server. Assign a \"<res_1>, <res_2>, <res_3>, <res_4>, ...\" array value, where <res_1> , <res_2> , <res_3> , and <res_4> are the IP addresses and/or domains, to the no_proxy variable to define a list of the resources which proxy should not be used for. This array should consist of IP addresses and/or domains. Resources that need to be addressed without a proxy Add the following IP addresses and domain to the list of the resources that have to be addressed without a proxy for the system to operate correctly: 127.0.0.1 , 127.0.0.8 , 127.0.0.9 , and localhost . The 127.0.0.8 and 127.0.0.9 IP addresses are used for the operation of the Wallarm filter node. The example of the correct /etc/environment file contents below demonstrates the following configuration: HTTPS and HTTP requests are proxied to the 1.2.3.4 host with the 1234 port, using the admin username and the 01234 password for authorization on the proxy server. Proxying is disabled for the requests sent to 127.0.0.1 , 127.0.0.8 , 127.0.0.9 , and localhost . https_proxy=http://admin:01234@1.2.3.4:1234 http_proxy=http://admin:01234@1.2.3.4:1234 no_proxy=\"127.0.0.1, 127.0.0.8, 127.0.0.9, localhost\" 3. Restart NGINX \u00b6 After saving the edited configuration file, restart NGINX: # service nginx reload Perform the checking to see that the filter node is operational and filters traffic. See Check the filter node operation .","title":"Configure Traffic Proxying"},{"location":"en/quickstart-en/qs-setup-proxy-en/#configure-traffic-proxying","text":"To process the HTTP requests, Wallarm uses the web and proxy server NGINX with additional modules to analyze the traffic. To configure the proxying and filtering rules, you must: Edit the NGINX configuration files. Set up the filter node for using a proxy server. Restart NGINX.","title":"Configure Traffic Proxying"},{"location":"en/quickstart-en/qs-setup-proxy-en/#1-edit-the-nginx-configuration-files","text":"The etc/nginx/conf.d directory contains NGINX and Wallarm filter node configuration files. By default, this directory contains the following configuration files: The default.conf file defines the configuration of NGINX. The wallarm.conf file defines the global configuration of Wallarm filter node. The wallarm-status.conf file defines the Wallarm monitoring configuration. You can create your own configuration files to define the operation of NGINX and Wallarm. It is recommended to create a separate configuration file with the server block for each group of the domains that should be processed in the same way. To see detailed information about working with NGINX configuration files, proceed to the official NGINX documentation . Wallarm directives define the operation logic of the Wallarm filter node. To see the list of Wallarm directives available, proceed to the Wallarm configuration options page.","title":"1. Edit the NGINX Configuration Files"},{"location":"en/quickstart-en/qs-setup-proxy-en/#a-configuration-file-example","text":"Let us suppose that you need to configure the server to work in the following conditions: Only HTTP traffic is processed. There are no HTTPS requests processed. The following domains receive the requests: example.com and www.example.com . All requests must be passed to the server 10.80.0.5 . All incoming requests are considered less than 1MB in size (default setting). The processing of a request takes no more than 60 seconds (default setting). Wallarm must operate in the monitor mode. Clients access the filter node directly, without an intermediate HTTP load balancer. Creating a configuration file You can create a custom NGINX configuration file (e.g. example.com.conf ) or modify the default NGINX configuration file ( default.conf ). When creating a custom configuration file, make sure that NGINX listens to the incoming connections on the free port. To meet the listed conditions, the contents of the configuration file must be the following: server { listen 80; listen [::]:80 ipv6only=on; # the domains for which traffic is processed server_name example.com; server_name www.example.com; # turn on the monitoring mode of traffic processing wallarm_mode monitoring; # wallarm_instance 1; location / { # setting the address for request forwarding proxy_pass http://10.80.0.5; proxy_set_header Host $host; proxy_set_header X-Real-IP $remote_addr; proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for; } }","title":"A Configuration File Example"},{"location":"en/quickstart-en/qs-setup-proxy-en/#2-set-up-the-filter-node-for-using-a-proxy-server","text":"Info This setup step is intended for users who use their own proxy server for the operation of the protected web applications. If you do not use a proxy server, skip this step of the setup. You need to assign new values to the environment variables, which define the proxy server used, to configure Wallarm node for using your proxy server. Add new values of the environment variables to the /etc/environment file: Add https_proxy to define a proxy for the https protocol. Add http_proxy to define a proxy for the http protocol. Add no_proxy to define the list of the resources proxy should not be used for. Assign the <scheme>://<proxy_user>:<proxy_pass>@<host>:<port> string values to the https_proxy and http_proxy variables. <scheme> defines the protocol used. It should match the protocol that the current environment variable sets up proxy for. <proxy_user> defines the username for proxy authorization. <proxy_pass> defines the password for proxy authorization. <host> defines a host of the proxy server. <port> defines a port of the proxy server. Assign a \"<res_1>, <res_2>, <res_3>, <res_4>, ...\" array value, where <res_1> , <res_2> , <res_3> , and <res_4> are the IP addresses and/or domains, to the no_proxy variable to define a list of the resources which proxy should not be used for. This array should consist of IP addresses and/or domains. Resources that need to be addressed without a proxy Add the following IP addresses and domain to the list of the resources that have to be addressed without a proxy for the system to operate correctly: 127.0.0.1 , 127.0.0.8 , 127.0.0.9 , and localhost . The 127.0.0.8 and 127.0.0.9 IP addresses are used for the operation of the Wallarm filter node. The example of the correct /etc/environment file contents below demonstrates the following configuration: HTTPS and HTTP requests are proxied to the 1.2.3.4 host with the 1234 port, using the admin username and the 01234 password for authorization on the proxy server. Proxying is disabled for the requests sent to 127.0.0.1 , 127.0.0.8 , 127.0.0.9 , and localhost . https_proxy=http://admin:01234@1.2.3.4:1234 http_proxy=http://admin:01234@1.2.3.4:1234 no_proxy=\"127.0.0.1, 127.0.0.8, 127.0.0.9, localhost\"","title":"2. Set up the Filter Node for Using a Proxy Server"},{"location":"en/quickstart-en/qs-setup-proxy-en/#3-restart-nginx","text":"After saving the edited configuration file, restart NGINX: # service nginx reload Perform the checking to see that the filter node is operational and filters traffic. See Check the filter node operation .","title":"3. Restart NGINX"},{"location":"en/release-notes-en/relnotes-en_v2.10/","text":"Wallarm Node \u2014 Version 2.10 \u00b6 Changes Highlights \u00b6 The loading mechanism for filtration rules was reworked. Important: changes in the file permissions The filtration rules format was enchanced. Selectors by the absence of value. Selectors by the HTTP request method. Resolved a conflict between disabling attack types and vpatch implementation. The support for the Prometheus monitoring system was added. Metadata on whether the request was blocked is now saved. Added an option to set up tags in the NGINX configuration file. The directive wallarm_worker_rlimit_vmem was flagged as legacy. The support for Debian GNU/Linux 7.x (wheezy) was discontinued. New Method of Loading Filtration Rules \u00b6 Previously, the LOM file was loaded into memory during the processing of the config file. To update the filtration rules, the NGINX reload was required. Now the filtering rules are updated in the background mode, within a separate \"cache manager\" process, and there is no need to restart the NGINX workers. Moreover, we changed the method for storing data in the memory. The results of the loading are cached into a file. Thanks to this, there is no need to reload the filtration rules each time the config file is updated. #### Warning:: File permissions! The user starting the NGINX worker processes must have read access to license.key, proton.db and LOM files. When standard settings are in place, no additional configuring is necessary. However, if you use a custom NGINX package or run this service under a non-standard user, you will need to make the following changes: When installing a new filter node, run addnode --nginx-group ... to register it in Wallarm cloud As for the existing installations, add to /etc/wallarm/node.yaml the following: syncnode: group: ... Changes in the Filtration Rules Format \u00b6 We've added the ability to add rules based on whether a specified parameter is absent in the request. Positive rules are also supported. It is now also possible to process the request depending on the request method (GET/POST/etc.). The earlier conflict between the rules for disabling the attack type and the virtual patch applied to one and the same parameter was resolved. Prometheus Monitoring Support \u00b6 The directive wallarm_status now allows setting up metrics export in the Prometheus-compatible format. More... \u00b6 The filtering node now saves data on whether request was blocked. This data is now available in attack view in Wallarm console. In the NGINX configuration, you can now add additional information to each request in the key-value format using the directive wallarm_set_tag . This data is available for use in the postanalytics subsystem. The directive wallarm_worker_rlimit_vmem is now rendered obsolete; its behavior is equivalent to wallarm_ts_request_memory_limit . The support for Debian GNU/Linux 7.x (wheezy) was discontinued.","title":"Version 2.10"},{"location":"en/release-notes-en/relnotes-en_v2.10/#wallarm-node-version-210","text":"","title":"Wallarm Node \u2014 Version 2.10"},{"location":"en/release-notes-en/relnotes-en_v2.10/#changes-highlights","text":"The loading mechanism for filtration rules was reworked. Important: changes in the file permissions The filtration rules format was enchanced. Selectors by the absence of value. Selectors by the HTTP request method. Resolved a conflict between disabling attack types and vpatch implementation. The support for the Prometheus monitoring system was added. Metadata on whether the request was blocked is now saved. Added an option to set up tags in the NGINX configuration file. The directive wallarm_worker_rlimit_vmem was flagged as legacy. The support for Debian GNU/Linux 7.x (wheezy) was discontinued.","title":"Changes Highlights"},{"location":"en/release-notes-en/relnotes-en_v2.10/#new-method-of-loading-filtration-rules","text":"Previously, the LOM file was loaded into memory during the processing of the config file. To update the filtration rules, the NGINX reload was required. Now the filtering rules are updated in the background mode, within a separate \"cache manager\" process, and there is no need to restart the NGINX workers. Moreover, we changed the method for storing data in the memory. The results of the loading are cached into a file. Thanks to this, there is no need to reload the filtration rules each time the config file is updated. #### Warning:: File permissions! The user starting the NGINX worker processes must have read access to license.key, proton.db and LOM files. When standard settings are in place, no additional configuring is necessary. However, if you use a custom NGINX package or run this service under a non-standard user, you will need to make the following changes: When installing a new filter node, run addnode --nginx-group ... to register it in Wallarm cloud As for the existing installations, add to /etc/wallarm/node.yaml the following: syncnode: group: ...","title":"New Method of Loading Filtration Rules"},{"location":"en/release-notes-en/relnotes-en_v2.10/#changes-in-the-filtration-rules-format","text":"We've added the ability to add rules based on whether a specified parameter is absent in the request. Positive rules are also supported. It is now also possible to process the request depending on the request method (GET/POST/etc.). The earlier conflict between the rules for disabling the attack type and the virtual patch applied to one and the same parameter was resolved.","title":"Changes in the Filtration Rules Format"},{"location":"en/release-notes-en/relnotes-en_v2.10/#prometheus-monitoring-support","text":"The directive wallarm_status now allows setting up metrics export in the Prometheus-compatible format.","title":"Prometheus Monitoring Support"},{"location":"en/release-notes-en/relnotes-en_v2.10/#more","text":"The filtering node now saves data on whether request was blocked. This data is now available in attack view in Wallarm console. In the NGINX configuration, you can now add additional information to each request in the key-value format using the directive wallarm_set_tag . This data is available for use in the postanalytics subsystem. The directive wallarm_worker_rlimit_vmem is now rendered obsolete; its behavior is equivalent to wallarm_ts_request_memory_limit . The support for Debian GNU/Linux 7.x (wheezy) was discontinued.","title":"More..."},{"location":"en/release-notes-en/relnotes-en_v2.12/","text":"Wallarm Node \u2014 Version 2.12 \u00b6 Breaking Change \u00b6 Custom NGINX Build with Embedded Wallarm Module Deleted \u00b6 Now only a dynamic module for nginx is supported. Changes Highlights \u00b6 Attack grouping added. URL encoding recognition added to the htmljs parser. The possibility to limit request data processing iteration time added. The wallarm_request_chunk_size directive that allows limiting the number of bytes to be processed in one request parameter added. The informational pages about blocking added. The time_tnt parameter was removed from the displayed node statistics. The information about the data on whether the query is received completely added. The assessment of the time_detect parameter in the filter node statistics fixed. Query processing- and system resilience-related improvements were made. Warning:: Version 2.12 update sequence \u00b6 Before updating to 2.12, ensure that wallarm-tarantool version 1.11.0 or higher is already installed. Version 1.11.0 has added support for the new format of serialized requests. Attack Grouping Added \u00b6 If multiple identical attack instances related to the same part of the request are created during the request processing, they are added to one group. If one of the attacks detected by the htmljs or percent parser in the group is marked as false positive, all attacks in the group are treated by the filter node as false positive automatically. #### Warning:: The number of false positive attacks found in the request body may increase. URL Encoding Recognition Added to the htmljs Parser \u00b6 The htmljs parser can now process URL-encoded parts of the request. The Possibility to Limit Request Data Processing Iteration Time Added. \u00b6 If the request parameter contains a large amount of data, its processing could be time-consuming. Now you can limit data processing iteration time by setting up the wallarm_timeslice directive value. The new wallarm_timeslice directive can be used together with the wallarm_process_time_limit directive that was added earlier. The wallarm_process_time_limit directive sets up a limit on the total time that a filter node spends on all iterations of processing a single request. The wallarm_timeslice directive sets up a limit on the time that a filter node spends on one iteration of processing a request before it switches to the next request. Upon reaching the time limit, the filter node proceeds to process the next request in the queue. After performing one iteration on each of the requests in the queue, the node performs the second iteration of processing on the first request in the queue. Info Due to nginx server limitations, it is necessary to disable the request buffering by assigning the off value to the proxy_request_buffering nginx directive for the wallarm_timeslice directive to work. The wallarm_request_chunk_size Directive that Allows Limiting the Number of Bytes to Be Processed in One Request Parameter Added \u00b6 The wallarm_request_chunk_size allows you to limit the size of the parameter part that will be processed during a single iteration. By default this limit is 8 Kb. You can assign a desired integer value to the wallarm_request_chunk_size directive to set up the limit in bytes. The directive also supports the following postfixes: k or K for kilobytes m or M for megabytes g or G for gigabytes The Informational Pages about Blocking Added \u00b6 You can now configure the node to display the default informational page to the blocked user. The default page contains the following list of dynamic values: the blocked IP-address, blocking date, and the identifier of request that is answered by showing the current page. To enable the blocking page display, uncomment the wallarm_block_page directive in the configuration file by removing the # symbol at the beginning of the line. You can also replace the default informational page for blocked users with a custom one by assigning the new value to the wallarm_block_page . The time_tnt Parameter Removed \u00b6 Due to migration to the asynchronous execution flow in one of the previous versions, the time_tnt parameter is always zero. Thus, it will not be displayed in the filter node statistics anymore. The Data on whether the Query is Received Completely Added \u00b6 Previously, the query could be received only partially after an attack was detected in its header or body. Now, if the query is received and analyzed completely, this fact will be indicated in the web-interface. The Assessment of the time_detect Parameter in the Filter Node Statistics Fixed \u00b6 The time_detect parameter of the filter node statistics now displays precise time of serialized queries analysis in seconds. #### Warning:: Memory consumption increase After upgrading to version 2.12, the filter node may increase the consumption of computing resources (CPU and RAM) by NGINX processes by 15%.","title":"Version 2.12"},{"location":"en/release-notes-en/relnotes-en_v2.12/#wallarm-node-version-212","text":"","title":"Wallarm Node \u2014 Version 2.12"},{"location":"en/release-notes-en/relnotes-en_v2.12/#breaking-change","text":"","title":"Breaking Change"},{"location":"en/release-notes-en/relnotes-en_v2.12/#custom-nginx-build-with-embedded-wallarm-module-deleted","text":"Now only a dynamic module for nginx is supported.","title":"Custom NGINX Build with Embedded Wallarm Module Deleted"},{"location":"en/release-notes-en/relnotes-en_v2.12/#changes-highlights","text":"Attack grouping added. URL encoding recognition added to the htmljs parser. The possibility to limit request data processing iteration time added. The wallarm_request_chunk_size directive that allows limiting the number of bytes to be processed in one request parameter added. The informational pages about blocking added. The time_tnt parameter was removed from the displayed node statistics. The information about the data on whether the query is received completely added. The assessment of the time_detect parameter in the filter node statistics fixed. Query processing- and system resilience-related improvements were made.","title":"Changes Highlights"},{"location":"en/release-notes-en/relnotes-en_v2.12/#warning-version-212-update-sequence","text":"Before updating to 2.12, ensure that wallarm-tarantool version 1.11.0 or higher is already installed. Version 1.11.0 has added support for the new format of serialized requests.","title":"Warning:: Version 2.12 update sequence"},{"location":"en/release-notes-en/relnotes-en_v2.12/#attack-grouping-added","text":"If multiple identical attack instances related to the same part of the request are created during the request processing, they are added to one group. If one of the attacks detected by the htmljs or percent parser in the group is marked as false positive, all attacks in the group are treated by the filter node as false positive automatically. #### Warning:: The number of false positive attacks found in the request body may increase.","title":"Attack Grouping Added"},{"location":"en/release-notes-en/relnotes-en_v2.12/#url-encoding-recognition-added-to-the-htmljs-parser","text":"The htmljs parser can now process URL-encoded parts of the request.","title":"URL Encoding Recognition Added to the htmljs Parser"},{"location":"en/release-notes-en/relnotes-en_v2.12/#the-possibility-to-limit-request-data-processing-iteration-time-added","text":"If the request parameter contains a large amount of data, its processing could be time-consuming. Now you can limit data processing iteration time by setting up the wallarm_timeslice directive value. The new wallarm_timeslice directive can be used together with the wallarm_process_time_limit directive that was added earlier. The wallarm_process_time_limit directive sets up a limit on the total time that a filter node spends on all iterations of processing a single request. The wallarm_timeslice directive sets up a limit on the time that a filter node spends on one iteration of processing a request before it switches to the next request. Upon reaching the time limit, the filter node proceeds to process the next request in the queue. After performing one iteration on each of the requests in the queue, the node performs the second iteration of processing on the first request in the queue. Info Due to nginx server limitations, it is necessary to disable the request buffering by assigning the off value to the proxy_request_buffering nginx directive for the wallarm_timeslice directive to work.","title":"The Possibility to Limit Request Data Processing Iteration Time Added."},{"location":"en/release-notes-en/relnotes-en_v2.12/#the-wallarm_request_chunk_size-directive-that-allows-limiting-the-number-of-bytes-to-be-processed-in-one-request-parameter-added","text":"The wallarm_request_chunk_size allows you to limit the size of the parameter part that will be processed during a single iteration. By default this limit is 8 Kb. You can assign a desired integer value to the wallarm_request_chunk_size directive to set up the limit in bytes. The directive also supports the following postfixes: k or K for kilobytes m or M for megabytes g or G for gigabytes","title":"The wallarm_request_chunk_size Directive that Allows Limiting the Number of Bytes to Be Processed in One Request Parameter Added"},{"location":"en/release-notes-en/relnotes-en_v2.12/#the-informational-pages-about-blocking-added","text":"You can now configure the node to display the default informational page to the blocked user. The default page contains the following list of dynamic values: the blocked IP-address, blocking date, and the identifier of request that is answered by showing the current page. To enable the blocking page display, uncomment the wallarm_block_page directive in the configuration file by removing the # symbol at the beginning of the line. You can also replace the default informational page for blocked users with a custom one by assigning the new value to the wallarm_block_page .","title":"The Informational Pages about Blocking Added"},{"location":"en/release-notes-en/relnotes-en_v2.12/#the-time_tnt-parameter-removed","text":"Due to migration to the asynchronous execution flow in one of the previous versions, the time_tnt parameter is always zero. Thus, it will not be displayed in the filter node statistics anymore.","title":"The time_tnt Parameter Removed"},{"location":"en/release-notes-en/relnotes-en_v2.12/#the-data-on-whether-the-query-is-received-completely-added","text":"Previously, the query could be received only partially after an attack was detected in its header or body. Now, if the query is received and analyzed completely, this fact will be indicated in the web-interface.","title":"The Data on whether the Query is Received Completely Added"},{"location":"en/release-notes-en/relnotes-en_v2.12/#the-assessment-of-the-time_detect-parameter-in-the-filter-node-statistics-fixed","text":"The time_detect parameter of the filter node statistics now displays precise time of serialized queries analysis in seconds. #### Warning:: Memory consumption increase After upgrading to version 2.12, the filter node may increase the consumption of computing resources (CPU and RAM) by NGINX processes by 15%.","title":"The Assessment of the time_detect Parameter in the Filter Node Statistics Fixed"},{"location":"en/release-notes-en/relnotes-en_v2.14/","text":"Wallarm Node\u2014Version 2.14 \u00b6 Highlights of Changes \u00b6 Support for gRPC was added: now Wallarm can protect API and web applications that operates via the gRPC protocol. #### Info:: About the gRPC Protocol gRPC is a modern open-source high-performance Remote Procedure Call (RPC) framework from Google. Its high performance is achieved through the use of HTTP/2 for transport and protobuf for data type descriptions. The gRPC protocol can be used as an alternative to the REST when building APIs and services. Support for the customizable block pages and server response codes was added for the events of blocking by IP address. A few improvements were made to the monitoring and other system components. Support for the following operating systems was added: Debian 10, Amazon Linux 2.","title":"Version 2.14"},{"location":"en/release-notes-en/relnotes-en_v2.14/#wallarm-nodeversion-214","text":"","title":"Wallarm Node\u2014Version 2.14"},{"location":"en/release-notes-en/relnotes-en_v2.14/#highlights-of-changes","text":"Support for gRPC was added: now Wallarm can protect API and web applications that operates via the gRPC protocol. #### Info:: About the gRPC Protocol gRPC is a modern open-source high-performance Remote Procedure Call (RPC) framework from Google. Its high performance is achieved through the use of HTTP/2 for transport and protobuf for data type descriptions. The gRPC protocol can be used as an alternative to the REST when building APIs and services. Support for the customizable block pages and server response codes was added for the events of blocking by IP address. A few improvements were made to the monitoring and other system components. Support for the following operating systems was added: Debian 10, Amazon Linux 2.","title":"Highlights of Changes"},{"location":"en/release-notes-en/relnotes-en_v2.2/","text":"Wallarm Node \u2014 Version 2.2 \u00b6 Changes Highlights \u00b6 Limits for resource consumption are introduced. If a query processing time exceeds a specified value, the query is considered an attack. The time limits for analysis and blocking are set with the wallarm_process_time_limit_block and wallarm_process_time_limit directives . A memory limit for NGINX operation is configured via the wallarm_worker_rlimit_vmem directive. Default values: The time it takes to analyze a request is limited to 1 second (excluding the time it takes the backend to respond). The NGINX worker memory is limited to 1 GB. See also Wallarm configuration options . Added the ability to control NGINX when filtration rules error out on download. You can now save backup copies of proton.db and LOM . You can use the backup data when the filtration rules are missing or corrupted. When there is no option to use the backup data, the Wallarm module will be disabled, and NGINX will carry on. Before version 2.2. it was not possible to start NGINX without downloading the filtration rules. To manage the behavior on rules download error, use the wallarm_fallback and wallarm_cache_path directives in the configuration file. See also Wallarm configuration options . Improved the attack detection mechanisms. Optimized the NGINX server memory consumption. Added the ability to manage the blocking mode through filtration rules. You can manage the behavior with the wallarm_mode_allow_override directive. See also Wallarm configuration options . The /etc/wallarm/triggers.d/nginx trigger is renamed to /etc/wallarm/triggers.d/nginx-wallarm . This trigger is used by NGINX-Wallarm. New Installation Features \u00b6 You can now install postanalytics on a separate pool of servers. The subsystem of traffic processing can be integrated with a running NGINX server. This integration scheme is restrictive for binary compatibility: the Wallarm module is compatible only with a particular NGINX version and can operate only with this version. Wallarm supports the latest stable version of NGINX. The list of recent NGINX versions is available at www.nginx.org . Warning:: NGINX package dependency \u00b6 The Wallarm module packages does have the NGINX package dependency specified. Ensure you monitor the Wallarm module and NGINX compliance.","title":"Version 2.2"},{"location":"en/release-notes-en/relnotes-en_v2.2/#wallarm-node-version-22","text":"","title":"Wallarm Node \u2014 Version 2.2"},{"location":"en/release-notes-en/relnotes-en_v2.2/#changes-highlights","text":"Limits for resource consumption are introduced. If a query processing time exceeds a specified value, the query is considered an attack. The time limits for analysis and blocking are set with the wallarm_process_time_limit_block and wallarm_process_time_limit directives . A memory limit for NGINX operation is configured via the wallarm_worker_rlimit_vmem directive. Default values: The time it takes to analyze a request is limited to 1 second (excluding the time it takes the backend to respond). The NGINX worker memory is limited to 1 GB. See also Wallarm configuration options . Added the ability to control NGINX when filtration rules error out on download. You can now save backup copies of proton.db and LOM . You can use the backup data when the filtration rules are missing or corrupted. When there is no option to use the backup data, the Wallarm module will be disabled, and NGINX will carry on. Before version 2.2. it was not possible to start NGINX without downloading the filtration rules. To manage the behavior on rules download error, use the wallarm_fallback and wallarm_cache_path directives in the configuration file. See also Wallarm configuration options . Improved the attack detection mechanisms. Optimized the NGINX server memory consumption. Added the ability to manage the blocking mode through filtration rules. You can manage the behavior with the wallarm_mode_allow_override directive. See also Wallarm configuration options . The /etc/wallarm/triggers.d/nginx trigger is renamed to /etc/wallarm/triggers.d/nginx-wallarm . This trigger is used by NGINX-Wallarm.","title":"Changes Highlights"},{"location":"en/release-notes-en/relnotes-en_v2.2/#new-installation-features","text":"You can now install postanalytics on a separate pool of servers. The subsystem of traffic processing can be integrated with a running NGINX server. This integration scheme is restrictive for binary compatibility: the Wallarm module is compatible only with a particular NGINX version and can operate only with this version. Wallarm supports the latest stable version of NGINX. The list of recent NGINX versions is available at www.nginx.org .","title":"New Installation Features"},{"location":"en/release-notes-en/relnotes-en_v2.2/#warning-nginx-package-dependency","text":"The Wallarm module packages does have the NGINX package dependency specified. Ensure you monitor the Wallarm module and NGINX compliance.","title":"Warning:: NGINX package dependency"},{"location":"en/release-notes-en/relnotes-en_v2.4/","text":"Wallarm Node \u2014 Version 2.4 \u00b6 Changes Highlights \u00b6 Support of the view state format \u2013 a technique used by ASP.NET to persist changes to the state of a Web Form across postbacks. Now Wallarm can parse the unencrypted view state data, which allows for more flexible with .NET-applications by tuning blocking rules more precisely and thus providing more security for .NET-applications. Integrated the libdetection library. libdetection is a Wallarm-developed open-source product that you can use to develop your own parsers to protect from injection attacks. This approach provides greater flexibility when compared to the traditional attack detection mechanisms based on regular expressions. libdetection allows non-signature based detection. New LOM format that reduces memory consumption for the filtering rules storage. Parsers' management for parameters. Now when describing the structure you can set required parser parameters, set the blacklist mode that allows all parsers except for the prohibited ones, and set the whitelist mode that allows all parsers excepted for the listed ones. The new structure provides stricter control. You can also set a required parser for a particular parameter. If the parser cannot process the set parameter, Wallarm will consider the parameter invalid. Improved brute-force attack detection algorithm. Improved NGINX-Wallarm memory consumption. The module improved by up to 30%. Warning:: Memory consumption on the first use \u00b6 After updating the filter node to version 2.4 but before downloading the new LOM, the NGINX-Wallarm module memory consumption will exceed the regular levels. The memory consumption will go significantly down after downloading the new LOM.","title":"Version 2.4"},{"location":"en/release-notes-en/relnotes-en_v2.4/#wallarm-node-version-24","text":"","title":"Wallarm Node \u2014 Version 2.4"},{"location":"en/release-notes-en/relnotes-en_v2.4/#changes-highlights","text":"Support of the view state format \u2013 a technique used by ASP.NET to persist changes to the state of a Web Form across postbacks. Now Wallarm can parse the unencrypted view state data, which allows for more flexible with .NET-applications by tuning blocking rules more precisely and thus providing more security for .NET-applications. Integrated the libdetection library. libdetection is a Wallarm-developed open-source product that you can use to develop your own parsers to protect from injection attacks. This approach provides greater flexibility when compared to the traditional attack detection mechanisms based on regular expressions. libdetection allows non-signature based detection. New LOM format that reduces memory consumption for the filtering rules storage. Parsers' management for parameters. Now when describing the structure you can set required parser parameters, set the blacklist mode that allows all parsers except for the prohibited ones, and set the whitelist mode that allows all parsers excepted for the listed ones. The new structure provides stricter control. You can also set a required parser for a particular parameter. If the parser cannot process the set parameter, Wallarm will consider the parameter invalid. Improved brute-force attack detection algorithm. Improved NGINX-Wallarm memory consumption. The module improved by up to 30%.","title":"Changes Highlights"},{"location":"en/release-notes-en/relnotes-en_v2.4/#warning-memory-consumption-on-the-first-use","text":"After updating the filter node to version 2.4 but before downloading the new LOM, the NGINX-Wallarm module memory consumption will exceed the regular levels. The memory consumption will go significantly down after downloading the new LOM.","title":"Warning:: Memory consumption on the first use"},{"location":"en/release-notes-en/relnotes-en_v2.6/","text":"Wallarm Node \u2014 Version 2.6 \u00b6 Changes Highlights \u00b6 Added the ability to add headers to server responses. Added the ability to use regular expressions to detect attacks. Added the ability to upload the attacks data directly into the API without using Tarantool. Added the ability to analyze the server response metrics. The installation now does not require providing your license manually. The license is automatically downloaded from the Wallarm servers.","title":"Version 2.6"},{"location":"en/release-notes-en/relnotes-en_v2.6/#wallarm-node-version-26","text":"","title":"Wallarm Node \u2014 Version 2.6"},{"location":"en/release-notes-en/relnotes-en_v2.6/#changes-highlights","text":"Added the ability to add headers to server responses. Added the ability to use regular expressions to detect attacks. Added the ability to upload the attacks data directly into the API without using Tarantool. Added the ability to analyze the server response metrics. The installation now does not require providing your license manually. The license is automatically downloaded from the Wallarm servers.","title":"Changes Highlights"},{"location":"en/release-notes-en/relnotes-en_v2.8/","text":"Wallarm Node \u2014 Version 2.8 \u00b6 Changes Highlights \u00b6 Added the function to block requests from blacklisted IP addresses via NGINX. Implemented memory consumption ceiling for a single request processing. Added support for the deflate and brotli compression formats in HTTP responses. Enhanced monitoring capabilities. Improved logging mechanism. Blocking of Blacklisted IP Addresses \u00b6 In addition to the previously available capability to block attackers by their IP addresses using a firewall (e.g. iptables), one can now block blacklisted IP address via the NGINX itself. This is a more convenient way to block requests using blacklists as it doesn\u2019t require integration with the firewall. It\u2019s also the only option when the filter instance is behind HTTP load balancer. More ... Limiting Memory Consumption \u00b6 Previously, the memory limit could be configured only for the entire worker process. Now you can restrict both the overall memory consumption as well as memory consumed while processing individual requests. This can be set up with the following directives: wallarm_request_memory_limit wallarm_ts_request_memory_limit By default, the old mechanism for restricting memory consumption is used. Monitoring \u00b6 New parameters are added to the output of wallarm-status page: memfaults segfaults Logging \u00b6 The format of the error messages remained unchanged. However, you can now customise debug messages. The logging is configured by the following directives wallarm_proton_log_mask_master wallarm_proton_log_mask_worker","title":"Version 2.8"},{"location":"en/release-notes-en/relnotes-en_v2.8/#wallarm-node-version-28","text":"","title":"Wallarm Node \u2014 Version 2.8"},{"location":"en/release-notes-en/relnotes-en_v2.8/#changes-highlights","text":"Added the function to block requests from blacklisted IP addresses via NGINX. Implemented memory consumption ceiling for a single request processing. Added support for the deflate and brotli compression formats in HTTP responses. Enhanced monitoring capabilities. Improved logging mechanism.","title":"Changes Highlights"},{"location":"en/release-notes-en/relnotes-en_v2.8/#blocking-of-blacklisted-ip-addresses","text":"In addition to the previously available capability to block attackers by their IP addresses using a firewall (e.g. iptables), one can now block blacklisted IP address via the NGINX itself. This is a more convenient way to block requests using blacklists as it doesn\u2019t require integration with the firewall. It\u2019s also the only option when the filter instance is behind HTTP load balancer. More ...","title":"Blocking of Blacklisted IP Addresses"},{"location":"en/release-notes-en/relnotes-en_v2.8/#limiting-memory-consumption","text":"Previously, the memory limit could be configured only for the entire worker process. Now you can restrict both the overall memory consumption as well as memory consumed while processing individual requests. This can be set up with the following directives: wallarm_request_memory_limit wallarm_ts_request_memory_limit By default, the old mechanism for restricting memory consumption is used.","title":"Limiting Memory Consumption"},{"location":"en/release-notes-en/relnotes-en_v2.8/#monitoring","text":"New parameters are added to the output of wallarm-status page: memfaults segfaults","title":"Monitoring"},{"location":"en/release-notes-en/relnotes-en_v2.8/#logging","text":"The format of the error messages remained unchanged. However, you can now customise debug messages. The logging is configured by the following directives wallarm_proton_log_mask_master wallarm_proton_log_mask_worker","title":"Logging"},{"location":"en/user-guides/cloud-ui/use-sso/","text":"Guide to Using SSO Authentication to Log in to Wallarm \u00b6 This guide will cover the process of user authentication on the Wallarm portal using Single Sign-On (SSO) technology. #### Info:: Prerequisites: If SSO authentication was enabled and your account role is not *Admin*, then you can now only use SSO authentication to log in to the Wallarm portal. This guide assumes that you already have an account with one of the identity providers, such as [Okta][link-okta] or [G Suite][link-gsuite]. If this is not the case, please contact your administrator. To authenticate using SSO, go to the Wallarm login page. If you use an address like <some_domain>.wallarm.com (e.g., my.wallarm.com ) to log in to Wallarm, then you will need to click the Sign in with SAML SSO link to login with SSO (login/password pair is considered a priority). If you use an address like <company_domain>.wallarm.io (the domain allocated to the company your account belongs to) to log in to Wallarm, then the priority login method is the SSO login, and the login form will be different from the one given above. To log in to Wallarm using SSO, you need to enter your email. If the entered email is registered and SSO authentication is configured for it, you will be redirected to an identity provider (IdP) service, such as Okta or G Suite. If you are also not authorized by this provider, you will be redirected to the login page. The login pages for the Okta and G Suite services are shown below. Enter your email and password (additional options with two-factor authentication). After successful authentication by the identity provider and verification of access rights to the requested resource (Wallarm), the provider redirects you to the Wallarm portal. At the same time, the provider sends a request to the Wallarm side confirming that you are a legitimate user, as well as other necessary parameters. In this way, you will be logged in to the Wallarm portal and the dashboard page will be opened. This completes the SSO authentication process.","title":"Guide to Using SSO Authentication to Log in to Wallarm"},{"location":"en/user-guides/cloud-ui/use-sso/#guide-to-using-sso-authentication-to-log-in-to-wallarm","text":"This guide will cover the process of user authentication on the Wallarm portal using Single Sign-On (SSO) technology. #### Info:: Prerequisites: If SSO authentication was enabled and your account role is not *Admin*, then you can now only use SSO authentication to log in to the Wallarm portal. This guide assumes that you already have an account with one of the identity providers, such as [Okta][link-okta] or [G Suite][link-gsuite]. If this is not the case, please contact your administrator. To authenticate using SSO, go to the Wallarm login page. If you use an address like <some_domain>.wallarm.com (e.g., my.wallarm.com ) to log in to Wallarm, then you will need to click the Sign in with SAML SSO link to login with SSO (login/password pair is considered a priority). If you use an address like <company_domain>.wallarm.io (the domain allocated to the company your account belongs to) to log in to Wallarm, then the priority login method is the SSO login, and the login form will be different from the one given above. To log in to Wallarm using SSO, you need to enter your email. If the entered email is registered and SSO authentication is configured for it, you will be redirected to an identity provider (IdP) service, such as Okta or G Suite. If you are also not authorized by this provider, you will be redirected to the login page. The login pages for the Okta and G Suite services are shown below. Enter your email and password (additional options with two-factor authentication). After successful authentication by the identity provider and verification of access rights to the requested resource (Wallarm), the provider redirects you to the Wallarm portal. At the same time, the provider sends a request to the Wallarm side confirming that you are a legitimate user, as well as other necessary parameters. In this way, you will be logged in to the Wallarm portal and the dashboard page will be opened. This completes the SSO authentication process.","title":"Guide to Using SSO Authentication to Log in to Wallarm"},{"location":"en/user-guides/cloud-ui/user-intro/","text":"Introduction \u00b6 This guide provides information on Wallarm operation options. All of these operations are performed using the Wallarm portal. #### Info:: Required Access Rights You must have analyst access to perform most of the operations described in this guide. You can set analyst access on the Settings \u2192 Users tab on the Wallarm portal in the EU or US cloud . Wallarm Portal Overview \u00b6 After logging in to the Wallarm portal, you will be presented with the following: A sidebar with tabs on the left side of the portal. Use these tabs to navigate from one component of the Wallarm solution to another. Some component's pages contain their own tabs, horizontally aligned. The Help & Docs button is located at the bottom of the sidebar. Upon clicking this button, the Quick Help sidebar will be opened on the right side of the portal, allowing you to explore various product information and submit a message to the support team. #### Info:: A note on Component Availability Your Wallarm portal may look different from the screenshots demonstrated in this User Guide. The availability of some components and UI elements depends on the subscriptions in use. See the \u201cSubscriptions\u201d document for more details. A search box at the top of the portal. This search box is available everywhere in the portal except for the Events tab. Type in a search query and you will be redirected to the search results on the Events tab. The \u201cUsing Search\u201d document introduces you to the search query syntax and explains how to use search. A Settings button at the upper right corner of the portal near the search box. This button looks like small gear. Use this button to open the Wallarm settings page. Depending on the actions you take, some additional sidebars might be displayed to you at the very right of the portal. See also Administrator guide","title":"Introduction"},{"location":"en/user-guides/cloud-ui/user-intro/#introduction","text":"This guide provides information on Wallarm operation options. All of these operations are performed using the Wallarm portal. #### Info:: Required Access Rights You must have analyst access to perform most of the operations described in this guide. You can set analyst access on the Settings \u2192 Users tab on the Wallarm portal in the EU or US cloud .","title":"Introduction"},{"location":"en/user-guides/cloud-ui/user-intro/#wallarm-portal-overview","text":"After logging in to the Wallarm portal, you will be presented with the following: A sidebar with tabs on the left side of the portal. Use these tabs to navigate from one component of the Wallarm solution to another. Some component's pages contain their own tabs, horizontally aligned. The Help & Docs button is located at the bottom of the sidebar. Upon clicking this button, the Quick Help sidebar will be opened on the right side of the portal, allowing you to explore various product information and submit a message to the support team. #### Info:: A note on Component Availability Your Wallarm portal may look different from the screenshots demonstrated in this User Guide. The availability of some components and UI elements depends on the subscriptions in use. See the \u201cSubscriptions\u201d document for more details. A search box at the top of the portal. This search box is available everywhere in the portal except for the Events tab. Type in a search query and you will be redirected to the search results on the Events tab. The \u201cUsing Search\u201d document introduces you to the search query syntax and explains how to use search. A Settings button at the upper right corner of the portal near the search box. This button looks like small gear. Use this button to open the Wallarm settings page. Depending on the actions you take, some additional sidebars might be displayed to you at the very right of the portal. See also Administrator guide","title":"Wallarm Portal Overview"},{"location":"en/user-guides/cloud-ui/blacklist/blacklist/","text":"IP Address Blacklist \u00b6 Wallarm can block most harmful traffic request-by-request if a malicious payload is detected. However, for behavioral-based attacks when every single request by itself is legitimate (e.g. login attempts with username/password pairs), blocking by origin is necessary. Wallarm can block bots and behavioral-based attacks, such as application abuse, brute-force, and forced browsing, by automatically adding IPs to the blacklist. Administrators can also manually add IP addresses and subnets for blocking. The blacklist is available at the Blacklist tab where users can Review the list of blocked IP addresses and the reasons they were blocked; Instantly unblock any IP address or set the time to unblock; Add an IP address or a whole subnet to the blacklist. Warning:: Enable on Wallarm Node \u00b6 For the blacklisting to take effect, you must enable it on Wallarm Node. More... Review the Active Blacklist \u00b6 By default, Wallarm will show the list of all IPs that are currently blacklisted. The same view is available by clicking the Now filter. For every element of a blacklist entry, Wallarm shows: IP : the blocked IP address. There may also be a country code in small-sized grey font. Reason : automatically generated or manually inserted reason for blacklisting. Application : the application that is protected by the blacklist. Blocked : the date and time of the blocking. Unblock : a time period after which the blocking will expire. Clicking a row will expand the history data for the selected IP address. It is possible to instantly unblock an IP address or change the duration of the ban with the contextual buttons. Review Blocking History \u00b6 Select one of the filters above the table of the blocked entries. Filter by Blocking Date \u00b6 The filter Day displays the blocking history for the last 24 hours. You can also select a custom time filter to specify the time range of the events to be displayed. Both blocking and unblocking events that occurred during the time range will be displayed. Filter by Application \u00b6 Select an application to see its blocking entries. Alternatively, blocking entries for all applications can be viewed by selecting the All apps option. Filter by IP Address \u00b6 In the search field, enter the IP address to filter the list. Block Manually \u00b6 To start blocking: Click the Now button and the Add IP or subnet button. Enter a value in the field IP, range, or subnet . Pick a date or use the slider to specify the blocking time. Choose whether to block IPs for all applications or for a selected application. Optionally, provide a comment on the blocking reason. Click Add to blacklist . The minimum blocking time period is 60 minutes. Entering an IP address with a subnet mask will list every blocked IP address in the expanded table. For example, entering a.b.c.0/24 will expand the table to list 256 IP addresses. Extending the Blocking Time \u00b6 One can extend the blocking time for the IP address by locating it in the list of currently blocked IPs and changing the ban time. Filters can be useful when there is a large number of entries in the list. Unblocking IPs \u00b6 Click Unblock on the entry with a blocked IP to remove it from the blacklist. Exporting Blacklist Entries \u00b6 To export the blocking data, click Export list . Wallarm will export a CSV file based on the date range currently selected in the UI with the following fields: ID : the blocking record number. Application : the application ID. Type : the action type ( blocked or unblocked ). Time : the date and time of the action. Country : the blocked IP address's country. Reason : automatically generated or manually inserted reason for blacklisting.","title":"IP Address Blacklist"},{"location":"en/user-guides/cloud-ui/blacklist/blacklist/#ip-address-blacklist","text":"Wallarm can block most harmful traffic request-by-request if a malicious payload is detected. However, for behavioral-based attacks when every single request by itself is legitimate (e.g. login attempts with username/password pairs), blocking by origin is necessary. Wallarm can block bots and behavioral-based attacks, such as application abuse, brute-force, and forced browsing, by automatically adding IPs to the blacklist. Administrators can also manually add IP addresses and subnets for blocking. The blacklist is available at the Blacklist tab where users can Review the list of blocked IP addresses and the reasons they were blocked; Instantly unblock any IP address or set the time to unblock; Add an IP address or a whole subnet to the blacklist.","title":"IP Address Blacklist"},{"location":"en/user-guides/cloud-ui/blacklist/blacklist/#warning-enable-on-wallarm-node","text":"For the blacklisting to take effect, you must enable it on Wallarm Node. More...","title":"Warning:: Enable on Wallarm Node"},{"location":"en/user-guides/cloud-ui/blacklist/blacklist/#review-the-active-blacklist","text":"By default, Wallarm will show the list of all IPs that are currently blacklisted. The same view is available by clicking the Now filter. For every element of a blacklist entry, Wallarm shows: IP : the blocked IP address. There may also be a country code in small-sized grey font. Reason : automatically generated or manually inserted reason for blacklisting. Application : the application that is protected by the blacklist. Blocked : the date and time of the blocking. Unblock : a time period after which the blocking will expire. Clicking a row will expand the history data for the selected IP address. It is possible to instantly unblock an IP address or change the duration of the ban with the contextual buttons.","title":"Review the Active Blacklist"},{"location":"en/user-guides/cloud-ui/blacklist/blacklist/#review-blocking-history","text":"Select one of the filters above the table of the blocked entries.","title":"Review Blocking History"},{"location":"en/user-guides/cloud-ui/blacklist/blacklist/#filter-by-blocking-date","text":"The filter Day displays the blocking history for the last 24 hours. You can also select a custom time filter to specify the time range of the events to be displayed. Both blocking and unblocking events that occurred during the time range will be displayed.","title":"Filter by Blocking Date"},{"location":"en/user-guides/cloud-ui/blacklist/blacklist/#filter-by-application","text":"Select an application to see its blocking entries. Alternatively, blocking entries for all applications can be viewed by selecting the All apps option.","title":"Filter by Application"},{"location":"en/user-guides/cloud-ui/blacklist/blacklist/#filter-by-ip-address","text":"In the search field, enter the IP address to filter the list.","title":"Filter by IP Address"},{"location":"en/user-guides/cloud-ui/blacklist/blacklist/#block-manually","text":"To start blocking: Click the Now button and the Add IP or subnet button. Enter a value in the field IP, range, or subnet . Pick a date or use the slider to specify the blocking time. Choose whether to block IPs for all applications or for a selected application. Optionally, provide a comment on the blocking reason. Click Add to blacklist . The minimum blocking time period is 60 minutes. Entering an IP address with a subnet mask will list every blocked IP address in the expanded table. For example, entering a.b.c.0/24 will expand the table to list 256 IP addresses.","title":"Block Manually"},{"location":"en/user-guides/cloud-ui/blacklist/blacklist/#extending-the-blocking-time","text":"One can extend the blocking time for the IP address by locating it in the list of currently blocked IPs and changing the ban time. Filters can be useful when there is a large number of entries in the list.","title":"Extending the Blocking Time"},{"location":"en/user-guides/cloud-ui/blacklist/blacklist/#unblocking-ips","text":"Click Unblock on the entry with a blocked IP to remove it from the blacklist.","title":"Unblocking IPs"},{"location":"en/user-guides/cloud-ui/blacklist/blacklist/#exporting-blacklist-entries","text":"To export the blocking data, click Export list . Wallarm will export a CSV file based on the date range currently selected in the UI with the following fields: ID : the blocking record number. Application : the application ID. Type : the action type ( blocked or unblocked ). Time : the date and time of the action. Country : the blocked IP address's country. Reason : automatically generated or manually inserted reason for blacklisting.","title":"Exporting Blacklist Entries"},{"location":"en/user-guides/cloud-ui/dashboard/intro/","text":"Dashboards Overview \u00b6 The Dashboard tab is the main page of the Wallarm portal in the EU or US cloud . After logging in to the Wallarm portal, you will be presented with a few dashboards that show the current status of the protected resources and provide some historical insights into the system events. The available dashboards are: \u201cWAF\u201d \u201cScanner\u201d All dashboards are placed on a single scrollable page, one after the other. The \u201cWAF\u201d Dashboard \u00b6 This dashboard provides you with information related to the web firewall operations: traffic statistics data about applications under attack blacklisted IP addresses The \u201cScanner\u201d Dashboard \u00b6 This dashboard provides you with information about vulnerabilities detected by the scanner . #### Info:: Extras If you have any of the dashboards opened, you could gather information about how to start with Wallarm by pressing the *Get started* button at the bottom right corner of the portal.","title":"Overview"},{"location":"en/user-guides/cloud-ui/dashboard/intro/#dashboards-overview","text":"The Dashboard tab is the main page of the Wallarm portal in the EU or US cloud . After logging in to the Wallarm portal, you will be presented with a few dashboards that show the current status of the protected resources and provide some historical insights into the system events. The available dashboards are: \u201cWAF\u201d \u201cScanner\u201d All dashboards are placed on a single scrollable page, one after the other.","title":"Dashboards Overview"},{"location":"en/user-guides/cloud-ui/dashboard/intro/#the-waf-dashboard","text":"This dashboard provides you with information related to the web firewall operations: traffic statistics data about applications under attack blacklisted IP addresses","title":"The \u201cWAF\u201d Dashboard"},{"location":"en/user-guides/cloud-ui/dashboard/intro/#the-scanner-dashboard","text":"This dashboard provides you with information about vulnerabilities detected by the scanner . #### Info:: Extras If you have any of the dashboards opened, you could gather information about how to start with Wallarm by pressing the *Get started* button at the bottom right corner of the portal.","title":"The \u201cScanner\u201d Dashboard"},{"location":"en/user-guides/cloud-ui/dashboard/scanner/","text":"The \u201cScanner\u201d Dashboard \u00b6 This dashboard provides you with information about vulnerabilities detected by the scanner. When working with this dashboard, you can choose the date range you are interested in (default choice: one month prior to the current date). This choice influences all information on the dashboard. Available statistics are: the number of vulnerabilities of all risk levels in the current month the number of vulnerabilities of all risk levels that were not fixed by the end of the chosen date range changes in the numbers of vulnerabilities of all risk levels for the whole chosen date range Click one of the pie charts with a vulnerabilities number on the right to be redirected to the Events tab . The table on this tab will contain unfixed vulnerabilities of the chosen risk level in the selected time range.","title":"The \u201cScanner\u201d Dashboard"},{"location":"en/user-guides/cloud-ui/dashboard/scanner/#the-scanner-dashboard","text":"This dashboard provides you with information about vulnerabilities detected by the scanner. When working with this dashboard, you can choose the date range you are interested in (default choice: one month prior to the current date). This choice influences all information on the dashboard. Available statistics are: the number of vulnerabilities of all risk levels in the current month the number of vulnerabilities of all risk levels that were not fixed by the end of the chosen date range changes in the numbers of vulnerabilities of all risk levels for the whole chosen date range Click one of the pie charts with a vulnerabilities number on the right to be redirected to the Events tab . The table on this tab will contain unfixed vulnerabilities of the chosen risk level in the selected time range.","title":"The \u201cScanner\u201d Dashboard"},{"location":"en/user-guides/cloud-ui/dashboard/waf/","text":"The \u201cWAF\u201d Dashboard \u00b6 This dashboard provides you with information related to web firewall operations: traffic statistics data about applications under attack blacklisted IP addresses When working with this dashboard, you can choose the date range you are interested in (default choice: one month prior to the current date). This choice influences all information on the dashboard. choose the application you are interested in (default choice: all applications). This choice influences the displayed traffic statistics. To use this filter, configure a few applications first. Traffic Statistics \u00b6 Available statistics are the number of requests, hits , and blocked hits in the current month the real-time speed at which requests and hits are encountered graphs for the chosen date range: the amount of traffic the number of requests, hits, and incidents the approximated cost of the attacks Hover the mouse pointer over a point on the graph to get extra information about exact numbers of traffic and events in the particular period of time. To view detailed data, click the point on the graph. The Events tab will open. The table on this tab will contain events or incidents in the selected period. Data About Applications Under Attack \u00b6 For each configured application, the dashboard shows the number of detected incidents, and the number of hits. You can filter the data displayed on the pie chart. To do this, check or uncheck the checkbox to the left of the application's name. Blacklisted IP Addresses \u00b6 This part of the dashboard shows a few blacklisted IP addresses. A reason for blocking and the time until unblocking are shown for each entry in the list. Press the Full list button to be redirected to the Blacklist tab , where you can view the full blacklist and manage its entries. Also, there is a graph on the right that shows statistics on IP address blocking and unblocking events.","title":"The \u201cWAF\u201d Dashboard"},{"location":"en/user-guides/cloud-ui/dashboard/waf/#the-waf-dashboard","text":"This dashboard provides you with information related to web firewall operations: traffic statistics data about applications under attack blacklisted IP addresses When working with this dashboard, you can choose the date range you are interested in (default choice: one month prior to the current date). This choice influences all information on the dashboard. choose the application you are interested in (default choice: all applications). This choice influences the displayed traffic statistics. To use this filter, configure a few applications first.","title":"The \u201cWAF\u201d Dashboard"},{"location":"en/user-guides/cloud-ui/dashboard/waf/#traffic-statistics","text":"Available statistics are the number of requests, hits , and blocked hits in the current month the real-time speed at which requests and hits are encountered graphs for the chosen date range: the amount of traffic the number of requests, hits, and incidents the approximated cost of the attacks Hover the mouse pointer over a point on the graph to get extra information about exact numbers of traffic and events in the particular period of time. To view detailed data, click the point on the graph. The Events tab will open. The table on this tab will contain events or incidents in the selected period.","title":"Traffic Statistics"},{"location":"en/user-guides/cloud-ui/dashboard/waf/#data-about-applications-under-attack","text":"For each configured application, the dashboard shows the number of detected incidents, and the number of hits. You can filter the data displayed on the pie chart. To do this, check or uncheck the checkbox to the left of the application's name.","title":"Data About Applications Under Attack"},{"location":"en/user-guides/cloud-ui/dashboard/waf/#blacklisted-ip-addresses","text":"This part of the dashboard shows a few blacklisted IP addresses. A reason for blocking and the time until unblocking are shown for each entry in the list. Press the Full list button to be redirected to the Blacklist tab , where you can view the full blacklist and manage its entries. Also, there is a graph on the right that shows statistics on IP address blocking and unblocking events.","title":"Blacklisted IP Addresses"},{"location":"en/user-guides/cloud-ui/events/analyze-attack/","text":"Analyzing Attacks \u00b6 You can check attacks in the Events tab of the Wallarm interface. Wallarm automatically groups associated malicious requests into one entity \u2014an attack. Analyze an Attack \u00b6 You can get information about an attack by investigating all the table columns described in \u201cChecking Attacks and Incidents.\u201d Analyze Requests in an Attack \u00b6 Select an attack. Click the number in the Requests column. Clicking the number will unfold all requests in the selected attack. Each request displays the associated information in the following columns: Date : Date and time of the request. Payload : Attack vector . Clicking the value in the payload column displays reference information on the attack type. Source : The IP address from which the request originated. Clicking the IP address adds the IP address value into the search field. If Wallarm can determine which data center the given IP address belongs to, then the corresponding tag will be displayed in the column: the \u201cAWS\u201d tag for Amazon, the \u201cGCP\u201d tag for Google and the \u201cAzure\u201d tag for Microsoft data centers. If the IP address belongs to the Tor network, then the \u201cTor\u201d tag will be shown in the column below the address. Status : The server's response status code from the request. Size : The server's response size. Time : The server's response time. If the attack is happening at the current moment, the \u201cnow\u201d label is shown under the request graph. Analyze a Request in Raw Format \u00b6 The raw format of a request is the maximum possible level of detail. Select an attack. Click the number in the Requests column. Click the arrow next to the date of the request. The Wallarm interface will display the request in its raw format. See also Working with false attacks","title":"Analyzing Attacks"},{"location":"en/user-guides/cloud-ui/events/analyze-attack/#analyzing-attacks","text":"You can check attacks in the Events tab of the Wallarm interface. Wallarm automatically groups associated malicious requests into one entity \u2014an attack.","title":"Analyzing Attacks"},{"location":"en/user-guides/cloud-ui/events/analyze-attack/#analyze-an-attack","text":"You can get information about an attack by investigating all the table columns described in \u201cChecking Attacks and Incidents.\u201d","title":"Analyze an Attack"},{"location":"en/user-guides/cloud-ui/events/analyze-attack/#analyze-requests-in-an-attack","text":"Select an attack. Click the number in the Requests column. Clicking the number will unfold all requests in the selected attack. Each request displays the associated information in the following columns: Date : Date and time of the request. Payload : Attack vector . Clicking the value in the payload column displays reference information on the attack type. Source : The IP address from which the request originated. Clicking the IP address adds the IP address value into the search field. If Wallarm can determine which data center the given IP address belongs to, then the corresponding tag will be displayed in the column: the \u201cAWS\u201d tag for Amazon, the \u201cGCP\u201d tag for Google and the \u201cAzure\u201d tag for Microsoft data centers. If the IP address belongs to the Tor network, then the \u201cTor\u201d tag will be shown in the column below the address. Status : The server's response status code from the request. Size : The server's response size. Time : The server's response time. If the attack is happening at the current moment, the \u201cnow\u201d label is shown under the request graph.","title":"Analyze Requests in an Attack"},{"location":"en/user-guides/cloud-ui/events/analyze-attack/#analyze-a-request-in-raw-format","text":"The raw format of a request is the maximum possible level of detail. Select an attack. Click the number in the Requests column. Click the arrow next to the date of the request. The Wallarm interface will display the request in its raw format. See also Working with false attacks","title":"Analyze a Request in Raw Format"},{"location":"en/user-guides/cloud-ui/events/check-attack/","text":"Checking Events \u00b6 You can check attacks, incidents, and vulnerabilities in the Events tab of the Wallarm interface. This tab displays data in the following tabs: The Attacks tab displays all groups of associated malicious requests. The Incidents tab displays all the malicious requests that exploit existing vulnerabilities. The Vulnerabilities tab displays all the discovered errors made when building or implementing a web application that can lead to an information security risk. You can use the search field or manually set the data period. The Attacks Tab \u00b6 The Attacks tab displays information in the following columns: Date : The date and time of the malicious request. If several requests of the same type were detected at short intervals, the attack duration appears under the date. Duration is the time period between the first request of a certain type and the last request of the same type in the specified timeframe. If the attack is happening at the current moment, the \u201cnow\u201d label will appear in a small red font. Requests : The number of requests in the attack in the specified time frame. Payloads : The number of requests of the most encountered malicious code type and its name. The number in a smaller font displayed under the main number shows the total number of requests of the same type in the attack during the specified timeframe. Top IP/Source : The IP address from which the malicious requests originated. When the malicious requests originate from several IP addresses, the interface shows the IP address responsible for the most requests. The number in smaller black font displayed under the main number shows the total number of IP addresses from which the requests in the same attack originated during the specified timeframe. The number in small grey font shows the total number of IP addresses from which the requests in the same attack originated during the entire time. If Wallarm can determine which data center the given IP addresses belong to, then one or more corresponding tags will be displayed in the column: the \u201cAWS\u201d tag for Amazon, the \u201cGCP\u201d tag for Google and the \u201cAzure\u201d tag for Microsoft data centers. If the attack's source is the Tor network, then the \u201cTor\u201d tag will be shown in the column. Domain : The domain that the request targeted. The line in a smaller font displayed under the domain is the path that the request targeted. Status : The server's response status code on the request. When there are several response status codes, the most frequent one is displayed. The number in a smaller font displayed under the main number shows the total number of different response status codes of the protected resource on the selected attack in the specified timeframe. Parameter : The malicious request's parameters. Verification : The attack verification status. You can click the \u201c Sort by latest hit \u201d switch to sort attacks by the time of the last request from the most recent one to the oldest one. The Incidents Tab \u00b6 The Incidents tab displays information similarly to the Attacks tab, except for the last column. The table of incidents does not have the Verification column, but the Vulnerabilities column instead. The Vulnerabilities column displays the vulnerability, that the corresponding incident exploited. Clicking on the corresponding vulnerability brings you to its detailed description and instructions on how to fix it. You can click the \u201c Sort by latest hit \u201d switch to sort incidents by the time of the last request from the latest one to the oldest one. The Vulnerabilities tab \u00b6 The Vulnerabilities tab displays information in the following columns: Date : The date and time of vulnerability discovery. Risk : The danger level of the vulnerability. Target : The side to be the victim in the case of vulnerability exploitation. Type : The type of the malicious code that exploits the vulnerability. Domain : The domain that the vulnerability was discovered at. ID : The unique identifier of the vulnerability in the Wallarm system. Title : The title of the vulnerability. Events that are Currently Happening \u00b6 You can check events in real time. If your company resources are receiving malicious requests, the Wallarm interface will display the following elements: The number of events that have happened in the last 5 minutes, which will be displayed by the event counter next to the Events tab. The now label, which is shown under the event date in the \u201cattacks\u201d or the \u201cincidents\u201d table. You may also add the now keyword to the search field to only display those events happening at the moment. attacks now \u2014only display attacks happening right now. incidents now \u2014only display incidents happening right now. attacks incidents now \u2014only display attacks and incidents happening right now. See also Using search Using filters Checking vulnerabilities","title":"Checking Events"},{"location":"en/user-guides/cloud-ui/events/check-attack/#checking-events","text":"You can check attacks, incidents, and vulnerabilities in the Events tab of the Wallarm interface. This tab displays data in the following tabs: The Attacks tab displays all groups of associated malicious requests. The Incidents tab displays all the malicious requests that exploit existing vulnerabilities. The Vulnerabilities tab displays all the discovered errors made when building or implementing a web application that can lead to an information security risk. You can use the search field or manually set the data period.","title":"Checking Events"},{"location":"en/user-guides/cloud-ui/events/check-attack/#the-attacks-tab","text":"The Attacks tab displays information in the following columns: Date : The date and time of the malicious request. If several requests of the same type were detected at short intervals, the attack duration appears under the date. Duration is the time period between the first request of a certain type and the last request of the same type in the specified timeframe. If the attack is happening at the current moment, the \u201cnow\u201d label will appear in a small red font. Requests : The number of requests in the attack in the specified time frame. Payloads : The number of requests of the most encountered malicious code type and its name. The number in a smaller font displayed under the main number shows the total number of requests of the same type in the attack during the specified timeframe. Top IP/Source : The IP address from which the malicious requests originated. When the malicious requests originate from several IP addresses, the interface shows the IP address responsible for the most requests. The number in smaller black font displayed under the main number shows the total number of IP addresses from which the requests in the same attack originated during the specified timeframe. The number in small grey font shows the total number of IP addresses from which the requests in the same attack originated during the entire time. If Wallarm can determine which data center the given IP addresses belong to, then one or more corresponding tags will be displayed in the column: the \u201cAWS\u201d tag for Amazon, the \u201cGCP\u201d tag for Google and the \u201cAzure\u201d tag for Microsoft data centers. If the attack's source is the Tor network, then the \u201cTor\u201d tag will be shown in the column. Domain : The domain that the request targeted. The line in a smaller font displayed under the domain is the path that the request targeted. Status : The server's response status code on the request. When there are several response status codes, the most frequent one is displayed. The number in a smaller font displayed under the main number shows the total number of different response status codes of the protected resource on the selected attack in the specified timeframe. Parameter : The malicious request's parameters. Verification : The attack verification status. You can click the \u201c Sort by latest hit \u201d switch to sort attacks by the time of the last request from the most recent one to the oldest one.","title":"The Attacks Tab"},{"location":"en/user-guides/cloud-ui/events/check-attack/#the-incidents-tab","text":"The Incidents tab displays information similarly to the Attacks tab, except for the last column. The table of incidents does not have the Verification column, but the Vulnerabilities column instead. The Vulnerabilities column displays the vulnerability, that the corresponding incident exploited. Clicking on the corresponding vulnerability brings you to its detailed description and instructions on how to fix it. You can click the \u201c Sort by latest hit \u201d switch to sort incidents by the time of the last request from the latest one to the oldest one.","title":"The Incidents Tab"},{"location":"en/user-guides/cloud-ui/events/check-attack/#the-vulnerabilities-tab","text":"The Vulnerabilities tab displays information in the following columns: Date : The date and time of vulnerability discovery. Risk : The danger level of the vulnerability. Target : The side to be the victim in the case of vulnerability exploitation. Type : The type of the malicious code that exploits the vulnerability. Domain : The domain that the vulnerability was discovered at. ID : The unique identifier of the vulnerability in the Wallarm system. Title : The title of the vulnerability.","title":"The Vulnerabilities tab"},{"location":"en/user-guides/cloud-ui/events/check-attack/#events-that-are-currently-happening","text":"You can check events in real time. If your company resources are receiving malicious requests, the Wallarm interface will display the following elements: The number of events that have happened in the last 5 minutes, which will be displayed by the event counter next to the Events tab. The now label, which is shown under the event date in the \u201cattacks\u201d or the \u201cincidents\u201d table. You may also add the now keyword to the search field to only display those events happening at the moment. attacks now \u2014only display attacks happening right now. incidents now \u2014only display incidents happening right now. attacks incidents now \u2014only display attacks and incidents happening right now. See also Using search Using filters Checking vulnerabilities","title":"Events that are Currently Happening"},{"location":"en/user-guides/cloud-ui/events/false-attack/","text":"Working with False Attacks \u00b6 A false attack is a valid request erroneously qualified as an attack. After analyzing an attack, you may conclude that the attack is a false positive. Mark an Attack as a False Positive \u00b6 Select an attack. Click a number in the Requests column. Click False in the Actions column. Wallarm will remove all the requests associated with this attack and reconfigure the traffic filtration rules. These requests will not be detected as an attack from now on. See also Analyzing attacks","title":"Working with False Attacks"},{"location":"en/user-guides/cloud-ui/events/false-attack/#working-with-false-attacks","text":"A false attack is a valid request erroneously qualified as an attack. After analyzing an attack, you may conclude that the attack is a false positive.","title":"Working with False Attacks"},{"location":"en/user-guides/cloud-ui/events/false-attack/#mark-an-attack-as-a-false-positive","text":"Select an attack. Click a number in the Requests column. Click False in the Actions column. Wallarm will remove all the requests associated with this attack and reconfigure the traffic filtration rules. These requests will not be detected as an attack from now on. See also Analyzing attacks","title":"Mark an Attack as a False Positive"},{"location":"en/user-guides/cloud-ui/events/verify-attack/","text":"Verifying Attacks \u00b6 Wallarm automatically rechecks attacks. You can check the attack verification status and force an attack recheck on the Events tab. Check the Attack Verification Status \u00b6 Click the Events tab. Check the status in the \"Verification\" column. Attack Verification Status Legend \u00b6 Verified : The attack has been verified. Error : An attempt to verify an attack type that does not support verification. Forced : The attack has a raised priority in the verification queue. Scheduled : The attack is queued for verification. Could not connect to the server : It is not possible to access the server at this time. Forcing an Attack Verification \u00b6 Select an attack. Click the status sign in the \"Verification\" column. Click Force verification . Wallarm will raise the priority of the attack verification in the queue. Attack Types that Do Not Support Verification \u00b6 Attacks of the following types do not support verification: Brute-force . Forced browsing . Attacks with a request processing limit. Attacks for which the vulnerabilities have already been closed. Attacks that do not contain enough data for verification.","title":"Verifying Attacks"},{"location":"en/user-guides/cloud-ui/events/verify-attack/#verifying-attacks","text":"Wallarm automatically rechecks attacks. You can check the attack verification status and force an attack recheck on the Events tab.","title":"Verifying Attacks"},{"location":"en/user-guides/cloud-ui/events/verify-attack/#check-the-attack-verification-status","text":"Click the Events tab. Check the status in the \"Verification\" column.","title":"Check the Attack Verification Status"},{"location":"en/user-guides/cloud-ui/events/verify-attack/#attack-verification-status-legend","text":"Verified : The attack has been verified. Error : An attempt to verify an attack type that does not support verification. Forced : The attack has a raised priority in the verification queue. Scheduled : The attack is queued for verification. Could not connect to the server : It is not possible to access the server at this time.","title":"Attack Verification Status Legend"},{"location":"en/user-guides/cloud-ui/events/verify-attack/#forcing-an-attack-verification","text":"Select an attack. Click the status sign in the \"Verification\" column. Click Force verification . Wallarm will raise the priority of the attack verification in the queue.","title":"Forcing an Attack Verification"},{"location":"en/user-guides/cloud-ui/events/verify-attack/#attack-types-that-do-not-support-verification","text":"Attacks of the following types do not support verification: Brute-force . Forced browsing . Attacks with a request processing limit. Attacks for which the vulnerabilities have already been closed. Attacks that do not contain enough data for verification.","title":"Attack Types that Do Not Support Verification"},{"location":"en/user-guides/cloud-ui/nodes/create-node/","text":"Creating and Managing a Node \u00b6 Creating a Node \u00b6 To create a new node: Click the Create new node button. Enter the name of the new node and choose its type (WAF or FAST). Choose the installation type (for WAF type nodes only). Click the Create button. Managing the Nodes Displayed as Tickets \u00b6 You can open the dropdown menu by clicking the button in the upper-right corner of the ticket. The menu allows you to perform the following operations: Copy token : adds the node token to your clipboard (only for filter nodes installed on the cloud or FAST nodes). Regenerate token : creates a new token for the node (only for filter nodes installed on the cloud or FAST nodes). Delete : deletes the node. Managing the Nodes Displayed in Tables \u00b6 You can open the dropdown menu by clicking the button in the right corner of the node entry. The menu allows you to perform the following operations: Copy token : adds the node token to your clipboard (only for nodes installed on the cloud or FAST nodes). Regenerate token : creates a new token for the node (only for nodes installed on the cloud or FAST nodes). Delete : deletes the node. Bulk Deleting the Nodes Displayed in Tables \u00b6 To bulk delete nodes: Click the checkboxes next to the nodes you want to delete. Click Delete to remove the selected nodes.","title":"Creating and Managing a Node"},{"location":"en/user-guides/cloud-ui/nodes/create-node/#creating-and-managing-a-node","text":"","title":"Creating and Managing a Node"},{"location":"en/user-guides/cloud-ui/nodes/create-node/#creating-a-node","text":"To create a new node: Click the Create new node button. Enter the name of the new node and choose its type (WAF or FAST). Choose the installation type (for WAF type nodes only). Click the Create button.","title":"Creating a Node"},{"location":"en/user-guides/cloud-ui/nodes/create-node/#managing-the-nodes-displayed-as-tickets","text":"You can open the dropdown menu by clicking the button in the upper-right corner of the ticket. The menu allows you to perform the following operations: Copy token : adds the node token to your clipboard (only for filter nodes installed on the cloud or FAST nodes). Regenerate token : creates a new token for the node (only for filter nodes installed on the cloud or FAST nodes). Delete : deletes the node.","title":"Managing the Nodes Displayed as Tickets"},{"location":"en/user-guides/cloud-ui/nodes/create-node/#managing-the-nodes-displayed-in-tables","text":"You can open the dropdown menu by clicking the button in the right corner of the node entry. The menu allows you to perform the following operations: Copy token : adds the node token to your clipboard (only for nodes installed on the cloud or FAST nodes). Regenerate token : creates a new token for the node (only for nodes installed on the cloud or FAST nodes). Delete : deletes the node.","title":"Managing the Nodes Displayed in Tables"},{"location":"en/user-guides/cloud-ui/nodes/create-node/#bulk-deleting-the-nodes-displayed-in-tables","text":"To bulk delete nodes: Click the checkboxes next to the nodes you want to delete. Click Delete to remove the selected nodes.","title":"Bulk Deleting the Nodes Displayed in Tables"},{"location":"en/user-guides/cloud-ui/nodes/nodes/","text":"Nodes Overview \u00b6 You can check existing nodes and edit the nodes list on the Nodes tab of the Wallarm interface. If you are working with multiple Wallarm products (e.g., WAF and FAST), the information on nodes will be displayed in tabs, which correspond to each of the products. You can navigate between the nodes of the products by clicking these tabs. Tickets Nodes Display \u00b6 If you have less than 10 nodes, the information on them will be displayed in tickets. Filter Nodes \u00b6 Each ticket in the WAF nodes tab contains the following information: The name that was given to the node upon creation. The node's universally unique identifier (only for nodes that are not installed on the cloud). The number of active nodes and the total number of nodes connected with a single token (only for nodes that are installed on the cloud). The node's creation date. Last synchronization date or time. The average number of requests per second received by the node in one minute. The Copy token link. Upon pressing this link, the node token is copied to the clipboard (only for nodes that are installed on the cloud). If the node was installed on the cloud, the cloud icon will be shown next to the node's name. FAST Nodes \u00b6 Each ticket in the FAST nodes tab contains the following information: The name that was given to the node upon creation. The node's creation date. The Copy token link. Upon pressing this link, the node token is copied to the clipboard. If the node was installed on the cloud, the cloud icon will be shown next to the node's name. Table Nodes Display \u00b6 If you have 10 or more nodes, the information on them will be displayed in tables. Filter Nodes \u00b6 The WAF nodes table displays information in the following columns: Hostname : the name that was given to the node upon creation. The number of active nodes is displayed in small-sized grey font, if multiple nodes were grouped into one entry in the table. RPS : the average number of requests per second received by the node in one minute. Requests this month : the number of requests received by the node in the current month. IP : the node's IP address. Node UUID : the universally unique identifier of the node (only for nodes that are not installed on the cloud). Synced : the last synchronization date or time. Installed : the node's creation date. Actions : the menu button containing possible operations for the node. If the node was installed on the cloud, the cloud icon will be shown next to the node's name. FAST Nodes \u00b6 The FAST nodes table displays information in the following columns: Hostname : the name that was given to the node upon creation. Token : the token that was generated for the node. IP : the node's IP address. Installed : the node's creation date. Actions : the menu button containing possible operations for the node. If the node was installed on the cloud, the cloud icon will be shown next to the node's name. See also Creating and managing nodes","title":"Nodes Overview"},{"location":"en/user-guides/cloud-ui/nodes/nodes/#nodes-overview","text":"You can check existing nodes and edit the nodes list on the Nodes tab of the Wallarm interface. If you are working with multiple Wallarm products (e.g., WAF and FAST), the information on nodes will be displayed in tabs, which correspond to each of the products. You can navigate between the nodes of the products by clicking these tabs.","title":"Nodes Overview"},{"location":"en/user-guides/cloud-ui/nodes/nodes/#tickets-nodes-display","text":"If you have less than 10 nodes, the information on them will be displayed in tickets.","title":"Tickets Nodes Display"},{"location":"en/user-guides/cloud-ui/nodes/nodes/#filter-nodes","text":"Each ticket in the WAF nodes tab contains the following information: The name that was given to the node upon creation. The node's universally unique identifier (only for nodes that are not installed on the cloud). The number of active nodes and the total number of nodes connected with a single token (only for nodes that are installed on the cloud). The node's creation date. Last synchronization date or time. The average number of requests per second received by the node in one minute. The Copy token link. Upon pressing this link, the node token is copied to the clipboard (only for nodes that are installed on the cloud). If the node was installed on the cloud, the cloud icon will be shown next to the node's name.","title":"Filter Nodes"},{"location":"en/user-guides/cloud-ui/nodes/nodes/#fast-nodes","text":"Each ticket in the FAST nodes tab contains the following information: The name that was given to the node upon creation. The node's creation date. The Copy token link. Upon pressing this link, the node token is copied to the clipboard. If the node was installed on the cloud, the cloud icon will be shown next to the node's name.","title":"FAST Nodes"},{"location":"en/user-guides/cloud-ui/nodes/nodes/#table-nodes-display","text":"If you have 10 or more nodes, the information on them will be displayed in tables.","title":"Table Nodes Display"},{"location":"en/user-guides/cloud-ui/nodes/nodes/#filter-nodes_1","text":"The WAF nodes table displays information in the following columns: Hostname : the name that was given to the node upon creation. The number of active nodes is displayed in small-sized grey font, if multiple nodes were grouped into one entry in the table. RPS : the average number of requests per second received by the node in one minute. Requests this month : the number of requests received by the node in the current month. IP : the node's IP address. Node UUID : the universally unique identifier of the node (only for nodes that are not installed on the cloud). Synced : the last synchronization date or time. Installed : the node's creation date. Actions : the menu button containing possible operations for the node. If the node was installed on the cloud, the cloud icon will be shown next to the node's name.","title":"Filter Nodes"},{"location":"en/user-guides/cloud-ui/nodes/nodes/#fast-nodes_1","text":"The FAST nodes table displays information in the following columns: Hostname : the name that was given to the node upon creation. Token : the token that was generated for the node. IP : the node's IP address. Installed : the node's creation date. Actions : the menu button containing possible operations for the node. If the node was installed on the cloud, the cloud icon will be shown next to the node's name. See also Creating and managing nodes","title":"FAST Nodes"},{"location":"en/user-guides/cloud-ui/rules/add-rule/","text":"Adding Rules in the Application Profile \u00b6 To add a new rule, go to the Profile & Rules tab. Rules can be added to both existing and new branches. They can be created from scratch or based on one of the existing branches. To add a rule to an existing branch, click Add rule (the button will appear in the pop-up menu on the right after hovering the mouse cursor over the branch description line). You can also perform this operation on the rule page of this branch. If necessary, it is possible to modify the branch to which a rule will be added. For this, click on the If request is clause in the rule-adding form and make changes to the branch description conditions. If a new branch is created, it will appear on the screen, and the application structure view will be updated. Branch Description \u00b6 A branch description consists of a set of conditions for various parameters that an HTTP request must fulfill; otherwise, the rules associated with this branch will not be applied. Each line in the If request is section of the rule-adding form refers to a separate condition comprised of three fields: point, type, and comparison argument. The rules described in the branch are only applied to the request if all the conditions are fulfilled. The point field indicates which parameter value should be extracted from the request for comparison. At present, not all of the points that can be analyzed by the filter node, are supported. The following points are currently supported: instance : application ID. proto : HTTP protocol version (1.0, 1.1, 2.0, ...). scheme : http or https. url : full URL of the request in the same form as it was passed in the first line of the HTTP request. path , action_name , action_ext : URL elements. The details are provided in the request analysis description . get : GET parameters in the request. header : request headers. method : request methods. Condition categories: equal : point value must match precisely with the comparison argument. regex : point value must match the regular expression. Note that the system uses a limited subset of the regular expression syntax . absent : the request should not contain the designated point. In this case, the comparison argument is not used. Rule \u00b6 The added request processing rule is described in the Then section. The following rules are supported: Set the filter mode . Mask sensitive data . Apply a virtual patch . User-defined detection rules .","title":"Adding Rules in the Application Profile"},{"location":"en/user-guides/cloud-ui/rules/add-rule/#adding-rules-in-the-application-profile","text":"To add a new rule, go to the Profile & Rules tab. Rules can be added to both existing and new branches. They can be created from scratch or based on one of the existing branches. To add a rule to an existing branch, click Add rule (the button will appear in the pop-up menu on the right after hovering the mouse cursor over the branch description line). You can also perform this operation on the rule page of this branch. If necessary, it is possible to modify the branch to which a rule will be added. For this, click on the If request is clause in the rule-adding form and make changes to the branch description conditions. If a new branch is created, it will appear on the screen, and the application structure view will be updated.","title":"Adding Rules in the Application Profile"},{"location":"en/user-guides/cloud-ui/rules/add-rule/#branch-description","text":"A branch description consists of a set of conditions for various parameters that an HTTP request must fulfill; otherwise, the rules associated with this branch will not be applied. Each line in the If request is section of the rule-adding form refers to a separate condition comprised of three fields: point, type, and comparison argument. The rules described in the branch are only applied to the request if all the conditions are fulfilled. The point field indicates which parameter value should be extracted from the request for comparison. At present, not all of the points that can be analyzed by the filter node, are supported. The following points are currently supported: instance : application ID. proto : HTTP protocol version (1.0, 1.1, 2.0, ...). scheme : http or https. url : full URL of the request in the same form as it was passed in the first line of the HTTP request. path , action_name , action_ext : URL elements. The details are provided in the request analysis description . get : GET parameters in the request. header : request headers. method : request methods. Condition categories: equal : point value must match precisely with the comparison argument. regex : point value must match the regular expression. Note that the system uses a limited subset of the regular expression syntax . absent : the request should not contain the designated point. In this case, the comparison argument is not used.","title":"Branch Description"},{"location":"en/user-guides/cloud-ui/rules/add-rule/#rule","text":"The added request processing rule is described in the Then section. The following rules are supported: Set the filter mode . Mask sensitive data . Apply a virtual patch . User-defined detection rules .","title":"Rule"},{"location":"en/user-guides/cloud-ui/rules/compiling/","text":"Compilation and Update of Security Rules \u00b6 To analyze requests and detect attacks, the filtering node relies on the LOM (Local Object Module), which contains specially formatted rules from application profiles. Data in the LOM file is optimized to accelerate request analysis. #### Warning:: Changes in the analysis rules are not applied instantly Before the rules can be applied, they need to be processed which means * The LOM file is compiled * The newly compiled version of the LOM is downloaded from the Wallarm Cloud to every Wallarm Node The process of compiling the LOM typically takes from a few minutes for the simple application to up to an hour for resources with complex structures. Monitoring the progress of LOM assembly is currently unavailable, although it is on our roadmap. One indicator of the LOM processing progress is when and how it gets downloaded to the filter nodes. This information is accessible from the Nodes tab. The LOM downloads happen during filter nodes with Wallarm Cloud synchronization. This synchronization is launched every 15 minutes. You can verify the status of LOM downloads in the log found at /var/log/wallarm/syncnode.log .","title":"Compilation and Update Of Security Rules"},{"location":"en/user-guides/cloud-ui/rules/compiling/#compilation-and-update-of-security-rules","text":"To analyze requests and detect attacks, the filtering node relies on the LOM (Local Object Module), which contains specially formatted rules from application profiles. Data in the LOM file is optimized to accelerate request analysis. #### Warning:: Changes in the analysis rules are not applied instantly Before the rules can be applied, they need to be processed which means * The LOM file is compiled * The newly compiled version of the LOM is downloaded from the Wallarm Cloud to every Wallarm Node The process of compiling the LOM typically takes from a few minutes for the simple application to up to an hour for resources with complex structures. Monitoring the progress of LOM assembly is currently unavailable, although it is on our roadmap. One indicator of the LOM processing progress is when and how it gets downloaded to the filter nodes. This information is accessible from the Nodes tab. The LOM downloads happen during filter nodes with Wallarm Cloud synchronization. This synchronization is launched every 15 minutes. You can verify the status of LOM downloads in the log found at /var/log/wallarm/syncnode.log .","title":"Compilation and Update of Security Rules"},{"location":"en/user-guides/cloud-ui/rules/intro/","text":"Application Profile Rules \u00b6 On the Profile & Rules tab you may review and change the rules for handling requests enabled for the current application profile. The application profile is a collection of known information about protected applications. It is used to fine-tune the behavior of the system during the analysis of requests and their further processing in the post-analysis module as well as in the cloud. For a better understanding of how the traffic processing rules are applied, it is advisable to learn how the filter node analyzes the requests . One important thing about making changes to the rules is that these changes don't take effect immediately. It may take some time to compile the rules and download them into filter nodes. Terminology \u00b6 Point \u00b6 Each parameter of the HTTP request in the Wallarm system is described with a sequence of filters applied for request processing, e.g., headers, body, URL, Base64, etc. This sequence is called the point . Request processing filters are also called parsers. Rule Branch \u00b6 The set of HTTP request parameters and their conditions is called the branch . If the conditions are fulfilled, the rules related to this branch will be applied. For example, the rule branch example.com/**/*.* describes the conditions matching all requests to any URL of the domain example.com . Endpoint (Endpoint Branch) \u00b6 A branch without nested rule branches is called an endpoint branch . Ideally, an application endpoint corresponds to one business function of the protected application. For instance, such business function as authorization can be an endpoint rule branch of example.com/login.php . Rule \u00b6 A request processing setting for the filter node, the post-analysis module, or the cloud is called a rule . Processing rules are linked to the branches or endpoints. A rule is applied to a request only if the request matches all the conditions described in the branch.","title":"Application Profile Rules"},{"location":"en/user-guides/cloud-ui/rules/intro/#application-profile-rules","text":"On the Profile & Rules tab you may review and change the rules for handling requests enabled for the current application profile. The application profile is a collection of known information about protected applications. It is used to fine-tune the behavior of the system during the analysis of requests and their further processing in the post-analysis module as well as in the cloud. For a better understanding of how the traffic processing rules are applied, it is advisable to learn how the filter node analyzes the requests . One important thing about making changes to the rules is that these changes don't take effect immediately. It may take some time to compile the rules and download them into filter nodes.","title":"Application Profile Rules"},{"location":"en/user-guides/cloud-ui/rules/intro/#terminology","text":"","title":"Terminology"},{"location":"en/user-guides/cloud-ui/rules/intro/#point","text":"Each parameter of the HTTP request in the Wallarm system is described with a sequence of filters applied for request processing, e.g., headers, body, URL, Base64, etc. This sequence is called the point . Request processing filters are also called parsers.","title":"Point"},{"location":"en/user-guides/cloud-ui/rules/intro/#rule-branch","text":"The set of HTTP request parameters and their conditions is called the branch . If the conditions are fulfilled, the rules related to this branch will be applied. For example, the rule branch example.com/**/*.* describes the conditions matching all requests to any URL of the domain example.com .","title":"Rule Branch"},{"location":"en/user-guides/cloud-ui/rules/intro/#endpoint-endpoint-branch","text":"A branch without nested rule branches is called an endpoint branch . Ideally, an application endpoint corresponds to one business function of the protected application. For instance, such business function as authorization can be an endpoint rule branch of example.com/login.php .","title":"Endpoint (Endpoint Branch)"},{"location":"en/user-guides/cloud-ui/rules/intro/#rule","text":"A request processing setting for the filter node, the post-analysis module, or the cloud is called a rule . Processing rules are linked to the branches or endpoints. A rule is applied to a request only if the request matches all the conditions described in the branch.","title":"Rule"},{"location":"en/user-guides/cloud-ui/rules/regex-rule/","text":"User-Defined Detection Rules \u00b6 In some cases, it may prove useful to add a signature for attack detection manually or to create a so-called virtual patch . As such, Wallarm does not use regular expressions to detect attacks, but it does allow users to add additional signatures based on regular expressions. Adding a New Detection Rule \u00b6 To do this, you need to create the rule Define a request as an attack based on a regular expression and fill in the fields: Regex : regular expression (signature). If the value of the following parameter matches the expression, that request is detected as an attack. Note that the system supports a limited subset of the regular expression syntax . Attack : the type of attack that will be detected when the parameter value in the request matches the regular expression. Experimental : this flag allows you to safely check the triggering of a regular expression without blocking requests. The requests won't be blocked even when the filter node is set to the blocking mode. These requests will be considered as attacks detected by the experimental method. They can be accessed using search query experimental attacks . in this part of request : determines a point in the request, where the system should detect the corresponding attacks. Example: Blocking All Headers with an Incorrect X-Authentication Header \u00b6 If the following conditions take place: the application is accessible at the domain example.com the application uses the X-Authentication header for user authentication the header format is 32 hex symbols Then , to create a rule for rejecting incorrect format tokens: Go to the Rules tab Find the branch for example.com/**/*.* and click Add rule Select Define as an attack on the basis of a regular expression Set Regex value as [^0-9a-f]|^.{33,}$|^.{0,31}$ Choose Virtual patch as the type of Attack Set the point Header X-AUTHENTICATION Click Create Partial Disabling of a New Detection Rule \u00b6 If the created rule should be partially disabled for a particular branch, this can easily be done by creating the rule Ignore regular expression with the following fields: Regex ID : identifiers of the previously created regular expressions that must be ignored. in this part of request : indicates the parameter that requires setting up an exception. Getting an ID of a Regular Expression \u00b6 Identifier is generated automatically when you add a new regular expression rule. To get an ID of a regular expression, proceed to the following steps: In the Rules tab click the button All rules and select Define a request as an attack based on a regular expression from the drop-down list. Select the branch which the desired regular expression was set for. Select the group of rules which contains the desired regular expression. Click the desired regular expression entry. The Regex ID field on the appeared panel contains the desired regular expression identifier. Click the button next to the field to copy it to the clipboard. Example: Permit an Incorrect X-Authentication Header for a Designated URL. \u00b6 Let's say you have a script at example.com/test.php , and you want to change the format of the tokens for it. To create the relevant rule: Go to the Rules tab Find or create the branch for example.com/test.php and click Add rule Choose Ignore regular expressions Enter the ID of the rule that you want to disable into the Regex ID field Set the point Header X-AUTHENTICATION Click Create","title":"User-Defined Detection Rules"},{"location":"en/user-guides/cloud-ui/rules/regex-rule/#user-defined-detection-rules","text":"In some cases, it may prove useful to add a signature for attack detection manually or to create a so-called virtual patch . As such, Wallarm does not use regular expressions to detect attacks, but it does allow users to add additional signatures based on regular expressions.","title":"User-Defined Detection Rules"},{"location":"en/user-guides/cloud-ui/rules/regex-rule/#adding-a-new-detection-rule","text":"To do this, you need to create the rule Define a request as an attack based on a regular expression and fill in the fields: Regex : regular expression (signature). If the value of the following parameter matches the expression, that request is detected as an attack. Note that the system supports a limited subset of the regular expression syntax . Attack : the type of attack that will be detected when the parameter value in the request matches the regular expression. Experimental : this flag allows you to safely check the triggering of a regular expression without blocking requests. The requests won't be blocked even when the filter node is set to the blocking mode. These requests will be considered as attacks detected by the experimental method. They can be accessed using search query experimental attacks . in this part of request : determines a point in the request, where the system should detect the corresponding attacks.","title":"Adding a New Detection Rule"},{"location":"en/user-guides/cloud-ui/rules/regex-rule/#example-blocking-all-headers-with-an-incorrect-x-authentication-header","text":"If the following conditions take place: the application is accessible at the domain example.com the application uses the X-Authentication header for user authentication the header format is 32 hex symbols Then , to create a rule for rejecting incorrect format tokens: Go to the Rules tab Find the branch for example.com/**/*.* and click Add rule Select Define as an attack on the basis of a regular expression Set Regex value as [^0-9a-f]|^.{33,}$|^.{0,31}$ Choose Virtual patch as the type of Attack Set the point Header X-AUTHENTICATION Click Create","title":"Example: Blocking All Headers with an Incorrect X-Authentication Header"},{"location":"en/user-guides/cloud-ui/rules/regex-rule/#partial-disabling-of-a-new-detection-rule","text":"If the created rule should be partially disabled for a particular branch, this can easily be done by creating the rule Ignore regular expression with the following fields: Regex ID : identifiers of the previously created regular expressions that must be ignored. in this part of request : indicates the parameter that requires setting up an exception.","title":"Partial Disabling of a New Detection Rule"},{"location":"en/user-guides/cloud-ui/rules/regex-rule/#getting-an-id-of-a-regular-expression","text":"Identifier is generated automatically when you add a new regular expression rule. To get an ID of a regular expression, proceed to the following steps: In the Rules tab click the button All rules and select Define a request as an attack based on a regular expression from the drop-down list. Select the branch which the desired regular expression was set for. Select the group of rules which contains the desired regular expression. Click the desired regular expression entry. The Regex ID field on the appeared panel contains the desired regular expression identifier. Click the button next to the field to copy it to the clipboard.","title":"Getting an ID of a Regular Expression"},{"location":"en/user-guides/cloud-ui/rules/regex-rule/#example-permit-an-incorrect-x-authentication-header-for-a-designated-url","text":"Let's say you have a script at example.com/test.php , and you want to change the format of the tokens for it. To create the relevant rule: Go to the Rules tab Find or create the branch for example.com/test.php and click Add rule Choose Ignore regular expressions Enter the ID of the rule that you want to disable into the Regex ID field Set the point Header X-AUTHENTICATION Click Create","title":"Example: Permit an Incorrect X-Authentication Header for a Designated URL."},{"location":"en/user-guides/cloud-ui/rules/request-processing/","text":"How Wallarm Analyzes Requests \u00b6 We believe that for an effective request analysis, a Wallarm NG-WAF component should work with the same data as the protected application and consider the context of data processing. For instance, if an application provides a JSON API, the processed parameters will be also encoded in JSON format. To analyze requests to such an API, it is necessary to parse the JSON format to get the values that will be used by the application. There are also more complex cases where the data is encoded several times \u2014 for example, JSON to BASE64 to JSON. Speaking of data processing contexts, it should be noted that the same parameter can be handled differently by different parts of the application. For instance, the parameter name can be passed in creation requests both as the product name and as a username. But the processing code for such requests could have been written by different developers according to different requirements. The term endpoint is commonly used in API descriptions, so we shall continue using it in this document. In light of the above, we can assume that the analysis of requests includes the following stages: identifying the format and applying corresponding format parsers for each parameter; calculation of metrics that allow registering an attack for each parameter; identification of the application endpoint of the request; and comparison of the calculated metrics against the normal values for this endpoint. Parameter Parsing \u00b6 Starting from the top level of the HTTP request, the filter node attempts to sequentially apply each of the suitable parsers to each parameter. The output from the parsers becomes an additional set of parameters that has to be analyzed in a similar way. Parser output sometimes becomes a complex structure. All of those structures can be considered as a sequence of applied filters, each of which gives a single element, array, or associative array. The list of applied parsers depends on the nature of the data and the results of the previous training of the system. URL \u00b6 Every HTTP request contains an URL. To find attacks, the filter node processes the URL as follows: it analyzes both the original value and its individual components. When creating rules, it is preferable to use separate URL components because this allows the system to apply rules more efficiently. The URL parser provides the following filters that apply to an HTTP request: url : string with the original URL value; path : an array with URL parts separated by the / symbol (the last URL part is not included in the array). If there is only one part in the URL, the array will be empty; action_name : the last part of the URL after the / symbol and before the first period . . This part of the URL is always present in the request even if its value is an empty string; action_ext : the part of the URL after the last period . . It may be missing in the request; get : parameters after the ? symbol. Read more about them below. For example, in the request /blogs/123/index.php?q=aaa , there will be the following parameters: [url] \u2014 /blogs/123/index.php?q=aaa [path, 0] \u2014 blogs [path, 1] \u2014 123 [action_name] \u2014 index [action_ext] \u2014 php [get, 'q'] \u2014 aaa GET Parameters \u00b6 If parameters are passed to the application using a GET encoding, their names and values are included directly in the request URL after the character ? . Typically, values are passed in the key-value format, but a more complex structure can also be used. For example, in the request /?q=some+text&check=yes the following parameters are passed: [get, 'q'] \u2014 some text [get, 'check'] \u2014 yes An example of a complex structure of parameters in the /?p1[x]=1&p1[y]=2&p2[]=aaa&p2[]=bbb request: [get, 'p1', hash, 'x'] \u2014 1 [get, 'p1', hash, 'y'] \u2014 2 [get, 'p2', array, 0] \u2014 aaa [get, 'p2', array, 1] \u2014 bbb In addition, some web servers support so-called \u00abpollution\u00bb when the values of the parameters with the same name are combined. For example, if the web server supports pollution, then the parameters in /?request?p3=1&p3=2 are arranged in the following form: [get, 'p3', array, 0] \u2014 1 [get, 'p3', array, 1] \u2014 2 [get, 'p3', pollution] \u2014 1,2 Headers \u00b6 Headers are present in the HTTP request and some other formats (e.g., multipart). The header filter is used to get request headers. It always converts header names to uppercase. Note that pollution is also supported for headers. For example, in the following request: GET / HTTP/1.1 Host: example.com X-Test: aaa X-Test: bbb there will be the following parameters: [header, 'HOST'] \u2014 example.com [header, 'X-TEST', array, 0] \u2014 aaa [header, 'X-TEST', array, 1] \u2014 aaa [header, 'X-TEST', pollution] \u2014 aaa,bbb Request Body \u00b6 If a body is present in an HTTP request, it is made available by the [post] filter. Meta-Information \u00b6 The following additional filters are supported for HTTP request information: * method : an HTTP method of the request; * proto : version of the HTTP Protocol; * scheme : http/https; * instance : ID of the application. Base64 \u00b6 There is a Base64 filter and a Base64 parser that can be applied to any string. For example, the options might look like this: [get, 'token', base64] [post, multipart, 'data', base64] Cookies \u00b6 The value of the Cookie header is processed in a special way by both the application and the filter node. The value is parsed using a cookie parser that provides a filter of the same name. For example, in the following request: GET / HTTP/1.1 Cookie: a=1; b=2 there will be the following parameters: [header, 'COOKIE', cookie, 'a'] = 1 [header, 'COOKIE', cookie, 'b'] = 2 Form-Urlencoded \u00b6 If the data in the request body is passed in the application/x-www-form-urlencoded format, then individual parameters will be available using the form_urlencoded filter. Names with complex structure and pollution are supported. For example, in the following request: ... p1=1&p2[a]=2&p2[b]=3&p3[]=4&p3[]=5&p4=6&p4=7 there will be the following parameters: [post, form_urlencoded, 'p1'] \u2014 1 [post, form_urlencoded, 'p2', hash, 'a'] \u2014 2 [post, form_urlencoded, 'p2', hash, 'b'] \u2014 3 [post, form_urlencoded, 'p3', array, 0] \u2014 4 [post, form_urlencoded, 'p3', array, 1] \u2014 5 [post, form_urlencoded, 'p4', array, 0] \u2014 6 [post, form_urlencoded, 'p4', array, 1] \u2014 7 [post, form_urlencoded, 'p4', pollution] \u2014 6,7 Gzip \u00b6 The Gzip parser can be applied to any string and provides a filter of the same name. For example, the options might look like this: [get, 'token', base64, gzip] [post, multipart, 'data', gzip] JSON \u00b6 JSON enables you to encode data with a complex structure and provides the following filters: json_doc : top-level container for JSON data. json_array : array that can be referenced by the alias array ; json_obj : an associative array that can be referenced by the alias hash . For example, the following structure: {\"p1\":\"value\",\"p2\":[\"v1\",\"v2\"],\"p3\":{\"somekey\":\"somevalue\"}} contains the following parameters: [..., json_doc, hash, 'p1'] \u2014 value [..., json_doc, hash, 'p2', array, 0] \u2014 v1 [..., json_doc, hash, 'p2', array, 1] \u2014 v2 [..., json_doc, hash, 'p3', hash, 'somekey'] \u2014 somevalue Multipart \u00b6 Data in the request body can be transmitted in multipart format. In a request similar to the example for Form-Urlencoded , the following parameters are [post, multipart, 'p1'] \u2014 1 [post, multipart, 'p2', hash, 'a'] \u2014 2 [post, multipart, 'p2', hash, 'b'] \u2014 3 [post, multipart, 'p3', array, 0] \u2014 4 [post, multipart, 'p3', array, 1] \u2014 5 [post, multipart, 'p4', array, 0] \u2014 6 [post, multipart, 'p4', array, 1] \u2014 7 [post, multipart, 'p4', pollution] \u2014 6,7 In addition, each parameter can have its own headings. If a file name is specified in the Content-Disposition header, the file is considered to be loaded in this parameter, and the parameter will look like this: [post, multipart, 'someparam', file] \u2014 file contents Percent \u00b6 The parser Percent is applied to the source string with the URL and generates a URL decoding of the symbols. The parameter structure is as follows: [url, percent] Viewstate \u00b6 The Viewstate parser is designed to analyze the session state, the technology used by Microsoft ASP.NET. This parser provides the following filters: viewstate is a top-level container for viewstate data. viewstate_array is an array. viewstate_pair is an array. viewstate_triplet is an array. viewstate_dict is an associative array. viewstate_dict_key is a string. viewstate_dict_value is a string. viewstate_sparse_array is an associative array. XML \u00b6 XML enables you to encode data with a complex structure and provides the following filters: xml is the top-level container for the XML data. xml_comment is an array with comments in the body of an XML document. xml_dtd is the address of the external DTD schema being used. xml_dtd_entity is an array defined in the Entity DTD document. xml_pi is an array of instructions to process. xml_tag is an associative array of tags. xml_tag_array is an array of tag values; you can use the alias array . xml_attr is an associative array of attributes. Can only be used after the tag filter. The XML parser does not differentiate between the contents of the tag and the first element in the array of values for the tag. That is, the parameters [..., xml, xml_tag, 't1'] and [..., xml, xml_tag, 't1', array, 0] are identical and interchangeable. For example, the following XML data: <?xml version=\"1.0\"?> <!DOCTYPE foo [<!ENTITY xxe SYSTEM \"aaaa\">]> <?xml-stylesheet type=\"text/xsl\" href=\"style.xsl\"?> <!-- test --> <methodCall> <methodName>&xxe;</methodName> <methodArgs check=\"true\">123</methodArgs> <methodArgs>234</methodArgs> </methodCall> contains the following parameters: [..., xml, xml_dtd_entity, 0] \u2014 name = xxe , value = aaaa [..., xml, xml_pi, 0] \u2014 name = xml-stylesheet , value = type=\"text/xsl\" href=\"style.xsl\" [..., xml, xml_comment, 0] \u2014 test [..., xml, xml_tag, 'methodCall', xml_tag, 'methodName'] \u2014 aaaa [..., xml, xml_tag, 'methodCall', xml_tag, 'methodArgs'] \u2014 123 [..., xml, xml_tag, 'methodCall', xml_tag, 'methodArgs', xml_attr, 'check'] \u2014 true [..., xml, xml_tag, 'methodCall', xml_tag, 'methodArgs', array, 1] \u2014 234 Endpoints and Their Norms \u00b6 To make a decision about blocking a request, the filter instance verifies that the metric calculated for each parameter does not exceed the pre-defined limits. Acceptable metric limits or metric norms are specified in the LOM file for each endpoint. Endpoints are described using a set of HTTP request parameters and conditions. As a condition, you can use an exact match check, a match check against a regular expression, or the absence of a parameter in the request. For example, in order to describe the endpoint to request example.com/admin/index.php we need to establish the following conditions: * [header, 'HOST'] = example.com * [path, 0] = admin * [path, 1] is missing * [action_name] = index * [action_ext] = php To speed up endpoint identification, the LOM file uses an analogue of the decision tree. When describing partially overlapping endpoints, the size of the LOM file can dramatically increase due to combinatorial explosion. Norms can be described for values of the parameters, for example, [get 'id'] ; values of all parameters, for example, [get_all] ; default values, such as [get_default] ; parameter names, such as [get_name] .","title":"How Wallarm Analyzes Requests"},{"location":"en/user-guides/cloud-ui/rules/request-processing/#how-wallarm-analyzes-requests","text":"We believe that for an effective request analysis, a Wallarm NG-WAF component should work with the same data as the protected application and consider the context of data processing. For instance, if an application provides a JSON API, the processed parameters will be also encoded in JSON format. To analyze requests to such an API, it is necessary to parse the JSON format to get the values that will be used by the application. There are also more complex cases where the data is encoded several times \u2014 for example, JSON to BASE64 to JSON. Speaking of data processing contexts, it should be noted that the same parameter can be handled differently by different parts of the application. For instance, the parameter name can be passed in creation requests both as the product name and as a username. But the processing code for such requests could have been written by different developers according to different requirements. The term endpoint is commonly used in API descriptions, so we shall continue using it in this document. In light of the above, we can assume that the analysis of requests includes the following stages: identifying the format and applying corresponding format parsers for each parameter; calculation of metrics that allow registering an attack for each parameter; identification of the application endpoint of the request; and comparison of the calculated metrics against the normal values for this endpoint.","title":"How Wallarm Analyzes Requests"},{"location":"en/user-guides/cloud-ui/rules/request-processing/#parameter-parsing","text":"Starting from the top level of the HTTP request, the filter node attempts to sequentially apply each of the suitable parsers to each parameter. The output from the parsers becomes an additional set of parameters that has to be analyzed in a similar way. Parser output sometimes becomes a complex structure. All of those structures can be considered as a sequence of applied filters, each of which gives a single element, array, or associative array. The list of applied parsers depends on the nature of the data and the results of the previous training of the system.","title":"Parameter Parsing"},{"location":"en/user-guides/cloud-ui/rules/request-processing/#url","text":"Every HTTP request contains an URL. To find attacks, the filter node processes the URL as follows: it analyzes both the original value and its individual components. When creating rules, it is preferable to use separate URL components because this allows the system to apply rules more efficiently. The URL parser provides the following filters that apply to an HTTP request: url : string with the original URL value; path : an array with URL parts separated by the / symbol (the last URL part is not included in the array). If there is only one part in the URL, the array will be empty; action_name : the last part of the URL after the / symbol and before the first period . . This part of the URL is always present in the request even if its value is an empty string; action_ext : the part of the URL after the last period . . It may be missing in the request; get : parameters after the ? symbol. Read more about them below. For example, in the request /blogs/123/index.php?q=aaa , there will be the following parameters: [url] \u2014 /blogs/123/index.php?q=aaa [path, 0] \u2014 blogs [path, 1] \u2014 123 [action_name] \u2014 index [action_ext] \u2014 php [get, 'q'] \u2014 aaa","title":"URL"},{"location":"en/user-guides/cloud-ui/rules/request-processing/#get-parameters","text":"If parameters are passed to the application using a GET encoding, their names and values are included directly in the request URL after the character ? . Typically, values are passed in the key-value format, but a more complex structure can also be used. For example, in the request /?q=some+text&check=yes the following parameters are passed: [get, 'q'] \u2014 some text [get, 'check'] \u2014 yes An example of a complex structure of parameters in the /?p1[x]=1&p1[y]=2&p2[]=aaa&p2[]=bbb request: [get, 'p1', hash, 'x'] \u2014 1 [get, 'p1', hash, 'y'] \u2014 2 [get, 'p2', array, 0] \u2014 aaa [get, 'p2', array, 1] \u2014 bbb In addition, some web servers support so-called \u00abpollution\u00bb when the values of the parameters with the same name are combined. For example, if the web server supports pollution, then the parameters in /?request?p3=1&p3=2 are arranged in the following form: [get, 'p3', array, 0] \u2014 1 [get, 'p3', array, 1] \u2014 2 [get, 'p3', pollution] \u2014 1,2","title":"GET Parameters"},{"location":"en/user-guides/cloud-ui/rules/request-processing/#headers","text":"Headers are present in the HTTP request and some other formats (e.g., multipart). The header filter is used to get request headers. It always converts header names to uppercase. Note that pollution is also supported for headers. For example, in the following request: GET / HTTP/1.1 Host: example.com X-Test: aaa X-Test: bbb there will be the following parameters: [header, 'HOST'] \u2014 example.com [header, 'X-TEST', array, 0] \u2014 aaa [header, 'X-TEST', array, 1] \u2014 aaa [header, 'X-TEST', pollution] \u2014 aaa,bbb","title":"Headers"},{"location":"en/user-guides/cloud-ui/rules/request-processing/#request-body","text":"If a body is present in an HTTP request, it is made available by the [post] filter.","title":"Request Body"},{"location":"en/user-guides/cloud-ui/rules/request-processing/#meta-information","text":"The following additional filters are supported for HTTP request information: * method : an HTTP method of the request; * proto : version of the HTTP Protocol; * scheme : http/https; * instance : ID of the application.","title":"Meta-Information"},{"location":"en/user-guides/cloud-ui/rules/request-processing/#base64","text":"There is a Base64 filter and a Base64 parser that can be applied to any string. For example, the options might look like this: [get, 'token', base64] [post, multipart, 'data', base64]","title":"Base64"},{"location":"en/user-guides/cloud-ui/rules/request-processing/#cookies","text":"The value of the Cookie header is processed in a special way by both the application and the filter node. The value is parsed using a cookie parser that provides a filter of the same name. For example, in the following request: GET / HTTP/1.1 Cookie: a=1; b=2 there will be the following parameters: [header, 'COOKIE', cookie, 'a'] = 1 [header, 'COOKIE', cookie, 'b'] = 2","title":"Cookies"},{"location":"en/user-guides/cloud-ui/rules/request-processing/#form-urlencoded","text":"If the data in the request body is passed in the application/x-www-form-urlencoded format, then individual parameters will be available using the form_urlencoded filter. Names with complex structure and pollution are supported. For example, in the following request: ... p1=1&p2[a]=2&p2[b]=3&p3[]=4&p3[]=5&p4=6&p4=7 there will be the following parameters: [post, form_urlencoded, 'p1'] \u2014 1 [post, form_urlencoded, 'p2', hash, 'a'] \u2014 2 [post, form_urlencoded, 'p2', hash, 'b'] \u2014 3 [post, form_urlencoded, 'p3', array, 0] \u2014 4 [post, form_urlencoded, 'p3', array, 1] \u2014 5 [post, form_urlencoded, 'p4', array, 0] \u2014 6 [post, form_urlencoded, 'p4', array, 1] \u2014 7 [post, form_urlencoded, 'p4', pollution] \u2014 6,7","title":"Form-Urlencoded"},{"location":"en/user-guides/cloud-ui/rules/request-processing/#gzip","text":"The Gzip parser can be applied to any string and provides a filter of the same name. For example, the options might look like this: [get, 'token', base64, gzip] [post, multipart, 'data', gzip]","title":"Gzip"},{"location":"en/user-guides/cloud-ui/rules/request-processing/#json","text":"JSON enables you to encode data with a complex structure and provides the following filters: json_doc : top-level container for JSON data. json_array : array that can be referenced by the alias array ; json_obj : an associative array that can be referenced by the alias hash . For example, the following structure: {\"p1\":\"value\",\"p2\":[\"v1\",\"v2\"],\"p3\":{\"somekey\":\"somevalue\"}} contains the following parameters: [..., json_doc, hash, 'p1'] \u2014 value [..., json_doc, hash, 'p2', array, 0] \u2014 v1 [..., json_doc, hash, 'p2', array, 1] \u2014 v2 [..., json_doc, hash, 'p3', hash, 'somekey'] \u2014 somevalue","title":"JSON"},{"location":"en/user-guides/cloud-ui/rules/request-processing/#multipart","text":"Data in the request body can be transmitted in multipart format. In a request similar to the example for Form-Urlencoded , the following parameters are [post, multipart, 'p1'] \u2014 1 [post, multipart, 'p2', hash, 'a'] \u2014 2 [post, multipart, 'p2', hash, 'b'] \u2014 3 [post, multipart, 'p3', array, 0] \u2014 4 [post, multipart, 'p3', array, 1] \u2014 5 [post, multipart, 'p4', array, 0] \u2014 6 [post, multipart, 'p4', array, 1] \u2014 7 [post, multipart, 'p4', pollution] \u2014 6,7 In addition, each parameter can have its own headings. If a file name is specified in the Content-Disposition header, the file is considered to be loaded in this parameter, and the parameter will look like this: [post, multipart, 'someparam', file] \u2014 file contents","title":"Multipart"},{"location":"en/user-guides/cloud-ui/rules/request-processing/#percent","text":"The parser Percent is applied to the source string with the URL and generates a URL decoding of the symbols. The parameter structure is as follows: [url, percent]","title":"Percent"},{"location":"en/user-guides/cloud-ui/rules/request-processing/#viewstate","text":"The Viewstate parser is designed to analyze the session state, the technology used by Microsoft ASP.NET. This parser provides the following filters: viewstate is a top-level container for viewstate data. viewstate_array is an array. viewstate_pair is an array. viewstate_triplet is an array. viewstate_dict is an associative array. viewstate_dict_key is a string. viewstate_dict_value is a string. viewstate_sparse_array is an associative array.","title":"Viewstate"},{"location":"en/user-guides/cloud-ui/rules/request-processing/#xml","text":"XML enables you to encode data with a complex structure and provides the following filters: xml is the top-level container for the XML data. xml_comment is an array with comments in the body of an XML document. xml_dtd is the address of the external DTD schema being used. xml_dtd_entity is an array defined in the Entity DTD document. xml_pi is an array of instructions to process. xml_tag is an associative array of tags. xml_tag_array is an array of tag values; you can use the alias array . xml_attr is an associative array of attributes. Can only be used after the tag filter. The XML parser does not differentiate between the contents of the tag and the first element in the array of values for the tag. That is, the parameters [..., xml, xml_tag, 't1'] and [..., xml, xml_tag, 't1', array, 0] are identical and interchangeable. For example, the following XML data: <?xml version=\"1.0\"?> <!DOCTYPE foo [<!ENTITY xxe SYSTEM \"aaaa\">]> <?xml-stylesheet type=\"text/xsl\" href=\"style.xsl\"?> <!-- test --> <methodCall> <methodName>&xxe;</methodName> <methodArgs check=\"true\">123</methodArgs> <methodArgs>234</methodArgs> </methodCall> contains the following parameters: [..., xml, xml_dtd_entity, 0] \u2014 name = xxe , value = aaaa [..., xml, xml_pi, 0] \u2014 name = xml-stylesheet , value = type=\"text/xsl\" href=\"style.xsl\" [..., xml, xml_comment, 0] \u2014 test [..., xml, xml_tag, 'methodCall', xml_tag, 'methodName'] \u2014 aaaa [..., xml, xml_tag, 'methodCall', xml_tag, 'methodArgs'] \u2014 123 [..., xml, xml_tag, 'methodCall', xml_tag, 'methodArgs', xml_attr, 'check'] \u2014 true [..., xml, xml_tag, 'methodCall', xml_tag, 'methodArgs', array, 1] \u2014 234","title":"XML"},{"location":"en/user-guides/cloud-ui/rules/request-processing/#endpoints-and-their-norms","text":"To make a decision about blocking a request, the filter instance verifies that the metric calculated for each parameter does not exceed the pre-defined limits. Acceptable metric limits or metric norms are specified in the LOM file for each endpoint. Endpoints are described using a set of HTTP request parameters and conditions. As a condition, you can use an exact match check, a match check against a regular expression, or the absence of a parameter in the request. For example, in order to describe the endpoint to request example.com/admin/index.php we need to establish the following conditions: * [header, 'HOST'] = example.com * [path, 0] = admin * [path, 1] is missing * [action_name] = index * [action_ext] = php To speed up endpoint identification, the LOM file uses an analogue of the decision tree. When describing partially overlapping endpoints, the size of the LOM file can dramatically increase due to combinatorial explosion. Norms can be described for values of the parameters, for example, [get 'id'] ; values of all parameters, for example, [get_all] ; default values, such as [get_default] ; parameter names, such as [get_name] .","title":"Endpoints and Their Norms"},{"location":"en/user-guides/cloud-ui/rules/sensitive-data-rule/","text":"Rules for Data Masking \u00b6 Requests to a web application may contain sensitive data that should not be transferred outside of the server on which it is processed. Typically, this category includes authorization (cookies, tokens, passwords), personal data and payment credentials. Wallarm Node supports data masking in requests. The real values will be replaced by * and will not be accessible either in the Wallarm Cloud or in the local post-analysis module. This method ensures that the protected data cannot leak outside the trusted environment. It can affect the display of attacks, active attack (threat) verification, and the detection of brute force attacks. Example: Masking of a Cookie Value \u00b6 If the following conditions take place: the application is accessible at the domain example.com the application uses a PHPSESSID cookie for user authentication security policies deny access to this information for employees using Wallarm Then , to create a data masking rule for this cookie, the following actions should be performed: Go to the Rules tab Find the branch for example.com/**/*.* and click Add rule Choose Mark as sensitive data Select the Header parameter and enter its value COOKIE ; select the cookie parameter and enter its value PHPSESSID after in this part of request Click Create","title":"Rules for Data Masking"},{"location":"en/user-guides/cloud-ui/rules/sensitive-data-rule/#rules-for-data-masking","text":"Requests to a web application may contain sensitive data that should not be transferred outside of the server on which it is processed. Typically, this category includes authorization (cookies, tokens, passwords), personal data and payment credentials. Wallarm Node supports data masking in requests. The real values will be replaced by * and will not be accessible either in the Wallarm Cloud or in the local post-analysis module. This method ensures that the protected data cannot leak outside the trusted environment. It can affect the display of attacks, active attack (threat) verification, and the detection of brute force attacks.","title":"Rules for Data Masking"},{"location":"en/user-guides/cloud-ui/rules/sensitive-data-rule/#example-masking-of-a-cookie-value","text":"If the following conditions take place: the application is accessible at the domain example.com the application uses a PHPSESSID cookie for user authentication security policies deny access to this information for employees using Wallarm Then , to create a data masking rule for this cookie, the following actions should be performed: Go to the Rules tab Find the branch for example.com/**/*.* and click Add rule Choose Mark as sensitive data Select the Header parameter and enter its value COOKIE ; select the cookie parameter and enter its value PHPSESSID after in this part of request Click Create","title":"Example: Masking of a Cookie Value"},{"location":"en/user-guides/cloud-ui/rules/view/","text":"Inspecting Application Profile Rules \u00b6 Application Structure Display \u00b6 To view the application structure, go to the Profile & Rules tab. This section represents branches and endpoints that are already known. The system automatically groups the rules by branches, highlighting common conditions and building a tree-like structure. As a result, a branch may have child branches. To show or hide nested branches, click on the blue circle to the left of the branch description. Two asterisks ** in a branch description refer to any number of nested paths. For instance, the branch /**/*.php will contain both /index.php and /app/admin/install.php . The size of the blue circle indicates the relative quantity of the nested branches. Its color indicates the relative quantity of the rules within the branch and its sub-branches. On each nesting level, the size and color of the circles are independent from each other. To the right of the branch description, the system may display an orange number, which indicates the number of rules in that branch (only the direct descendants, not the nested rules). If no number is displayed, then that branch is \"virtual\" \u2014 it is used only for grouping similar sub-branches. Branches with no rules available for the user (according to the privilege model) are automatically hidden . Rule Display \u00b6 In each branch, the user can look through the list of rules attached to it. To switch over to the page with the rule list, click on the description of the corresponding branch. The rules within a branch are grouped by the point field. The rules that affect the entire request, rather than individual parameters, are grouped together into one line. To see the entire list, click on the line. For each rule, the system displays the following parameters: last modified time, quantity, types, and point. By default, only the rules linked to the selected branch are shown. To see the rules inherited from more common branches, click on the Hidden button.","title":"Inspecting Application Profile Rules"},{"location":"en/user-guides/cloud-ui/rules/view/#inspecting-application-profile-rules","text":"","title":"Inspecting Application Profile Rules"},{"location":"en/user-guides/cloud-ui/rules/view/#application-structure-display","text":"To view the application structure, go to the Profile & Rules tab. This section represents branches and endpoints that are already known. The system automatically groups the rules by branches, highlighting common conditions and building a tree-like structure. As a result, a branch may have child branches. To show or hide nested branches, click on the blue circle to the left of the branch description. Two asterisks ** in a branch description refer to any number of nested paths. For instance, the branch /**/*.php will contain both /index.php and /app/admin/install.php . The size of the blue circle indicates the relative quantity of the nested branches. Its color indicates the relative quantity of the rules within the branch and its sub-branches. On each nesting level, the size and color of the circles are independent from each other. To the right of the branch description, the system may display an orange number, which indicates the number of rules in that branch (only the direct descendants, not the nested rules). If no number is displayed, then that branch is \"virtual\" \u2014 it is used only for grouping similar sub-branches. Branches with no rules available for the user (according to the privilege model) are automatically hidden .","title":"Application Structure Display"},{"location":"en/user-guides/cloud-ui/rules/view/#rule-display","text":"In each branch, the user can look through the list of rules attached to it. To switch over to the page with the rule list, click on the description of the corresponding branch. The rules within a branch are grouped by the point field. The rules that affect the entire request, rather than individual parameters, are grouped together into one line. To see the entire list, click on the line. For each rule, the system displays the following parameters: last modified time, quantity, types, and point. By default, only the rules linked to the selected branch are shown. To see the rules inherited from more common branches, click on the Hidden button.","title":"Rule Display"},{"location":"en/user-guides/cloud-ui/rules/vpatch-rule/","text":"Virtual Patching \u00b6 A virtual patch allows blocking malicious requests even in monitoring mode or when a request does not seem to contain any known attack vectors. Virtual patches are especially useful in cases when it is impossible to fix a critical vulnerability in the code or install the necessary security updates quickly. If attack types are selected, the request will be blocked only if the filter node detects an attack of one of the listed types in the corresponding parameter. If the setting Any request is selected, the system will block the requests with the defined parameter, even if it does not contain an attack vector. Example: Blocking SQLi Attack in the GET Parameter id \u00b6 If the following conditions take place: the application is accessible at the domain example.com the application's parameter id is vulnerable to SQL injection attacks the filter node is set to monitoring mode attempts at vulnerability exploitation must be blocked Then , to create a virtual patch Go to the Rules tab Find the branch example.com/**/*.* and click Add rule Choose Create a virtual patch Choose SQLi as the type of attack Select the GET parameter and enter its value id after in this part of request Click Create Example: Block All Requests With the GET Parameter refresh \u00b6 If the following conditions take place: the application is accessible at the domain example.com the application crashes upon processing the GET parameter refresh attempts at vulnerability exploitation must be blocked Then , to create a virtual patch Go to the Rules tab Find the branch example.com/**/*.* and click Add rule Choose Create a virtual patch Choose Any request Select the GET parameter and enter its value refresh after in this part of request Click Create","title":"Virtual Patching"},{"location":"en/user-guides/cloud-ui/rules/vpatch-rule/#virtual-patching","text":"A virtual patch allows blocking malicious requests even in monitoring mode or when a request does not seem to contain any known attack vectors. Virtual patches are especially useful in cases when it is impossible to fix a critical vulnerability in the code or install the necessary security updates quickly. If attack types are selected, the request will be blocked only if the filter node detects an attack of one of the listed types in the corresponding parameter. If the setting Any request is selected, the system will block the requests with the defined parameter, even if it does not contain an attack vector.","title":"Virtual Patching"},{"location":"en/user-guides/cloud-ui/rules/vpatch-rule/#example-blocking-sqli-attack-in-the-get-parameter-id","text":"If the following conditions take place: the application is accessible at the domain example.com the application's parameter id is vulnerable to SQL injection attacks the filter node is set to monitoring mode attempts at vulnerability exploitation must be blocked Then , to create a virtual patch Go to the Rules tab Find the branch example.com/**/*.* and click Add rule Choose Create a virtual patch Choose SQLi as the type of attack Select the GET parameter and enter its value id after in this part of request Click Create","title":"Example: Blocking SQLi Attack in the GET Parameter id"},{"location":"en/user-guides/cloud-ui/rules/vpatch-rule/#example-block-all-requests-with-the-get-parameter-refresh","text":"If the following conditions take place: the application is accessible at the domain example.com the application crashes upon processing the GET parameter refresh attempts at vulnerability exploitation must be blocked Then , to create a virtual patch Go to the Rules tab Find the branch example.com/**/*.* and click Add rule Choose Create a virtual patch Choose Any request Select the GET parameter and enter its value refresh after in this part of request Click Create","title":"Example: Block All Requests With the GET Parameter refresh"},{"location":"en/user-guides/cloud-ui/rules/wallarm-mode-rule/","text":"Filter Mode Rule \u00b6 The filter mode allows you to enable and disable the blocking of requests to various parts of a web application. To set a filter mode, create a Set traffic filtration mode rule and select the appropriate mode. The filter mode can take one of the following values: default : the system will work in accordance with the parameters specified in the NGINX configuration files. off : the analysis and filtration of requests are disabled completely. monitoring : the requests are analyzed and displayed in the interface but they are not blocked. blocking : malicious requests are blocked and displayed in the interface. To implement this rule, the NGINX configuration files must permit centralized management of the operation mode . Example: Disabling Request Blocking During User Registration \u00b6 If the following conditions take place: new user registration is available at example.com/signup it is better to overlook an attack than to lose a customer Then , to create a rule disabling blocking during user registration Go to the Rules tab Find the branch for example.com/signup , and click Add rule Choose Set traffic filtration mode Choose operation mode monitoring Click Create","title":"Filter Mode Rule"},{"location":"en/user-guides/cloud-ui/rules/wallarm-mode-rule/#filter-mode-rule","text":"The filter mode allows you to enable and disable the blocking of requests to various parts of a web application. To set a filter mode, create a Set traffic filtration mode rule and select the appropriate mode. The filter mode can take one of the following values: default : the system will work in accordance with the parameters specified in the NGINX configuration files. off : the analysis and filtration of requests are disabled completely. monitoring : the requests are analyzed and displayed in the interface but they are not blocked. blocking : malicious requests are blocked and displayed in the interface. To implement this rule, the NGINX configuration files must permit centralized management of the operation mode .","title":"Filter Mode Rule"},{"location":"en/user-guides/cloud-ui/rules/wallarm-mode-rule/#example-disabling-request-blocking-during-user-registration","text":"If the following conditions take place: new user registration is available at example.com/signup it is better to overlook an attack than to lose a customer Then , to create a rule disabling blocking during user registration Go to the Rules tab Find the branch for example.com/signup , and click Add rule Choose Set traffic filtration mode Choose operation mode monitoring Click Create","title":"Example: Disabling Request Blocking During User Registration"},{"location":"en/user-guides/cloud-ui/scanner/check-scope/","text":"Working with the Scope \u00b6 You can see information on the company's public resources on the Scanner tab of the Wallarm interface. The Wallarm scanner discovers the scope. Scanner Settings Overview \u00b6 In the Scanner block, the following data is shown: current scanner settings time of the last scan To learn more about configuring the scanner, see the \u201cScanner settings\u201d page. Scope Overview \u00b6 In the Scope block of the Scanner tab, the elements are shown in three columns: Domains , IPs , and Services . The total number of elements of a certain type is shown near the column name in a small grey font. If Wallarm can determine which data center the given IP address belongs to, then the corresponding tag will be displayed to the right of the element or group of elements: the \u201cAWS\u201d tag for Amazon, the \u201cGCP\u201d tag for Google and the \u201cAzure\u201d tag for Microsoft data centers. Info By default, the scope scanning starts with the domain of the e-mail address that was specified upon Wallarm account creation. The elements' names displayed in bold font correspond with the group of observed resources. The number of resources the certain group contains is shown in small grey font near its name. Click the group name to expand the list of the resources it contains. Use the search field to find elements by their names. You can also search for substrings. For example, the query domain.com displays all domains that have \u201cdomain.com\u201d as a substring: \u201ca.domain.com\u201d, \u201cb.domain.com\u201d and their associations. Click one of the buttons on the bar to filter elements by their status: All elements : display all of the resources within the scope. New : display the newly discovered resources that have not been viewed yet. Disabled : display the resources for which scanning is disabled. Check the Resource Associations \u00b6 Click one of the scope elements. The Wallarm interface will display the selected element's associations. The resources' domain, IP address, and port are interdependent. A domain always has a higher priority than an IP address, and an IP address always has priority over a port. When you disable the scanning of or delete a resource with a lower priority, the resource with a higher priority remains active. For example, when you disable the scanning of a domain, the system will also disable the scanning of the IP address and ports that depend on that domain. When you delete an IP address, the system will also delete the associated ports, but keep the domain active, because a domain may have more than one IP address. You can disable the resources' connections to manage each resource independently. Disable and Enable the Resource Connection \u00b6 You can disable the resources' interconnection to manage each resource's scanning settings independently. To disable the resources' interconnection: Select one resource from the resource pair you need to disconnect from each other; Click the switch next to the resource paired with the current one. Determining the current resource The name of the current resource is shown in bold. The web-interface also displays its discovery date. To enable resource interconnection, follow the same steps as when you were disabling the interconnection. Disable Resource Scanning \u00b6 You can disable scanning for any of the resources within the scope. In so doing, the resource you selected will remain in the system as detectable, but will not be scanned for vulnerabilities. Click one of the scope elements. Click the switch next to the selected element. Delete a Resource from the Scope \u00b6 You can delete any resource from the scope. The purpose of this operation is to delete an accidentally added resource. Select the desired resources by clicking the checkboxes next to their names. Click Delete element(s) . Warning:: Recovering the deleted resources \u00b6 The deleted resources will not be discovered in future scannings. If you have deleted the resource by mistake, contact the Wallarm support team . Add a Domain or an IP Address \u00b6 You can manually add a domain or an IP address. Click Add domain or IP . In the window that appears, enter the new domain or IP and click Add . After the new domain or IP address is added, the scanner will launch the scanning procedure to search for elements connected with the resource and will add them to the scope. #### Warning:: Reserved domains Reserved domains and subdomains can only be added to the scope by a certain client. Wallarm reserves domain for a client on request. You cannot add a domain that is reserved by another client to your scope. To see detailed information about reserved domains, proceed to this [link][link-reserved-domains]. Limit Scanning Speed \u00b6 You can limit the speed of domain or IP address scanning. The total speed of sending requests by the scanner will not exceed the specified value. Select one of the scope elements of the following types: Domain , IP . Click the Set RPS limits button or the current limit value. Fill in the Domain RPS field for the domain or the IP RPS field for the IP address. You can also limit the RPS for each of the domain's dependent IP addresses. To set this limit, enter the desired value in the RPS per IP field. Click Save . To return to the default settings, use an empty value or enter 0 . See also Scanner overview Scanner settings","title":"Working with the Scope"},{"location":"en/user-guides/cloud-ui/scanner/check-scope/#working-with-the-scope","text":"You can see information on the company's public resources on the Scanner tab of the Wallarm interface. The Wallarm scanner discovers the scope.","title":"Working with the Scope"},{"location":"en/user-guides/cloud-ui/scanner/check-scope/#scanner-settings-overview","text":"In the Scanner block, the following data is shown: current scanner settings time of the last scan To learn more about configuring the scanner, see the \u201cScanner settings\u201d page.","title":"Scanner Settings Overview"},{"location":"en/user-guides/cloud-ui/scanner/check-scope/#scope-overview","text":"In the Scope block of the Scanner tab, the elements are shown in three columns: Domains , IPs , and Services . The total number of elements of a certain type is shown near the column name in a small grey font. If Wallarm can determine which data center the given IP address belongs to, then the corresponding tag will be displayed to the right of the element or group of elements: the \u201cAWS\u201d tag for Amazon, the \u201cGCP\u201d tag for Google and the \u201cAzure\u201d tag for Microsoft data centers. Info By default, the scope scanning starts with the domain of the e-mail address that was specified upon Wallarm account creation. The elements' names displayed in bold font correspond with the group of observed resources. The number of resources the certain group contains is shown in small grey font near its name. Click the group name to expand the list of the resources it contains. Use the search field to find elements by their names. You can also search for substrings. For example, the query domain.com displays all domains that have \u201cdomain.com\u201d as a substring: \u201ca.domain.com\u201d, \u201cb.domain.com\u201d and their associations. Click one of the buttons on the bar to filter elements by their status: All elements : display all of the resources within the scope. New : display the newly discovered resources that have not been viewed yet. Disabled : display the resources for which scanning is disabled.","title":"Scope Overview"},{"location":"en/user-guides/cloud-ui/scanner/check-scope/#check-the-resource-associations","text":"Click one of the scope elements. The Wallarm interface will display the selected element's associations. The resources' domain, IP address, and port are interdependent. A domain always has a higher priority than an IP address, and an IP address always has priority over a port. When you disable the scanning of or delete a resource with a lower priority, the resource with a higher priority remains active. For example, when you disable the scanning of a domain, the system will also disable the scanning of the IP address and ports that depend on that domain. When you delete an IP address, the system will also delete the associated ports, but keep the domain active, because a domain may have more than one IP address. You can disable the resources' connections to manage each resource independently.","title":"Check the Resource Associations"},{"location":"en/user-guides/cloud-ui/scanner/check-scope/#disable-and-enable-the-resource-connection","text":"You can disable the resources' interconnection to manage each resource's scanning settings independently. To disable the resources' interconnection: Select one resource from the resource pair you need to disconnect from each other; Click the switch next to the resource paired with the current one. Determining the current resource The name of the current resource is shown in bold. The web-interface also displays its discovery date. To enable resource interconnection, follow the same steps as when you were disabling the interconnection.","title":"Disable and Enable the Resource Connection"},{"location":"en/user-guides/cloud-ui/scanner/check-scope/#disable-resource-scanning","text":"You can disable scanning for any of the resources within the scope. In so doing, the resource you selected will remain in the system as detectable, but will not be scanned for vulnerabilities. Click one of the scope elements. Click the switch next to the selected element.","title":"Disable Resource Scanning"},{"location":"en/user-guides/cloud-ui/scanner/check-scope/#delete-a-resource-from-the-scope","text":"You can delete any resource from the scope. The purpose of this operation is to delete an accidentally added resource. Select the desired resources by clicking the checkboxes next to their names. Click Delete element(s) .","title":"Delete a Resource from the Scope"},{"location":"en/user-guides/cloud-ui/scanner/check-scope/#warning-recovering-the-deleted-resources","text":"The deleted resources will not be discovered in future scannings. If you have deleted the resource by mistake, contact the Wallarm support team .","title":"Warning:: Recovering the deleted resources"},{"location":"en/user-guides/cloud-ui/scanner/check-scope/#add-a-domain-or-an-ip-address","text":"You can manually add a domain or an IP address. Click Add domain or IP . In the window that appears, enter the new domain or IP and click Add . After the new domain or IP address is added, the scanner will launch the scanning procedure to search for elements connected with the resource and will add them to the scope. #### Warning:: Reserved domains Reserved domains and subdomains can only be added to the scope by a certain client. Wallarm reserves domain for a client on request. You cannot add a domain that is reserved by another client to your scope. To see detailed information about reserved domains, proceed to this [link][link-reserved-domains].","title":"Add a Domain or an IP Address"},{"location":"en/user-guides/cloud-ui/scanner/check-scope/#limit-scanning-speed","text":"You can limit the speed of domain or IP address scanning. The total speed of sending requests by the scanner will not exceed the specified value. Select one of the scope elements of the following types: Domain , IP . Click the Set RPS limits button or the current limit value. Fill in the Domain RPS field for the domain or the IP RPS field for the IP address. You can also limit the RPS for each of the domain's dependent IP addresses. To set this limit, enter the desired value in the RPS per IP field. Click Save . To return to the default settings, use an empty value or enter 0 . See also Scanner overview Scanner settings","title":"Limit Scanning Speed"},{"location":"en/user-guides/cloud-ui/scanner/configure-scanner-modules/","text":"Configuring Scanner Modules \u00b6 Click the Configure link under the scanner toggle to configure the scanner. Configuring the Vulnerabilities Detection List \u00b6 The scanner consists of multiple modules, each of which is responsible for detecting a certain type of vulnerability. The full modules list is specified in the \u201cConfigure Scanner\u201d menu. Filtering Modules by Tag \u00b6 You can filter modules by their tags, which are grouped by type: The vulnerability type\u2014tags for different vulnerability types, such as Remote Code Execution, Path Traversal, or Cross-Site Scripting. The vulnerable technology\u2014tags for different technologies and software, that if used may cause a vulnerability detection. The presence of the vulnerability in the Common Vulnerabilities and Exposures (CVE) database\u2014such vulnerabilities contain the CVE tag. To filter the scanner modules by tag, perform the following actions: Click the Filter by tag field. In the drop-down list that appears the tags are grouped by their type. Select the desired tags by clicking them. You can remove a tag from the filtering field by clicking the tick next to the tag name. Filtering by multiple tags If the filtering field contains multiple tags, the result will consist of only those modules that are marked with all of the specified tags. After you filter the modules by tag, the Wallarm interface displays the total number of the modules that correspond with the specified tags and the number of the filtered modules that correspond with each of the vulnerability classes in the Common Weakness Enumeration (CWE) . Now you can disable all of the filtered modules at once by clicking the toggle next to the Modules found label. You can also disable all of the filtered modules that correspond with a certain vulnerability class by clicking the necessary toggle. Disabling and Enabling All Modules \u00b6 You can disable or enable all of the modules at once by clicking the All modules toggle that is available when no tags are selected in the filtering field. Disabling and Enabling All Modules Detecting Certain Classes of Vulnerabilities \u00b6 In the left column, all of the modules are grouped in accordance with the CWE . You can disable and enable all modules that detect vulnerabilities of a certain class by clicking the corresponding toggle. Disabling and Enabling Individual Modules \u00b6 In the right column, all of the modules are filtered according to the filtering field. Here you can individually enable and disable modules. Disabling and Enabling Vulnerability Rechecking \u00b6 During the active vulnerability check, the scanner restarts tests to check whether the previously detected vulnerabilities are still present. If a previously detected vulnerability is not found after the recheck, the scanner marks it as resolved. You can disable or enable vulnerability rechecking using the Recheck vulnerabilities toggle.","title":"Configuring Scanner Modules"},{"location":"en/user-guides/cloud-ui/scanner/configure-scanner-modules/#configuring-scanner-modules","text":"Click the Configure link under the scanner toggle to configure the scanner.","title":"Configuring Scanner Modules"},{"location":"en/user-guides/cloud-ui/scanner/configure-scanner-modules/#configuring-the-vulnerabilities-detection-list","text":"The scanner consists of multiple modules, each of which is responsible for detecting a certain type of vulnerability. The full modules list is specified in the \u201cConfigure Scanner\u201d menu.","title":"Configuring the Vulnerabilities Detection List"},{"location":"en/user-guides/cloud-ui/scanner/configure-scanner-modules/#filtering-modules-by-tag","text":"You can filter modules by their tags, which are grouped by type: The vulnerability type\u2014tags for different vulnerability types, such as Remote Code Execution, Path Traversal, or Cross-Site Scripting. The vulnerable technology\u2014tags for different technologies and software, that if used may cause a vulnerability detection. The presence of the vulnerability in the Common Vulnerabilities and Exposures (CVE) database\u2014such vulnerabilities contain the CVE tag. To filter the scanner modules by tag, perform the following actions: Click the Filter by tag field. In the drop-down list that appears the tags are grouped by their type. Select the desired tags by clicking them. You can remove a tag from the filtering field by clicking the tick next to the tag name. Filtering by multiple tags If the filtering field contains multiple tags, the result will consist of only those modules that are marked with all of the specified tags. After you filter the modules by tag, the Wallarm interface displays the total number of the modules that correspond with the specified tags and the number of the filtered modules that correspond with each of the vulnerability classes in the Common Weakness Enumeration (CWE) . Now you can disable all of the filtered modules at once by clicking the toggle next to the Modules found label. You can also disable all of the filtered modules that correspond with a certain vulnerability class by clicking the necessary toggle.","title":"Filtering Modules by Tag"},{"location":"en/user-guides/cloud-ui/scanner/configure-scanner-modules/#disabling-and-enabling-all-modules","text":"You can disable or enable all of the modules at once by clicking the All modules toggle that is available when no tags are selected in the filtering field.","title":"Disabling and Enabling All Modules"},{"location":"en/user-guides/cloud-ui/scanner/configure-scanner-modules/#disabling-and-enabling-all-modules-detecting-certain-classes-of-vulnerabilities","text":"In the left column, all of the modules are grouped in accordance with the CWE . You can disable and enable all modules that detect vulnerabilities of a certain class by clicking the corresponding toggle.","title":"Disabling and Enabling All Modules Detecting Certain Classes of Vulnerabilities"},{"location":"en/user-guides/cloud-ui/scanner/configure-scanner-modules/#disabling-and-enabling-individual-modules","text":"In the right column, all of the modules are filtered according to the filtering field. Here you can individually enable and disable modules.","title":"Disabling and Enabling Individual Modules"},{"location":"en/user-guides/cloud-ui/scanner/configure-scanner-modules/#disabling-and-enabling-vulnerability-rechecking","text":"During the active vulnerability check, the scanner restarts tests to check whether the previously detected vulnerabilities are still present. If a previously detected vulnerability is not found after the recheck, the scanner marks it as resolved. You can disable or enable vulnerability rechecking using the Recheck vulnerabilities toggle.","title":"Disabling and Enabling Vulnerability Rechecking"},{"location":"en/user-guides/cloud-ui/scanner/configure-scanner/","text":"General Scanner Settings \u00b6 To access scanner settings, go to the Scanner tab and click the Settings button on the left. Scanner \u00b6 This setting enables or disables the discovery of resources in the scope and searches for typical vulnerabilities. To manually restart the scanning, if the setting is on, switch it off, and then switch it back on again. Viewing detected vulnerabilities The vulnerabilities found by the scanner can be viewed on the Vulnerabilities tab of the web interface. In the scanner settings, you can perform the following actions: Configuring the list of detected vulnerabilities Disabling and enabling vulnerability re-check Configuring the scanner To see detailed information about configuring the scanner, proceed to this link . Active Threat Verification \u00b6 This setting enables or completely disables automatic attack reproduction by the scanner. You can later manually run the attack verification by clicking the Check button or using the Rules tab. Scanner's RPS Limits \u00b6 This setting limits the maximum load on the web application that will be generated by the scanner requests. The maximum number of requests per second (RPS) can be configured to a domain to an IP address If multiple domains are associated with the same IP address, then the speed of requests to this IP address will not exceed the limits for the IP address. If multiple IP addresses are associated with one domain, then the total speed of requests to these IP addresses within this domain will not exceed the limits for the domain. Limits can be overridden for individual IP addresses or domains. This is done within the network scope section. To restore default scanner RPS settings, click the Restore defaults button. Click Save to apply any changes made to the scanner settings.","title":"Scanner Settings"},{"location":"en/user-guides/cloud-ui/scanner/configure-scanner/#general-scanner-settings","text":"To access scanner settings, go to the Scanner tab and click the Settings button on the left.","title":"General Scanner Settings"},{"location":"en/user-guides/cloud-ui/scanner/configure-scanner/#scanner","text":"This setting enables or disables the discovery of resources in the scope and searches for typical vulnerabilities. To manually restart the scanning, if the setting is on, switch it off, and then switch it back on again. Viewing detected vulnerabilities The vulnerabilities found by the scanner can be viewed on the Vulnerabilities tab of the web interface. In the scanner settings, you can perform the following actions: Configuring the list of detected vulnerabilities Disabling and enabling vulnerability re-check Configuring the scanner To see detailed information about configuring the scanner, proceed to this link .","title":"Scanner"},{"location":"en/user-guides/cloud-ui/scanner/configure-scanner/#active-threat-verification","text":"This setting enables or completely disables automatic attack reproduction by the scanner. You can later manually run the attack verification by clicking the Check button or using the Rules tab.","title":"Active Threat Verification"},{"location":"en/user-guides/cloud-ui/scanner/configure-scanner/#scanners-rps-limits","text":"This setting limits the maximum load on the web application that will be generated by the scanner requests. The maximum number of requests per second (RPS) can be configured to a domain to an IP address If multiple domains are associated with the same IP address, then the speed of requests to this IP address will not exceed the limits for the IP address. If multiple IP addresses are associated with one domain, then the total speed of requests to these IP addresses within this domain will not exceed the limits for the domain. Limits can be overridden for individual IP addresses or domains. This is done within the network scope section. To restore default scanner RPS settings, click the Restore defaults button. Click Save to apply any changes made to the scanner settings.","title":"Scanner's RPS Limits"},{"location":"en/user-guides/cloud-ui/scanner/intro/","text":"Scanner Overview \u00b6 Scanner performs the following tasks: Network scope scanning Searching for typical vulnerabilities and security issues Active threat verification Updating the status of previously detected vulnerabilities Network Scope Scanning \u00b6 A network scope is a company's public resources (domains and IP addresses) connected to public networks. It defines an area to be scanned for typical vulnerabilities and is the cornerstone of the security process. As the project develops, the number of resources in the scope steadily increases and control over them inevitably decreases. The resources may be located not only in the company's data centers but also on shared hostings \u2014 for example, your marketers will create new landing pages and start new campaigns. These resources are placed on subdomains of the main project and can jeopardize the project's security. Hackers always choose the least protected resources on the company's scope and attempt to compromise these resources first. Wallarm integrates all the scope discovery mechanisms used by white hat hackers when assessing a company's security and running penetration tests. The scope discovery does not end at the domain and IP address mapping but also discovers the network resources that can be accessed from the Internet. To do this, Wallarm first scans ports and then detects the network resources on these ports. Various methods are used in the continuous process of collecting and updating scope data: Automatic modes DNS zone transfer ( AXFR ) NS and MX records receiving SPF records data receiving Subdomain dictionary search SSL certificate parsing Manual data entry via web interface or Wallarm API . This results in a map of the company's resources that is of the same quality as the one done by white hat hackers when doing penetration testing. Searching for Typical Vulnerabilities and Security Issues \u00b6 After collecting the network scope, the scanner checks all IP addresses and domains within it for any typical vulnerabilities. Active Threat Verification \u00b6 The scanner will automatically reproduce each attack from the traffic. This mechanism allows the detection of vulnerabilities that could have been exploited during the attack. For safety reasons, when reproducing attacks from requests, the authentication data (cookies, basic-auth, viewstate) is deleted. Correct operation of this functionality may require additional configuration from the application side. Updating the Status of Previously Detected Vulnerabilities \u00b6 The scanner regularly checks the status of vulnerabilities and automatically marks them as fixed or, on the contrary, reopens newly reproduced ones. Current vulnerabilities and vulnerabilities fixed less than a month ago are checked once a day. Vulnerabilities that were fixed more than a month ago are checked once a week. Vulnerabilities marked as false are not checked. See also Working with the scope Scanner settings","title":"Scanner Overview"},{"location":"en/user-guides/cloud-ui/scanner/intro/#scanner-overview","text":"Scanner performs the following tasks: Network scope scanning Searching for typical vulnerabilities and security issues Active threat verification Updating the status of previously detected vulnerabilities","title":"Scanner Overview"},{"location":"en/user-guides/cloud-ui/scanner/intro/#network-scope-scanning","text":"A network scope is a company's public resources (domains and IP addresses) connected to public networks. It defines an area to be scanned for typical vulnerabilities and is the cornerstone of the security process. As the project develops, the number of resources in the scope steadily increases and control over them inevitably decreases. The resources may be located not only in the company's data centers but also on shared hostings \u2014 for example, your marketers will create new landing pages and start new campaigns. These resources are placed on subdomains of the main project and can jeopardize the project's security. Hackers always choose the least protected resources on the company's scope and attempt to compromise these resources first. Wallarm integrates all the scope discovery mechanisms used by white hat hackers when assessing a company's security and running penetration tests. The scope discovery does not end at the domain and IP address mapping but also discovers the network resources that can be accessed from the Internet. To do this, Wallarm first scans ports and then detects the network resources on these ports. Various methods are used in the continuous process of collecting and updating scope data: Automatic modes DNS zone transfer ( AXFR ) NS and MX records receiving SPF records data receiving Subdomain dictionary search SSL certificate parsing Manual data entry via web interface or Wallarm API . This results in a map of the company's resources that is of the same quality as the one done by white hat hackers when doing penetration testing.","title":"Network Scope Scanning"},{"location":"en/user-guides/cloud-ui/scanner/intro/#searching-for-typical-vulnerabilities-and-security-issues","text":"After collecting the network scope, the scanner checks all IP addresses and domains within it for any typical vulnerabilities.","title":"Searching for Typical Vulnerabilities and Security Issues"},{"location":"en/user-guides/cloud-ui/scanner/intro/#active-threat-verification","text":"The scanner will automatically reproduce each attack from the traffic. This mechanism allows the detection of vulnerabilities that could have been exploited during the attack. For safety reasons, when reproducing attacks from requests, the authentication data (cookies, basic-auth, viewstate) is deleted. Correct operation of this functionality may require additional configuration from the application side.","title":"Active Threat Verification"},{"location":"en/user-guides/cloud-ui/scanner/intro/#updating-the-status-of-previously-detected-vulnerabilities","text":"The scanner regularly checks the status of vulnerabilities and automatically marks them as fixed or, on the contrary, reopens newly reproduced ones. Current vulnerabilities and vulnerabilities fixed less than a month ago are checked once a day. Vulnerabilities that were fixed more than a month ago are checked once a week. Vulnerabilities marked as false are not checked. See also Working with the scope Scanner settings","title":"Updating the Status of Previously Detected Vulnerabilities"},{"location":"en/user-guides/cloud-ui/scanner/reserved-domains/","text":"Domain Reservation \u00b6 If you reserve your domain in Wallarm, other customers cannot add them to their network scopes. Upon trying adding the reserved domain into another network scope, the following error message appears: This domain is reserved for a different Wallarm customer and cannot be added . How To Reserve Your Domain in Wallarm \u00b6 To reserve your domain, contact the Wallarm support team .","title":"Reserved Domains"},{"location":"en/user-guides/cloud-ui/scanner/reserved-domains/#domain-reservation","text":"If you reserve your domain in Wallarm, other customers cannot add them to their network scopes. Upon trying adding the reserved domain into another network scope, the following error message appears: This domain is reserved for a different Wallarm customer and cannot be added .","title":"Domain Reservation"},{"location":"en/user-guides/cloud-ui/scanner/reserved-domains/#how-to-reserve-your-domain-in-wallarm","text":"To reserve your domain, contact the Wallarm support team .","title":"How To Reserve Your Domain in Wallarm"},{"location":"en/user-guides/cloud-ui/search-and-filters/custom-report/","text":"Creating a Custom Report \u00b6 You can create a PDF report from your customized search results. Wallarm will email the custom report to you. Create a Report \u00b6 Go to the Events tab. Use the Search field to customize your search results. Click the report button on the right. Put in your e-mail address and click the report button next to the e-mail field. Wallarm will generate the report and email it to you. See also Using search","title":"Creating a Custom Report"},{"location":"en/user-guides/cloud-ui/search-and-filters/custom-report/#creating-a-custom-report","text":"You can create a PDF report from your customized search results. Wallarm will email the custom report to you.","title":"Creating a Custom Report"},{"location":"en/user-guides/cloud-ui/search-and-filters/custom-report/#create-a-report","text":"Go to the Events tab. Use the Search field to customize your search results. Click the report button on the right. Put in your e-mail address and click the report button next to the e-mail field. Wallarm will generate the report and email it to you. See also Using search","title":"Create a Report"},{"location":"en/user-guides/cloud-ui/search-and-filters/use-filter/","text":"Using Filters \u00b6 You can select data via filters. To open the filter panel, click the filter button on the search bar. The filters that can be applied to data will appear under the search bar. The values set in the filters are automatically duplicated in the search field, and vice versa. Any search query or a filter combination can be saved by clicking Save as template .","title":"Using Filters"},{"location":"en/user-guides/cloud-ui/search-and-filters/use-filter/#using-filters","text":"You can select data via filters. To open the filter panel, click the filter button on the search bar. The filters that can be applied to data will appear under the search bar. The values set in the filters are automatically duplicated in the search field, and vice versa. Any search query or a filter combination can be saved by clicking Save as template .","title":"Using Filters"},{"location":"en/user-guides/cloud-ui/search-and-filters/use-search/","text":"Using Search \u00b6 You can search for virtually any attribute of attacks, incidents, and vulnerabilities. Wallarm is equipped with a query language similar to human language, which makes submitting queries intuitive. Queries can be refined using special modifiers, which are described below. When values of different parameters are specified, the results will meet all those conditions. When different values for the same parameter are specified, the results will meet any of those conditions. To search within a single application, specify in the search string pool:<application name> , where <application name> is set on the Applications tab in the Settings section. Examples of search requests: attacks xss : to search for all XSS-attacks . attacks today : to search for all attacks that happened today. vulns sqli : to search for SQL-injection vulnerabilities. vulns 01/01/2019-01/10/2019 : to search for vulnerabilities within a certain period of time. xss 01/14/2019 : to search for all vulnerabilities, suspicions, attacks, and incidents of cross-site scripting on 14 January 2019. p:xss 01/14/2019 : to search for all vulnerabilities, suspicions, attacks, and incidents of all types within the xss HTTP request parameter (i.e. http://localhost/?xss=attack-here ) as of 14 January 2019. attacks 2-9/2018 : to search for all attacks from February to September 2018. rce /catalog/import.php : to search for all RCE attacks, incidents, and vulnerabilities on /catalog/import.php path since yesterday. In addition to using the search string, you can retrieve data using filters (see Using Filters ). Parameters you enter into the search string will automatically duplicate in the filters and vice versa. Save as a filter Any search query or combination of filters can be saved using the Save as template button and quickly accessed later with the Searches drop-down list. Search Attributes \u00b6 Type of object Type of attack or vulnerability Aim of attack or vulnerability Severity level Vulnerability identifier Vulnerability status Time IP address Server response status Server response size HTTP request method Domain Path Parameter Request identifier Search by Object Type \u00b6 Specify in the search string: attack , attacks : to search only for the attacks that are not aimed at known vulnerabilities. incident , incidents : to search only for incidents (attacks exploiting a known vulnerability). vuln , vulns , vulnerability , vulnerabilities : to search only for vulnerabilities. Search by Attack Type or Vulnerability Type \u00b6 Specify in the search string: sqli : to search for SQL injection attacks/vulnerabilities. xss : to search for Cross Site Scripting attacks/vulnerabilities. rce : to search for OS Commanding attacks/vulnerabilities. brute : to search for brute-force attacks. ptrav : to search for path traversal attacks. crlf : to search for CRLF injection attacks/vulnerabilities. redir : to search for open redirect vulnerabilities. nosqli : to search for NoSQL injection attacks/vulnerabilities. logic_bomb : to search for logic bomb attacks. overlimit_res : to search for attacks aimed at overlimiting of computational resources . xxe : to search for XML External Entity attacks. vpatch : to search for virtual patches . dirbust : to search for forced browsing attacks. ldapi : to search for LDAP injection attacks/vulnerabilities. scanner : to search for port scanner attacks/vulnerabilities. info : to search for attacks/vulnerabilities of information disclosure . An attack or vulnerability name can be specified in both uppercase and lowercase letters: SQLI , sqli , and SQLi are equally correct. Search by the Attack Target or the Vulnerability Target \u00b6 Specify in the search string: client : to search for client data attacks/vulnerabilities. database : to search for database attacks/vulnerabilities. server : to search for app server attacks/vulnerabilities. Search by Risk Level \u00b6 Specify the risk level in the search string: low : low risk level. medium : medium risk level. high : high risk level. Search by Vulnerability Identifier \u00b6 To search for a certain vulnerability, specify its identifier. It can be specified in two ways: either fully: WLRM-ABCD-X0123 or in abbreviated form: X0123 Search by Vulnerability Status \u00b6 Specify vulnerability status in the search string. Vulnerability can have one of the three statuses: open : currently relevant vulnerability; closed : fixed vulnerability; falsepositive : vulnerability marked as false. Search by Event Time \u00b6 Specify time range in the search string. If the time interval is not specified, the search is conducted within the events occurred during the last 24 hours. Use the following data format: MM/DD/YYYY (for example, 01/14/2014 ). If year is not specified, the current year is used. Thus, 01/14 is the same as 01/14/2019 . Usage of string aliases is possible: yesterday : always equal to yesterday's date. today : always equal to today's date. You can also specify the following intervals for the search: by date: 01/10/2019-01/14/2019 by time (seconds are disregarded): 01/10/2019 11:11 , 11:30-12:22 , 01/10/2019 11:12-01/14/2019 12:14 with relation to a certain moment of time: >01/10/19 Search by IP Address \u00b6 To search by IP address, use the ip: prefix, after which you can specify A specific IP address, for example 192.168.0.1 \u2014in this case, all attacks and incidents will be found for which the source address of the attack corresponds to this IP address. An expression describing a range of IP addresses. A total number of IP addresses related to an attack or incident. Search by IP Address Range \u00b6 To set a required range of IP addresses, you can use An explicit IP address range: 192.168.0.0-192.168.63.255 10.0.0.0-10.255.255.255 A part of an IP address: 192.168. \u2014equivalent to 192.168.0.0-192.168.255.255 . Redundant format with the * modifier is allowed\u2014 192.168.* 192.168.0. \u2014equivalent to 192.168.0.0-192.168.0.255 An IP address or part of it with a range of values inside the last octet in the expression: 192.168.1.0-255 \u2014equivalent to 192.168.1.0-192.168.1.255 192.168.0-255 \u2014equivalent to 192.168.0.0-192.168.255.255 #### Warning:: Important When using a range of values within an octet, a dot is not set at the end. Subnet prefixes ( CIDR notation ): 192.168.1.0/24 \u2014equivalent to 192.168.1.0-192.168.1.255 192.168.0.0/17 \u2014equivalent to 192.168.0.1-192.168.127.255 #### Info:: Note You can combine the above methods for defining IP address ranges. To do this, list all the necessary ranges with the ip: prefix separately. Example : ip:192.168.0.0/24 ip:10.10. ip:10.0.10.0-128 Search by Number of IP Addresses \u00b6 It is possible to search by the total number of IP addresses that are related to an attack or an incident (only for attacks and incidents): ip:1000+ last month \u2014search for attacks and incidents over the past month for which the number of unique IP addresses is more than 1000 (equivalent to attacks incidents ip:1000+ last month ). xss ip:100+ \u2014search for all cross-site scripting attacks and incidents. The search result will be empty if the number of attacking IP addresses (with the XSS attack type) is less than 100. xss p:id ip:100+ \u2014search for all XSS attacks and incidents related to the id parameter ( ?id=aaa ). This will return results only if the number of different IP addresses exceeds 100. Search by Server Response Status \u00b6 To search by server response status, specify statuscode: prefix. Response status can be specified as: a number from 100 to 999. \u00abN\u2013M\u00bb range, where N and M are figures from 100 to 999. \u00abN+\u00bb and \u00abN-\u00bb ranges, where N is a number from 100 to 999. Search by Server Response Size \u00b6 To search by the server response size, use the s: or size: prefix. You can search for any integer value. Figures above 999 can be specified without a prefix. The \u00abN\u2013M\u00bb, \u00abN+\u00bb and \u00abN-\u00bb ranges can be specified, where figures above 999 can also be specified without a prefix. Search by HTTP Request Method \u00b6 To search by HTTP request method, specify the method: prefix. To search for GET , POST , PUT , DELETE , OPTIONS : if upper-case is used, then the search string can be specified without a prefix. For all other values, a prefix should be specified. Search by Domain \u00b6 To search by domain, use the d: or domain: prefix. Any string, that may be a domain of the second or a higher level can be specified without a prefix. Any string can be specified with a prefix. You may use masks within a domain. The symbol * replaces any number of characters; the symbol ? replaces any single character. Search by Path \u00b6 To search by path, use the u: or url: prefix. Strings that start with / are processed without a prefix. Any string can be specified with a prefix. Search by Parameter \u00b6 To search by parameter, use the p: , param: , or parameter: prefix and also the = suffix. For example, if you need to find attacks aimed at the xss parameter but not at XSS-attacks (for instance, SQL-injection attack having xss in the GET-parameter), specify attacks p:xss in the search string. A string that does not start with / and ends with = is considered to be a parameter (wherein the ending = character is not included in the value). Any string can be specified with a prefix. Search for Anomalies in Attacks \u00b6 To search for anomalies in attacks, use the a: or anomaly: prefix. To refine an anomaly search, use the following parameters: size statuscode time stamps impression vector Example: attacks sqli a:size will search for all SQL-injection attacks, that have response size anomalies in their requests. Search by Request Identifier \u00b6 To search for attacks and incidents by request identifier, specify the request_id prefix. The request_id parameter has the following value form: a79199bcea606040cc79f913325401fb . To make it easier to read, in the examples below this parameter has been replaced by the placeholder abbreviation <requestId> . Examples: attacks incidents request_id:<requestId> : to search for an attack or an incident with the request_id equal to <requestId> . attacks incidents !request_id:<requestId> : to search for attacks and incidents with the request_id not equal to <requestId> . attacks incidents request_id : to search for attacks and incidents with any request_id . attacks incidents !request_id : to search for attacks and incidents without any request_id . See also Using filters","title":"Using Search"},{"location":"en/user-guides/cloud-ui/search-and-filters/use-search/#using-search","text":"You can search for virtually any attribute of attacks, incidents, and vulnerabilities. Wallarm is equipped with a query language similar to human language, which makes submitting queries intuitive. Queries can be refined using special modifiers, which are described below. When values of different parameters are specified, the results will meet all those conditions. When different values for the same parameter are specified, the results will meet any of those conditions. To search within a single application, specify in the search string pool:<application name> , where <application name> is set on the Applications tab in the Settings section. Examples of search requests: attacks xss : to search for all XSS-attacks . attacks today : to search for all attacks that happened today. vulns sqli : to search for SQL-injection vulnerabilities. vulns 01/01/2019-01/10/2019 : to search for vulnerabilities within a certain period of time. xss 01/14/2019 : to search for all vulnerabilities, suspicions, attacks, and incidents of cross-site scripting on 14 January 2019. p:xss 01/14/2019 : to search for all vulnerabilities, suspicions, attacks, and incidents of all types within the xss HTTP request parameter (i.e. http://localhost/?xss=attack-here ) as of 14 January 2019. attacks 2-9/2018 : to search for all attacks from February to September 2018. rce /catalog/import.php : to search for all RCE attacks, incidents, and vulnerabilities on /catalog/import.php path since yesterday. In addition to using the search string, you can retrieve data using filters (see Using Filters ). Parameters you enter into the search string will automatically duplicate in the filters and vice versa. Save as a filter Any search query or combination of filters can be saved using the Save as template button and quickly accessed later with the Searches drop-down list.","title":"Using Search"},{"location":"en/user-guides/cloud-ui/search-and-filters/use-search/#search-attributes","text":"Type of object Type of attack or vulnerability Aim of attack or vulnerability Severity level Vulnerability identifier Vulnerability status Time IP address Server response status Server response size HTTP request method Domain Path Parameter Request identifier","title":"Search Attributes"},{"location":"en/user-guides/cloud-ui/search-and-filters/use-search/#search-by-object-type","text":"Specify in the search string: attack , attacks : to search only for the attacks that are not aimed at known vulnerabilities. incident , incidents : to search only for incidents (attacks exploiting a known vulnerability). vuln , vulns , vulnerability , vulnerabilities : to search only for vulnerabilities.","title":"Search by Object Type"},{"location":"en/user-guides/cloud-ui/search-and-filters/use-search/#search-by-attack-type-or-vulnerability-type","text":"Specify in the search string: sqli : to search for SQL injection attacks/vulnerabilities. xss : to search for Cross Site Scripting attacks/vulnerabilities. rce : to search for OS Commanding attacks/vulnerabilities. brute : to search for brute-force attacks. ptrav : to search for path traversal attacks. crlf : to search for CRLF injection attacks/vulnerabilities. redir : to search for open redirect vulnerabilities. nosqli : to search for NoSQL injection attacks/vulnerabilities. logic_bomb : to search for logic bomb attacks. overlimit_res : to search for attacks aimed at overlimiting of computational resources . xxe : to search for XML External Entity attacks. vpatch : to search for virtual patches . dirbust : to search for forced browsing attacks. ldapi : to search for LDAP injection attacks/vulnerabilities. scanner : to search for port scanner attacks/vulnerabilities. info : to search for attacks/vulnerabilities of information disclosure . An attack or vulnerability name can be specified in both uppercase and lowercase letters: SQLI , sqli , and SQLi are equally correct.","title":"Search by Attack Type or Vulnerability Type"},{"location":"en/user-guides/cloud-ui/search-and-filters/use-search/#search-by-the-attack-target-or-the-vulnerability-target","text":"Specify in the search string: client : to search for client data attacks/vulnerabilities. database : to search for database attacks/vulnerabilities. server : to search for app server attacks/vulnerabilities.","title":"Search by the Attack Target or the Vulnerability Target"},{"location":"en/user-guides/cloud-ui/search-and-filters/use-search/#search-by-risk-level","text":"Specify the risk level in the search string: low : low risk level. medium : medium risk level. high : high risk level.","title":"Search by Risk Level"},{"location":"en/user-guides/cloud-ui/search-and-filters/use-search/#search-by-vulnerability-identifier","text":"To search for a certain vulnerability, specify its identifier. It can be specified in two ways: either fully: WLRM-ABCD-X0123 or in abbreviated form: X0123","title":"Search by Vulnerability Identifier"},{"location":"en/user-guides/cloud-ui/search-and-filters/use-search/#search-by-vulnerability-status","text":"Specify vulnerability status in the search string. Vulnerability can have one of the three statuses: open : currently relevant vulnerability; closed : fixed vulnerability; falsepositive : vulnerability marked as false.","title":"Search by Vulnerability Status"},{"location":"en/user-guides/cloud-ui/search-and-filters/use-search/#search-by-event-time","text":"Specify time range in the search string. If the time interval is not specified, the search is conducted within the events occurred during the last 24 hours. Use the following data format: MM/DD/YYYY (for example, 01/14/2014 ). If year is not specified, the current year is used. Thus, 01/14 is the same as 01/14/2019 . Usage of string aliases is possible: yesterday : always equal to yesterday's date. today : always equal to today's date. You can also specify the following intervals for the search: by date: 01/10/2019-01/14/2019 by time (seconds are disregarded): 01/10/2019 11:11 , 11:30-12:22 , 01/10/2019 11:12-01/14/2019 12:14 with relation to a certain moment of time: >01/10/19","title":"Search by Event Time"},{"location":"en/user-guides/cloud-ui/search-and-filters/use-search/#search-by-ip-address","text":"To search by IP address, use the ip: prefix, after which you can specify A specific IP address, for example 192.168.0.1 \u2014in this case, all attacks and incidents will be found for which the source address of the attack corresponds to this IP address. An expression describing a range of IP addresses. A total number of IP addresses related to an attack or incident.","title":"Search by IP Address"},{"location":"en/user-guides/cloud-ui/search-and-filters/use-search/#search-by-ip-address-range","text":"To set a required range of IP addresses, you can use An explicit IP address range: 192.168.0.0-192.168.63.255 10.0.0.0-10.255.255.255 A part of an IP address: 192.168. \u2014equivalent to 192.168.0.0-192.168.255.255 . Redundant format with the * modifier is allowed\u2014 192.168.* 192.168.0. \u2014equivalent to 192.168.0.0-192.168.0.255 An IP address or part of it with a range of values inside the last octet in the expression: 192.168.1.0-255 \u2014equivalent to 192.168.1.0-192.168.1.255 192.168.0-255 \u2014equivalent to 192.168.0.0-192.168.255.255 #### Warning:: Important When using a range of values within an octet, a dot is not set at the end. Subnet prefixes ( CIDR notation ): 192.168.1.0/24 \u2014equivalent to 192.168.1.0-192.168.1.255 192.168.0.0/17 \u2014equivalent to 192.168.0.1-192.168.127.255 #### Info:: Note You can combine the above methods for defining IP address ranges. To do this, list all the necessary ranges with the ip: prefix separately. Example : ip:192.168.0.0/24 ip:10.10. ip:10.0.10.0-128","title":"Search by IP Address Range"},{"location":"en/user-guides/cloud-ui/search-and-filters/use-search/#search-by-number-of-ip-addresses","text":"It is possible to search by the total number of IP addresses that are related to an attack or an incident (only for attacks and incidents): ip:1000+ last month \u2014search for attacks and incidents over the past month for which the number of unique IP addresses is more than 1000 (equivalent to attacks incidents ip:1000+ last month ). xss ip:100+ \u2014search for all cross-site scripting attacks and incidents. The search result will be empty if the number of attacking IP addresses (with the XSS attack type) is less than 100. xss p:id ip:100+ \u2014search for all XSS attacks and incidents related to the id parameter ( ?id=aaa ). This will return results only if the number of different IP addresses exceeds 100.","title":"Search by Number of IP Addresses"},{"location":"en/user-guides/cloud-ui/search-and-filters/use-search/#search-by-server-response-status","text":"To search by server response status, specify statuscode: prefix. Response status can be specified as: a number from 100 to 999. \u00abN\u2013M\u00bb range, where N and M are figures from 100 to 999. \u00abN+\u00bb and \u00abN-\u00bb ranges, where N is a number from 100 to 999.","title":"Search by Server Response Status"},{"location":"en/user-guides/cloud-ui/search-and-filters/use-search/#search-by-server-response-size","text":"To search by the server response size, use the s: or size: prefix. You can search for any integer value. Figures above 999 can be specified without a prefix. The \u00abN\u2013M\u00bb, \u00abN+\u00bb and \u00abN-\u00bb ranges can be specified, where figures above 999 can also be specified without a prefix.","title":"Search by Server Response Size"},{"location":"en/user-guides/cloud-ui/search-and-filters/use-search/#search-by-http-request-method","text":"To search by HTTP request method, specify the method: prefix. To search for GET , POST , PUT , DELETE , OPTIONS : if upper-case is used, then the search string can be specified without a prefix. For all other values, a prefix should be specified.","title":"Search by HTTP Request Method"},{"location":"en/user-guides/cloud-ui/search-and-filters/use-search/#search-by-domain","text":"To search by domain, use the d: or domain: prefix. Any string, that may be a domain of the second or a higher level can be specified without a prefix. Any string can be specified with a prefix. You may use masks within a domain. The symbol * replaces any number of characters; the symbol ? replaces any single character.","title":"Search by Domain"},{"location":"en/user-guides/cloud-ui/search-and-filters/use-search/#search-by-path","text":"To search by path, use the u: or url: prefix. Strings that start with / are processed without a prefix. Any string can be specified with a prefix.","title":"Search by Path"},{"location":"en/user-guides/cloud-ui/search-and-filters/use-search/#search-by-parameter","text":"To search by parameter, use the p: , param: , or parameter: prefix and also the = suffix. For example, if you need to find attacks aimed at the xss parameter but not at XSS-attacks (for instance, SQL-injection attack having xss in the GET-parameter), specify attacks p:xss in the search string. A string that does not start with / and ends with = is considered to be a parameter (wherein the ending = character is not included in the value). Any string can be specified with a prefix.","title":"Search by Parameter"},{"location":"en/user-guides/cloud-ui/search-and-filters/use-search/#search-for-anomalies-in-attacks","text":"To search for anomalies in attacks, use the a: or anomaly: prefix. To refine an anomaly search, use the following parameters: size statuscode time stamps impression vector Example: attacks sqli a:size will search for all SQL-injection attacks, that have response size anomalies in their requests.","title":"Search for Anomalies in Attacks"},{"location":"en/user-guides/cloud-ui/search-and-filters/use-search/#search-by-request-identifier","text":"To search for attacks and incidents by request identifier, specify the request_id prefix. The request_id parameter has the following value form: a79199bcea606040cc79f913325401fb . To make it easier to read, in the examples below this parameter has been replaced by the placeholder abbreviation <requestId> . Examples: attacks incidents request_id:<requestId> : to search for an attack or an incident with the request_id equal to <requestId> . attacks incidents !request_id:<requestId> : to search for attacks and incidents with the request_id not equal to <requestId> . attacks incidents request_id : to search for attacks and incidents with any request_id . attacks incidents !request_id : to search for attacks and incidents without any request_id . See also Using filters","title":"Search by Request Identifier"},{"location":"en/user-guides/cloud-ui/settings/account/","text":"Checking Your Profile \u00b6 To see your profile data and settings, proceed to Settings \u2192 Profile tab. In your profile, you can check your account information. Your E-mail is shown in large font at the top of the page. Your Role in the Wallarm system \u2014 Admin , Analyst , or Deploy is shown right below your e-mail. Name & phone . Date & time format : your preferred date and time format to be used in the Wallarm system. E-mail reports : your preferred reports frequency and reported events. Security : your last password data change and Two-Factor authentication status. Recent sign in : your sign-in history in the Wallarm system. You can click the Sign out button to log out of your Wallarm account. Configuring Your Profile \u00b6 Changing Your Name and Phone Number \u00b6 Click your current name. In the form that appears, enter your new first name, last name, and phone number. Click the Save button to apply changes. Changing Your Date & Time Format \u00b6 Click your current preferred date&time format. Pick the desired date&time format from the drop-down list. Select the checkbox 24-hour time to display time in the 24-hour format. Changing Your Personal Reports Settings \u00b6 Click your current personal reports settings. In the form that appears, select your desired report frequency and reported events. Click the Save button to apply changes. Changing Your Password \u00b6 Click the Change button. In the form that appears, enter your current password, your new password, and a new password confirmation. Click the Change password button Enabling Two-Factor Authentication \u00b6 You can use Google Authenticator (or similar apps supporting TOTP) to enable two-factor authentication. Install the Google Authenticator app ( Android , iOS ) or any compatible one. Click Enable in Two-Factor Authentication setting. Scan the QR code that appears (or click the manual entry link and use the manual entry option). Enter the 6-digit verification code generated by your app. Click Confirm . Whenever you sign in you will be prompted for your second factor code after passing the password prompt. Get this code from your Google Authenticator app. The password is required if you want to turn two-factor authentication off. Compatibility You can use any application or device that supports Time-Based One-Time Password Algorithm (RFC6238) to generate one-time codes.","title":"Profile"},{"location":"en/user-guides/cloud-ui/settings/account/#checking-your-profile","text":"To see your profile data and settings, proceed to Settings \u2192 Profile tab. In your profile, you can check your account information. Your E-mail is shown in large font at the top of the page. Your Role in the Wallarm system \u2014 Admin , Analyst , or Deploy is shown right below your e-mail. Name & phone . Date & time format : your preferred date and time format to be used in the Wallarm system. E-mail reports : your preferred reports frequency and reported events. Security : your last password data change and Two-Factor authentication status. Recent sign in : your sign-in history in the Wallarm system. You can click the Sign out button to log out of your Wallarm account.","title":"Checking Your Profile"},{"location":"en/user-guides/cloud-ui/settings/account/#configuring-your-profile","text":"","title":"Configuring Your Profile"},{"location":"en/user-guides/cloud-ui/settings/account/#changing-your-name-and-phone-number","text":"Click your current name. In the form that appears, enter your new first name, last name, and phone number. Click the Save button to apply changes.","title":"Changing Your Name and Phone Number"},{"location":"en/user-guides/cloud-ui/settings/account/#changing-your-date-time-format","text":"Click your current preferred date&time format. Pick the desired date&time format from the drop-down list. Select the checkbox 24-hour time to display time in the 24-hour format.","title":"Changing Your Date &amp; Time Format"},{"location":"en/user-guides/cloud-ui/settings/account/#changing-your-personal-reports-settings","text":"Click your current personal reports settings. In the form that appears, select your desired report frequency and reported events. Click the Save button to apply changes.","title":"Changing Your Personal Reports Settings"},{"location":"en/user-guides/cloud-ui/settings/account/#changing-your-password","text":"Click the Change button. In the form that appears, enter your current password, your new password, and a new password confirmation. Click the Change password button","title":"Changing Your Password"},{"location":"en/user-guides/cloud-ui/settings/account/#enabling-two-factor-authentication","text":"You can use Google Authenticator (or similar apps supporting TOTP) to enable two-factor authentication. Install the Google Authenticator app ( Android , iOS ) or any compatible one. Click Enable in Two-Factor Authentication setting. Scan the QR code that appears (or click the manual entry link and use the manual entry option). Enter the 6-digit verification code generated by your app. Click Confirm . Whenever you sign in you will be prompted for your second factor code after passing the password prompt. Get this code from your Google Authenticator app. The password is required if you want to turn two-factor authentication off. Compatibility You can use any application or device that supports Time-Based One-Time Password Algorithm (RFC6238) to generate one-time codes.","title":"Enabling Two-Factor Authentication"},{"location":"en/user-guides/cloud-ui/settings/applications/","text":"Application Settings \u00b6 #### Warning:: Administrator access Only users with the **Administrator** role can access this setting. You can add applications on the Settings \u2192 Applications tab of the Wallarm interface. If your company has several web applications, you may find it convenient not only to view the statistics of the entire company's traffic and vulnerabilities but also to view the statistics separately for each application. You can set any arbitrary numeric value as an application ID. Adding an Application \u00b6 Click Add application . Set an application ID and an application name. In the filter node configuration file, set the created ID in the wallarm_instance directive. If the ID is unique, the Dashboard tab will let you select the new application. Managing Applications \u00b6 The Edit and Delete buttons appear upon hovering the cursor over the application entry. Edit : change the name of the corresponding application. Delete : remove the corresponding application entry. See also Wallarm configuration options","title":"Applications"},{"location":"en/user-guides/cloud-ui/settings/applications/#application-settings","text":"#### Warning:: Administrator access Only users with the **Administrator** role can access this setting. You can add applications on the Settings \u2192 Applications tab of the Wallarm interface. If your company has several web applications, you may find it convenient not only to view the statistics of the entire company's traffic and vulnerabilities but also to view the statistics separately for each application. You can set any arbitrary numeric value as an application ID.","title":"Application Settings"},{"location":"en/user-guides/cloud-ui/settings/applications/#adding-an-application","text":"Click Add application . Set an application ID and an application name. In the filter node configuration file, set the created ID in the wallarm_instance directive. If the ID is unique, the Dashboard tab will let you select the new application.","title":"Adding an Application"},{"location":"en/user-guides/cloud-ui/settings/applications/#managing-applications","text":"The Edit and Delete buttons appear upon hovering the cursor over the application entry. Edit : change the name of the corresponding application. Delete : remove the corresponding application entry. See also Wallarm configuration options","title":"Managing Applications"},{"location":"en/user-guides/cloud-ui/settings/audit-log/","text":"User Activity Log \u00b6 On the Settings \u2192 Activity log tab, you can check the history of user actions in the Wallarm system. Sort User Activity Records \u00b6 You can sort the user activity entries by selecting one of the following filters: All actions Create Update Delete See also Configure users","title":"Activity Log"},{"location":"en/user-guides/cloud-ui/settings/audit-log/#user-activity-log","text":"On the Settings \u2192 Activity log tab, you can check the history of user actions in the Wallarm system.","title":"User Activity Log"},{"location":"en/user-guides/cloud-ui/settings/audit-log/#sort-user-activity-records","text":"You can sort the user activity entries by selecting one of the following filters: All actions Create Update Delete See also Configure users","title":"Sort User Activity Records"},{"location":"en/user-guides/cloud-ui/settings/general/","text":"General Settings \u00b6 The General tab of the Settings section allows users to switch between different Wallarm operation modes: Default : this mode exploits settings from a filter node configuration file. Monitoring : all requests are processed, but none of them are blocked even if an attack is detected. Blocking : all requests where an attack was detected are blocked. To learn more about available configuration options, proceed to the link . Qrator Those Wallarm customers plugged in with Qrator traffic filters have the Blocking with Qrator setting. This setting enables automatic malicious requests blocking. The blocking is done with the Qrator IP blacklists. Wallarm transfers to Qrator the data on those IP addresses from which the attacks originated.","title":"General"},{"location":"en/user-guides/cloud-ui/settings/general/#general-settings","text":"The General tab of the Settings section allows users to switch between different Wallarm operation modes: Default : this mode exploits settings from a filter node configuration file. Monitoring : all requests are processed, but none of them are blocked even if an attack is detected. Blocking : all requests where an attack was detected are blocked. To learn more about available configuration options, proceed to the link . Qrator Those Wallarm customers plugged in with Qrator traffic filters have the Blocking with Qrator setting. This setting enables automatic malicious requests blocking. The blocking is done with the Qrator IP blacklists. Wallarm transfers to Qrator the data on those IP addresses from which the attacks originated.","title":"General Settings"},{"location":"en/user-guides/cloud-ui/settings/markers/","text":"Setting Markers \u00b6 You can set markers on the Settings \u2192 Markers tab. Markers allow you to mark HTTP/HTTPS packets to have Wallarm process them in a special way. Markers can be used for the following purposes: Authentication of the scanner and the application vulnerability checks. Start of the vulnerability search in the newly added application components or API (to provide Continuous Integration/Continuous Delivery). Update of an application profile (for situations, when you need to deploy an application's or API's new functionality as fast as possible). Creating a Marker \u00b6 A marker is a 64-bit secret key that must be placed into the X-Wallarm-Marker header of an HTTP request. An example of a marker in the request header: X-Wallarm-Marker: bdb1fcc94e807fbfa59c79xxxxxxxxxxcbd2ec8c33557c94a90b39a7491fd004 To create a marker proceed with the following steps: Click Add marker . Enter a description, an IP address, and a subnet mask into the form that appears. Click Add . Info:: \u00b6 The filter node will use the marker only if its current IP address and the subnet mask match the ones set in the Wallarm interface. The requests marked with the X-Wallarm-Marker header will be used to update the application profile. Markers and Fuzzing \u00b6 Fuzzing is a method of provoking abnormal behavior in a program by inputting atypical data in the program. There is a high probability that fuzzing can cause errors in the program. Wallarm uses fuzzing only for the requests that are marked as safe to be modified. This method, along with unit tests, provides greater coverage from the information security point of view and covers an application's new components that are being tested, deployed, or are already deployed. Advanced fuzzing support is in high demand with the companies using Continuous Integration/Continuous Delivery. Setting a Fuzzer \u00b6 To set up a fuzzer, do the following: Add the following header to the request: X-Wallarm-Marker: <marker> Add the following header to the request: X-Wallarm-Fuzzer: yes Add advanced settings to the header X-Wallarm-Fuzzer-Policy : * replace-all <N> * add-to-end <N> * add-to-begin <N> * replace-from-end <M> <N> * replace-from-begin <M> <N> * insert-into-random <N> Each vulnerability discovered during the checks will appear on the Vulnerabilities tab of the Wallarm interface. For such vulnerability, there will also be a report generated and sent to your email.","title":"Markers"},{"location":"en/user-guides/cloud-ui/settings/markers/#setting-markers","text":"You can set markers on the Settings \u2192 Markers tab. Markers allow you to mark HTTP/HTTPS packets to have Wallarm process them in a special way. Markers can be used for the following purposes: Authentication of the scanner and the application vulnerability checks. Start of the vulnerability search in the newly added application components or API (to provide Continuous Integration/Continuous Delivery). Update of an application profile (for situations, when you need to deploy an application's or API's new functionality as fast as possible).","title":"Setting Markers"},{"location":"en/user-guides/cloud-ui/settings/markers/#creating-a-marker","text":"A marker is a 64-bit secret key that must be placed into the X-Wallarm-Marker header of an HTTP request. An example of a marker in the request header: X-Wallarm-Marker: bdb1fcc94e807fbfa59c79xxxxxxxxxxcbd2ec8c33557c94a90b39a7491fd004 To create a marker proceed with the following steps: Click Add marker . Enter a description, an IP address, and a subnet mask into the form that appears. Click Add .","title":"Creating a Marker"},{"location":"en/user-guides/cloud-ui/settings/markers/#info","text":"The filter node will use the marker only if its current IP address and the subnet mask match the ones set in the Wallarm interface. The requests marked with the X-Wallarm-Marker header will be used to update the application profile.","title":"Info::"},{"location":"en/user-guides/cloud-ui/settings/markers/#markers-and-fuzzing","text":"Fuzzing is a method of provoking abnormal behavior in a program by inputting atypical data in the program. There is a high probability that fuzzing can cause errors in the program. Wallarm uses fuzzing only for the requests that are marked as safe to be modified. This method, along with unit tests, provides greater coverage from the information security point of view and covers an application's new components that are being tested, deployed, or are already deployed. Advanced fuzzing support is in high demand with the companies using Continuous Integration/Continuous Delivery.","title":"Markers and Fuzzing"},{"location":"en/user-guides/cloud-ui/settings/markers/#setting-a-fuzzer","text":"To set up a fuzzer, do the following: Add the following header to the request: X-Wallarm-Marker: <marker> Add the following header to the request: X-Wallarm-Fuzzer: yes Add advanced settings to the header X-Wallarm-Fuzzer-Policy : * replace-all <N> * add-to-end <N> * add-to-begin <N> * replace-from-end <M> <N> * replace-from-begin <M> <N> * insert-into-random <N> Each vulnerability discovered during the checks will appear on the Vulnerabilities tab of the Wallarm interface. For such vulnerability, there will also be a report generated and sent to your email.","title":"Setting a Fuzzer"},{"location":"en/user-guides/cloud-ui/settings/subscriptions/","text":"Subscriptions \u00b6 The Subscriptions tab of the Settings section allows users to view the status of their current subscriptions. The Subscriptions tab provides the following information: Name of the subscription and its status Subscription expiration date Quota usage and limits, if a quota is set for a subscription Request statistics: the average number of requests (monthly) List of the modules included in the subscription and additional information about each of them Viewing Information About a Quota \u00b6 The information about a monthly request quota is displayed right under the subscription's name: \u201cUnlimited,\u201d if no quota is set data about limits, if a quota is set To modify the existing quota limits, contact Wallarm Support . Viewing Request Statictics \u00b6 Monthly statistics are displayed under the \u201cMonthly requests average\u201d value. Click the \u201cView full usage history\u201d link to open a pop-up window containing the full statistics. In this window, you can sort the content either by the month or number of requests. To sort table entries, click the corresponding column. #### Info:: Calculation of the Average Requests Value Note that the number of requests in the current month is not taken into account when the \u201cMonthly requests average\u201d value is calculated. Working with Subscriptions \u00b6 Contact Wallarm Support to find out more about available subscriptions and included modules, to make changes to the current subscription plan, and to renew an expired subscription. To contact support, either send an email or click the \u201ccontact us\u201d link at the end of the Subscriptions page.","title":"Subscriptions"},{"location":"en/user-guides/cloud-ui/settings/subscriptions/#subscriptions","text":"The Subscriptions tab of the Settings section allows users to view the status of their current subscriptions. The Subscriptions tab provides the following information: Name of the subscription and its status Subscription expiration date Quota usage and limits, if a quota is set for a subscription Request statistics: the average number of requests (monthly) List of the modules included in the subscription and additional information about each of them","title":"Subscriptions"},{"location":"en/user-guides/cloud-ui/settings/subscriptions/#viewing-information-about-a-quota","text":"The information about a monthly request quota is displayed right under the subscription's name: \u201cUnlimited,\u201d if no quota is set data about limits, if a quota is set To modify the existing quota limits, contact Wallarm Support .","title":"Viewing Information About a Quota"},{"location":"en/user-guides/cloud-ui/settings/subscriptions/#viewing-request-statictics","text":"Monthly statistics are displayed under the \u201cMonthly requests average\u201d value. Click the \u201cView full usage history\u201d link to open a pop-up window containing the full statistics. In this window, you can sort the content either by the month or number of requests. To sort table entries, click the corresponding column. #### Info:: Calculation of the Average Requests Value Note that the number of requests in the current month is not taken into account when the \u201cMonthly requests average\u201d value is calculated.","title":"Viewing Request Statictics"},{"location":"en/user-guides/cloud-ui/settings/subscriptions/#working-with-subscriptions","text":"Contact Wallarm Support to find out more about available subscriptions and included modules, to make changes to the current subscription plan, and to renew an expired subscription. To contact support, either send an email or click the \u201ccontact us\u201d link at the end of the Subscriptions page.","title":"Working with Subscriptions"},{"location":"en/user-guides/cloud-ui/settings/users/","text":"Configuring Users \u00b6 You can manage user accounts in the Users tab located in Settings . #### Warning:: Administrator access Only users with the **Administrator** role can access this setting. User Roles \u00b6 There are three user roles: Analyst : a standard user who analyzes information about incidents and vulnerabilities . Administrator : a user with elevated access rights who can fine-tune the system. Deploy : a user who can only add new nodes. The Administrator role grants the following permissions to the user: Create, edit, and delete filter nodes using the Nodes tab. Create, edit, and delete triggers using the Triggers tab. Change the Wallarm mode settings using the Global tab. View, create, edit, and delete applications using the Applications tab. View, create, edit, and delete integrations using the Integrations tab. View, create, edit, and delete users using the Users tab. View the activity log using the Activity Log tab. Viewing Users \u00b6 You can view user lists in the following tabs: The main Users tab contains all users of your company registered in the Wallarm cloud. In this tab, any disabled users are highlighted in gray. The Disabled tab contains only disabled users. You can click the cells in the table header to sort users by name, role, email, and last login date. Also, you can choose one or several users by checking the checkboxes on the left from a user name; therefore, you will be able to do operations on a group of users. Searching Users \u00b6 You can use the search field above the table to search users by name, email, or system role. Create a User \u00b6 In the Users tab of the Settings section, click the Add user button. Select the user role from the dropdown list. Enter a first and a last name, an email, and a temporary password for the user. Click the Add user button. The new user will receive an automatic email with a link to login and set a new password. Change the User Info \u00b6 To change the data on the user, perform the following actions: In the Users tab of the Settings section, select the user to edit. Open the user actions menu by clicking the button to the right of the corresponding user. Click Edit user settings . In the form that appears, enter the new user info and click the Save button. The old user info will be replaced with the new. Two-Factor Authentication Settings Reset \u00b6 To reset the two-factor authentication settings, perform the following actions: In the Users tab of the Settings section, select the desired user. Open the user actions menu by clicking the button to the right of the corresponding user. Click Disable 2FA . In the form that appears, enter your Wallarm administrator account password and click the Disable 2FA button. The 2-factor authentication function will be disabled for the selected user. Disable Access for a User \u00b6 Disabling access for a user disables their Wallarm account. To disable a particular user\u2019s Wallarm account, perform the following actions: In the Users tab of the Settings section, select the desired user. Open the user actions menu by clicking the button to the right of the corresponding user. Click Disable Access . Now the selected user from your company will not be able to use their Wallarm account. If it is necessary to disable access for several user accounts, select the users whose access you need to revoke. The action panel will appear. Click the Disable Access button on this panel. Enable Access for a User \u00b6 Enabling access for a user enables their Wallarm account. To enable a particular user\u2019s Wallarm account, perform the following actions: In the Users tab of the Settings section, select the desired user with disabled access. Open the user actions menu by clicking the button to the right of the corresponding user. Click Enable Access . Now the selected user from your company will be able to use their Wallarm account. If it is necessary to enable access for several user accounts, select the users you need to grant access to. The action panel will appear. Click the Enable Access button on this panel. Delete a User \u00b6 To delete a particular user account, perform the following actions: In the Users tab of the Settings section, select the user to delete. Open the user actions menu by clicking the button to the right of the corresponding user. Click Delete . If it is necessary to delete several user accounts, select the users whose accounts you need to delete. The action panel will appear. Click the Delete button on this panel. See also User activity log","title":"Users"},{"location":"en/user-guides/cloud-ui/settings/users/#configuring-users","text":"You can manage user accounts in the Users tab located in Settings . #### Warning:: Administrator access Only users with the **Administrator** role can access this setting.","title":"Configuring Users"},{"location":"en/user-guides/cloud-ui/settings/users/#user-roles","text":"There are three user roles: Analyst : a standard user who analyzes information about incidents and vulnerabilities . Administrator : a user with elevated access rights who can fine-tune the system. Deploy : a user who can only add new nodes. The Administrator role grants the following permissions to the user: Create, edit, and delete filter nodes using the Nodes tab. Create, edit, and delete triggers using the Triggers tab. Change the Wallarm mode settings using the Global tab. View, create, edit, and delete applications using the Applications tab. View, create, edit, and delete integrations using the Integrations tab. View, create, edit, and delete users using the Users tab. View the activity log using the Activity Log tab.","title":"User Roles"},{"location":"en/user-guides/cloud-ui/settings/users/#viewing-users","text":"You can view user lists in the following tabs: The main Users tab contains all users of your company registered in the Wallarm cloud. In this tab, any disabled users are highlighted in gray. The Disabled tab contains only disabled users. You can click the cells in the table header to sort users by name, role, email, and last login date. Also, you can choose one or several users by checking the checkboxes on the left from a user name; therefore, you will be able to do operations on a group of users.","title":"Viewing Users"},{"location":"en/user-guides/cloud-ui/settings/users/#searching-users","text":"You can use the search field above the table to search users by name, email, or system role.","title":"Searching Users"},{"location":"en/user-guides/cloud-ui/settings/users/#create-a-user","text":"In the Users tab of the Settings section, click the Add user button. Select the user role from the dropdown list. Enter a first and a last name, an email, and a temporary password for the user. Click the Add user button. The new user will receive an automatic email with a link to login and set a new password.","title":"Create a User"},{"location":"en/user-guides/cloud-ui/settings/users/#change-the-user-info","text":"To change the data on the user, perform the following actions: In the Users tab of the Settings section, select the user to edit. Open the user actions menu by clicking the button to the right of the corresponding user. Click Edit user settings . In the form that appears, enter the new user info and click the Save button. The old user info will be replaced with the new.","title":"Change the User Info"},{"location":"en/user-guides/cloud-ui/settings/users/#two-factor-authentication-settings-reset","text":"To reset the two-factor authentication settings, perform the following actions: In the Users tab of the Settings section, select the desired user. Open the user actions menu by clicking the button to the right of the corresponding user. Click Disable 2FA . In the form that appears, enter your Wallarm administrator account password and click the Disable 2FA button. The 2-factor authentication function will be disabled for the selected user.","title":"Two-Factor Authentication Settings Reset"},{"location":"en/user-guides/cloud-ui/settings/users/#disable-access-for-a-user","text":"Disabling access for a user disables their Wallarm account. To disable a particular user\u2019s Wallarm account, perform the following actions: In the Users tab of the Settings section, select the desired user. Open the user actions menu by clicking the button to the right of the corresponding user. Click Disable Access . Now the selected user from your company will not be able to use their Wallarm account. If it is necessary to disable access for several user accounts, select the users whose access you need to revoke. The action panel will appear. Click the Disable Access button on this panel.","title":"Disable Access for a User"},{"location":"en/user-guides/cloud-ui/settings/users/#enable-access-for-a-user","text":"Enabling access for a user enables their Wallarm account. To enable a particular user\u2019s Wallarm account, perform the following actions: In the Users tab of the Settings section, select the desired user with disabled access. Open the user actions menu by clicking the button to the right of the corresponding user. Click Enable Access . Now the selected user from your company will be able to use their Wallarm account. If it is necessary to enable access for several user accounts, select the users you need to grant access to. The action panel will appear. Click the Enable Access button on this panel.","title":"Enable Access for a User"},{"location":"en/user-guides/cloud-ui/settings/users/#delete-a-user","text":"To delete a particular user account, perform the following actions: In the Users tab of the Settings section, select the user to delete. Open the user actions menu by clicking the button to the right of the corresponding user. Click Delete . If it is necessary to delete several user accounts, select the users whose accounts you need to delete. The action panel will appear. Click the Delete button on this panel. See also User activity log","title":"Delete a User"},{"location":"en/user-guides/cloud-ui/settings/integrations/email/","text":"Email Reports and Notifications \u00b6 You can enter email addresses that will be used to deliver scheduled reports and instant notifications. Notifications can be set up for the following events: System-related: new user created; integration settings changed. Vulnerability detected. Network perimeter changed. You can also schedule a full report delivery on a daily, weekly, or monthly basis. #### Info: To add the email addresses, you must have the *Administrator* role in the Wallarm system. Add Email Addresses and Configure Notifications \u00b6 Open Settings \u2192 Integrations tab. Click the Email reports block or click the Add integration button and choose Email reports . Enter email addresses using a comma as a separator. Enter an integration name. Choose the notification types and reports you need. Click Create . Wallarm will now deliver reports and notifications to those email addresses. Disabling Reports and Notifications \u00b6 Go to your Wallarm account > Settings > Integrations by the link below: * https://my.wallarm.com/settings/integrations/ for the EU cloud * https://us1.my.wallarm.com/settings/integrations/ for the US cloud Select an integration and click Disable . Click Save . Removing Integration \u00b6 Go to your Wallarm account > Settings > Integrations by the link below: * https://my.wallarm.com/settings/integrations/ for the EU cloud * https://us1.my.wallarm.com/settings/integrations/ for the US cloud Select an integration and click Remove . Click Sure? . See also Slack notifications Telegram reports and notifications OpsGenie notifications PagerDuty notifications Splunk notifications Sumo Logic notifications","title":"Email Reports and Notifications"},{"location":"en/user-guides/cloud-ui/settings/integrations/email/#email-reports-and-notifications","text":"You can enter email addresses that will be used to deliver scheduled reports and instant notifications. Notifications can be set up for the following events: System-related: new user created; integration settings changed. Vulnerability detected. Network perimeter changed. You can also schedule a full report delivery on a daily, weekly, or monthly basis. #### Info: To add the email addresses, you must have the *Administrator* role in the Wallarm system.","title":"Email Reports and Notifications"},{"location":"en/user-guides/cloud-ui/settings/integrations/email/#add-email-addresses-and-configure-notifications","text":"Open Settings \u2192 Integrations tab. Click the Email reports block or click the Add integration button and choose Email reports . Enter email addresses using a comma as a separator. Enter an integration name. Choose the notification types and reports you need. Click Create . Wallarm will now deliver reports and notifications to those email addresses.","title":"Add Email Addresses and Configure Notifications"},{"location":"en/user-guides/cloud-ui/settings/integrations/email/#disabling-reports-and-notifications","text":"Go to your Wallarm account > Settings > Integrations by the link below: * https://my.wallarm.com/settings/integrations/ for the EU cloud * https://us1.my.wallarm.com/settings/integrations/ for the US cloud Select an integration and click Disable . Click Save .","title":"Disabling Reports and Notifications"},{"location":"en/user-guides/cloud-ui/settings/integrations/email/#removing-integration","text":"Go to your Wallarm account > Settings > Integrations by the link below: * https://my.wallarm.com/settings/integrations/ for the EU cloud * https://us1.my.wallarm.com/settings/integrations/ for the US cloud Select an integration and click Remove . Click Sure? . See also Slack notifications Telegram reports and notifications OpsGenie notifications PagerDuty notifications Splunk notifications Sumo Logic notifications","title":"Removing Integration"},{"location":"en/user-guides/cloud-ui/settings/integrations/integrations-intro/","text":"Integrations Overview \u00b6 The Integrations tab of the Settings section allows you to configure reports and notifications on various events. All integrations are divided into the following blocks: Reports : Personal \u2014the reports that are sent to your email. You can also configure these reports on the Profile tab of the Settings section. Email reports \u2014 configure the list of other email addresses that the reports should be sent to. Slack \u2014 configure your team's Slack channel notifications. Telegram \u2014 configure the Telegram reports and notifications. Sumo Logic \u2014 configure the Sumo Logic notifications. Incident management : OpsGenie \u2014 configure the OpsGenie notifications. PagerDuty \u2014 configure the PagerDuty notifications. Splunk \u2014 configure the Splunk notifications. Sumo Logic \u2014 configure the Sumo Logic notifications. You can use the Add integration button in the top right corner to add new integrations in addition to the displayed blocks. You can use the All , Enabled , and Disabled buttons in the top part of the Integrations tab to filter the displayed integrations.","title":"Integrations Overview"},{"location":"en/user-guides/cloud-ui/settings/integrations/integrations-intro/#integrations-overview","text":"The Integrations tab of the Settings section allows you to configure reports and notifications on various events. All integrations are divided into the following blocks: Reports : Personal \u2014the reports that are sent to your email. You can also configure these reports on the Profile tab of the Settings section. Email reports \u2014 configure the list of other email addresses that the reports should be sent to. Slack \u2014 configure your team's Slack channel notifications. Telegram \u2014 configure the Telegram reports and notifications. Sumo Logic \u2014 configure the Sumo Logic notifications. Incident management : OpsGenie \u2014 configure the OpsGenie notifications. PagerDuty \u2014 configure the PagerDuty notifications. Splunk \u2014 configure the Splunk notifications. Sumo Logic \u2014 configure the Sumo Logic notifications. You can use the Add integration button in the top right corner to add new integrations in addition to the displayed blocks. You can use the All , Enabled , and Disabled buttons in the top part of the Integrations tab to filter the displayed integrations.","title":"Integrations Overview"},{"location":"en/user-guides/cloud-ui/settings/integrations/opsgenie/","text":"OpsGenie Notifications \u00b6 You can set up Wallarm to send notifications to OpsGenie. Notifications can be set up for the following events: System-related: integration settings changed. Vulnerability detected. Setting up Notifications \u00b6 Add new API integration in OpsGenie Dashboard. Copy the API key that was generated upon integration creation in OpsGenie to your clipboard. Open the Wallarm portal in the EU or US cloud . Open the Settings \u2192 Integrations tab. Click the OpsGenie block or click the Add integration button and choose OpsGenie . Paste the API key that you copied before into the API key field in Wallarm Dashboard. Enter the integration name and select the event types you want to be notified of. Click Create . Disabling Notifications \u00b6 Go to your Wallarm account > Settings > Integrations by the link below: * https://my.wallarm.com/settings/integrations/ for the EU cloud * https://us1.my.wallarm.com/settings/integrations/ for the US cloud Select an integration and click Disable . Click Save . Removing Integration \u00b6 Go to your Wallarm account > Settings > Integrations by the link below: * https://my.wallarm.com/settings/integrations/ for the EU cloud * https://us1.my.wallarm.com/settings/integrations/ for the US cloud Select an integration and click Remove . Click Sure? . See also Email reports and notifications Slack notifications Telegram reports and notifications PagerDuty notifications Splunk notifications Sumo Logic notifications","title":"OpsGenie Notifications"},{"location":"en/user-guides/cloud-ui/settings/integrations/opsgenie/#opsgenie-notifications","text":"You can set up Wallarm to send notifications to OpsGenie. Notifications can be set up for the following events: System-related: integration settings changed. Vulnerability detected.","title":"OpsGenie Notifications"},{"location":"en/user-guides/cloud-ui/settings/integrations/opsgenie/#setting-up-notifications","text":"Add new API integration in OpsGenie Dashboard. Copy the API key that was generated upon integration creation in OpsGenie to your clipboard. Open the Wallarm portal in the EU or US cloud . Open the Settings \u2192 Integrations tab. Click the OpsGenie block or click the Add integration button and choose OpsGenie . Paste the API key that you copied before into the API key field in Wallarm Dashboard. Enter the integration name and select the event types you want to be notified of. Click Create .","title":"Setting up Notifications"},{"location":"en/user-guides/cloud-ui/settings/integrations/opsgenie/#disabling-notifications","text":"Go to your Wallarm account > Settings > Integrations by the link below: * https://my.wallarm.com/settings/integrations/ for the EU cloud * https://us1.my.wallarm.com/settings/integrations/ for the US cloud Select an integration and click Disable . Click Save .","title":"Disabling Notifications"},{"location":"en/user-guides/cloud-ui/settings/integrations/opsgenie/#removing-integration","text":"Go to your Wallarm account > Settings > Integrations by the link below: * https://my.wallarm.com/settings/integrations/ for the EU cloud * https://us1.my.wallarm.com/settings/integrations/ for the US cloud Select an integration and click Remove . Click Sure? . See also Email reports and notifications Slack notifications Telegram reports and notifications PagerDuty notifications Splunk notifications Sumo Logic notifications","title":"Removing Integration"},{"location":"en/user-guides/cloud-ui/settings/integrations/pagerduty/","text":"PagerDuty Notifications \u00b6 You can set up Wallarm to send notifications to PagerDuty. Notifications can be set up for the following events: System-related: New user creation Integration settings change Vulnerability detection Network perimeter change Setting up Notifications \u00b6 In PagerDuty you can set up an integration for any existing service or create a new service specifically for Wallarm: Go to Configuration \u2192 Services . Select an existing service by clicking its name to set up an integration for it or create a new service by clicking the New service button. Create a new integration. If you are configuring integrations of the existing service, go to the Integrations tab and click the New Integration button. If you are creating a new service, enter the desired name for it into the Name field and proceed to the Integration Settings section. Enter the desired name of the integration into the Integration name field (e.g. Wallarm Integration ) and select the Use our API directly option as an integration type. If you are configuring integrations of the existing service, click the Add Integration button . If you are creating a new service, configure the rest of the settings sections and click the Add Service button. Copy the Integration Key that corresponds to the new integration. It will be used later to create an integration on the Wallarm console. To create a PagerDuty integration on the Wallarm console, perform the following actions: Go to the Integrations tab of the Settings . Click the PagerDuty block or click the Add integration button and choose PagerDuty . Paste the integration key that was copied from the PagerDuty interface into the Integration key field. Enter the integration name and select the event types you want to be notified of. Save the integration by clicking the Create button. You will now receive notifications on your PagerDuty account from the selected Wallarm event types. Disabling Notifications \u00b6 Go to your Wallarm account > Settings > Integrations by the link below: * https://my.wallarm.com/settings/integrations/ for the EU cloud * https://us1.my.wallarm.com/settings/integrations/ for the US cloud Select an integration and click Disable . Click Save . Removing Integration \u00b6 Go to your Wallarm account > Settings > Integrations by the link below: * https://my.wallarm.com/settings/integrations/ for the EU cloud * https://us1.my.wallarm.com/settings/integrations/ for the US cloud Select an integration and click Remove . Click Sure? . See also Email reports and notifications Slack notifications Telegram reports and notifications OpsGenie notifications Splunk notifications Sumo Logic notifications","title":"PagerDuty Notifications"},{"location":"en/user-guides/cloud-ui/settings/integrations/pagerduty/#pagerduty-notifications","text":"You can set up Wallarm to send notifications to PagerDuty. Notifications can be set up for the following events: System-related: New user creation Integration settings change Vulnerability detection Network perimeter change","title":"PagerDuty Notifications"},{"location":"en/user-guides/cloud-ui/settings/integrations/pagerduty/#setting-up-notifications","text":"In PagerDuty you can set up an integration for any existing service or create a new service specifically for Wallarm: Go to Configuration \u2192 Services . Select an existing service by clicking its name to set up an integration for it or create a new service by clicking the New service button. Create a new integration. If you are configuring integrations of the existing service, go to the Integrations tab and click the New Integration button. If you are creating a new service, enter the desired name for it into the Name field and proceed to the Integration Settings section. Enter the desired name of the integration into the Integration name field (e.g. Wallarm Integration ) and select the Use our API directly option as an integration type. If you are configuring integrations of the existing service, click the Add Integration button . If you are creating a new service, configure the rest of the settings sections and click the Add Service button. Copy the Integration Key that corresponds to the new integration. It will be used later to create an integration on the Wallarm console. To create a PagerDuty integration on the Wallarm console, perform the following actions: Go to the Integrations tab of the Settings . Click the PagerDuty block or click the Add integration button and choose PagerDuty . Paste the integration key that was copied from the PagerDuty interface into the Integration key field. Enter the integration name and select the event types you want to be notified of. Save the integration by clicking the Create button. You will now receive notifications on your PagerDuty account from the selected Wallarm event types.","title":"Setting up Notifications"},{"location":"en/user-guides/cloud-ui/settings/integrations/pagerduty/#disabling-notifications","text":"Go to your Wallarm account > Settings > Integrations by the link below: * https://my.wallarm.com/settings/integrations/ for the EU cloud * https://us1.my.wallarm.com/settings/integrations/ for the US cloud Select an integration and click Disable . Click Save .","title":"Disabling Notifications"},{"location":"en/user-guides/cloud-ui/settings/integrations/pagerduty/#removing-integration","text":"Go to your Wallarm account > Settings > Integrations by the link below: * https://my.wallarm.com/settings/integrations/ for the EU cloud * https://us1.my.wallarm.com/settings/integrations/ for the US cloud Select an integration and click Remove . Click Sure? . See also Email reports and notifications Slack notifications Telegram reports and notifications OpsGenie notifications Splunk notifications Sumo Logic notifications","title":"Removing Integration"},{"location":"en/user-guides/cloud-ui/settings/integrations/slack/","text":"Slack Notifications \u00b6 You can set up Wallarm to send notifications to your Slack channel. Notifications can be set up for the following events: System-related: new user created integration settings changes Vulnerability detected Network perimeter changed Setting up Notifications \u00b6 Open the Settings \u2192 Integrations tab. Click the Slack block or click the Add integration button and choose Slack . Go to the WebHooks link. Select the Slack channel that will receive notifications. Click Add Incoming WebHooks integration . Copy the link and put it in Wallarm into the WebHook link field . Enter the integration name and select the event types you want to be notified of. Click Create . Disabling Notifications \u00b6 Go to your Wallarm account > Settings > Integrations by the link below: * https://my.wallarm.com/settings/integrations/ for the EU cloud * https://us1.my.wallarm.com/settings/integrations/ for the US cloud Select an integration and click Disable . Click Save . Removing Integration \u00b6 Go to your Wallarm account > Settings > Integrations by the link below: * https://my.wallarm.com/settings/integrations/ for the EU cloud * https://us1.my.wallarm.com/settings/integrations/ for the US cloud Select an integration and click Remove . Click Sure? . See also Email reports and notifications Telegram reports and notifications OpsGenie notifications PagerDuty notifications Splunk notifications Sumo Logic notifications","title":"Slack Notifications"},{"location":"en/user-guides/cloud-ui/settings/integrations/slack/#slack-notifications","text":"You can set up Wallarm to send notifications to your Slack channel. Notifications can be set up for the following events: System-related: new user created integration settings changes Vulnerability detected Network perimeter changed","title":"Slack Notifications"},{"location":"en/user-guides/cloud-ui/settings/integrations/slack/#setting-up-notifications","text":"Open the Settings \u2192 Integrations tab. Click the Slack block or click the Add integration button and choose Slack . Go to the WebHooks link. Select the Slack channel that will receive notifications. Click Add Incoming WebHooks integration . Copy the link and put it in Wallarm into the WebHook link field . Enter the integration name and select the event types you want to be notified of. Click Create .","title":"Setting up Notifications"},{"location":"en/user-guides/cloud-ui/settings/integrations/slack/#disabling-notifications","text":"Go to your Wallarm account > Settings > Integrations by the link below: * https://my.wallarm.com/settings/integrations/ for the EU cloud * https://us1.my.wallarm.com/settings/integrations/ for the US cloud Select an integration and click Disable . Click Save .","title":"Disabling Notifications"},{"location":"en/user-guides/cloud-ui/settings/integrations/slack/#removing-integration","text":"Go to your Wallarm account > Settings > Integrations by the link below: * https://my.wallarm.com/settings/integrations/ for the EU cloud * https://us1.my.wallarm.com/settings/integrations/ for the US cloud Select an integration and click Remove . Click Sure? . See also Email reports and notifications Telegram reports and notifications OpsGenie notifications PagerDuty notifications Splunk notifications Sumo Logic notifications","title":"Removing Integration"},{"location":"en/user-guides/cloud-ui/settings/integrations/splunk/","text":"Splunk Notifications \u00b6 You can set up Wallarm to send notifications to Splunk for the following events: System-related: new user created integration settings changed Vulnerability detected Network perimeter changed Setting up Notifications \u00b6 Perform the following actions in the Splunk interface: Proceed to the Settings \u2192 Add data menu section. Select Monitor to proceed to the Select Source step. Select HTTP Event Collector and enter the integration name into the Name field. All other fields are optional. Press the Next button to proceed to the Input Settings step. On the Input Settings step, you can keep the default configuration and click the Review button. On the Review step, check the correctness of the configuration. Click the Submit button to confirm the settings and proceed to the Done step. The generated token is displayed in the Token Value field on the Done step. Copy it to the clipboard to enter it into the HEC Token field when later creating a Splunk integration in the Wallarm interface. Perform the following actions in the Wallarm interface: Proceed to the Integrations tab of the Settings section. Click the Splunk block or click the Add integration button and choose Splunk . Paste the token value generated in Splunk into the HEC Token field. Paste the URL of your Splunk instance into the API URL field. For example, if you are using the Splunk cloud, the URL should be similar to the following: https://prd-p-tj2xx2f2xntv.cloud.splunk.com . Enter the integration name and select the event types you want to be notified of. Click Create . Now notifications for events of the selected types will appear in Splunk. Disabling Notifications \u00b6 Go to your Wallarm account > Settings > Integrations by the link below: * https://my.wallarm.com/settings/integrations/ for the EU cloud * https://us1.my.wallarm.com/settings/integrations/ for the US cloud Select an integration and click Disable . Click Save . Removing Integration \u00b6 Go to your Wallarm account > Settings > Integrations by the link below: * https://my.wallarm.com/settings/integrations/ for the EU cloud * https://us1.my.wallarm.com/settings/integrations/ for the US cloud Select an integration and click Remove . Click Sure? . See also Email reports and notifications Slack notifications Telegram reports and notifications OpsGenie notifications PagerDuty notifications Sumo Logic notifications","title":"Splunk Notifications"},{"location":"en/user-guides/cloud-ui/settings/integrations/splunk/#splunk-notifications","text":"You can set up Wallarm to send notifications to Splunk for the following events: System-related: new user created integration settings changed Vulnerability detected Network perimeter changed","title":"Splunk Notifications"},{"location":"en/user-guides/cloud-ui/settings/integrations/splunk/#setting-up-notifications","text":"Perform the following actions in the Splunk interface: Proceed to the Settings \u2192 Add data menu section. Select Monitor to proceed to the Select Source step. Select HTTP Event Collector and enter the integration name into the Name field. All other fields are optional. Press the Next button to proceed to the Input Settings step. On the Input Settings step, you can keep the default configuration and click the Review button. On the Review step, check the correctness of the configuration. Click the Submit button to confirm the settings and proceed to the Done step. The generated token is displayed in the Token Value field on the Done step. Copy it to the clipboard to enter it into the HEC Token field when later creating a Splunk integration in the Wallarm interface. Perform the following actions in the Wallarm interface: Proceed to the Integrations tab of the Settings section. Click the Splunk block or click the Add integration button and choose Splunk . Paste the token value generated in Splunk into the HEC Token field. Paste the URL of your Splunk instance into the API URL field. For example, if you are using the Splunk cloud, the URL should be similar to the following: https://prd-p-tj2xx2f2xntv.cloud.splunk.com . Enter the integration name and select the event types you want to be notified of. Click Create . Now notifications for events of the selected types will appear in Splunk.","title":"Setting up Notifications"},{"location":"en/user-guides/cloud-ui/settings/integrations/splunk/#disabling-notifications","text":"Go to your Wallarm account > Settings > Integrations by the link below: * https://my.wallarm.com/settings/integrations/ for the EU cloud * https://us1.my.wallarm.com/settings/integrations/ for the US cloud Select an integration and click Disable . Click Save .","title":"Disabling Notifications"},{"location":"en/user-guides/cloud-ui/settings/integrations/splunk/#removing-integration","text":"Go to your Wallarm account > Settings > Integrations by the link below: * https://my.wallarm.com/settings/integrations/ for the EU cloud * https://us1.my.wallarm.com/settings/integrations/ for the US cloud Select an integration and click Remove . Click Sure? . See also Email reports and notifications Slack notifications Telegram reports and notifications OpsGenie notifications PagerDuty notifications Sumo Logic notifications","title":"Removing Integration"},{"location":"en/user-guides/cloud-ui/settings/integrations/sumologic/","text":"Sumo Logic Notifications \u00b6 You can set up Wallarm to send notifications to Sumo Logic for the following events: System-related: new user created integration settings changed Vulnerability detected Network perimeter changed Setting up Notifications \u00b6 Perform the following actions in the Sumo Logic interface: Configure a Hosted Collector following the instructions . Configure an HTTP Logs & Metrics Source following the instructions . Copy the provided HTTP Source Address (URL) . Perform the following actions in your Wallarm account: Go to your Wallarm account > Settings > Integrations by the link below: * https://my.wallarm.com/settings/integrations/ for the EU cloud * https://us1.my.wallarm.com/settings/integrations/ for the US cloud Click the Sumo Logic block or click the Add integration button and choose Sumo Logic . Paste the copied value of HTTP Source Address (URL) to the HTTP Source Address (URL) field. Enter the integration name and select the event types you want to be notified of. Click Create . Now notifications for events of the selected types will appear in Sumo Logic. Disabling Notifications \u00b6 Go to your Wallarm account > Settings > Integrations by the link below: * https://my.wallarm.com/settings/integrations/ for the EU cloud * https://us1.my.wallarm.com/settings/integrations/ for the US cloud Select an integration and click Disable . Click Save . Removing Integration \u00b6 Go to your Wallarm account > Settings > Integrations by the link below: * https://my.wallarm.com/settings/integrations/ for the EU cloud * https://us1.my.wallarm.com/settings/integrations/ for the US cloud Select an integration and click Remove . Click Sure? . See also Email reports and notifications Slack notifications Telegram reports and notifications OpsGenie notifications PagerDuty notifications Splunk notifications","title":"Sumo Logic Notifications"},{"location":"en/user-guides/cloud-ui/settings/integrations/sumologic/#sumo-logic-notifications","text":"You can set up Wallarm to send notifications to Sumo Logic for the following events: System-related: new user created integration settings changed Vulnerability detected Network perimeter changed","title":"Sumo Logic Notifications"},{"location":"en/user-guides/cloud-ui/settings/integrations/sumologic/#setting-up-notifications","text":"Perform the following actions in the Sumo Logic interface: Configure a Hosted Collector following the instructions . Configure an HTTP Logs & Metrics Source following the instructions . Copy the provided HTTP Source Address (URL) . Perform the following actions in your Wallarm account: Go to your Wallarm account > Settings > Integrations by the link below: * https://my.wallarm.com/settings/integrations/ for the EU cloud * https://us1.my.wallarm.com/settings/integrations/ for the US cloud Click the Sumo Logic block or click the Add integration button and choose Sumo Logic . Paste the copied value of HTTP Source Address (URL) to the HTTP Source Address (URL) field. Enter the integration name and select the event types you want to be notified of. Click Create . Now notifications for events of the selected types will appear in Sumo Logic.","title":"Setting up Notifications"},{"location":"en/user-guides/cloud-ui/settings/integrations/sumologic/#disabling-notifications","text":"Go to your Wallarm account > Settings > Integrations by the link below: * https://my.wallarm.com/settings/integrations/ for the EU cloud * https://us1.my.wallarm.com/settings/integrations/ for the US cloud Select an integration and click Disable . Click Save .","title":"Disabling Notifications"},{"location":"en/user-guides/cloud-ui/settings/integrations/sumologic/#removing-integration","text":"Go to your Wallarm account > Settings > Integrations by the link below: * https://my.wallarm.com/settings/integrations/ for the EU cloud * https://us1.my.wallarm.com/settings/integrations/ for the US cloud Select an integration and click Remove . Click Sure? . See also Email reports and notifications Slack notifications Telegram reports and notifications OpsGenie notifications PagerDuty notifications Splunk notifications","title":"Removing Integration"},{"location":"en/user-guides/cloud-ui/settings/integrations/telegram/","text":"Telegram Reports and Notifications \u00b6 You can set up Wallarm to send notifications to Telegram Notifications can be set up on the following events: System-related: new user created; integration settings changed. Vulnerability detected. Network perimeter changed. You can also schedule a full report delivery on a daily, weekly, or monthly basis. Setting up Reports and Notifications \u00b6 Open the Settings \u2192 Integrations tab. Click the Telegram block or click the Add integration button and choose Telegram . Click Open bot . > #### Info:: > If clicking the Open bot button did not open the Telegram chat with the bot, try using the link . In the new Telegram chat with the bot, click /start . The Wallarm bot will create a unique link. Click the created link. Click Authorize . Set the notification events and the report recurrence. Click Save . The selected notifications and reports will now be sent to Telegram. You can also add @WallarmBot to any of your chats. The notifications will be sent to the chat as well. Disabling Reports and Notifications \u00b6 Go to your Wallarm account > Settings > Integrations by the link below: * https://my.wallarm.com/settings/integrations/ for the EU cloud * https://us1.my.wallarm.com/settings/integrations/ for the US cloud Select an integration and click Disable . Click Save . Removing Integration \u00b6 Go to your Wallarm account > Settings > Integrations by the link below: * https://my.wallarm.com/settings/integrations/ for the EU cloud * https://us1.my.wallarm.com/settings/integrations/ for the US cloud Select an integration and click Remove . Click Sure? . See also Email reports and notifications Slack notifications OpsGenie notifications PagerDuty notifications Splunk notifications Sumo Logic notifications","title":"Telegram Reports and Notifications"},{"location":"en/user-guides/cloud-ui/settings/integrations/telegram/#telegram-reports-and-notifications","text":"You can set up Wallarm to send notifications to Telegram Notifications can be set up on the following events: System-related: new user created; integration settings changed. Vulnerability detected. Network perimeter changed. You can also schedule a full report delivery on a daily, weekly, or monthly basis.","title":"Telegram Reports and Notifications"},{"location":"en/user-guides/cloud-ui/settings/integrations/telegram/#setting-up-reports-and-notifications","text":"Open the Settings \u2192 Integrations tab. Click the Telegram block or click the Add integration button and choose Telegram . Click Open bot . > #### Info:: > If clicking the Open bot button did not open the Telegram chat with the bot, try using the link . In the new Telegram chat with the bot, click /start . The Wallarm bot will create a unique link. Click the created link. Click Authorize . Set the notification events and the report recurrence. Click Save . The selected notifications and reports will now be sent to Telegram. You can also add @WallarmBot to any of your chats. The notifications will be sent to the chat as well.","title":"Setting up Reports and Notifications"},{"location":"en/user-guides/cloud-ui/settings/integrations/telegram/#disabling-reports-and-notifications","text":"Go to your Wallarm account > Settings > Integrations by the link below: * https://my.wallarm.com/settings/integrations/ for the EU cloud * https://us1.my.wallarm.com/settings/integrations/ for the US cloud Select an integration and click Disable . Click Save .","title":"Disabling Reports and Notifications"},{"location":"en/user-guides/cloud-ui/settings/integrations/telegram/#removing-integration","text":"Go to your Wallarm account > Settings > Integrations by the link below: * https://my.wallarm.com/settings/integrations/ for the EU cloud * https://us1.my.wallarm.com/settings/integrations/ for the US cloud Select an integration and click Remove . Click Sure? . See also Email reports and notifications Slack notifications OpsGenie notifications PagerDuty notifications Splunk notifications Sumo Logic notifications","title":"Removing Integration"},{"location":"en/user-guides/cloud-ui/triggers/create-trigger/","text":"Creating Triggers \u00b6 Triggers are configured in your Wallarm account > the Triggers section. Only users with the Administrator role can access the section. Click the Create a new trigger button. Choose conditions. Add filters. Add reactions. Save the trigger. Step 1: Choosing a Condition \u00b6 A condition is a system event to be notified about. The following conditions are available for notification: Number of attacks Number of hits Number of incidents User added Choose a condition in your Wallarm account interface and set the lower threshold for the reaction, if the setting is available. Step 2: Adding Filters \u00b6 Filters are used for condition detailing. For example, you can set up the reaction to attacks with certain types, such as brute-force attacks, SQL Injection and others. The following filters are available for adding: Type is a type of an attack detected in the request or a type of the vulnerability the request was directed to. Application is an application received a request or in which an incident was detected. IP is an IP address from which the request was sent. Domain is a domain received a request or in which an incident was detected. Response status is the response code returned to the request. Target is an application architecture part that the attack was directed at or in which the incident was detected. It can take the following values: Server , Client , Database . User's role is the role of the added user. It can take the following values: Deploy , Analyst , Admin . Choose one or more filters in your Wallarm account interface and set values for them. Step 3: Adding Reactions \u00b6 A reaction is an action that should be performed if the specified condition and filters are met. Reactions are divided into the Notifications and Event management groups. The tools in groups are configured as integrations . You can select one or more integrations from the list: Email Slack Telegram OpsGenie PagerDuty Splunk Sumo Logic To add a reaction: Set up integrations with email, messengers and incident management or SIEM systems as described in the instruction . To use already existing integration, skip this step. Choose the configured integration in the trigger creation modal window. Step 4: Saving the Trigger \u00b6 Click the Create button in the trigger creation modal window. Specify trigger name and description if required and click the Done button. The saved trigger will be displayed in the trigger list in your Wallarm account. See also What are Triggers Disabling Triggers Deleting Triggers","title":"Creating Triggers"},{"location":"en/user-guides/cloud-ui/triggers/create-trigger/#creating-triggers","text":"Triggers are configured in your Wallarm account > the Triggers section. Only users with the Administrator role can access the section. Click the Create a new trigger button. Choose conditions. Add filters. Add reactions. Save the trigger.","title":"Creating Triggers"},{"location":"en/user-guides/cloud-ui/triggers/create-trigger/#step-1-choosing-a-condition","text":"A condition is a system event to be notified about. The following conditions are available for notification: Number of attacks Number of hits Number of incidents User added Choose a condition in your Wallarm account interface and set the lower threshold for the reaction, if the setting is available.","title":"Step 1: Choosing a Condition"},{"location":"en/user-guides/cloud-ui/triggers/create-trigger/#step-2-adding-filters","text":"Filters are used for condition detailing. For example, you can set up the reaction to attacks with certain types, such as brute-force attacks, SQL Injection and others. The following filters are available for adding: Type is a type of an attack detected in the request or a type of the vulnerability the request was directed to. Application is an application received a request or in which an incident was detected. IP is an IP address from which the request was sent. Domain is a domain received a request or in which an incident was detected. Response status is the response code returned to the request. Target is an application architecture part that the attack was directed at or in which the incident was detected. It can take the following values: Server , Client , Database . User's role is the role of the added user. It can take the following values: Deploy , Analyst , Admin . Choose one or more filters in your Wallarm account interface and set values for them.","title":"Step 2: Adding Filters"},{"location":"en/user-guides/cloud-ui/triggers/create-trigger/#step-3-adding-reactions","text":"A reaction is an action that should be performed if the specified condition and filters are met. Reactions are divided into the Notifications and Event management groups. The tools in groups are configured as integrations . You can select one or more integrations from the list: Email Slack Telegram OpsGenie PagerDuty Splunk Sumo Logic To add a reaction: Set up integrations with email, messengers and incident management or SIEM systems as described in the instruction . To use already existing integration, skip this step. Choose the configured integration in the trigger creation modal window.","title":"Step 3: Adding Reactions"},{"location":"en/user-guides/cloud-ui/triggers/create-trigger/#step-4-saving-the-trigger","text":"Click the Create button in the trigger creation modal window. Specify trigger name and description if required and click the Done button. The saved trigger will be displayed in the trigger list in your Wallarm account. See also What are Triggers Disabling Triggers Deleting Triggers","title":"Step 4: Saving the Trigger"},{"location":"en/user-guides/cloud-ui/triggers/delete-trigger/","text":"Deleting Triggers \u00b6 To stop sending notifications and reactions to events permanently, you can delete the trigger. To disable the trigger temporarily, you can disable the trigger. Triggers are deleted in your Wallarm account > the Triggers section via the Delete button. The section is available only for users with the Administrator role. Deleting a trigger cannot be undone. The trigger will be removed from the trigger list permanently. Click the Delete button. Confirm the action clicking Delete trigger in the confirmation window. See also What are Triggers Creating Triggers Disabling Triggers","title":"Deleting Triggers"},{"location":"en/user-guides/cloud-ui/triggers/delete-trigger/#deleting-triggers","text":"To stop sending notifications and reactions to events permanently, you can delete the trigger. To disable the trigger temporarily, you can disable the trigger. Triggers are deleted in your Wallarm account > the Triggers section via the Delete button. The section is available only for users with the Administrator role. Deleting a trigger cannot be undone. The trigger will be removed from the trigger list permanently. Click the Delete button. Confirm the action clicking Delete trigger in the confirmation window. See also What are Triggers Creating Triggers Disabling Triggers","title":"Deleting Triggers"},{"location":"en/user-guides/cloud-ui/triggers/disable-trigger/","text":"Disabling Triggers \u00b6 To stop sending notifications and reactions to events temporarily, you can disable the trigger. To disable the trigger permanently, you can delete the trigger. Triggers are disabled in your Wallarm account > the Triggers section via the Disable button. The section is available only for users with the Administrator role . A disabled trigger will be displayed in the lists with All and Disabled triggers. To re-enable sending notifications and reactions to events, the Enable option is used. See also What are Triggers Creating Triggers Deleting Triggers","title":"Disabling Triggers"},{"location":"en/user-guides/cloud-ui/triggers/disable-trigger/#disabling-triggers","text":"To stop sending notifications and reactions to events temporarily, you can disable the trigger. To disable the trigger permanently, you can delete the trigger. Triggers are disabled in your Wallarm account > the Triggers section via the Disable button. The section is available only for users with the Administrator role . A disabled trigger will be displayed in the lists with All and Disabled triggers. To re-enable sending notifications and reactions to events, the Enable option is used. See also What are Triggers Creating Triggers Deleting Triggers","title":"Disabling Triggers"},{"location":"en/user-guides/cloud-ui/triggers/triggers/","text":"What are Triggers \u00b6 Triggers is a tool to set up custom notifications and reactions to events. Using triggers, you can receive alerts on major events via tools you use for your day-to-day workflow, for example via corporate messengers or incident management systems. To reduce the amount of noise, you can also configure the parameters of events to be notified about. The following events are available for setup: attacks, incidents, hits, users added to the account. To receive notifications an reports, you can use Slack, email, Sumo Logic and other integrations . Trigger Examples Send the notification to Slack if at least one brute-force attack was detected in a second Send notifications to Slack and by email if the Analyst or Admin user was added to the account Send the data to Splunk if at least one incident with application server or database was detected in a second See also Creating Triggers Disabling Triggers Deleting Triggers","title":"What are Triggers"},{"location":"en/user-guides/cloud-ui/triggers/triggers/#what-are-triggers","text":"Triggers is a tool to set up custom notifications and reactions to events. Using triggers, you can receive alerts on major events via tools you use for your day-to-day workflow, for example via corporate messengers or incident management systems. To reduce the amount of noise, you can also configure the parameters of events to be notified about. The following events are available for setup: attacks, incidents, hits, users added to the account. To receive notifications an reports, you can use Slack, email, Sumo Logic and other integrations . Trigger Examples Send the notification to Slack if at least one brute-force attack was detected in a second Send notifications to Slack and by email if the Analyst or Admin user was added to the account Send the data to Splunk if at least one incident with application server or database was detected in a second See also Creating Triggers Disabling Triggers Deleting Triggers","title":"What are Triggers"},{"location":"en/user-guides/cloud-ui/vulnerabilities/analyze-vuln/","text":"Analyzing Vulnerabilities \u00b6 Check vulnerabilities on the Vulnerabilities tab of the Wallarm interface. Analyze a Vulnerability \u00b6 Click the vulnerability entry from the list to view detailed information about it. Wallarm displays the detailed information about the vulnerability: Internal ID Method by which the vulnerability was discovered Risk level Vulnerability status Last check date Domain Target resource Discovery date and time Path Request method Request parameter Related incidents Detailed description Additional information Exploit example If any malicious requests exploiting this vulnerability are discovered, the Exploit example field has the warning: Attention. Found by incidents . Clicking the link displays the associated security incidents. Vulnerability Detection Method \u00b6 Vulnerabilities can be detected in the protected applications by the following methods: Active Threat Verification : the vulnerability was found during the attack verification process. Passive Detection : the vulnerability was found due to the security incident that occurred. Vulnerability Scanner : the vulnerability was found during the scope scanning process. Test Run : the vulnerability was found during the test run conducted by FAST. If the method by which the vulnerability was discovered is unknown, this information is not shown. See also Working with false vulnerabilities Checking vulnerabilities","title":"Analyzing Vulnerabilities"},{"location":"en/user-guides/cloud-ui/vulnerabilities/analyze-vuln/#analyzing-vulnerabilities","text":"Check vulnerabilities on the Vulnerabilities tab of the Wallarm interface.","title":"Analyzing Vulnerabilities"},{"location":"en/user-guides/cloud-ui/vulnerabilities/analyze-vuln/#analyze-a-vulnerability","text":"Click the vulnerability entry from the list to view detailed information about it. Wallarm displays the detailed information about the vulnerability: Internal ID Method by which the vulnerability was discovered Risk level Vulnerability status Last check date Domain Target resource Discovery date and time Path Request method Request parameter Related incidents Detailed description Additional information Exploit example If any malicious requests exploiting this vulnerability are discovered, the Exploit example field has the warning: Attention. Found by incidents . Clicking the link displays the associated security incidents.","title":"Analyze a Vulnerability"},{"location":"en/user-guides/cloud-ui/vulnerabilities/analyze-vuln/#vulnerability-detection-method","text":"Vulnerabilities can be detected in the protected applications by the following methods: Active Threat Verification : the vulnerability was found during the attack verification process. Passive Detection : the vulnerability was found due to the security incident that occurred. Vulnerability Scanner : the vulnerability was found during the scope scanning process. Test Run : the vulnerability was found during the test run conducted by FAST. If the method by which the vulnerability was discovered is unknown, this information is not shown. See also Working with false vulnerabilities Checking vulnerabilities","title":"Vulnerability Detection Method"},{"location":"en/user-guides/cloud-ui/vulnerabilities/check-vuln/","text":"Checking Vulnerabilities \u00b6 You can check vulnerabilities on the Vulnerabilities tab of the Wallarm interface. By default, the list is sorted by the vulnerability discovery date. Wallarm stores the history of all discovered vulnerabilities and checks them regularly \u2014 both the open and closed ones. If a closed vulnerability opens as a result of checking, you will receive a corresponding notification. Clicking a vulnerability displays its change log. Sort the Vulnerabilities by Risk or Date \u00b6 You can sort the vulnerabilities by the following criteria: Risk: High first Low first Date From latest From earliest You can filter the vulnerabilities by the risk level by pressing one of the following buttons: All \u2014 display the vulnerabilities from all of the risk level groups High risk \u2014 display the high risk vulnerabilities Medium risk \u2014 display the medium risk vulnerabilities Low risk \u2014 display the low risk vulnerabilities Filter the Active and Closed Vulnerabilities \u00b6 Click Active to see the active vulnerabilities. Click closed to see the closed vulnerabilities. You can filter the closed vulnerabilities by clicking the following selectors: all : The list of closed and false vulnerabilities. fixed : The list fixed vulnerabilities only. false : The list of false vulnerabilities only. See also Working with false vulnerabilities","title":"Checking Vulnerabilities"},{"location":"en/user-guides/cloud-ui/vulnerabilities/check-vuln/#checking-vulnerabilities","text":"You can check vulnerabilities on the Vulnerabilities tab of the Wallarm interface. By default, the list is sorted by the vulnerability discovery date. Wallarm stores the history of all discovered vulnerabilities and checks them regularly \u2014 both the open and closed ones. If a closed vulnerability opens as a result of checking, you will receive a corresponding notification. Clicking a vulnerability displays its change log.","title":"Checking Vulnerabilities"},{"location":"en/user-guides/cloud-ui/vulnerabilities/check-vuln/#sort-the-vulnerabilities-by-risk-or-date","text":"You can sort the vulnerabilities by the following criteria: Risk: High first Low first Date From latest From earliest You can filter the vulnerabilities by the risk level by pressing one of the following buttons: All \u2014 display the vulnerabilities from all of the risk level groups High risk \u2014 display the high risk vulnerabilities Medium risk \u2014 display the medium risk vulnerabilities Low risk \u2014 display the low risk vulnerabilities","title":"Sort the Vulnerabilities by Risk or Date"},{"location":"en/user-guides/cloud-ui/vulnerabilities/check-vuln/#filter-the-active-and-closed-vulnerabilities","text":"Click Active to see the active vulnerabilities. Click closed to see the closed vulnerabilities. You can filter the closed vulnerabilities by clicking the following selectors: all : The list of closed and false vulnerabilities. fixed : The list fixed vulnerabilities only. false : The list of false vulnerabilities only. See also Working with false vulnerabilities","title":"Filter the Active and Closed Vulnerabilities"},{"location":"en/user-guides/cloud-ui/vulnerabilities/close-open-vuln/","text":"Closing and Opening Vulnerabilities \u00b6 You can check vulnerabilities on the Vulnerabilities tab of the Wallarm interface. You can close issues on a fixed vulnerability. You can reopen a closed vulnerability if you think the vulnerability is not fixed. Close a Vulnerability \u00b6 Click the Close button next to the desired vulnerability in the list to close this vulnerability. You can also close the vulnerability by clicking the Close button on the page of the desired vulnerability. Wallarm will mark the vulnerability as closed. Open a Vulnerability \u00b6 Click the Open button next to the desired vulnerability in the list to reopen the previously closed vulnerability. You can also reopen the vulnerability by clicking the Open button on the page of the desired vulnerability. The vulnerability will be reopened.","title":"Closing and Opening Vulnerabilities"},{"location":"en/user-guides/cloud-ui/vulnerabilities/close-open-vuln/#closing-and-opening-vulnerabilities","text":"You can check vulnerabilities on the Vulnerabilities tab of the Wallarm interface. You can close issues on a fixed vulnerability. You can reopen a closed vulnerability if you think the vulnerability is not fixed.","title":"Closing and Opening Vulnerabilities"},{"location":"en/user-guides/cloud-ui/vulnerabilities/close-open-vuln/#close-a-vulnerability","text":"Click the Close button next to the desired vulnerability in the list to close this vulnerability. You can also close the vulnerability by clicking the Close button on the page of the desired vulnerability. Wallarm will mark the vulnerability as closed.","title":"Close a Vulnerability"},{"location":"en/user-guides/cloud-ui/vulnerabilities/close-open-vuln/#open-a-vulnerability","text":"Click the Open button next to the desired vulnerability in the list to reopen the previously closed vulnerability. You can also reopen the vulnerability by clicking the Open button on the page of the desired vulnerability. The vulnerability will be reopened.","title":"Open a Vulnerability"},{"location":"en/user-guides/cloud-ui/vulnerabilities/false-vuln/","text":"Working with False Vulnerabilities \u00b6 A false vulnerability is an entity erroneously qualified as a vulnerability. After analyzing a vulnerability, you may conclude that the vulnerability is a false positive. Mark a Vulnerability as a False Positive \u00b6 Click the Mark as false button next to the desired vulnerability in the list to mark this vulnerability as a false positive. You can also mark the vulnerability as a false positive by clicking the Mark as false button on the page of the desired vulnerability. Wallarm will requalify the vulnerability as a false positive. See also Analyzing vulnerabilities","title":"Working with False Vulnerabilities"},{"location":"en/user-guides/cloud-ui/vulnerabilities/false-vuln/#working-with-false-vulnerabilities","text":"A false vulnerability is an entity erroneously qualified as a vulnerability. After analyzing a vulnerability, you may conclude that the vulnerability is a false positive.","title":"Working with False Vulnerabilities"},{"location":"en/user-guides/cloud-ui/vulnerabilities/false-vuln/#mark-a-vulnerability-as-a-false-positive","text":"Click the Mark as false button next to the desired vulnerability in the list to mark this vulnerability as a false positive. You can also mark the vulnerability as a false positive by clicking the Mark as false button on the page of the desired vulnerability. Wallarm will requalify the vulnerability as a false positive. See also Analyzing vulnerabilities","title":"Mark a Vulnerability as a False Positive"},{"location":"en/user-guides/cloud-ui/vulnerabilities/recheck-vuln/","text":"Rechecking a Vulnerability \u00b6 The Vulnerability tab displays information about vulnerabilities . You can recheck vulnerabilities. Recheck a Vulnerability \u00b6 Click a vulnerability. Click Recheck again . Wallarm will run the vulnerability recheck. See also Working with the scanner","title":"Rechecking Vulnerabilities"},{"location":"en/user-guides/cloud-ui/vulnerabilities/recheck-vuln/#rechecking-a-vulnerability","text":"The Vulnerability tab displays information about vulnerabilities . You can recheck vulnerabilities.","title":"Rechecking a Vulnerability"},{"location":"en/user-guides/cloud-ui/vulnerabilities/recheck-vuln/#recheck-a-vulnerability","text":"Click a vulnerability. Click Recheck again . Wallarm will run the vulnerability recheck. See also Working with the scanner","title":"Recheck a Vulnerability"},{"location":"extensions/admonition/","text":"Admonition \u00b6 Admonition is an extension included in the standard Markdown library that makes it possible to add block-styled side content to your documentation, for example summaries, notes, hints or warnings. Installation \u00b6 Add the following lines to your mkdocs.yml : markdown_extensions : - admonition Usage \u00b6 Admonition blocks follow a simple syntax: every block is started with !!! , followed by a single keyword which is used as the type qualifier of the block. The content of the block then follows on the next line, indented by four spaces. Example: !!! note Lorem ipsum dolor sit amet, consectetur adipiscing elit. Nulla et euismod nulla. Curabitur feugiat, tortor non consequat finibus, justo purus auctor massa, nec semper lorem quam in massa. Result: Note Lorem ipsum dolor sit amet, consectetur adipiscing elit. Nulla et euismod nulla. Curabitur feugiat, tortor non consequat finibus, justo purus auctor massa, nec semper lorem quam in massa. Changing the title \u00b6 By default, the block title will equal the type qualifier in titlecase. However, it can easily be changed by adding a quoted string after the type qualifier. Example: !!! note \"Phasellus posuere in sem ut cursus\" Lorem ipsum dolor sit amet, consectetur adipiscing elit. Nulla et euismod nulla. Curabitur feugiat, tortor non consequat finibus, justo purus auctor massa, nec semper lorem quam in massa. Result: Phasellus posuere in sem ut cursus Lorem ipsum dolor sit amet, consectetur adipiscing elit. Nulla et euismod nulla. Curabitur feugiat, tortor non consequat finibus, justo purus auctor massa, nec semper lorem quam in massa. Removing the title \u00b6 Similar to setting a custom title , the icon and title can be omitted by providing an empty string after the type qualifier: Example: !!! note \"\" Lorem ipsum dolor sit amet, consectetur adipiscing elit. Nulla et euismod nulla. Curabitur feugiat, tortor non consequat finibus, justo purus auctor massa, nec semper lorem quam in massa. Result: Lorem ipsum dolor sit amet, consectetur adipiscing elit. Nulla et euismod nulla. Curabitur feugiat, tortor non consequat finibus, justo purus auctor massa, nec semper lorem quam in massa. Embedded code blocks \u00b6 Blocks can contain all kinds of text content, including headlines, lists, paragraphs and other blocks \u2013 except code blocks, because the parser from the standard Markdown library does not account for those. However, the PyMdown Extensions package adds an extension called SuperFences , which makes it possible to nest code blocks within other blocks, respectively Admonition blocks. Example: Note Lorem ipsum dolor sit amet, consectetur adipiscing elit. Nulla et euismod nulla. Curabitur feugiat, tortor non consequat finibus, justo purus auctor massa, nec semper lorem quam in massa. SELECT Employees . EmployeeID , Employees . Name , Employees . Salary , Manager . Name AS Manager FROM Employees LEFT JOIN Employees AS Manager ON Employees . ManagerID = Manager . EmployeeID WHERE Employees . EmployeeID = '087652' ; Nunc eu odio eleifend, blandit leo a, volutpat sapien. Phasellus posuere in sem ut cursus. Nullam sit amet tincidunt ipsum, sit amet elementum turpis. Etiam ipsum quam, mattis in purus vitae, lacinia fermentum enim. Collapsible blocks \u00b6 The Details extension which is also part of the PyMdown Extensions package adds support for rendering collapsible Admonition blocks. This is useful for FAQs or content that is of secondary nature. Example: ??? note \"Phasellus posuere in sem ut cursus\" Lorem ipsum dolor sit amet, consectetur adipiscing elit. Nulla et euismod nulla. Curabitur feugiat, tortor non consequat finibus, justo purus auctor massa, nec semper lorem quam in massa. Result: Phasellus posuere in sem ut cursus Lorem ipsum dolor sit amet, consectetur adipiscing elit. Nulla et euismod nulla. Curabitur feugiat, tortor non consequat finibus, justo purus auctor massa, nec semper lorem quam in massa. By adding a + sign directly after the start marker, blocks can be rendered open by default. Types \u00b6 Admonition supports user-defined type qualifiers which may influence the style of the inserted block. Following is a list of type qualifiers provided by the Material theme, whereas the default type, and thus fallback for unknown type qualifiers, is note . Note \u00b6 Example: !!! note Lorem ipsum dolor sit amet, consectetur adipiscing elit. Nulla et euismod nulla. Curabitur feugiat, tortor non consequat finibus, justo purus auctor massa, nec semper lorem quam in massa. Result: Note Lorem ipsum dolor sit amet, consectetur adipiscing elit. Nulla et euismod nulla. Curabitur feugiat, tortor non consequat finibus, justo purus auctor massa, nec semper lorem quam in massa. Qualifiers: note seealso Abstract \u00b6 Example: !!! abstract Lorem ipsum dolor sit amet, consectetur adipiscing elit. Nulla et euismod nulla. Curabitur feugiat, tortor non consequat finibus, justo purus auctor massa, nec semper lorem quam in massa. Result: Abstract Lorem ipsum dolor sit amet, consectetur adipiscing elit. Nulla et euismod nulla. Curabitur feugiat, tortor non consequat finibus, justo purus auctor massa, nec semper lorem quam in massa. Qualifiers: abstract summary tldr Info \u00b6 Example: !!! info Lorem ipsum dolor sit amet, consectetur adipiscing elit. Nulla et euismod nulla. Curabitur feugiat, tortor non consequat finibus, justo purus auctor massa, nec semper lorem quam in massa. Result: Info Lorem ipsum dolor sit amet, consectetur adipiscing elit. Nulla et euismod nulla. Curabitur feugiat, tortor non consequat finibus, justo purus auctor massa, nec semper lorem quam in massa. Qualifiers: info todo Tip \u00b6 Example: !!! tip Lorem ipsum dolor sit amet, consectetur adipiscing elit. Nulla et euismod nulla. Curabitur feugiat, tortor non consequat finibus, justo purus auctor massa, nec semper lorem quam in massa. Result: Tip Lorem ipsum dolor sit amet, consectetur adipiscing elit. Nulla et euismod nulla. Curabitur feugiat, tortor non consequat finibus, justo purus auctor massa, nec semper lorem quam in massa. Qualifiers: tip hint important Success \u00b6 Example: !!! success Lorem ipsum dolor sit amet, consectetur adipiscing elit. Nulla et euismod nulla. Curabitur feugiat, tortor non consequat finibus, justo purus auctor massa, nec semper lorem quam in massa. Result: Success Lorem ipsum dolor sit amet, consectetur adipiscing elit. Nulla et euismod nulla. Curabitur feugiat, tortor non consequat finibus, justo purus auctor massa, nec semper lorem quam in massa. Qualifiers: success check done Question \u00b6 Example: !!! question Lorem ipsum dolor sit amet, consectetur adipiscing elit. Nulla et euismod nulla. Curabitur feugiat, tortor non consequat finibus, justo purus auctor massa, nec semper lorem quam in massa. Result: Question Lorem ipsum dolor sit amet, consectetur adipiscing elit. Nulla et euismod nulla. Curabitur feugiat, tortor non consequat finibus, justo purus auctor massa, nec semper lorem quam in massa. Qualifiers: question help faq Warning \u00b6 Example: !!! warning Lorem ipsum dolor sit amet, consectetur adipiscing elit. Nulla et euismod nulla. Curabitur feugiat, tortor non consequat finibus, justo purus auctor massa, nec semper lorem quam in massa. Result: Warning Lorem ipsum dolor sit amet, consectetur adipiscing elit. Nulla et euismod nulla. Curabitur feugiat, tortor non consequat finibus, justo purus auctor massa, nec semper lorem quam in massa. Qualifiers: warning caution attention Failure \u00b6 Example: !!! failure Lorem ipsum dolor sit amet, consectetur adipiscing elit. Nulla et euismod nulla. Curabitur feugiat, tortor non consequat finibus, justo purus auctor massa, nec semper lorem quam in massa. Result: Failure Lorem ipsum dolor sit amet, consectetur adipiscing elit. Nulla et euismod nulla. Curabitur feugiat, tortor non consequat finibus, justo purus auctor massa, nec semper lorem quam in massa. Qualifiers: failure fail missing Danger \u00b6 Example: !!! danger Lorem ipsum dolor sit amet, consectetur adipiscing elit. Nulla et euismod nulla. Curabitur feugiat, tortor non consequat finibus, justo purus auctor massa, nec semper lorem quam in massa. Result: Danger Lorem ipsum dolor sit amet, consectetur adipiscing elit. Nulla et euismod nulla. Curabitur feugiat, tortor non consequat finibus, justo purus auctor massa, nec semper lorem quam in massa. Qualifiers: danger error Bug \u00b6 Example: !!! bug Lorem ipsum dolor sit amet, consectetur adipiscing elit. Nulla et euismod nulla. Curabitur feugiat, tortor non consequat finibus, justo purus auctor massa, nec semper lorem quam in massa. Result: Bug Lorem ipsum dolor sit amet, consectetur adipiscing elit. Nulla et euismod nulla. Curabitur feugiat, tortor non consequat finibus, justo purus auctor massa, nec semper lorem quam in massa. Qualifiers: bug Example \u00b6 Example: !!! example Lorem ipsum dolor sit amet, consectetur adipiscing elit. Nulla et euismod nulla. Curabitur feugiat, tortor non consequat finibus, justo purus auctor massa, nec semper lorem quam in massa. Result: Example Lorem ipsum dolor sit amet, consectetur adipiscing elit. Nulla et euismod nulla. Curabitur feugiat, tortor non consequat finibus, justo purus auctor massa, nec semper lorem quam in massa. Qualifiers: example snippet Quote \u00b6 Example: !!! quote Lorem ipsum dolor sit amet, consectetur adipiscing elit. Nulla et euismod nulla. Curabitur feugiat, tortor non consequat finibus, justo purus auctor massa, nec semper lorem quam in massa. Result: Quote Lorem ipsum dolor sit amet, consectetur adipiscing elit. Nulla et euismod nulla. Curabitur feugiat, tortor non consequat finibus, justo purus auctor massa, nec semper lorem quam in massa. Qualifiers: quote cite","title":"Admonition"},{"location":"extensions/admonition/#admonition","text":"Admonition is an extension included in the standard Markdown library that makes it possible to add block-styled side content to your documentation, for example summaries, notes, hints or warnings.","title":"Admonition"},{"location":"extensions/admonition/#installation","text":"Add the following lines to your mkdocs.yml : markdown_extensions : - admonition","title":"Installation"},{"location":"extensions/admonition/#usage","text":"Admonition blocks follow a simple syntax: every block is started with !!! , followed by a single keyword which is used as the type qualifier of the block. The content of the block then follows on the next line, indented by four spaces. Example: !!! note Lorem ipsum dolor sit amet, consectetur adipiscing elit. Nulla et euismod nulla. Curabitur feugiat, tortor non consequat finibus, justo purus auctor massa, nec semper lorem quam in massa. Result: Note Lorem ipsum dolor sit amet, consectetur adipiscing elit. Nulla et euismod nulla. Curabitur feugiat, tortor non consequat finibus, justo purus auctor massa, nec semper lorem quam in massa.","title":"Usage"},{"location":"extensions/admonition/#changing-the-title","text":"By default, the block title will equal the type qualifier in titlecase. However, it can easily be changed by adding a quoted string after the type qualifier. Example: !!! note \"Phasellus posuere in sem ut cursus\" Lorem ipsum dolor sit amet, consectetur adipiscing elit. Nulla et euismod nulla. Curabitur feugiat, tortor non consequat finibus, justo purus auctor massa, nec semper lorem quam in massa. Result: Phasellus posuere in sem ut cursus Lorem ipsum dolor sit amet, consectetur adipiscing elit. Nulla et euismod nulla. Curabitur feugiat, tortor non consequat finibus, justo purus auctor massa, nec semper lorem quam in massa.","title":"Changing the title"},{"location":"extensions/admonition/#removing-the-title","text":"Similar to setting a custom title , the icon and title can be omitted by providing an empty string after the type qualifier: Example: !!! note \"\" Lorem ipsum dolor sit amet, consectetur adipiscing elit. Nulla et euismod nulla. Curabitur feugiat, tortor non consequat finibus, justo purus auctor massa, nec semper lorem quam in massa. Result: Lorem ipsum dolor sit amet, consectetur adipiscing elit. Nulla et euismod nulla. Curabitur feugiat, tortor non consequat finibus, justo purus auctor massa, nec semper lorem quam in massa.","title":"Removing the title"},{"location":"extensions/admonition/#embedded-code-blocks","text":"Blocks can contain all kinds of text content, including headlines, lists, paragraphs and other blocks \u2013 except code blocks, because the parser from the standard Markdown library does not account for those. However, the PyMdown Extensions package adds an extension called SuperFences , which makes it possible to nest code blocks within other blocks, respectively Admonition blocks. Example: Note Lorem ipsum dolor sit amet, consectetur adipiscing elit. Nulla et euismod nulla. Curabitur feugiat, tortor non consequat finibus, justo purus auctor massa, nec semper lorem quam in massa. SELECT Employees . EmployeeID , Employees . Name , Employees . Salary , Manager . Name AS Manager FROM Employees LEFT JOIN Employees AS Manager ON Employees . ManagerID = Manager . EmployeeID WHERE Employees . EmployeeID = '087652' ; Nunc eu odio eleifend, blandit leo a, volutpat sapien. Phasellus posuere in sem ut cursus. Nullam sit amet tincidunt ipsum, sit amet elementum turpis. Etiam ipsum quam, mattis in purus vitae, lacinia fermentum enim.","title":"Embedded code blocks"},{"location":"extensions/admonition/#collapsible-blocks","text":"The Details extension which is also part of the PyMdown Extensions package adds support for rendering collapsible Admonition blocks. This is useful for FAQs or content that is of secondary nature. Example: ??? note \"Phasellus posuere in sem ut cursus\" Lorem ipsum dolor sit amet, consectetur adipiscing elit. Nulla et euismod nulla. Curabitur feugiat, tortor non consequat finibus, justo purus auctor massa, nec semper lorem quam in massa. Result: Phasellus posuere in sem ut cursus Lorem ipsum dolor sit amet, consectetur adipiscing elit. Nulla et euismod nulla. Curabitur feugiat, tortor non consequat finibus, justo purus auctor massa, nec semper lorem quam in massa. By adding a + sign directly after the start marker, blocks can be rendered open by default.","title":"Collapsible blocks"},{"location":"extensions/admonition/#types","text":"Admonition supports user-defined type qualifiers which may influence the style of the inserted block. Following is a list of type qualifiers provided by the Material theme, whereas the default type, and thus fallback for unknown type qualifiers, is note .","title":"Types"},{"location":"extensions/admonition/#note","text":"Example: !!! note Lorem ipsum dolor sit amet, consectetur adipiscing elit. Nulla et euismod nulla. Curabitur feugiat, tortor non consequat finibus, justo purus auctor massa, nec semper lorem quam in massa. Result: Note Lorem ipsum dolor sit amet, consectetur adipiscing elit. Nulla et euismod nulla. Curabitur feugiat, tortor non consequat finibus, justo purus auctor massa, nec semper lorem quam in massa. Qualifiers: note seealso","title":"Note"},{"location":"extensions/admonition/#abstract","text":"Example: !!! abstract Lorem ipsum dolor sit amet, consectetur adipiscing elit. Nulla et euismod nulla. Curabitur feugiat, tortor non consequat finibus, justo purus auctor massa, nec semper lorem quam in massa. Result: Abstract Lorem ipsum dolor sit amet, consectetur adipiscing elit. Nulla et euismod nulla. Curabitur feugiat, tortor non consequat finibus, justo purus auctor massa, nec semper lorem quam in massa. Qualifiers: abstract summary tldr","title":"Abstract"},{"location":"extensions/admonition/#info","text":"Example: !!! info Lorem ipsum dolor sit amet, consectetur adipiscing elit. Nulla et euismod nulla. Curabitur feugiat, tortor non consequat finibus, justo purus auctor massa, nec semper lorem quam in massa. Result: Info Lorem ipsum dolor sit amet, consectetur adipiscing elit. Nulla et euismod nulla. Curabitur feugiat, tortor non consequat finibus, justo purus auctor massa, nec semper lorem quam in massa. Qualifiers: info todo","title":"Info"},{"location":"extensions/admonition/#tip","text":"Example: !!! tip Lorem ipsum dolor sit amet, consectetur adipiscing elit. Nulla et euismod nulla. Curabitur feugiat, tortor non consequat finibus, justo purus auctor massa, nec semper lorem quam in massa. Result: Tip Lorem ipsum dolor sit amet, consectetur adipiscing elit. Nulla et euismod nulla. Curabitur feugiat, tortor non consequat finibus, justo purus auctor massa, nec semper lorem quam in massa. Qualifiers: tip hint important","title":"Tip"},{"location":"extensions/admonition/#success","text":"Example: !!! success Lorem ipsum dolor sit amet, consectetur adipiscing elit. Nulla et euismod nulla. Curabitur feugiat, tortor non consequat finibus, justo purus auctor massa, nec semper lorem quam in massa. Result: Success Lorem ipsum dolor sit amet, consectetur adipiscing elit. Nulla et euismod nulla. Curabitur feugiat, tortor non consequat finibus, justo purus auctor massa, nec semper lorem quam in massa. Qualifiers: success check done","title":"Success"},{"location":"extensions/admonition/#question","text":"Example: !!! question Lorem ipsum dolor sit amet, consectetur adipiscing elit. Nulla et euismod nulla. Curabitur feugiat, tortor non consequat finibus, justo purus auctor massa, nec semper lorem quam in massa. Result: Question Lorem ipsum dolor sit amet, consectetur adipiscing elit. Nulla et euismod nulla. Curabitur feugiat, tortor non consequat finibus, justo purus auctor massa, nec semper lorem quam in massa. Qualifiers: question help faq","title":"Question"},{"location":"extensions/admonition/#warning","text":"Example: !!! warning Lorem ipsum dolor sit amet, consectetur adipiscing elit. Nulla et euismod nulla. Curabitur feugiat, tortor non consequat finibus, justo purus auctor massa, nec semper lorem quam in massa. Result: Warning Lorem ipsum dolor sit amet, consectetur adipiscing elit. Nulla et euismod nulla. Curabitur feugiat, tortor non consequat finibus, justo purus auctor massa, nec semper lorem quam in massa. Qualifiers: warning caution attention","title":"Warning"},{"location":"extensions/admonition/#failure","text":"Example: !!! failure Lorem ipsum dolor sit amet, consectetur adipiscing elit. Nulla et euismod nulla. Curabitur feugiat, tortor non consequat finibus, justo purus auctor massa, nec semper lorem quam in massa. Result: Failure Lorem ipsum dolor sit amet, consectetur adipiscing elit. Nulla et euismod nulla. Curabitur feugiat, tortor non consequat finibus, justo purus auctor massa, nec semper lorem quam in massa. Qualifiers: failure fail missing","title":"Failure"},{"location":"extensions/admonition/#danger","text":"Example: !!! danger Lorem ipsum dolor sit amet, consectetur adipiscing elit. Nulla et euismod nulla. Curabitur feugiat, tortor non consequat finibus, justo purus auctor massa, nec semper lorem quam in massa. Result: Danger Lorem ipsum dolor sit amet, consectetur adipiscing elit. Nulla et euismod nulla. Curabitur feugiat, tortor non consequat finibus, justo purus auctor massa, nec semper lorem quam in massa. Qualifiers: danger error","title":"Danger"},{"location":"extensions/admonition/#bug","text":"Example: !!! bug Lorem ipsum dolor sit amet, consectetur adipiscing elit. Nulla et euismod nulla. Curabitur feugiat, tortor non consequat finibus, justo purus auctor massa, nec semper lorem quam in massa. Result: Bug Lorem ipsum dolor sit amet, consectetur adipiscing elit. Nulla et euismod nulla. Curabitur feugiat, tortor non consequat finibus, justo purus auctor massa, nec semper lorem quam in massa. Qualifiers: bug","title":"Bug"},{"location":"extensions/admonition/#example","text":"Example: !!! example Lorem ipsum dolor sit amet, consectetur adipiscing elit. Nulla et euismod nulla. Curabitur feugiat, tortor non consequat finibus, justo purus auctor massa, nec semper lorem quam in massa. Result: Example Lorem ipsum dolor sit amet, consectetur adipiscing elit. Nulla et euismod nulla. Curabitur feugiat, tortor non consequat finibus, justo purus auctor massa, nec semper lorem quam in massa. Qualifiers: example snippet","title":"Example"},{"location":"extensions/admonition/#quote","text":"Example: !!! quote Lorem ipsum dolor sit amet, consectetur adipiscing elit. Nulla et euismod nulla. Curabitur feugiat, tortor non consequat finibus, justo purus auctor massa, nec semper lorem quam in massa. Result: Quote Lorem ipsum dolor sit amet, consectetur adipiscing elit. Nulla et euismod nulla. Curabitur feugiat, tortor non consequat finibus, justo purus auctor massa, nec semper lorem quam in massa. Qualifiers: quote cite","title":"Quote"},{"location":"extensions/codehilite/","text":"CodeHilite \u00b6 CodeHilite is an extension that adds syntax highlighting to code blocks and is included in the standard Markdown library. The highlighting process is executed during compilation of the Markdown file. Syntax highlighting not working? Please ensure that Pygments is installed. See the next section for further directions on how to set up Pygments or use the official Docker image with all dependencies pre-installed. Installation \u00b6 CodeHilite parses code blocks and wraps them in pre tags. If Pygments is installed, which is a generic syntax highlighter with support for over 300 languages , CodeHilite will also highlight the code block. Pygments can be installed with the following command: pip install pygments To enable CodeHilite, add the following lines to your mkdocs.yml : markdown_extensions : - codehilite Usage \u00b6 Specifying the language \u00b6 The CodeHilite extension uses the same syntax as regular Markdown code blocks, but needs to know the language of the code block. This can be done in three different ways. via Markdown syntax recommended \u00b6 In Markdown, code blocks can be opened and closed by writing three backticks on separate lines. To add code highlighting to those blocks, the easiest way is to specify the language directly after the opening block. Example: ``` python import tensorflow as tf ``` Result: import tensorflow as tf via Shebang \u00b6 Alternatively, if the first line of a code block contains a shebang, the language is derived from the path referenced in the shebang. This will only work for code blocks that are indented using four spaces, not for those encapsulated in three backticks. Example: #!/usr/bin/python import tensorflow as tf Result: #!/usr/bin/python import tensorflow as tf via three colons \u00b6 If the first line starts with three colons followed by a language identifier, the first line is stripped. This will only work for code blocks that are indented using four spaces, not for those encapsulated in three backticks. Example: :::python import tensorflow as tf Result: import tensorflow as tf Adding line numbers \u00b6 Line numbers can be added by enabling the linenums flag in your mkdocs.yml : markdown_extensions : - codehilite : linenums : true Example: ``` python \"\"\" Bubble sort \"\"\" def bubble_sort(items): for i in range(len(items)): for j in range(len(items) - 1 - i): if items[j] > items[j + 1]: items[j], items[j + 1] = items[j + 1], items[j] ``` Result: 1 2 3 4 5 6 \"\"\" Bubble sort \"\"\" def bubble_sort ( items ): for i in range ( len ( items )): for j in range ( len ( items ) - 1 - i ): if items [ j ] > items [ j + 1 ]: items [ j ], items [ j + 1 ] = items [ j + 1 ], items [ j ] Grouping code blocks \u00b6 The SuperFences extension which is part of the PyMdown Extensions package adds support for grouping code blocks with tabs. This is especially useful for documenting projects with multiple language bindings. Example: ``` bash tab=\"Bash\" #!/bin/bash echo \"Hello world!\" ``` ``` c tab=\"C\" #include <stdio.h> int main(void) { printf(\"Hello world!\\n\"); } ``` ``` c++ tab=\"C++\" #include <iostream> int main() { std::cout << \"Hello world!\" << std::endl; return 0; } ``` ``` c# tab=\"C#\" using System; class Program { static void Main(string[] args) { Console.WriteLine(\"Hello world!\"); } } ``` Result: Bash #!/bin/bash echo \"Hello world!\" C #include <stdio.h> int main ( void ) { printf ( \"Hello world! \\n \" ); } C++ #include <iostream> int main () { std :: cout << \"Hello world!\" << std :: endl ; return 0 ; } C# using System ; class Program { static void Main ( string [] args ) { Console . WriteLine ( \"Hello world!\" ); } } Highlighting specific lines \u00b6 Specific lines can be highlighted by passing the line numbers to the hl_lines argument placed right after the language identifier. Line counts start at 1. Example: ``` python hl_lines=\"3 4\" \"\"\" Bubble sort \"\"\" def bubble_sort(items): for i in range(len(items)): for j in range(len(items) - 1 - i): if items[j] > items[j + 1]: items[j], items[j + 1] = items[j + 1], items[j] ``` Result: 1 2 3 4 5 6 \"\"\" Bubble sort \"\"\" def bubble_sort ( items ): for i in range ( len ( items )): for j in range ( len ( items ) - 1 - i ): if items [ j ] > items [ j + 1 ]: items [ j ], items [ j + 1 ] = items [ j + 1 ], items [ j ] Supported languages excerpt \u00b6 CodeHilite uses Pygments , a generic syntax highlighter with support for over 300 languages , so the following list of examples is just an excerpt. Bash \u00b6 #!/bin/bash for OPT in \" $@ \" do case \" $OPT \" in '-f' ) canonicalize = 1 ;; '-n' ) switchlf = \"-n\" ;; esac done # readlink -f function __readlink_f { target = \" $1 \" while test -n \" $target \" ; do filepath = \" $target \" cd ` dirname \" $filepath \" ` target = ` readlink \" $filepath \" ` done /bin/echo $switchlf ` pwd -P ` / ` basename \" $filepath \" ` } if [ ! \" $canonicalize \" ] ; then readlink $switchlf \" $@ \" else for file in \" $@ \" do case \" $file \" in -* ) ;; * ) __readlink_f \" $file \" ;; esac done fi exit $? C \u00b6 extern size_t pb_varint_scan ( const uint8_t data [], size_t left ) { assert ( data && left ); left = left > 10 ? 10 : left ; #ifdef __SSE2__ /* Mapping: remaining bytes ==> bitmask */ static const int mask_map [] = { 0x0000 , 0x0001 , 0x0003 , 0x0007 , 0x000F , 0x001F , 0x003F , 0x007F , 0x00FF , 0x01FF , 0x03FF }; /* Load buffer into 128-bit integer and create high-bit mask */ __m128i temp = _mm_loadu_si128 (( const __m128i * ) data ); __m128i high = _mm_set1_epi8 ( 0x80 ); /* Intersect and extract mask with high-bits set */ int mask = _mm_movemask_epi8 ( _mm_and_si128 ( temp , high )); mask = ( mask & mask_map [ left ]) ^ mask_map [ left ]; /* Count trailing zeroes */ return mask ? __builtin_ctz ( mask ) + 1 : 0 ; #else /* Linear scan */ size_t size = 0 ; while ( data [ size ++ ] & 0x80 ) if ( !-- left ) return 0 ; return size ; #endif /* __SSE2__ */ } C++ \u00b6 Extension :: Extension ( const Descriptor * descriptor , const Descriptor * scope ) : descriptor_ ( descriptor ), scope_ ( scope ) { /* Extract full name for signature */ variables_ [ \"signature\" ] = descriptor_ -> full_name (); /* Prepare message symbol */ variables_ [ \"message\" ] = StringReplace ( variables_ [ \"signature\" ], \".\" , \"_\" , true ); LowerString ( & ( variables_ [ \"message\" ])); /* Suffix scope to identifiers, if given */ string suffix ( \"\" ); if ( scope_ ) { suffix = scope_ -> full_name (); /* Check if the base and extension types are in the same package */ if ( ! scope_ -> file () -> package (). compare ( descriptor_ -> file () -> package ())) suffix = StripPrefixString ( suffix , scope_ -> file () -> package () + \".\" ); /* Append to signature */ variables_ [ \"signature\" ] += \".[\" + suffix + \"]\" ; suffix = \"_\" + suffix ; } /* Prepare extension symbol */ variables_ [ \"extension\" ] = StringReplace ( suffix , \".\" , \"_\" , true ); LowerString ( & ( variables_ [ \"extension\" ])); } C# \u00b6 public static void Send ( Socket socket , byte [] buffer , int offset , int size , int timeout ) { int startTickCount = Environment . TickCount ; int sent = 0 ; do { if ( Environment . TickCount > startTickCount + timeout ) throw new Exception ( \"Timeout.\" ); try { sent += socket . Send ( buffer , offset + sent , size - sent , SocketFlags . None ); } catch ( SocketException ex ) { if ( ex . SocketErrorCode == SocketError . WouldBlock || ex . SocketErrorCode == SocketError . IOPending || ex . SocketErrorCode == SocketError . NoBufferSpaceAvailable ) { /* Socket buffer is probably full, wait and try again */ Thread . Sleep ( 30 ); } else { throw ex ; } } } while ( sent < size ); } Clojure \u00b6 ( clojure-version ) ( defn partition-when [ f ] ( fn [ rf ] ( let [ a ( java.util.ArrayList. ) fval ( volatile! false )] ( fn ([] ( rf )) ([ result ] ( let [ result ( if ( .isEmpty a ) result ( let [ v ( vec ( .toArray a ))] ;; Clear first ( .clear a ) ( unreduced ( rf result v ))))] ( rf result ))) ([ result input ] ( if-not ( and ( f input ) @ fval ) ( do ( vreset! fval true ) ( .add a input ) result ) ( let [ v ( vec ( .toArray a ))] ( .clear a ) ( let [ ret ( rf result v )] ( when-not ( reduced? ret ) ( .add a input )) ret )))))))) ( into [] ( partition-when # ( .startsWith % \">>\" )) [ \"1d\" \"33\" \">> 1\" \">> 2\" \"22\" \">> 3\" ]) Diff \u00b6 Index: grunt.js =================================================================== --- grunt.js (revision 31200) +++ grunt.js (working copy) @@ -12,6 +12,7 @@ module.exports = function (grunt) { + console.log('hello world'); // Project configuration. grunt.initConfig({ lint: { @@ -19,10 +20,6 @@ 'packages/services.web/{!(test)/**/,}*.js', 'packages/error/**/*.js' ], - scripts: [ - 'grunt.js', - 'db/**/*.js' - ], browser: [ 'packages/web/server.js', 'packages/web/server/**/*.js', Docker \u00b6 FROM ubuntu # Install vnc, xvfb in order to create a 'fake' display and firefox RUN apt-get update && apt-get install -y x11vnc xvfb firefox RUN mkdir ~/.vnc # Setup a password RUN x11vnc -storepasswd 1234 ~/.vnc/passwd # Autostart firefox (might not be the best way, but it does the trick) RUN bash -c 'echo \"firefox\" >> /.bashrc' EXPOSE 5900 CMD [ \"x11vnc\" , \"-forever\" , \"-usepw\" , \"-create\" ] Elixir \u00b6 require Logger def accept ( port ) do { :ok , socket } = :gen_tcp . listen ( port , [ :binary , packet : :line , active : false , reuseaddr : true ]) Logger . info \"Accepting connections on port #{ port } \" loop_acceptor ( socket ) end defp loop_acceptor ( socket ) do { :ok , client } = :gen_tcp . accept ( socket ) serve ( client ) loop_acceptor ( socket ) end defp serve ( socket ) do socket |> read_line () |> write_line ( socket ) serve ( socket ) end defp read_line ( socket ) do { :ok , data } = :gen_tcp . recv ( socket , 0 ) data end defp write_line ( line , socket ) do :gen_tcp . send ( socket , line ) end Erlang \u00b6 circular ( Defs ) -> [ { { Type , Base }, Fields } || { { Type , Base }, Fields } <- Defs , Type == msg , circular ( Base , Defs ) ]. circular ( Base , Defs ) -> Fields = proplists : get_value ({ msg , Base }, Defs ), circular ( Defs , Fields , [ Base ]). circular (_ Defs , [], _ Path ) -> false ; circular ( Defs , [ Field | Fields ], Path ) -> case Field #field.type of { msg , Type } -> case lists : member ( Type , Path ) of false -> Children = proplists : get_value ({ msg , Type }, Defs ), case circular ( Defs , Children , [ Type | Path ]) of false -> circular ( Defs , Fields , Path ); true -> true end ; true -> Type == lists : last ( Path ) andalso ( length ( Path ) == 1 orelse not is_tree ( Path )) end ; _ -> circular ( Defs , Fields , Path ) end . F# \u00b6 /// Asynchronously download retangles from the server /// and decode the JSON format to F# Rectangle record let [< Js >] getRectangles () : Async < Rectangle [] > = async { let req = XMLHttpRequest () req . Open ( \"POST\" , \"/get\" , true ) let! resp = req . AsyncSend () return JSON . parse ( resp ) } /// Repeatedly update rectangles after 0.5 sec let [< Js >] updateLoop () = async { while true do do ! Async . Sleep ( 500 ) let! rects = getRectangles () cleanRectangles () rects |> Array . iter createRectangle } Go \u00b6 package main import \"fmt\" func counter ( id int , channel chan int , closer bool ) { for i := 0 ; i < 10000000 ; i ++ { fmt . Println ( \"process\" , id , \" send\" , i ) channel <- 1 } if closer { close ( channel ) } } func main () { channel := make ( chan int ) go counter ( 1 , channel , false ) go counter ( 2 , channel , true ) x := 0 // receiving data from channel for i := range channel { fmt . Println ( \"receiving\" ) x += i } fmt . Println ( x ) } HTML \u00b6 <!doctype html> < html class = \"no-js\" lang = \"\" > < head > < meta charset = \"utf-8\" > < meta http-equiv = \"x-ua-compatible\" content = \"ie=edge\" > < title > HTML5 Boilerplate </ title > < meta name = \"description\" content = \"\" > < meta name = \"viewport\" content = \"width=device-width, initial-scale=1\" > < link rel = \"apple-touch-icon\" href = \"apple-touch-icon.png\" > < link rel = \"stylesheet\" href = \"css/normalize.css\" > < link rel = \"stylesheet\" href = \"css/main.css\" > < script src = \"js/vendor/modernizr-2.8.3.min.js\" ></ script > </ head > < body > < p > Hello world! This is HTML5 Boilerplate. </ p > </ body > </ html > Java \u00b6 import java.util.LinkedList ; import java.lang.reflect.Array ; public class UnsortedHashSet < E > { private static final double LOAD_FACTOR_LIMIT = 0.7 ; private int size ; private LinkedList < E >[] con ; public UnsortedHashSet () { con = ( LinkedList < E >[] )( new LinkedList [ 10 ] ); } public boolean add ( E obj ) { int oldSize = size ; int index = Math . abs ( obj . hashCode ()) % con . length ; if ( con [ index ] == null ) con [ index ] = new LinkedList < E > (); if ( ! con [ index ] . contains ( obj )) { con [ index ] . add ( obj ); size ++ ; } if ( 1.0 * size / con . length > LOAD_FACTOR_LIMIT ) resize (); return oldSize != size ; } private void resize () { UnsortedHashSet < E > temp = new UnsortedHashSet < E > (); temp . con = ( LinkedList < E >[] )( new LinkedList [ con . length * 2 + 1 ] ); for ( int i = 0 ; i < con . length ; i ++ ) { if ( con [ i ] != null ) for ( E e : con [ i ] ) temp . add ( e ); } con = temp . con ; } public int size () { return size ; } } JavaScript \u00b6 var Math = require ( 'lib/math' ); var _extends = function ( target ) { for ( var i = 1 ; i < arguments . length ; i ++ ) { var source = arguments [ i ]; for ( var key in source ) { target [ key ] = source [ key ]; } } return target ; }; var e = exports . e = 2.71828182846 ; exports [ 'default' ] = function ( x ) { return Math . exp ( x ); }; module . exports = _extends ( exports [ 'default' ], exports ); JSON \u00b6 { \"name\" : \"mkdocs-material\" , \"version\" : \"0.2.4\" , \"description\" : \"A Material Design theme for MkDocs\" , \"homepage\" : \"http://squidfunk.github.io/mkdocs-material/\" , \"authors\" : [ \"squidfunk <martin.donath@squidfunk.com>\" ], \"license\" : \"MIT\" , \"main\" : \"Gulpfile.js\" , \"scripts\" : { \"start\" : \"./node_modules/.bin/gulp watch --mkdocs\" , \"build\" : \"./node_modules/.bin/gulp build --production\" } ... } Julia \u00b6 using MXNet mlp = @mx . chain mx . Variable ( : data ) => mx . FullyConnected ( name =: fc1 , num_hidden = 128 ) => mx . Activation ( name =: relu1 , act_type =: relu ) => mx . FullyConnected ( name =: fc2 , num_hidden = 64 ) => mx . Activation ( name =: relu2 , act_type =: relu ) => mx . FullyConnected ( name =: fc3 , num_hidden = 10 ) => mx . SoftmaxOutput ( name =: softmax ) # data provider batch_size = 100 include ( Pkg . dir ( \"MXNet\" , \"examples\" , \"mnist\" , \"mnist-data.jl\" )) train_provider , eval_provider = get_mnist_providers ( batch_size ) # setup model model = mx . FeedForward ( mlp , context = mx . cpu ()) # optimization algorithm optimizer = mx . SGD ( lr = 0.1 , momentum = 0.9 ) # fit parameters mx . fit ( model , optimizer , train_provider , n_epoch = 20 , eval_data = eval_provider ) Lua \u00b6 local ffi = require ( \"ffi\" ) ffi . cdef [[ void Sleep(int ms); int poll(struct pollfd *fds, unsigned long nfds, int timeout); ]] local sleep if ffi . os == \"Windows\" then function sleep ( s ) ffi . C . Sleep ( s * 1000 ) end else function sleep ( s ) ffi . C . poll ( nil , 0 , s * 1000 ) end end for i = 1 , 160 do io.write ( \".\" ); io.flush () sleep ( 0.01 ) end io.write ( \" \\n \" ) MySQL \u00b6 SELECT Employees . EmployeeID , Employees . Name , Employees . Salary , Manager . Name AS Manager FROM Employees LEFT JOIN Employees AS Manager ON Employees . ManagerID = Manager . EmployeeID WHERE Employees . EmployeeID = '087652' ; PHP \u00b6 <?php // src/AppBundle/Controller/LuckyController.php namespace AppBundle\\Controller ; use Sensio\\Bundle\\FrameworkExtraBundle\\Configuration\\Route ; use Symfony\\Component\\HttpFoundation\\Response ; class LuckyController { /** * @Route(\"/lucky/number\") */ public function numberAction () { $number = mt_rand ( 0 , 100 ); return new Response ( '<html><body>Lucky number: ' . $number . '</body></html>' ); } } Protocol Buffers \u00b6 syntax = \"proto2\" ; package caffe ; // Specifies the shape (dimensions) of a Blob. message BlobShape { repeated int64 dim = 1 [ packed = true ]; } message BlobProto { optional BlobShape shape = 7 ; repeated float data = 5 [ packed = true ]; repeated float diff = 6 [ packed = true ]; // 4D dimensions -- deprecated. Use \"shape\" instead. optional int32 num = 1 [ default = 0 ]; optional int32 channels = 2 [ default = 0 ]; optional int32 height = 3 [ default = 0 ]; optional int32 width = 4 [ default = 0 ]; } Python \u00b6 \"\"\" A very simple MNIST classifier. See extensive documentation at http://tensorflow.org/tutorials/mnist/beginners/index.md \"\"\" from __future__ import absolute_import from __future__ import division from __future__ import print_function # Import data from tensorflow.examples.tutorials.mnist import input_data import tensorflow as tf flags = tf . app . flags FLAGS = flags . FLAGS flags . DEFINE_string ( 'data_dir' , '/tmp/data/' , 'Directory for storing data' ) mnist = input_data . read_data_sets ( FLAGS . data_dir , one_hot = True ) sess = tf . InteractiveSession () # Create the model x = tf . placeholder ( tf . float32 , [ None , 784 ]) W = tf . Variable ( tf . zeros ([ 784 , 10 ])) b = tf . Variable ( tf . zeros ([ 10 ])) y = tf . nn . softmax ( tf . matmul ( x , W ) + b ) Ruby \u00b6 require 'finity/event' require 'finity/machine' require 'finity/state' require 'finity/transition' require 'finity/version' module Finity class InvalidCallback < StandardError ; end class MissingCallback < StandardError ; end class InvalidState < StandardError ; end # Class methods to be injected into the including class upon inclusion. module ClassMethods # Instantiate a new state machine for the including class by accepting a # block with state and event (and subsequent transition) definitions. def finity options = {}, & block @finity ||= Machine . new self , options , & block end # Return the names of all registered states. def states @finity . states . map { | name , _ | name } end # Return the names of all registered events. def events @finity . events . map { | name , _ | name } end end # Inject methods into the including class upon inclusion. def self . included base base . extend ClassMethods end end Scala \u00b6 // Every record of this DataFrame contains the label and // features represented by a vector. val df = sqlContext . createDataFrame ( data ). toDF ( \"label\" , \"features\" ) // Set parameters for the algorithm. // Here, we limit the number of iterations to 10. val lr = new LogisticRegression (). setMaxIter ( 10 ) // Fit the model to the data. val model = lr . fit ( df ) // Inspect the model: get the feature weights. val weights = model . weights // Given a dataset, predict each point's label, and show the results. model . transform ( df ). show () g XML \u00b6 <?xml version=\"1.0\" encoding=\"UTF-8\"?> <!DOCTYPE mainTag SYSTEM \"some.dtd\" [ENTITY % entity]> <?oxygen RNGSchema=\"some.rng\" type=\"xml\"?> <xs:main-Tag xmlns:xs= \"http://www.w3.org/2001/XMLSchema\" > <!-- This is a sample comment --> <childTag attribute= \"Quoted Value\" another-attribute= 'Single quoted value' a-third-attribute= '123' > <withTextContent> Some text content </withTextContent> <withEntityContent> Some text content with &lt; entities &gt; and mentioning uint8_t and int32_t </withEntityContent> <otherTag attribute= 'Single quoted Value' /> </childTag> <![CDATA[ some CData ]]> </main-Tag>","title":"CodeHilite"},{"location":"extensions/codehilite/#codehilite","text":"CodeHilite is an extension that adds syntax highlighting to code blocks and is included in the standard Markdown library. The highlighting process is executed during compilation of the Markdown file. Syntax highlighting not working? Please ensure that Pygments is installed. See the next section for further directions on how to set up Pygments or use the official Docker image with all dependencies pre-installed.","title":"CodeHilite"},{"location":"extensions/codehilite/#installation","text":"CodeHilite parses code blocks and wraps them in pre tags. If Pygments is installed, which is a generic syntax highlighter with support for over 300 languages , CodeHilite will also highlight the code block. Pygments can be installed with the following command: pip install pygments To enable CodeHilite, add the following lines to your mkdocs.yml : markdown_extensions : - codehilite","title":"Installation"},{"location":"extensions/codehilite/#usage","text":"","title":"Usage"},{"location":"extensions/codehilite/#specifying-the-language","text":"The CodeHilite extension uses the same syntax as regular Markdown code blocks, but needs to know the language of the code block. This can be done in three different ways.","title":"Specifying the language"},{"location":"extensions/codehilite/#via-markdown-syntax-recommended","text":"In Markdown, code blocks can be opened and closed by writing three backticks on separate lines. To add code highlighting to those blocks, the easiest way is to specify the language directly after the opening block. Example: ``` python import tensorflow as tf ``` Result: import tensorflow as tf","title":"via Markdown syntax recommended"},{"location":"extensions/codehilite/#via-shebang","text":"Alternatively, if the first line of a code block contains a shebang, the language is derived from the path referenced in the shebang. This will only work for code blocks that are indented using four spaces, not for those encapsulated in three backticks. Example: #!/usr/bin/python import tensorflow as tf Result: #!/usr/bin/python import tensorflow as tf","title":"via Shebang"},{"location":"extensions/codehilite/#via-three-colons","text":"If the first line starts with three colons followed by a language identifier, the first line is stripped. This will only work for code blocks that are indented using four spaces, not for those encapsulated in three backticks. Example: :::python import tensorflow as tf Result: import tensorflow as tf","title":"via three colons"},{"location":"extensions/codehilite/#adding-line-numbers","text":"Line numbers can be added by enabling the linenums flag in your mkdocs.yml : markdown_extensions : - codehilite : linenums : true Example: ``` python \"\"\" Bubble sort \"\"\" def bubble_sort(items): for i in range(len(items)): for j in range(len(items) - 1 - i): if items[j] > items[j + 1]: items[j], items[j + 1] = items[j + 1], items[j] ``` Result: 1 2 3 4 5 6 \"\"\" Bubble sort \"\"\" def bubble_sort ( items ): for i in range ( len ( items )): for j in range ( len ( items ) - 1 - i ): if items [ j ] > items [ j + 1 ]: items [ j ], items [ j + 1 ] = items [ j + 1 ], items [ j ]","title":"Adding line numbers"},{"location":"extensions/codehilite/#grouping-code-blocks","text":"The SuperFences extension which is part of the PyMdown Extensions package adds support for grouping code blocks with tabs. This is especially useful for documenting projects with multiple language bindings. Example: ``` bash tab=\"Bash\" #!/bin/bash echo \"Hello world!\" ``` ``` c tab=\"C\" #include <stdio.h> int main(void) { printf(\"Hello world!\\n\"); } ``` ``` c++ tab=\"C++\" #include <iostream> int main() { std::cout << \"Hello world!\" << std::endl; return 0; } ``` ``` c# tab=\"C#\" using System; class Program { static void Main(string[] args) { Console.WriteLine(\"Hello world!\"); } } ``` Result: Bash #!/bin/bash echo \"Hello world!\" C #include <stdio.h> int main ( void ) { printf ( \"Hello world! \\n \" ); } C++ #include <iostream> int main () { std :: cout << \"Hello world!\" << std :: endl ; return 0 ; } C# using System ; class Program { static void Main ( string [] args ) { Console . WriteLine ( \"Hello world!\" ); } }","title":"Grouping code blocks"},{"location":"extensions/codehilite/#highlighting-specific-lines","text":"Specific lines can be highlighted by passing the line numbers to the hl_lines argument placed right after the language identifier. Line counts start at 1. Example: ``` python hl_lines=\"3 4\" \"\"\" Bubble sort \"\"\" def bubble_sort(items): for i in range(len(items)): for j in range(len(items) - 1 - i): if items[j] > items[j + 1]: items[j], items[j + 1] = items[j + 1], items[j] ``` Result: 1 2 3 4 5 6 \"\"\" Bubble sort \"\"\" def bubble_sort ( items ): for i in range ( len ( items )): for j in range ( len ( items ) - 1 - i ): if items [ j ] > items [ j + 1 ]: items [ j ], items [ j + 1 ] = items [ j + 1 ], items [ j ]","title":"Highlighting specific lines"},{"location":"extensions/codehilite/#supported-languages-excerpt","text":"CodeHilite uses Pygments , a generic syntax highlighter with support for over 300 languages , so the following list of examples is just an excerpt.","title":"Supported languages excerpt"},{"location":"extensions/codehilite/#bash","text":"#!/bin/bash for OPT in \" $@ \" do case \" $OPT \" in '-f' ) canonicalize = 1 ;; '-n' ) switchlf = \"-n\" ;; esac done # readlink -f function __readlink_f { target = \" $1 \" while test -n \" $target \" ; do filepath = \" $target \" cd ` dirname \" $filepath \" ` target = ` readlink \" $filepath \" ` done /bin/echo $switchlf ` pwd -P ` / ` basename \" $filepath \" ` } if [ ! \" $canonicalize \" ] ; then readlink $switchlf \" $@ \" else for file in \" $@ \" do case \" $file \" in -* ) ;; * ) __readlink_f \" $file \" ;; esac done fi exit $?","title":"Bash"},{"location":"extensions/codehilite/#c","text":"extern size_t pb_varint_scan ( const uint8_t data [], size_t left ) { assert ( data && left ); left = left > 10 ? 10 : left ; #ifdef __SSE2__ /* Mapping: remaining bytes ==> bitmask */ static const int mask_map [] = { 0x0000 , 0x0001 , 0x0003 , 0x0007 , 0x000F , 0x001F , 0x003F , 0x007F , 0x00FF , 0x01FF , 0x03FF }; /* Load buffer into 128-bit integer and create high-bit mask */ __m128i temp = _mm_loadu_si128 (( const __m128i * ) data ); __m128i high = _mm_set1_epi8 ( 0x80 ); /* Intersect and extract mask with high-bits set */ int mask = _mm_movemask_epi8 ( _mm_and_si128 ( temp , high )); mask = ( mask & mask_map [ left ]) ^ mask_map [ left ]; /* Count trailing zeroes */ return mask ? __builtin_ctz ( mask ) + 1 : 0 ; #else /* Linear scan */ size_t size = 0 ; while ( data [ size ++ ] & 0x80 ) if ( !-- left ) return 0 ; return size ; #endif /* __SSE2__ */ }","title":"C"},{"location":"extensions/codehilite/#c_1","text":"Extension :: Extension ( const Descriptor * descriptor , const Descriptor * scope ) : descriptor_ ( descriptor ), scope_ ( scope ) { /* Extract full name for signature */ variables_ [ \"signature\" ] = descriptor_ -> full_name (); /* Prepare message symbol */ variables_ [ \"message\" ] = StringReplace ( variables_ [ \"signature\" ], \".\" , \"_\" , true ); LowerString ( & ( variables_ [ \"message\" ])); /* Suffix scope to identifiers, if given */ string suffix ( \"\" ); if ( scope_ ) { suffix = scope_ -> full_name (); /* Check if the base and extension types are in the same package */ if ( ! scope_ -> file () -> package (). compare ( descriptor_ -> file () -> package ())) suffix = StripPrefixString ( suffix , scope_ -> file () -> package () + \".\" ); /* Append to signature */ variables_ [ \"signature\" ] += \".[\" + suffix + \"]\" ; suffix = \"_\" + suffix ; } /* Prepare extension symbol */ variables_ [ \"extension\" ] = StringReplace ( suffix , \".\" , \"_\" , true ); LowerString ( & ( variables_ [ \"extension\" ])); }","title":"C++"},{"location":"extensions/codehilite/#c_2","text":"public static void Send ( Socket socket , byte [] buffer , int offset , int size , int timeout ) { int startTickCount = Environment . TickCount ; int sent = 0 ; do { if ( Environment . TickCount > startTickCount + timeout ) throw new Exception ( \"Timeout.\" ); try { sent += socket . Send ( buffer , offset + sent , size - sent , SocketFlags . None ); } catch ( SocketException ex ) { if ( ex . SocketErrorCode == SocketError . WouldBlock || ex . SocketErrorCode == SocketError . IOPending || ex . SocketErrorCode == SocketError . NoBufferSpaceAvailable ) { /* Socket buffer is probably full, wait and try again */ Thread . Sleep ( 30 ); } else { throw ex ; } } } while ( sent < size ); }","title":"C&#35;"},{"location":"extensions/codehilite/#clojure","text":"( clojure-version ) ( defn partition-when [ f ] ( fn [ rf ] ( let [ a ( java.util.ArrayList. ) fval ( volatile! false )] ( fn ([] ( rf )) ([ result ] ( let [ result ( if ( .isEmpty a ) result ( let [ v ( vec ( .toArray a ))] ;; Clear first ( .clear a ) ( unreduced ( rf result v ))))] ( rf result ))) ([ result input ] ( if-not ( and ( f input ) @ fval ) ( do ( vreset! fval true ) ( .add a input ) result ) ( let [ v ( vec ( .toArray a ))] ( .clear a ) ( let [ ret ( rf result v )] ( when-not ( reduced? ret ) ( .add a input )) ret )))))))) ( into [] ( partition-when # ( .startsWith % \">>\" )) [ \"1d\" \"33\" \">> 1\" \">> 2\" \"22\" \">> 3\" ])","title":"Clojure"},{"location":"extensions/codehilite/#diff","text":"Index: grunt.js =================================================================== --- grunt.js (revision 31200) +++ grunt.js (working copy) @@ -12,6 +12,7 @@ module.exports = function (grunt) { + console.log('hello world'); // Project configuration. grunt.initConfig({ lint: { @@ -19,10 +20,6 @@ 'packages/services.web/{!(test)/**/,}*.js', 'packages/error/**/*.js' ], - scripts: [ - 'grunt.js', - 'db/**/*.js' - ], browser: [ 'packages/web/server.js', 'packages/web/server/**/*.js',","title":"Diff"},{"location":"extensions/codehilite/#docker","text":"FROM ubuntu # Install vnc, xvfb in order to create a 'fake' display and firefox RUN apt-get update && apt-get install -y x11vnc xvfb firefox RUN mkdir ~/.vnc # Setup a password RUN x11vnc -storepasswd 1234 ~/.vnc/passwd # Autostart firefox (might not be the best way, but it does the trick) RUN bash -c 'echo \"firefox\" >> /.bashrc' EXPOSE 5900 CMD [ \"x11vnc\" , \"-forever\" , \"-usepw\" , \"-create\" ]","title":"Docker"},{"location":"extensions/codehilite/#elixir","text":"require Logger def accept ( port ) do { :ok , socket } = :gen_tcp . listen ( port , [ :binary , packet : :line , active : false , reuseaddr : true ]) Logger . info \"Accepting connections on port #{ port } \" loop_acceptor ( socket ) end defp loop_acceptor ( socket ) do { :ok , client } = :gen_tcp . accept ( socket ) serve ( client ) loop_acceptor ( socket ) end defp serve ( socket ) do socket |> read_line () |> write_line ( socket ) serve ( socket ) end defp read_line ( socket ) do { :ok , data } = :gen_tcp . recv ( socket , 0 ) data end defp write_line ( line , socket ) do :gen_tcp . send ( socket , line ) end","title":"Elixir"},{"location":"extensions/codehilite/#erlang","text":"circular ( Defs ) -> [ { { Type , Base }, Fields } || { { Type , Base }, Fields } <- Defs , Type == msg , circular ( Base , Defs ) ]. circular ( Base , Defs ) -> Fields = proplists : get_value ({ msg , Base }, Defs ), circular ( Defs , Fields , [ Base ]). circular (_ Defs , [], _ Path ) -> false ; circular ( Defs , [ Field | Fields ], Path ) -> case Field #field.type of { msg , Type } -> case lists : member ( Type , Path ) of false -> Children = proplists : get_value ({ msg , Type }, Defs ), case circular ( Defs , Children , [ Type | Path ]) of false -> circular ( Defs , Fields , Path ); true -> true end ; true -> Type == lists : last ( Path ) andalso ( length ( Path ) == 1 orelse not is_tree ( Path )) end ; _ -> circular ( Defs , Fields , Path ) end .","title":"Erlang"},{"location":"extensions/codehilite/#f","text":"/// Asynchronously download retangles from the server /// and decode the JSON format to F# Rectangle record let [< Js >] getRectangles () : Async < Rectangle [] > = async { let req = XMLHttpRequest () req . Open ( \"POST\" , \"/get\" , true ) let! resp = req . AsyncSend () return JSON . parse ( resp ) } /// Repeatedly update rectangles after 0.5 sec let [< Js >] updateLoop () = async { while true do do ! Async . Sleep ( 500 ) let! rects = getRectangles () cleanRectangles () rects |> Array . iter createRectangle }","title":"F&#35;"},{"location":"extensions/codehilite/#go","text":"package main import \"fmt\" func counter ( id int , channel chan int , closer bool ) { for i := 0 ; i < 10000000 ; i ++ { fmt . Println ( \"process\" , id , \" send\" , i ) channel <- 1 } if closer { close ( channel ) } } func main () { channel := make ( chan int ) go counter ( 1 , channel , false ) go counter ( 2 , channel , true ) x := 0 // receiving data from channel for i := range channel { fmt . Println ( \"receiving\" ) x += i } fmt . Println ( x ) }","title":"Go"},{"location":"extensions/codehilite/#html","text":"<!doctype html> < html class = \"no-js\" lang = \"\" > < head > < meta charset = \"utf-8\" > < meta http-equiv = \"x-ua-compatible\" content = \"ie=edge\" > < title > HTML5 Boilerplate </ title > < meta name = \"description\" content = \"\" > < meta name = \"viewport\" content = \"width=device-width, initial-scale=1\" > < link rel = \"apple-touch-icon\" href = \"apple-touch-icon.png\" > < link rel = \"stylesheet\" href = \"css/normalize.css\" > < link rel = \"stylesheet\" href = \"css/main.css\" > < script src = \"js/vendor/modernizr-2.8.3.min.js\" ></ script > </ head > < body > < p > Hello world! This is HTML5 Boilerplate. </ p > </ body > </ html >","title":"HTML"},{"location":"extensions/codehilite/#java","text":"import java.util.LinkedList ; import java.lang.reflect.Array ; public class UnsortedHashSet < E > { private static final double LOAD_FACTOR_LIMIT = 0.7 ; private int size ; private LinkedList < E >[] con ; public UnsortedHashSet () { con = ( LinkedList < E >[] )( new LinkedList [ 10 ] ); } public boolean add ( E obj ) { int oldSize = size ; int index = Math . abs ( obj . hashCode ()) % con . length ; if ( con [ index ] == null ) con [ index ] = new LinkedList < E > (); if ( ! con [ index ] . contains ( obj )) { con [ index ] . add ( obj ); size ++ ; } if ( 1.0 * size / con . length > LOAD_FACTOR_LIMIT ) resize (); return oldSize != size ; } private void resize () { UnsortedHashSet < E > temp = new UnsortedHashSet < E > (); temp . con = ( LinkedList < E >[] )( new LinkedList [ con . length * 2 + 1 ] ); for ( int i = 0 ; i < con . length ; i ++ ) { if ( con [ i ] != null ) for ( E e : con [ i ] ) temp . add ( e ); } con = temp . con ; } public int size () { return size ; } }","title":"Java"},{"location":"extensions/codehilite/#javascript","text":"var Math = require ( 'lib/math' ); var _extends = function ( target ) { for ( var i = 1 ; i < arguments . length ; i ++ ) { var source = arguments [ i ]; for ( var key in source ) { target [ key ] = source [ key ]; } } return target ; }; var e = exports . e = 2.71828182846 ; exports [ 'default' ] = function ( x ) { return Math . exp ( x ); }; module . exports = _extends ( exports [ 'default' ], exports );","title":"JavaScript"},{"location":"extensions/codehilite/#json","text":"{ \"name\" : \"mkdocs-material\" , \"version\" : \"0.2.4\" , \"description\" : \"A Material Design theme for MkDocs\" , \"homepage\" : \"http://squidfunk.github.io/mkdocs-material/\" , \"authors\" : [ \"squidfunk <martin.donath@squidfunk.com>\" ], \"license\" : \"MIT\" , \"main\" : \"Gulpfile.js\" , \"scripts\" : { \"start\" : \"./node_modules/.bin/gulp watch --mkdocs\" , \"build\" : \"./node_modules/.bin/gulp build --production\" } ... }","title":"JSON"},{"location":"extensions/codehilite/#julia","text":"using MXNet mlp = @mx . chain mx . Variable ( : data ) => mx . FullyConnected ( name =: fc1 , num_hidden = 128 ) => mx . Activation ( name =: relu1 , act_type =: relu ) => mx . FullyConnected ( name =: fc2 , num_hidden = 64 ) => mx . Activation ( name =: relu2 , act_type =: relu ) => mx . FullyConnected ( name =: fc3 , num_hidden = 10 ) => mx . SoftmaxOutput ( name =: softmax ) # data provider batch_size = 100 include ( Pkg . dir ( \"MXNet\" , \"examples\" , \"mnist\" , \"mnist-data.jl\" )) train_provider , eval_provider = get_mnist_providers ( batch_size ) # setup model model = mx . FeedForward ( mlp , context = mx . cpu ()) # optimization algorithm optimizer = mx . SGD ( lr = 0.1 , momentum = 0.9 ) # fit parameters mx . fit ( model , optimizer , train_provider , n_epoch = 20 , eval_data = eval_provider )","title":"Julia"},{"location":"extensions/codehilite/#lua","text":"local ffi = require ( \"ffi\" ) ffi . cdef [[ void Sleep(int ms); int poll(struct pollfd *fds, unsigned long nfds, int timeout); ]] local sleep if ffi . os == \"Windows\" then function sleep ( s ) ffi . C . Sleep ( s * 1000 ) end else function sleep ( s ) ffi . C . poll ( nil , 0 , s * 1000 ) end end for i = 1 , 160 do io.write ( \".\" ); io.flush () sleep ( 0.01 ) end io.write ( \" \\n \" )","title":"Lua"},{"location":"extensions/codehilite/#mysql","text":"SELECT Employees . EmployeeID , Employees . Name , Employees . Salary , Manager . Name AS Manager FROM Employees LEFT JOIN Employees AS Manager ON Employees . ManagerID = Manager . EmployeeID WHERE Employees . EmployeeID = '087652' ;","title":"MySQL"},{"location":"extensions/codehilite/#php","text":"<?php // src/AppBundle/Controller/LuckyController.php namespace AppBundle\\Controller ; use Sensio\\Bundle\\FrameworkExtraBundle\\Configuration\\Route ; use Symfony\\Component\\HttpFoundation\\Response ; class LuckyController { /** * @Route(\"/lucky/number\") */ public function numberAction () { $number = mt_rand ( 0 , 100 ); return new Response ( '<html><body>Lucky number: ' . $number . '</body></html>' ); } }","title":"PHP"},{"location":"extensions/codehilite/#protocol-buffers","text":"syntax = \"proto2\" ; package caffe ; // Specifies the shape (dimensions) of a Blob. message BlobShape { repeated int64 dim = 1 [ packed = true ]; } message BlobProto { optional BlobShape shape = 7 ; repeated float data = 5 [ packed = true ]; repeated float diff = 6 [ packed = true ]; // 4D dimensions -- deprecated. Use \"shape\" instead. optional int32 num = 1 [ default = 0 ]; optional int32 channels = 2 [ default = 0 ]; optional int32 height = 3 [ default = 0 ]; optional int32 width = 4 [ default = 0 ]; }","title":"Protocol Buffers"},{"location":"extensions/codehilite/#python","text":"\"\"\" A very simple MNIST classifier. See extensive documentation at http://tensorflow.org/tutorials/mnist/beginners/index.md \"\"\" from __future__ import absolute_import from __future__ import division from __future__ import print_function # Import data from tensorflow.examples.tutorials.mnist import input_data import tensorflow as tf flags = tf . app . flags FLAGS = flags . FLAGS flags . DEFINE_string ( 'data_dir' , '/tmp/data/' , 'Directory for storing data' ) mnist = input_data . read_data_sets ( FLAGS . data_dir , one_hot = True ) sess = tf . InteractiveSession () # Create the model x = tf . placeholder ( tf . float32 , [ None , 784 ]) W = tf . Variable ( tf . zeros ([ 784 , 10 ])) b = tf . Variable ( tf . zeros ([ 10 ])) y = tf . nn . softmax ( tf . matmul ( x , W ) + b )","title":"Python"},{"location":"extensions/codehilite/#ruby","text":"require 'finity/event' require 'finity/machine' require 'finity/state' require 'finity/transition' require 'finity/version' module Finity class InvalidCallback < StandardError ; end class MissingCallback < StandardError ; end class InvalidState < StandardError ; end # Class methods to be injected into the including class upon inclusion. module ClassMethods # Instantiate a new state machine for the including class by accepting a # block with state and event (and subsequent transition) definitions. def finity options = {}, & block @finity ||= Machine . new self , options , & block end # Return the names of all registered states. def states @finity . states . map { | name , _ | name } end # Return the names of all registered events. def events @finity . events . map { | name , _ | name } end end # Inject methods into the including class upon inclusion. def self . included base base . extend ClassMethods end end","title":"Ruby"},{"location":"extensions/codehilite/#scala","text":"// Every record of this DataFrame contains the label and // features represented by a vector. val df = sqlContext . createDataFrame ( data ). toDF ( \"label\" , \"features\" ) // Set parameters for the algorithm. // Here, we limit the number of iterations to 10. val lr = new LogisticRegression (). setMaxIter ( 10 ) // Fit the model to the data. val model = lr . fit ( df ) // Inspect the model: get the feature weights. val weights = model . weights // Given a dataset, predict each point's label, and show the results. model . transform ( df ). show () g","title":"Scala"},{"location":"extensions/codehilite/#xml","text":"<?xml version=\"1.0\" encoding=\"UTF-8\"?> <!DOCTYPE mainTag SYSTEM \"some.dtd\" [ENTITY % entity]> <?oxygen RNGSchema=\"some.rng\" type=\"xml\"?> <xs:main-Tag xmlns:xs= \"http://www.w3.org/2001/XMLSchema\" > <!-- This is a sample comment --> <childTag attribute= \"Quoted Value\" another-attribute= 'Single quoted value' a-third-attribute= '123' > <withTextContent> Some text content </withTextContent> <withEntityContent> Some text content with &lt; entities &gt; and mentioning uint8_t and int32_t </withEntityContent> <otherTag attribute= 'Single quoted Value' /> </childTag> <![CDATA[ some CData ]]> </main-Tag>","title":"XML"},{"location":"extensions/footnotes/","text":"Footnotes \u00b6 Footnotes is another extension included in the standard Markdown library. As the name says, it adds the ability to add footnotes to your documentation. Installation \u00b6 Add the following lines to your mkdocs.yml : markdown_extensions : - footnotes Usage \u00b6 The markup for footnotes is similar to the standard Markdown markup for links. A reference is inserted in the text, which can then be defined at any point in the document. Inserting the reference \u00b6 The footnote reference is enclosed in square brackets and starts with a caret, followed by an arbitrary label which may contain numeric identifiers [1, 2, 3, ...] or names [Granovetter et al. 1998]. The rendered references are always consecutive superscripted numbers. Example: Lorem ipsum[^1] dolor sit amet, consectetur adipiscing elit.[^2] Result: Lorem ipsum 1 dolor sit amet, consectetur adipiscing elit. 2 Inserting the content \u00b6 The footnote content is also declared with a label, which must match the label used for the footnote reference. It can be inserted at an arbitrary position in the document and is always rendered at the bottom of the page. Furthermore, a backlink is automatically added to the footnote reference. on a single line \u00b6 Short statements can be written on the same line. Example: [^1]: Lorem ipsum dolor sit amet, consectetur adipiscing elit. Result: Jump to footnote at the bottom of the page on multiple lines \u00b6 Paragraphs should be written on the next line. As with all Markdown blocks, the content must be indented by four spaces. Example: [^2]: Lorem ipsum dolor sit amet, consectetur adipiscing elit. Nulla et euismod nulla. Curabitur feugiat, tortor non consequat finibus, justo purus auctor massa, nec semper lorem quam in massa. Result: Jump to footnote at the bottom of the page Lorem ipsum dolor sit amet, consectetur adipiscing elit. \u21a9 Lorem ipsum dolor sit amet, consectetur adipiscing elit. Nulla et euismod nulla. Curabitur feugiat, tortor non consequat finibus, justo purus auctor massa, nec semper lorem quam in massa. \u21a9","title":"Footnotes"},{"location":"extensions/footnotes/#footnotes","text":"Footnotes is another extension included in the standard Markdown library. As the name says, it adds the ability to add footnotes to your documentation.","title":"Footnotes"},{"location":"extensions/footnotes/#installation","text":"Add the following lines to your mkdocs.yml : markdown_extensions : - footnotes","title":"Installation"},{"location":"extensions/footnotes/#usage","text":"The markup for footnotes is similar to the standard Markdown markup for links. A reference is inserted in the text, which can then be defined at any point in the document.","title":"Usage"},{"location":"extensions/footnotes/#inserting-the-reference","text":"The footnote reference is enclosed in square brackets and starts with a caret, followed by an arbitrary label which may contain numeric identifiers [1, 2, 3, ...] or names [Granovetter et al. 1998]. The rendered references are always consecutive superscripted numbers. Example: Lorem ipsum[^1] dolor sit amet, consectetur adipiscing elit.[^2] Result: Lorem ipsum 1 dolor sit amet, consectetur adipiscing elit. 2","title":"Inserting the reference"},{"location":"extensions/footnotes/#inserting-the-content","text":"The footnote content is also declared with a label, which must match the label used for the footnote reference. It can be inserted at an arbitrary position in the document and is always rendered at the bottom of the page. Furthermore, a backlink is automatically added to the footnote reference.","title":"Inserting the content"},{"location":"extensions/footnotes/#on-a-single-line","text":"Short statements can be written on the same line. Example: [^1]: Lorem ipsum dolor sit amet, consectetur adipiscing elit. Result: Jump to footnote at the bottom of the page","title":"on a single line"},{"location":"extensions/footnotes/#on-multiple-lines","text":"Paragraphs should be written on the next line. As with all Markdown blocks, the content must be indented by four spaces. Example: [^2]: Lorem ipsum dolor sit amet, consectetur adipiscing elit. Nulla et euismod nulla. Curabitur feugiat, tortor non consequat finibus, justo purus auctor massa, nec semper lorem quam in massa. Result: Jump to footnote at the bottom of the page Lorem ipsum dolor sit amet, consectetur adipiscing elit. \u21a9 Lorem ipsum dolor sit amet, consectetur adipiscing elit. Nulla et euismod nulla. Curabitur feugiat, tortor non consequat finibus, justo purus auctor massa, nec semper lorem quam in massa. \u21a9","title":"on multiple lines"},{"location":"extensions/metadata/","text":"Metadata \u00b6 The Metadata extension makes it possible to add metadata to a document which gives more control over the theme in a page-specific context. Installation \u00b6 Add the following lines to your mkdocs.yml : markdown_extensions : - meta Usage \u00b6 Metadata is written as a series of key-value pairs at the beginning of the Markdown document, delimited by a blank line which ends the metadata context. Naturally, the metadata is stripped from the document before rendering the actual page content and made available to the theme. Example: title: Lorem ipsum dolor sit amet description: Nullam urna elit, malesuada eget finibus ut, ac tortor. path: path/to/file source: file.js # Headline ... See the next section which covers the metadata that is supported by Material. Setting a hero text \u00b6 Material exposes a simple text-only page-local hero via Metadata, as you can see on the current page when you scroll to the top. It's as simple as: hero: Metadata enables hero teaser texts Linking sources \u00b6 When a document is related to a specific set of source files and the repo_url is defined inside the project's mkdocs.yml , the files can be linked using the source key: source: file.js The filename is appended to the repo_url set in your mkdocs.yml , but can be prefixed with a path to ensure correct path resolving: Example: path: tree/master/docs/extensions source: metadata.md Result: See the source section for the resulting output. Redirecting to another page \u00b6 It's sometimes necessary to move documents around in the navigation tree and redirect user from the old URL to the new one. The redirect meta-tag allows to create a redirection from the current document to the address specified in the tag. For instance, if your document contains: redirect: /new/url accessing that document's URL will automatically redirect to /new/url . Overrides \u00b6 Page title \u00b6 The page title can be overridden on a per-document level: title: Lorem ipsum dolor sit amet This will set the title tag inside the document head for the current page to the provided value. It will also override the default behavior of Material for MkDocs which appends the site title using a dash as a separator to the page title. Page description \u00b6 The page description can also be overridden on a per-document level: description : Nullam urna elit, malesuada eget finibus ut, ac tortor. This will set the meta tag containing the site description inside the document head for the current page to the provided value. Disqus \u00b6 As described in the getting started guide , the Disqus comments section can be enabled on a per-document level: disqus: your-shortname Disqus can be disabled for a specific page by setting it to an empty value: disqus:","title":"Metadata"},{"location":"extensions/metadata/#metadata","text":"The Metadata extension makes it possible to add metadata to a document which gives more control over the theme in a page-specific context.","title":"Metadata"},{"location":"extensions/metadata/#installation","text":"Add the following lines to your mkdocs.yml : markdown_extensions : - meta","title":"Installation"},{"location":"extensions/metadata/#usage","text":"Metadata is written as a series of key-value pairs at the beginning of the Markdown document, delimited by a blank line which ends the metadata context. Naturally, the metadata is stripped from the document before rendering the actual page content and made available to the theme. Example: title: Lorem ipsum dolor sit amet description: Nullam urna elit, malesuada eget finibus ut, ac tortor. path: path/to/file source: file.js # Headline ... See the next section which covers the metadata that is supported by Material.","title":"Usage"},{"location":"extensions/metadata/#setting-a-hero-text","text":"Material exposes a simple text-only page-local hero via Metadata, as you can see on the current page when you scroll to the top. It's as simple as: hero: Metadata enables hero teaser texts","title":"Setting a hero text"},{"location":"extensions/metadata/#linking-sources","text":"When a document is related to a specific set of source files and the repo_url is defined inside the project's mkdocs.yml , the files can be linked using the source key: source: file.js The filename is appended to the repo_url set in your mkdocs.yml , but can be prefixed with a path to ensure correct path resolving: Example: path: tree/master/docs/extensions source: metadata.md Result: See the source section for the resulting output.","title":"Linking sources"},{"location":"extensions/metadata/#redirecting-to-another-page","text":"It's sometimes necessary to move documents around in the navigation tree and redirect user from the old URL to the new one. The redirect meta-tag allows to create a redirection from the current document to the address specified in the tag. For instance, if your document contains: redirect: /new/url accessing that document's URL will automatically redirect to /new/url .","title":"Redirecting to another page"},{"location":"extensions/metadata/#overrides","text":"","title":"Overrides"},{"location":"extensions/metadata/#page-title","text":"The page title can be overridden on a per-document level: title: Lorem ipsum dolor sit amet This will set the title tag inside the document head for the current page to the provided value. It will also override the default behavior of Material for MkDocs which appends the site title using a dash as a separator to the page title.","title":"Page title"},{"location":"extensions/metadata/#page-description","text":"The page description can also be overridden on a per-document level: description : Nullam urna elit, malesuada eget finibus ut, ac tortor. This will set the meta tag containing the site description inside the document head for the current page to the provided value.","title":"Page description"},{"location":"extensions/metadata/#disqus","text":"As described in the getting started guide , the Disqus comments section can be enabled on a per-document level: disqus: your-shortname Disqus can be disabled for a specific page by setting it to an empty value: disqus:","title":"Disqus"},{"location":"extensions/permalinks/","text":"Permalinks \u00b6 Permalinks are a feature of the Table of Contents extension, which is part of the standard Markdown library. The extension inserts an anchor at the end of each headline, which makes it possible to directly link to a subpart of the document. Installation \u00b6 To enable permalinks, add the following to your mkdocs.yml : markdown_extensions : - toc : permalink : true This will add a link containing the paragraph symbol \u00b6 at the end of each headline (exactly like on the page you're currently viewing), which the Material theme will make appear on hover. In order to change the text of the permalink, a string can be passed, e.g.: markdown_extensions: - toc: permalink: Link Usage \u00b6 When enabled, permalinks are inserted automatically.","title":"Permalinks"},{"location":"extensions/permalinks/#permalinks","text":"Permalinks are a feature of the Table of Contents extension, which is part of the standard Markdown library. The extension inserts an anchor at the end of each headline, which makes it possible to directly link to a subpart of the document.","title":"Permalinks"},{"location":"extensions/permalinks/#installation","text":"To enable permalinks, add the following to your mkdocs.yml : markdown_extensions : - toc : permalink : true This will add a link containing the paragraph symbol \u00b6 at the end of each headline (exactly like on the page you're currently viewing), which the Material theme will make appear on hover. In order to change the text of the permalink, a string can be passed, e.g.: markdown_extensions: - toc: permalink: Link","title":"Installation"},{"location":"extensions/permalinks/#usage","text":"When enabled, permalinks are inserted automatically.","title":"Usage"},{"location":"extensions/pymdown/","text":"PyMdown Extensions \u00b6 PyMdown Extensions is a collection of Markdown extensions that add some great features to the standard Markdown library. For this reason, the installation of this package is highly recommended as it's well-integrated with the Material theme. Installation \u00b6 The PyMdown Extensions package can be installed with the following command: pip install pymdown-extensions The following list of extensions that are part of the PyMdown Extensions package are recommended to be used together with the Material theme: markdown_extensions : - pymdownx.arithmatex - pymdownx.betterem : smart_enable : all - pymdownx.caret - pymdownx.critic - pymdownx.details - pymdownx.emoji : emoji_generator : !!python/name:pymdownx.emoji.to_svg - pymdownx.inlinehilite - pymdownx.magiclink - pymdownx.mark - pymdownx.smartsymbols - pymdownx.superfences - pymdownx.tasklist : custom_checkbox : true - pymdownx.tilde Usage \u00b6 Arithmatex MathJax \u00b6 Arithmatex integrates Material with MathJax which parses block-style and inline equations written in TeX markup and outputs them in mathematical notation. See this thread for a short introduction and quick reference on how to write equations in TeX syntax. Besides activating the extension in the mkdocs.yml , the MathJax JavaScript runtime needs to be included. This must be done with additional JavaScript : extra_javascript : - 'https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.0/MathJax.js?config=TeX-MML-AM_CHTML' If you want to override the default MathJax configuration, you can do this by adding another JavaScript file before the MathJax runtime in extra_javascript which contains your MathJax configuration, e.g.: window . MathJax = { tex2jax : { inlineMath : [ [ \"\\\\(\" , \"\\\\)\" ] ], displayMath : [ [ \"\\\\[\" , \"\\\\]\" ] ] }, TeX : { TagSide : \"right\" , TagIndent : \".8em\" , MultLineWidth : \"85%\" , equationNumbers : { autoNumber : \"AMS\" , }, unicode : { fonts : \"STIXGeneral,'Arial Unicode MS'\" } }, displayAlign : \"left\" , showProcessingMessages : false , messageStyle : \"none\" }; In your mkdocs.yml , include it with: extra_javascript : - 'javascripts/extra.js' - 'https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.0/MathJax.js?config=TeX-MML-AM_CHTML' Blocks \u00b6 Blocks are enclosed in $$ ... $$ which are placed on separate lines. Example: $$ \\frac {n ! }{k !( n - k )! } = \\binom {n}{k} $$ Result: \\frac{n!}{k!(n-k)!} = \\binom{n}{k} \\frac{n!}{k!(n-k)!} = \\binom{n}{k} Inline \u00b6 Inline equations need to be enclosed in $ ... $ : Example: Lorem ipsum dolor sit amet: $ p ( x|y ) = \\frac {p ( y|x ) p ( x ) }{p ( y ) } $ Result: Lorem ipsum dolor sit amet: p(x|y) = \\frac{p(y|x)p(x)}{p(y)} p(x|y) = \\frac{p(y|x)p(x)}{p(y)} BetterEm \u00b6 BetterEm improves the handling of emphasis markup ( bold and italic ) within Markdown by providing a more sophisticated parser for better detecting start and end tokens. Read the documentation for usage notes . Caret \u00b6 Caret makes it possible to highlight inserted text . The portion of text that should be marked as added must be enclosed in two carets ^^...^^ . Critic \u00b6 Critic implements Critic Markup , a Markdown extension that enables the tracking of changes (additions, deletions and comments) on documents. During compilation of the Markdown document, changes can be rendered (default), accepted or rejected. Text can be deleted and replacement text added . This can also be combined into one a single operation. Highlighting is also possible and comments can be added inline . Formatting can also be applied to blocks, by putting the opening and closing tags on separate lines and adding new lines between the tags and the content. Details \u00b6 Details adds collapsible Admonition-style blocks which can contain arbitrary content using the HTML5 details and summary tags. Additionally, all Admonition qualifiers can be used, e.g. note , question , warning etc.: How many Prolog programmers does it take to change a lightbulb? Yes. Emoji \u00b6 Emoji adds the ability to insert a -load of emojis that we use in our daily lives. By default, Emoji uses JoyPixles' emoji under the former name EmojiOne. Recent versions of the extension lock support to an older version (2.2.7) due to JoyPixels' newer, less permissible licenses included in later releases. This restricts support to Unicode 9. To get the latest support for the current Unicode version, you can use Twemoji instead which has a much more permissable license. Simply override the default emoji index being used: markdown_extensions: - pymdownx.emoji: emoji_index: !!python/name:pymdownx.emoji.twemoji emoji_generator: !!python/name:pymdownx.emoji.to_svg To view all the available short names and emoji available, see Emoji's documentation on your chosen index which includes links to the files containing the short names and emoji associated with each supported index. Happy scrolling . Legal disclaimer Material has no affiliation with JoyPixles or Twemoji , both of which use releases that are under CC BY 4.0 . When including images or CSS from either provider, please read the the respective licenses: EmojiOne or Twemoji to ensure proper usage and attribution. InlineHilite \u00b6 InlineHilite adds support for inline code highlighting. It's useful for short snippets included within body copy, e.g. var test = 0 ; and can be achieved by prefixing inline code with a shebang and language identifier, e.g. #!js . MagicLink \u00b6 MagicLink detects links in Markdown and auto-generates the necessary markup, so no special syntax is required. It auto-links http[s]:// and ftp:// links, as well as references to email addresses. Mark \u00b6 Mark adds the ability to highlight text like it was marked with a text marker . The portion of text that should be highlighted must be enclosed in two equal signs ==...== . SmartSymbols \u00b6 SmartSymbols converts markup for special characters into their corresponding symbols, e.g. arrows (\u2190, \u2192, \u2194), trademark and copyright symbols (\u00a9, \u2122, \u00ae) and fractions (\u00bd, \u00bc, ...). SuperFences \u00b6 SuperFences provides the ability to nest code blocks under blockquotes, lists and other block elements, which the Fenced Code Blocks extension from the standard Markdown library doesn't parse correctly. SuperFences does also allow grouping code blocks with tabs . Tasklist \u00b6 Tasklist adds support for styled checkbox lists. This is useful for keeping track of tasks and showing what has been done and has yet to be done. Checkbox lists are like regular lists, but prefixed with [ ] for empty or [x] for filled checkboxes. Example: * [x] Lorem ipsum dolor sit amet, consectetur adipiscing elit * [x] Nulla lobortis egestas semper * [x] Curabitur elit nibh, euismod et ullamcorper at, iaculis feugiat est * [ ] Vestibulum convallis sit amet nisi a tincidunt * [x] In hac habitasse platea dictumst * [x] In scelerisque nibh non dolor mollis congue sed et metus * [x] Sed egestas felis quis elit dapibus, ac aliquet turpis mattis * [ ] Praesent sed risus massa * [ ] Aenean pretium efficitur erat, donec pharetra, ligula non scelerisque * [ ] Nulla vel eros venenatis, imperdiet enim id, faucibus nisi Result: Lorem ipsum dolor sit amet, consectetur adipiscing elit Nulla lobortis egestas semper Curabitur elit nibh, euismod et ullamcorper at, iaculis feugiat est Vestibulum convallis sit amet nisi a tincidunt In hac habitasse platea dictumst In scelerisque nibh non dolor mollis congue sed et metus Sed egestas felis quis elit dapibus, ac aliquet turpis mattis Praesent sed risus massa Aenean pretium efficitur erat, donec pharetra, ligula non scelerisque Nulla vel eros venenatis, imperdiet enim id, faucibus nisi Tilde \u00b6 Tilde provides an easy way to strike through cross out text. The portion of text that should be erased must be enclosed in two tildes ~~...~~ and the extension will take care of the rest.","title":"PyMdown"},{"location":"extensions/pymdown/#pymdown-extensions","text":"PyMdown Extensions is a collection of Markdown extensions that add some great features to the standard Markdown library. For this reason, the installation of this package is highly recommended as it's well-integrated with the Material theme.","title":"PyMdown Extensions"},{"location":"extensions/pymdown/#installation","text":"The PyMdown Extensions package can be installed with the following command: pip install pymdown-extensions The following list of extensions that are part of the PyMdown Extensions package are recommended to be used together with the Material theme: markdown_extensions : - pymdownx.arithmatex - pymdownx.betterem : smart_enable : all - pymdownx.caret - pymdownx.critic - pymdownx.details - pymdownx.emoji : emoji_generator : !!python/name:pymdownx.emoji.to_svg - pymdownx.inlinehilite - pymdownx.magiclink - pymdownx.mark - pymdownx.smartsymbols - pymdownx.superfences - pymdownx.tasklist : custom_checkbox : true - pymdownx.tilde","title":"Installation"},{"location":"extensions/pymdown/#usage","text":"","title":"Usage"},{"location":"extensions/pymdown/#arithmatex-mathjax","text":"Arithmatex integrates Material with MathJax which parses block-style and inline equations written in TeX markup and outputs them in mathematical notation. See this thread for a short introduction and quick reference on how to write equations in TeX syntax. Besides activating the extension in the mkdocs.yml , the MathJax JavaScript runtime needs to be included. This must be done with additional JavaScript : extra_javascript : - 'https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.0/MathJax.js?config=TeX-MML-AM_CHTML' If you want to override the default MathJax configuration, you can do this by adding another JavaScript file before the MathJax runtime in extra_javascript which contains your MathJax configuration, e.g.: window . MathJax = { tex2jax : { inlineMath : [ [ \"\\\\(\" , \"\\\\)\" ] ], displayMath : [ [ \"\\\\[\" , \"\\\\]\" ] ] }, TeX : { TagSide : \"right\" , TagIndent : \".8em\" , MultLineWidth : \"85%\" , equationNumbers : { autoNumber : \"AMS\" , }, unicode : { fonts : \"STIXGeneral,'Arial Unicode MS'\" } }, displayAlign : \"left\" , showProcessingMessages : false , messageStyle : \"none\" }; In your mkdocs.yml , include it with: extra_javascript : - 'javascripts/extra.js' - 'https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.0/MathJax.js?config=TeX-MML-AM_CHTML'","title":"Arithmatex MathJax"},{"location":"extensions/pymdown/#blocks","text":"Blocks are enclosed in $$ ... $$ which are placed on separate lines. Example: $$ \\frac {n ! }{k !( n - k )! } = \\binom {n}{k} $$ Result: \\frac{n!}{k!(n-k)!} = \\binom{n}{k} \\frac{n!}{k!(n-k)!} = \\binom{n}{k}","title":"Blocks"},{"location":"extensions/pymdown/#inline","text":"Inline equations need to be enclosed in $ ... $ : Example: Lorem ipsum dolor sit amet: $ p ( x|y ) = \\frac {p ( y|x ) p ( x ) }{p ( y ) } $ Result: Lorem ipsum dolor sit amet: p(x|y) = \\frac{p(y|x)p(x)}{p(y)} p(x|y) = \\frac{p(y|x)p(x)}{p(y)}","title":"Inline"},{"location":"extensions/pymdown/#betterem","text":"BetterEm improves the handling of emphasis markup ( bold and italic ) within Markdown by providing a more sophisticated parser for better detecting start and end tokens. Read the documentation for usage notes .","title":"BetterEm"},{"location":"extensions/pymdown/#caret","text":"Caret makes it possible to highlight inserted text . The portion of text that should be marked as added must be enclosed in two carets ^^...^^ .","title":"Caret"},{"location":"extensions/pymdown/#critic","text":"Critic implements Critic Markup , a Markdown extension that enables the tracking of changes (additions, deletions and comments) on documents. During compilation of the Markdown document, changes can be rendered (default), accepted or rejected. Text can be deleted and replacement text added . This can also be combined into one a single operation. Highlighting is also possible and comments can be added inline . Formatting can also be applied to blocks, by putting the opening and closing tags on separate lines and adding new lines between the tags and the content.","title":"Critic"},{"location":"extensions/pymdown/#details","text":"Details adds collapsible Admonition-style blocks which can contain arbitrary content using the HTML5 details and summary tags. Additionally, all Admonition qualifiers can be used, e.g. note , question , warning etc.: How many Prolog programmers does it take to change a lightbulb? Yes.","title":"Details"},{"location":"extensions/pymdown/#emoji","text":"Emoji adds the ability to insert a -load of emojis that we use in our daily lives. By default, Emoji uses JoyPixles' emoji under the former name EmojiOne. Recent versions of the extension lock support to an older version (2.2.7) due to JoyPixels' newer, less permissible licenses included in later releases. This restricts support to Unicode 9. To get the latest support for the current Unicode version, you can use Twemoji instead which has a much more permissable license. Simply override the default emoji index being used: markdown_extensions: - pymdownx.emoji: emoji_index: !!python/name:pymdownx.emoji.twemoji emoji_generator: !!python/name:pymdownx.emoji.to_svg To view all the available short names and emoji available, see Emoji's documentation on your chosen index which includes links to the files containing the short names and emoji associated with each supported index. Happy scrolling . Legal disclaimer Material has no affiliation with JoyPixles or Twemoji , both of which use releases that are under CC BY 4.0 . When including images or CSS from either provider, please read the the respective licenses: EmojiOne or Twemoji to ensure proper usage and attribution.","title":"Emoji"},{"location":"extensions/pymdown/#inlinehilite","text":"InlineHilite adds support for inline code highlighting. It's useful for short snippets included within body copy, e.g. var test = 0 ; and can be achieved by prefixing inline code with a shebang and language identifier, e.g. #!js .","title":"InlineHilite"},{"location":"extensions/pymdown/#magiclink","text":"MagicLink detects links in Markdown and auto-generates the necessary markup, so no special syntax is required. It auto-links http[s]:// and ftp:// links, as well as references to email addresses.","title":"MagicLink"},{"location":"extensions/pymdown/#mark","text":"Mark adds the ability to highlight text like it was marked with a text marker . The portion of text that should be highlighted must be enclosed in two equal signs ==...== .","title":"Mark"},{"location":"extensions/pymdown/#smartsymbols","text":"SmartSymbols converts markup for special characters into their corresponding symbols, e.g. arrows (\u2190, \u2192, \u2194), trademark and copyright symbols (\u00a9, \u2122, \u00ae) and fractions (\u00bd, \u00bc, ...).","title":"SmartSymbols"},{"location":"extensions/pymdown/#superfences","text":"SuperFences provides the ability to nest code blocks under blockquotes, lists and other block elements, which the Fenced Code Blocks extension from the standard Markdown library doesn't parse correctly. SuperFences does also allow grouping code blocks with tabs .","title":"SuperFences"},{"location":"extensions/pymdown/#tasklist","text":"Tasklist adds support for styled checkbox lists. This is useful for keeping track of tasks and showing what has been done and has yet to be done. Checkbox lists are like regular lists, but prefixed with [ ] for empty or [x] for filled checkboxes. Example: * [x] Lorem ipsum dolor sit amet, consectetur adipiscing elit * [x] Nulla lobortis egestas semper * [x] Curabitur elit nibh, euismod et ullamcorper at, iaculis feugiat est * [ ] Vestibulum convallis sit amet nisi a tincidunt * [x] In hac habitasse platea dictumst * [x] In scelerisque nibh non dolor mollis congue sed et metus * [x] Sed egestas felis quis elit dapibus, ac aliquet turpis mattis * [ ] Praesent sed risus massa * [ ] Aenean pretium efficitur erat, donec pharetra, ligula non scelerisque * [ ] Nulla vel eros venenatis, imperdiet enim id, faucibus nisi Result: Lorem ipsum dolor sit amet, consectetur adipiscing elit Nulla lobortis egestas semper Curabitur elit nibh, euismod et ullamcorper at, iaculis feugiat est Vestibulum convallis sit amet nisi a tincidunt In hac habitasse platea dictumst In scelerisque nibh non dolor mollis congue sed et metus Sed egestas felis quis elit dapibus, ac aliquet turpis mattis Praesent sed risus massa Aenean pretium efficitur erat, donec pharetra, ligula non scelerisque Nulla vel eros venenatis, imperdiet enim id, faucibus nisi","title":"Tasklist"},{"location":"extensions/pymdown/#tilde","text":"Tilde provides an easy way to strike through cross out text. The portion of text that should be erased must be enclosed in two tildes ~~...~~ and the extension will take care of the rest.","title":"Tilde"},{"location":"plugins/minify-html/","text":"Minify HTML \u00b6 mkdocs-minify-plugin is an extension that minifies HTML by stripping all whitespace from the generated documentation. Installation \u00b6 Install the plugin using pip with the following command: pip install mkdocs-minify-plugin Next, add the following lines to your mkdocs.yml : plugins : - search - minify : minify_html : true Remember to re-add the search plugin If you have no plugins entry in your config file yet, you'll likely also want to add the search plugin. MkDocs enables it by default if there is no plugins entry set. Usage \u00b6 The output is automatically minified by the plugin.","title":"Minify HTML"},{"location":"plugins/minify-html/#minify-html","text":"mkdocs-minify-plugin is an extension that minifies HTML by stripping all whitespace from the generated documentation.","title":"Minify HTML"},{"location":"plugins/minify-html/#installation","text":"Install the plugin using pip with the following command: pip install mkdocs-minify-plugin Next, add the following lines to your mkdocs.yml : plugins : - search - minify : minify_html : true Remember to re-add the search plugin If you have no plugins entry in your config file yet, you'll likely also want to add the search plugin. MkDocs enables it by default if there is no plugins entry set.","title":"Installation"},{"location":"plugins/minify-html/#usage","text":"The output is automatically minified by the plugin.","title":"Usage"},{"location":"plugins/revision-date/","text":"Revision date \u00b6 mkdocs-git-revision-date-localized-plugin is an extension that shows the date on which a Markdown file was last updated in Git at the bottom of each page. The date is extracted at the time of the build, so mkdocs build must be triggered from within a Git repository. Installation \u00b6 Install the plugin using pip with the following command: pip install mkdocs-git-revision-date-localized-plugin Next, add the following lines to your mkdocs.yml : plugins : - search - git-revision-date-localized Remember to re-add the search plugin If you have no plugins entry in your config file yet, you'll likely also want to add the search plugin. MkDocs enables it by default if there is no plugins entry set. Usage \u00b6 The date is automatically added at the bottom of each page, e.g.: Last updated: 9 December, 2019 Changing the language \u00b6 The date is printed according to the locale which is determined through the theme language that was set in mkdocs.yml . Changing the format \u00b6 To change the date format, set the type parameter to one of date , datetime , iso_date , iso_datetime or timeago , i.e.: 28 November, 2019 # type: date 28 November, 2019 13:57:28 # type: datetime 2019-11-28 # type: iso_date 2019-11-28 13:57:26 # type: iso_datetime 20 hours ago # type: timeago Example: plugins : - git-revision-date-localized : type : timeago Result: 20 hours ago","title":"Revision date"},{"location":"plugins/revision-date/#revision-date","text":"mkdocs-git-revision-date-localized-plugin is an extension that shows the date on which a Markdown file was last updated in Git at the bottom of each page. The date is extracted at the time of the build, so mkdocs build must be triggered from within a Git repository.","title":"Revision date"},{"location":"plugins/revision-date/#installation","text":"Install the plugin using pip with the following command: pip install mkdocs-git-revision-date-localized-plugin Next, add the following lines to your mkdocs.yml : plugins : - search - git-revision-date-localized Remember to re-add the search plugin If you have no plugins entry in your config file yet, you'll likely also want to add the search plugin. MkDocs enables it by default if there is no plugins entry set.","title":"Installation"},{"location":"plugins/revision-date/#usage","text":"The date is automatically added at the bottom of each page, e.g.: Last updated: 9 December, 2019","title":"Usage"},{"location":"plugins/revision-date/#changing-the-language","text":"The date is printed according to the locale which is determined through the theme language that was set in mkdocs.yml .","title":"Changing the language"},{"location":"plugins/revision-date/#changing-the-format","text":"To change the date format, set the type parameter to one of date , datetime , iso_date , iso_datetime or timeago , i.e.: 28 November, 2019 # type: date 28 November, 2019 13:57:28 # type: datetime 2019-11-28 # type: iso_date 2019-11-28 13:57:26 # type: iso_datetime 20 hours ago # type: timeago Example: plugins : - git-revision-date-localized : type : timeago Result: 20 hours ago","title":"Changing the format"},{"location":"plugins/search/","text":"Search \u00b6 MkDocs enables the search plugin by default if there is no plugins entry set in mkdocs.yml . If additional plugins are installed, the search plugin must be added to your mkdocs.yml . See Site search for more information about how to use search with Material. Installation \u00b6 Add the following lines to your mkdocs.yml : plugins : - search Remember to re-add the search plugin If you have no plugins entry in your config file yet, you'll likely also want to add the search plugin. MkDocs enables it by default if there is no plugins entry set.","title":"Search"},{"location":"plugins/search/#search","text":"MkDocs enables the search plugin by default if there is no plugins entry set in mkdocs.yml . If additional plugins are installed, the search plugin must be added to your mkdocs.yml . See Site search for more information about how to use search with Material.","title":"Search"},{"location":"plugins/search/#installation","text":"Add the following lines to your mkdocs.yml : plugins : - search Remember to re-add the search plugin If you have no plugins entry in your config file yet, you'll likely also want to add the search plugin. MkDocs enables it by default if there is no plugins entry set.","title":"Installation"}]}